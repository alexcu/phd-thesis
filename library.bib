Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Curumsing:2020semotion,
archivePrefix = {arXiv},
arxivId = {2004.03120},
author = {Curumsing, Maheswaree Kissoon and Cummaudo, Alex and Graetsch, Ulrike Maria and Barnett, Scott and Vasa, Rajesh},
eprint = {2004.03120},
journal = {arXiv preprint arXiv:2004.03120},
title = {{Ranking Computer Vision Service Issues using Emotion}},
url = {http://arxiv.org/abs/2004.03120},
year = {2020}
}
@inproceedings{LaForge:2018tm,
address = {London, England, UK},
author = {Laforge, Guillaume},
booktitle = {QCon},
month = {jun},
title = {{Machine Intelligence at Google Scale}},
url = {http://bit.ly/2S0xC1B},
year = {2018}
}
@article{Rosenfeld:2018ut,
archivePrefix = {arXiv},
arxivId = {1808.03305},
author = {Rosenfeld, Amir and Zemel, Richard and Tsotsos, John K},
eprint = {1808.03305},
journal = {arXiv preprint arXiv:1808.03305},
title = {{The Elephant in the Room}},
url = {https://arxiv.org/abs/1808.03305},
year = {2018}
}
@inproceedings{Eykholt:2018vk,
abstract = {Recent studies show that the state-of-the-art deep neural networks (DNNs) are vulnerable to adversarial examples, resulting from small-magnitude perturbations added to the input. Given that that emerging physical systems are using DNNs in safety-critical situations, adversarial examples could mislead these systems and cause dangerous situations. Therefore, understanding adversarial examples in the physical world is an important step towards developing resilient learning algorithms. We propose a general attack algorithm, Robust Physical Perturbations (RP2), to generate robust visual adversarial perturbations under different physical conditions. Using the real-world case of road sign classification, we show that adversarial examples generated using RP2 achieve high targeted misclassification rates against standard-architecture road sign classifiers in the physical world under various environmental conditions, including viewpoints. Due to the current lack of a standardized testing method, we propose a two-stage evaluation methodology for robust physical adversarial examples consisting of lab and field tests. Using this methodology, we evaluate the efficacy of physical adversarial manipulations on real objects. With a perturbation in the form of only black and white stickers, we attack a real stop sign, causing targeted misclassification in 100{\%} of the images obtained in lab settings, and in 84.8{\%} of the captured video frames obtained on a moving vehicle (field test) for the target classifier.},
address = {Honolulu, HI, USA},
author = {Eykholt, Kevin and Evtimov, Ivan and Fernandes, Earlence and Li, Bo and Rahmati, Amir and Xiao, Chaowei and Prakash, Atul and Kohno, Tadayoshi and Song, Dawn},
booktitle = {Proceedings of the 2017 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2018.00175},
isbn = {978-1-53-866420-9},
issn = {1063-6919},
month = {jul},
pages = {1625--1634},
title = {{Robust Physical-World Attacks on Deep Learning Visual Classification}},
year = {2018}
}
@book{Pressman:2005vf,
author = {Pressman, Roger S},
edition = {8th},
isbn = {978-0-07-802212-8},
publisher = {McGraw-Hill},
title = {{Software Engineering: A Practitioner's Approach}},
year = {2005}
}
@inproceedings{Sen:1995uk,
address = {Montreal, QC, Canada},
author = {Sen, Sandip and Knight, Leslie},
booktitle = {Proceedings of the International Joint Conference on Artificial Intelligence},
month = {aug},
pages = {725--733},
publisher = {Morgan Kaufmann},
title = {{A genetic prototype learner}},
year = {1995}
}
@inproceedings{Ross:2017vn,
abstract = {Neural networks are among the most accurate supervised learning methods in use today. However, their opacity makes them difficult to trust in critical applications, especially if conditions in training may differ from those in test. Recent work on explanations for black-box models has produced tools (e.g. LIME) to show the implicit rules behind predictions. These tools can help us identify when models are right for the wrong reasons. However, these methods do not scale to explaining entire datasets and cannot correct the problems they reveal. We introduce a method for efficiently explaining and regularizing differentiable models by examining and selectively penalizing their input gradients. We apply these penalties both based on expert annotation and in an unsupervised fashion that produces multiple classifiers with qualitatively different decision boundaries. On multiple datasets, we show our approach generates faithful explanations and models that generalize much better when conditions differ between training and test.},
address = {Melbourne, Australia},
archivePrefix = {arXiv},
arxivId = {1703.03717},
author = {Ross, Andrew Slavin and Hughes, Michael C and Doshi-Velez, Finale},
booktitle = {Proceedings of the 26th International Joint Conferences on Artificial Intelligence},
doi = {10.24963/ijcai.2017/371},
eprint = {1703.03717},
isbn = {978-0-99-924110-3},
issn = {1045-0823},
month = {aug},
pages = {2662--2670},
title = {{Right for the right reasons: Training differentiable models by constraining their explanations}},
year = {2017}
}
@article{Moody:2009vo,
abstract = {Visual notations form an integral part of the language of software engineering (SE). Yet historically, SE researchers and notation designers have ignored or undervalued issues of visual representation. In evaluating and comparing notations, details of visual syntax are rarely discussed. In designing notations, the majority of effort is spent on semantics, with graphical conventions largely an afterthought. Typically, no design rationale, scientific or otherwise, is provided for visual representation choices. While SE has developed mature methods for evaluating and designing semantics, it lacks equivalent methods for visual syntax. This paper defines a set of principles for designing cognitively effective visual notations: ones that are optimized for human communication and problem solving. Together these form a design theory, called the Physics of Notations as it focuses on the physical (perceptual) properties of notations rather than their logical (semantic) properties. The principles were synthesized from theory and empirical evidence from a wide range of fields and rest on an explicit theory of how visual notations communicate. They can be used to evaluate, compare, and improve existing visual notations as well as to construct new ones. The paper identifies serious design flaws in some of the leading SE notations, together with practical suggestions for improving them. It also showcases some examples of visual notation design excellence from SE and other fields. {\textcopyright}2009 IEEE.},
author = {Moody, Daniel},
doi = {10.1109/TSE.2009.67},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Analysis,Communication,Concrete syntax,Diagrams,Modeling,Visual syntax,Visualization},
number = {6},
pages = {756--779},
title = {{The physics of notations: Toward a scientific basis for constructing visual notations in software engineering}},
volume = {35},
year = {2009}
}
@misc{Jimerson:2017vh,
address = {San Francisco, CA, USA},
author = {Jimerson, Brian and Gregory, Brian},
month = {dec},
title = {{Pivotal Cloud Foundry, Google ML, and Spring}},
url = {http://bit.ly/2RUBIIL},
year = {2017}
}
@inproceedings{Choi:2015wo,
abstract = {We present a preliminary investigation of Stack Overflow to reveal practitioner's interests about code clones. We then discuss possible future directions of research on code clones.},
address = {Montreal, QC, Canada},
author = {Choi, Eunjong and Yoshida, Norihiro and Kula, Raula Gaikovina and Inoue, Katsuro},
booktitle = {Proceedings of the 9th International Workshop on Software Clones},
doi = {10.1109/IWSC.2015.7069890},
isbn = {978-1-46-736914-5},
month = {mar},
pages = {49--50},
title = {{What do practitioners ask about code clone? a preliminary investigation of stack overflow}},
year = {2015}
}
@inproceedings{Ohtake:2019vi,
abstract = {Intelligent APIs, such as Google Cloud Vision or Amazon Rekognition, are becoming evermore pervasive and easily accessible to developers to build applications. Because of the stochastic nature that machine learning entails and disparate datasets used in their training, the output from different APIs varies over time, with low reliability in some cases when compared against each other. Merging multiple unreliable API responses from multiple vendors may increase the reliability of the overall response, and thus the reliability of the intelligent end-product. We introduce a novel methodology – inspired by the proportional representation used in electoral systems – to merge outputs of different intelligent computer vision APIs provided by multiple vendors. Experiments show that our method outperforms both naive merge methods and traditional proportional representation methods by 0.015 F-measure.},
address = {Daejeon, Republic of Korea},
author = {Ohtake, Tomohiro and Cummaudo, Alex and Abdelrazek, Mohamed and Vasa, Rajesh and Grundy, John},
booktitle = {Proceedings of the 19th International Conference on Web Engineering},
doi = {10.1007/978-3-030-19274-7\_28},
isbn = {978-3-03-019273-0},
issn = {1611-3349},
keywords = {Application programming interfaces,Artificial intelligence,Data integration,Supervised learning,Web services},
month = {jun},
pages = {391--406},
publisher = {Springer},
title = {{Merging intelligent API responses using a proportional representation approach}},
year = {2019}
}
@article{Sokolova:2009vu,
abstract = {This paper presents a systematic analysis of twenty four performance measures used in the complete spectrum of Machine Learning classification tasks, i.e., binary, multi-class, multi-labelled, and hierarchical. For each classification task, the study relates a set of changes in a confusion matrix to specific characteristics of data. Then the analysis concentrates on the type of changes to a confusion matrix that do not change a measure, therefore, preserve a classifier's evaluation (measure invariance). The result is the measure invariance taxonomy with respect to all relevant label distribution changes in a classification problem. This formal analysis is supported by examples of applications where invariance properties of measures lead to a more reliable evaluation of classifiers. Text classification supplements the discussion with several case studies. {\textcopyright}2009 Elsevier Ltd. All rights reserved.},
author = {Sokolova, Marina and Lapalme, Guy},
doi = {10.1016/j.ipm.2009.03.002},
issn = {0306-4573},
journal = {Information Processing and Management},
keywords = {Machine Learning,Performance evaluation,Text classification},
number = {4},
pages = {427--437},
title = {{A systematic analysis of performance measures for classification tasks}},
volume = {45},
year = {2009}
}
@article{BenDavid:1995up,
abstract = {Decision trees that are based on information-theory are useful paradigms for learning from examples. However, in some real-world applications, known information-theoretic methods frequently generate nonmonotonic decision trees, in which objects with better attribute values are sometimes classified to lower classes than objects with inferior values. This property is undesirable for problem solving in many application domains, such as credit scoring and insurance premium determination, where monotonicity of subsequent classifications is important. An attribute-selection metric is proposed here that takes both the error as well as monotonicity into account while building decision trees. The metric is empirically shown capable of significantly reducing the degree of non-monotonicity of decision trees without sacrificing their inductive accuracy. {\textcopyright}1995, Kluwer Academic Publishers. All rights reserved.},
author = {Ben-David, Arie},
doi = {10.1023/A:1022655006810},
issn = {1573-0565},
journal = {Machine Learning},
keywords = {accuracy,consistency,information theory,monotonic classification problems,monotonic decision trees},
number = {1},
pages = {29--43},
title = {{Monotonicity Maintenance in Information-Theoretic Machine Learning Algorithms}},
volume = {19},
year = {1995}
}
@inproceedings{Patel:2008:ISM:1357054.1357160,
abstract = {As statistical machine learning algorithms and techniques continue to mature, many researchers and developers see statistical machine learning not only as a topic of expert study, but also as a tool for software development. Extensive prior work has studied software development, but little prior work has studied software developers applying statistical machine learning. This paper presents interviews of eleven researchers experienced in applying statistical machine learning algorithms and techniques to human-computer interaction problems, as well as a study of ten participants working during a five-hour study to apply statistical machine learning algorithms and techniques to a realistic problem. We distil] three related categories of difficulties that arise in applying statistical machine learning as a tool for software development: (1) difficulty pursuing statistical machine learning as an iterative and exploratory process, (2) difficulty understanding relationships between data and the behavior of statistical machine learning algorithms, and (3) difficulty evaluating the performance of statistical machine learning algorithms and techniques in the context of applications. This paper provides important new insight into these difficulties and the need for development tools that better support the application of statistical machine learning. Copyright 2008 ACM.},
address = {Florence, Italy},
author = {Patel, Kayur and Fogarty, James and Landay, James A and Harrison, Beverly},
booktitle = {Proceedings of the 26th SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/1357054.1357160},
isbn = {978-1-60-558011-1},
keywords = {Software development,Statistical machine learning},
month = {apr},
pages = {667--676},
publisher = {ACM},
series = {CHI '08},
title = {{Investigating statistical machine learning as a tool for software development}},
year = {2008}
}
@inproceedings{hardt2016equality,
abstract = {We propose a criterion for discrimination against a specified sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our definition. Our framework also improves incentives by shifting the cost of poor classification from disadvantaged groups to the decision maker, who can respond by improving the classification accuracy. We enourage readers to consult the more complete manuscript on the arXiv.},
address = {Barcelona, Spain},
archivePrefix = {arXiv},
arxivId = {1610.02413},
author = {Hardt, Moritz and Price, Eric and Srebro, Nathan},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
doi = {978-1-51-083881-9},
eprint = {1610.02413},
issn = {1049-5258},
month = {dec},
pages = {3323--3331},
publisher = {Curran Associates Inc.},
title = {{Equality of opportunity in supervised learning}},
year = {2016}
}
@misc{Tabor:1997tw,
address = {New York, NY, USA},
author = {Tabor, Mary B W},
booktitle = {New York Times},
month = {feb},
title = {{Student Proves That S.A.T. Can Be: (D) Wrong}},
url = {https://nyti.ms/2UiKrrd},
year = {1997}
}
@phdthesis{Barnett:2018Kx,
address = {Hawthorn, VIC, Australia},
author = {Barnett, Scott},
school = {Swinburne University of Technology},
title = {{Extracting technical domain knowledge to improve software architecture}},
year = {2018}
}
@article{Biggs:2014ur,
abstract = {Incluye bibliograf{\'{i}}a e {\'{i}}ndice},
author = {Biggs, J and Collis, K},
doi = {10.1177/089202068700100412},
isbn = {0-12-097551-1},
issn = {0892-0206},
journal = {Management in Education},
number = {4},
pages = {20},
title = {{Evaluating the Quality of Learning: The SOLO Taxonomy (Structure of the Observed Learning Outcome)}},
volume = {1},
year = {1987}
}
@inproceedings{Allahyari:2011ud,
abstract = {This paper reviews methods for evaluating and analyzing the understandability of classification models in the context of data mining. The motivation for this study is the fact that the majority of previous work on evaluation and optimization of classification models has focused on assessing or increasing the accuracy of the models and thus user-oriented properties such as comprehensibility and understandability have been largely overlooked. We conduct a quantitative survey to examine the concept of understandability from the user's point of view. The survey results are analyzed using the analytic hierarchy process (AHP) to rank models according to their understandability. The results indicate that decision tree models are perceived as more understandable than rule-based models. Using the survey results regarding understandability of a number of models in conjunction with quantitative measurements of the complexity of the models, we are able to establish a negative correlation between the complexity and understandability of the classification models, at least for one of the two studied data sets. ?? 2011 The authors and IOS Press. All rights reserved.},
address = {Trondheim, Norway},
author = {Allahyari, Hiva and Lavesson, Niklas},
booktitle = {Proceedings of the 11th Scandinavian Conference on Artificial Intelligence},
doi = {10.3233/978-1-60750-754-3-11},
isbn = {978-1-60-750753-6},
issn = {0922-6389},
keywords = {Classification,evaluation,understandability},
month = {may},
pages = {11--19},
publisher = {IOS Press},
title = {{User-oriented assessment of classification model understandability}},
volume = {227},
year = {2011}
}
@inproceedings{Canfora:2005vd,
abstract = {Service Oriented Architectures, and particularly Web Services, are receiving a growing attention from research and industry. With Web Services, software is used and not owned and operation happens on machines that are out of the user control. Therefore, providing users with means to build confidence that a service delivers the desired function with the expected QoS becomes a key issue.},
address = {Manchester, England, UK},
author = {Canfora, Gerardo},
booktitle = {Proceedings of the 9th European Conference on Software Maintenance and Reengineering},
doi = {10.1109/csmr.2005.57},
issn = {1534-5351},
month = {mar},
pages = {301},
publisher = {IEEE},
title = {{User-side testing of Web Services}},
year = {2005}
}
@misc{Finalyson:2018aa,
address = {Fredericksburg, VA, USA},
author = {Finalyson, Ian},
publisher = {University of Mary Washington},
title = {{Nondeterministic Finite Automata}},
url = {http://bit.ly/319GOF9},
year = {2018}
}
@misc{Mapillar97:online,
annote = {Accessed: 25 January 2019},
author = {{GeoSpatial World}},
month = {sep},
title = {{Mapillary and Amazon Rekognition collaborate to build a parking solution for US cities through computer vision}},
url = {http://bit.ly/36AdRmS},
year = {2018}
}
@inproceedings{Subramanian:2014bg,
abstract = {Application Programming Interfaces (APIs) provide powerful abstraction mechanisms that enable complex functionality to be used by client programs. However, this abstraction does not come for free: understanding how to use an API can be difficult. While API documentation can help, it is often insufficient on its own. Online sites like Stack Overflow and Github Gists have grown to fill the gap between traditional API documentation and more example-based resources. Unfortunately, these two important classes of documentation are independent. In this paper we describe an iterative, deductive method of linking source code examples to API documentation. We also present an implementation of this method, called Baker, that is highly precise (0.97) and supports both Java and JavaScript. Baker can be used to enhance traditional API documentation with up-to-date source code examples; it can also be used to incorporate links to the API documentation into the code snippets that use the API.},
address = {Hyderabad, India},
author = {Subramanian, Siddharth and Inozemtseva, Laura and Holmes, Reid},
booktitle = {Proceedings of the 36th International Conference on Software Engineering},
doi = {10.1145/2568225.2568313},
issn = {0270-5257},
keywords = {Source code examples,documentation,source code search},
month = {may},
pages = {643--652},
publisher = {ACM},
title = {{Live API documentation}},
year = {2014}
}
@inproceedings{Watson:2013fx,
abstract = {Studies of what software developers need from API documentation have reported consistent findings over the years; however, these studies all used similar methods - usually a form of observation or survey. Our study looks at API documentation as artifacts of the open-source software communities who produce them to study how documentation produced by the communities who use the software compares to past studies of what software developers want and need from API documentation. We reviewed API documentation from 33 of the most popular open-source software projects, assessed their documentation elements, and evaluated the quality of their visual design and writing. We found that the documentation we studied included most or all the documentation elements reported as desirable in earlier studies and in the process, we found that the design and writing quality of many documentation sets received considerable attention. Our findings reinforce the API requirements identified in the literature and suggest that the design and writing quality of the documentation are also critical API documentation requirements that warrant further study. {\textcopyright} 2013 ACM.},
address = {Greenville, SC, USA},
author = {Watson, Robert and {Mark Stamnes}, Mark and Jeannot-Schroeder, Jacob and Spyridakis, Jan H.},
booktitle = {Proceedings of the 31st ACM International Conference on Design of Communication},
doi = {10.1145/2507065.2507076},
keywords = {api,api reference documentation,application programming interface,software documentation,software libraries},
month = {sep},
pages = {165--174},
publisher = {ACM},
title = {{API documentation and software community values: A survey of open-source API documentation}},
year = {2013}
}
@inproceedings{tu2000evolution,
abstract = {Most studies of software evolution have been performed on systems developed within a single company using traditional management techniques. With the widespread availability of several large software systems that have been developed using an 'open source' development approach, we now have a chance to examine these systems in detail, and see if their evolutionary narratives are significantly different from commercially developed systems. This paper summarizes our preliminary investigations into the evolution of the best known open source system: the Linux operating system kernel. Because Linux is large (over two million lines of code in the most recent version) and because its development model is not as tightly planned and managed as most industrial software processes, we had expected to find that Linux was growing more slowly as it got bigger and more complex. Instead, we have found that Linux has been growing at a super-linear rate for several years. In this paper, we explore the evolution of the Linux kernel both at the system level and within the major subsystems, and we discuss why we think Linux continues to exhibit such strong growth.},
address = {San Jose, CA, USA},
author = {Godfrey, Michael W and Tu, Qiang},
booktitle = {Conference on Software Maintenance},
doi = {10.1109/icsm.2000.883030},
month = {aug},
organization = {IEEE},
pages = {131--142},
title = {{Evolution in open source software: a case study}},
year = {2000}
}
@article{DBLP:journals/corr/abs-1907-04135,
abstract = {A key challenge in developing and deploying Machine Learning (ML) systems is understanding their performance across a wide range of inputs. To address this challenge, we created the What-If Tool, an open-source application that allows practitioners to probe, visualize, and analyze ML systems, with minimal coding. The What-If Tool lets practitioners test performance in hypothetical situations, analyze the importance of different data features, and visualize model behavior across multiple models and subsets of input data. It also lets practitioners measure systems according to multiple ML fairness metrics. We describe the design of the tool, and report on real-life usage at different organizations.},
archivePrefix = {arXiv},
arxivId = {1907.04135},
author = {Wexler, James and Pushkarna, Mahima and Bolukbasi, Tolga and Wattenberg, Martin and Viegas, Fernanda and Wilson, Jimbo},
doi = {10.1109/tvcg.2019.2934619},
eprint = {1907.04135},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
pages = {56--65},
title = {{The What-If Tool: Interactive Probing of Machine Learning Models}},
volume = {26},
year = {2019}
}
@inproceedings{calefato2017,
address = {San Antonio, TX, USA},
author = {Calefato, Fabio and Lanubile, Filippo and Novielli, Nicole},
booktitle = {Proceedings of the 7th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos},
doi = {10.1109/ACIIW.2017.8272591},
month = {oct},
pages = {79--80},
publisher = {IEEE},
title = {{EmoTxt: a toolkit for emotion recognition from text}},
year = {2017}
}
@book{pyle1999data,
author = {Pyle, Dorian},
edition = {1st},
isbn = {978-15-5-860529-9},
pages = {560},
publisher = {Morgan Kaufmann},
title = {{Data Preparation for Data Mining}},
year = {1994}
}
@article{cicchetti1994guidelines,
abstract = {In the context of the development of prototypic assessment instruments in the areas of cognition, personality, and adaptive functioning, the issues of standardization, norming procedures, and the important psychometrics of test reliability and validity are evaluated critically. Criteria, guidelines, and simple rules of thumb are provided to assist the clinician faced with the challenge of choosing an appropriate test instrument for a given psychological assessment.},
author = {Cicchetti, Domenic V.},
doi = {10.1037/1040-3590.6.4.284},
issn = {10403590},
journal = {Psychological Assessment},
number = {4},
pages = {284--290},
publisher = {American Psychological Association},
title = {{Guidelines, Criteria, and Rules of Thumb for Evaluating Normed and Standardized Assessment Instruments in Psychology}},
volume = {6},
year = {1994}
}
@inproceedings{Graetsch:2020ase-industry,
annote = {Unpublished},
author = {Graetsch, Ulrike Maria and Cummaudo, Alex and Vasa, Rajesh and Curumsing, Maheswaree Kissoon},
keywords = {InReview},
mendeley-tags = {InReview},
title = {{Lessons learnt using a pre-trained AI model}},
year = {2020}
}
@inproceedings{Caruana:2015jk,
abstract = {In machine learning often a tradeoff must be made between accuracy and intelligibility. More accurate models such as boosted trees, random forests, and neural nets usually are not intelligible, but more intelligible models such as logistic regression, naive-Bayes, and single decision trees often have significantly worse accuracy. This tradeoff sometimes limits the accuracy of models that can be applied in mission-critical applications such as healthcare where being able to understand, validate, edit, and trust a learned model is important. We present two case studies where high-performance generalized additive models with pairwise interactions (GA2Ms) are applied to real healthcare problems yielding intelligible models with state-of-the-art accuracy. In the pneumonia risk prediction case study, the intelligible model uncovers surprising patterns in the data that previously had prevented complex learned models from being fielded in this domain, but because it is intelligible and modular allows these patterns to be recognized and removed. In the 30-day hospital readmission case study, we show that the same methods scale to large datasets containing hundreds of thousands of patients and thousands of attributes while remaining intelligible and providing accuracy comparable to the best (unintelligible) machine learning methods.},
address = {Sydney, Australia},
author = {Caruana, Rich and Lou, Yin and Gehrke, Johannes and Koch, Paul and Sturm, Marc and Elhadad, No{\'{e}}mie},
booktitle = {Proceedings of the 21st ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/2783258.2788613},
isbn = {978-1-45-033664-2},
keywords = {Additive models,Classification,Healthcare,Intelligibility,Interaction detection,Logistic regression,Risk prediction},
month = {aug},
pages = {1721--1730},
publisher = {ACM},
title = {{Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission}},
volume = {2015-Augus},
year = {2015}
}
@inproceedings{Rubey:1968fg,
address = {Las Vegas, NV, USA},
author = {Rubey, Raymond J and Hartwick, R Dean},
booktitle = {Proceedings of the 1968 23rd ACM National Conference},
doi = {10.1145/800186.810631},
isbn = {978-1-45-037486-6},
month = {aug},
pages = {671--677},
publisher = {ACM},
title = {{Quantitative measurement of program quality}},
year = {1968}
}
@techreport{BernersLee:2004vf,
author = {Berners-Lee, Tim and Fielding, Roy and Masinter, Larry},
title = {{Uniform resource identifier (URI): Generic syntax}},
year = {2004}
}
@inproceedings{Cummaudo:2019icsme,
abstract = {Recent advances in artificial intelligence (AI) and machine learning (ML), such as computer vision, are now available as intelligent services and their accessibility and simplicity is compelling. Multiple vendors now offer this technology as cloud services and developers want to leverage these advances to provide value to end-users. However, there is no firm investigation into the maintenance and evolution risks arising from use of these intelligent services; in particular, their behavioural consistency and transparency of their functionality. We evaluated the responses of three different intelligent services (specifically computer vision) over 11 months using 3 different data sets, verifying responses against the respective documentation and assessing evolution risk. We found that there are: (1) inconsistencies in how these services behave; (2) evolution risk in the responses; and (3) a lack of clear communication that documents these risks and inconsistencies. We propose a set of recommendations to both developers and intelligent service providers to inform risk and assist maintainability.},
address = {Cleveland, OH, USA},
author = {Cummaudo, Alex and Vasa, Rajesh and Grundy, John and Abdelrazek, Mohamed and Cain, Andrew},
booktitle = {Proceedings of the 35th IEEE International Conference on Software Maintenance and Evolution},
doi = {10.1109/ICSME.2019.00051},
isbn = {978-1-72-813094-1},
month = {dec},
pages = {333--342},
publisher = {IEEE},
title = {{Losing Confidence in Quality: Unspoken Evolution of Computer Vision Services}},
year = {2019}
}
@article{EhteshamiBejnordi:2017kq,
abstract = {IMPORTANCE: Application of deep learning algorithms to whole-slide pathology imagescan potentially improve diagnostic accuracy and efficiency. OBJECTIVE: Assess the performance of automated deep learning algorithms at detecting metastases in hematoxylin and eosin-stained tissue sections of lymph nodes of women with breast cancer and compare it with pathologists' diagnoses in a diagnostic setting. DESIGN, SETTING, AND PARTICIPANTS: Researcher challenge competition (CAMELYON16) to develop automated solutions for detecting lymph node metastases (November 2015-November 2016). A training data set of whole-slide images from 2 centers in the Netherlands with (n = 110) and without (n = 160) nodal metastases verified by immunohistochemical staining were provided to challenge participants to build algorithms. Algorithm performance was evaluated in an independent test set of 129 whole-slide images (49 with and 80 without metastases). The same test set of corresponding glass slides was also evaluated by a panel of 11 pathologists with time constraint (WTC) from the Netherlands to ascertain likelihood of nodal metastases for each slide in a flexible 2-hour session, simulating routine pathology workflow, and by 1 pathologist without time constraint (WOTC). EXPOSURES: Deep learning algorithms submitted as part of a challenge competition or pathologist interpretation. MAIN OUTCOMES AND MEASURES: The presence of specific metastatic foci and the absence vs presence of lymph node metastasis in a slide or image using receiver operating characteristic curve analysis. The 11 pathologists participating in the simulation exercise rated their diagnostic confidence as definitely normal, probably normal, equivocal, probably tumor, or definitely tumor. RESULTS: The area under the receiver operating characteristic curve (AUC) for the algorithms ranged from 0.556 to 0.994. The top-performing algorithm achieved a lesion-level, true-positive fraction comparable with that of the pathologist WOTC (72.4{\%} [95{\%} CI, 64.3{\%}-80.4{\%}]) at a mean of 0.0125 false-positives per normal whole-slide image. For the whole-slide image classification task, the best algorithm (AUC, 0.994 [95{\%} CI, 0.983-0.999]) performed significantly better than the pathologists WTC in a diagnostic simulation (mean AUC, 0.810 [range, 0.738-0.884]; P {\textless}.001). The top 5 algorithms had a mean AUC that was comparable with the pathologist interpreting the slides in the absence of time constraints (mean AUC, 0.960 [range, 0.923-0.994] for the top 5 algorithms vs 0.966 [95{\%} CI, 0.927-0.998] for the pathologist WOTC). CONCLUSIONS AND RELEVANCE: In the setting of a challenge competition, some deep learning algorithms achieved better diagnostic performance than a panel of 11 pathologists participating in a simulation exercise designed to mimic routine pathology workflow; algorithm performance was comparable with an expert pathologist interpreting whole-slide images without time constraints. Whether this approach has clinical utility will require evaluation in a clinical setting.},
author = {Bejnordi, Babak Ehteshami and Veta, Mitko and {Van Diest}, Paul Johannes and {Van Ginneken}, Bram and Karssemeijer, Nico and Litjens, Geert and {Van Der Laak}, Jeroen A W M and Hermsen, Meyke and Manson, Quirine F and Balkenhol, Maschenka and Geessink, Oscar and Stathonikos, Nikolaos and {Van Dijk}, Marcory C R F and Bult, Peter and Beca, Francisco and Beck, Andrew H and Wang, Dayong and Khosla, Aditya and Gargeya, Rishab and Irshad, Humayun and Zhong, Aoxiao and Dou, Qi and Li, Quanzheng and Chen, Hao and Lin, Huang Jing and Heng, Pheng Ann and Ha{\ss}, Christian and Bruni, Elia and Wong, Quincy and Halici, Ugur and {\"{O}}ner, Mustafa {\"{U}}mit and Cetin-Atalay, Rengul and Berseth, Matt and Khvatkov, Vitali and Vylegzhanin, Alexei and Kraus, Oren and Shaban, Muhammad and Rajpoot, Nasir and Awan, Ruqayya and Sirinukunwattana, Korsuk and Qaiser, Talha and Tsang, Yee Wah and Tellez, David and Annuscheit, Jonas and Hufnagl, Peter and Valkonen, Mira and Kartasalo, Kimmo and Latonen, Leena and Ruusuvuori, Pekka and Liimatainen, Kaisa and Albarqouni, Shadi and Mungal, Bharti and George, Ami and Demirci, Stefanie and Navab, Nassir and Watanabe, Seiryo and Seno, Shigeto and Takenaka, Yoichi and Matsuda, Hideo and Phoulady, Hady Ahmady and Kovalev, Vassili and Kalinovsky, Alexander and Liauchuk, Vitali and Bueno, Gloria and Fernandez-Carrobles, M Milagro and Serrano, Ismael and Deniz, Oscar and Racoceanu, Daniel and Ven{\^{a}}ncio, Rui},
doi = {10.1001/jama.2017.14585},
issn = {1538-3598},
journal = {Journal of the American Medical Association},
month = {dec},
number = {22},
pages = {2199--2210},
pmid = {29234806},
title = {{Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer}},
volume = {318},
year = {2017}
}
@article{GAROUSI2019101,
abstract = {Context: A Multivocal Literature Review (MLR) is a form of a Systematic Literature Review (SLR) which includes the grey literature (e.g., blog posts, videos and white papers) in addition to the published (formal) literature (e.g., journal and conference papers). MLRs are useful for both researchers and practitioners since they provide summaries both the state-of-the art and –practice in a given area. MLRs are popular in other fields and have recently started to appear in software engineering (SE). As more MLR studies are conducted and reported, it is important to have a set of guidelines to ensure high quality of MLR processes and their results. Objective: There are several guidelines to conduct SLR studies in SE. However, several phases of MLRs differ from those of traditional SLRs, for instance with respect to the search process and source quality assessment. Therefore, SLR guidelines are only partially useful for conducting MLR studies. Our goal in this paper is to present guidelines on how to conduct MLR studies in SE. Method: To develop the MLR guidelines, we benefit from several inputs: (1) existing SLR guidelines in SE, (2), a literature survey of MLR guidelines and experience papers in other fields, and (3) our own experiences in conducting several MLRs in SE. We took the popular SLR guidelines of Kitchenham and Charters as the baseline and extended/adopted them to conduct MLR studies in SE. All derived guidelines are discussed in the context of an already-published MLR in SE as the running example. Results: The resulting guidelines cover all phases of conducting and reporting MLRs in SE from the planning phase, over conducting the review to the final reporting of the review. In particular, we believe that incorporating and adopting a vast set of experience-based recommendations from MLR guidelines and experience papers in other fields have enabled us to propose a set of guidelines with solid foundations. Conclusion: Having been developed on the basis of several types of experience and evidence, the provided MLR guidelines will support researchers to effectively and efficiently conduct new MLRs in any area of SE. The authors recommend the researchers to utilize these guidelines in their MLR studies and then share their lessons learned and experiences.},
archivePrefix = {arXiv},
arxivId = {1707.02553},
author = {Garousi, Vahid and Felderer, Michael and M{\"{a}}ntyl{\"{a}}, Mika V},
doi = {10.1016/j.infsof.2018.09.006},
eprint = {1707.02553},
issn = {0950-5849},
journal = {Information and Software Technology},
keywords = {Evidence-based software engineering,Grey literature,Guidelines,Literature study,Multivocal literature review,Systematic literature review,Systematic mapping study},
pages = {101--121},
title = {{Guidelines for including grey literature and conducting multivocal literature reviews in software engineering}},
volume = {106},
year = {2019}
}
@inproceedings{sculley2011detecting,
address = {San Diego, CA, USA},
author = {Sculley, D and Otey, Matthew Eric and Pohl, Michael and Spitznagel, Bridget and Hainsworth, John and Zhou, Yunkai},
booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/2020408.2020455},
month = {aug},
organization = {ACM},
pages = {274--282},
publisher = {ACM},
title = {{Detecting adversarial advertisements in the wild}},
year = {2011}
}
@inproceedings{Aman2007IdentifyingText,
abstract = {Finding emotions in text is an area of research with wide-ranging applications. We describe an emotion annotation task of identifying emotion category, emotion intensity and the words/phrases that indicate emotion in text. We introduce the annotation scheme and present results of an annotation agreement study on a corpus of blog posts. The average inter-annotator agreement on labeling a sentence as emotion or non-emotion was 0.76. The agreement on emotion categories was in the range 0.6 to 0.79; for emotion indicators, it was 0.66. Preliminary results of emotion classification experiments show the accuracy of 73.89{\%}, significantly above the baseline.},
address = {Pilsen, Czech Republic},
author = {Aman, Saima and Szpakowicz, Stan},
booktitle = {Proceedings of the 10th International Conference on Text, Speech and Dialogue},
doi = {10.1007/978-3-540-74628-7_27},
month = {sep},
pages = {196--205},
publisher = {Springer},
title = {{Identifying Expressions of Emotion in Text}},
year = {2007}
}
@book{Rosenberry:1992up,
author = {Rosenberry, Ward and Kenney, David and Fisher, Gerry},
isbn = {978-1-56-592005-7},
publisher = {O'Reilly {\&} Associates, Inc.},
title = {{Understanding DCE}},
year = {1992}
}
@article{Huysmans:2011gq,
abstract = {An important objective of data mining is the development of predictive models. Based on a number of observations, a model is constructed that allows the analysts to provide classifications or predictions for new observations. Currently, most research focuses on improving the accuracy or precision of these models and comparatively little research has been undertaken to increase their comprehensibility to the analyst or end-user. This is mainly due to the subjective nature of 'comprehensibility', which depends on many factors outside the model, such as the user's experience and his/her prior knowledge. Despite this influence of the observer, some representation formats are generally considered to be more easily interpretable than others. In this paper, an empirical study is presented which investigates the suitability of a number of alternative representation formats for classification when interpretability is a key requirement. The formats under consideration are decision tables, (binary) decision trees, propositional rules, and oblique rules. An end-user experiment was designed to test the accuracy, response time, and answer confidence for a set of problem-solving tasks involving the former representations. Analysis of the results reveals that decision tables perform significantly better on all three criteria, while post-test voting also reveals a clear preference of users for decision tables in terms of ease of use. {\textcopyright}2010 Elsevier B.V. All rights reserved.},
author = {Huysmans, Johan and Dejaeger, Karel and Mues, Christophe and Vanthienen, Jan and Baesens, Bart},
doi = {10.1016/j.dss.2010.12.003},
issn = {0167-9236},
journal = {Decision Support Systems},
keywords = {Classification,Comprehensibility,Data mining,Decision tables,Knowledge representation},
month = {apr},
number = {1},
pages = {141--154},
title = {{An empirical evaluation of the comprehensibility of decision table, tree and rule based predictive models}},
volume = {51},
year = {2011}
}
@article{Niemeyer2008240,
author = {Niemeyer, Horst F and Niemeyer, Alice C},
issn = {0165-4896},
journal = {Mathematical Social Sciences},
keywords = {Alabama Paradox,Apportionment method,D'Hondt method,Hare/Hamilton method,Sainte-Lagu{\"{e}} method},
number = {2},
pages = {240--253},
title = {{Apportionment methods}},
volume = {56},
year = {2008}
}
@article{Cohen:1960tf,
abstract = {A coefficient of interjudge agreement for nominal scales, formula-omitted, is presented. It is directly interpretable as the pro-portion of joint judgments in which there is agreement, after chance agreement is excluded. Its upper limit is +1.00, and its lower limit falls between zero and -1.00, depending on the distribution of judgments by the two judges. The maximum value which x can take for any given problem is given, and the implications of this value to the question of agreement discussed. An interesting characteristic of x is its identity with 0 in the dichotomous case when the judges give the same marginal distributions. Finally, its standard error and techniques for estimation and hypothesis testing are presented. {\textcopyright}1960, Sage Publications. All rights reserved.},
author = {Cohen, Jacob},
doi = {10.1177/001316446002000104},
issn = {1552-3888},
journal = {Educational and Psychological Measurement},
number = {1},
pages = {37--46},
title = {{A Coefficient of Agreement for Nominal Scales}},
volume = {20},
year = {1960}
}
@article{Lipton:2016if,
archivePrefix = {arXiv},
arxivId = {1606.03490},
author = {Lipton, Zachary C},
doi = {10.1145/3233231},
eprint = {1606.03490},
issn = {1557-7317},
journal = {Communications of the ACM},
number = {10},
pages = {35--43},
title = {{The mythos of model interpretability}},
volume = {61},
year = {2018}
}
@inbook{Krig2016,
abstract = {This chapter discusses several topics pertaining to ground truth data, the basis for computer vision metric analysis. We look at examples to illustrate the importance of ground truth data design and use, including manual and automated methods. We then propose a method and corresponding ground truth dataset for measuring interest point detector response as compared to human visual system response and human expectations. Also included here are example applications of the general robustness criteria and the general vision taxonomy developed in Chap. 5as applied to the preparation of hypothetical ground truth data. Lastly, we look at the current state of the art, its best practices, and a survey of available ground truth datasets.},
address = {Cham},
author = {Krig, Scott},
booktitle = {Computer Vision Metrics: Textbook Edition},
doi = {10.1007/978-3-319-33762-3_7},
isbn = {978-3-319-33762-3},
pages = {247--271},
publisher = {Springer International Publishing},
title = {{Ground Truth Data, Content, Metrics, and Analysis}},
year = {2016}
}
@inproceedings{4659256,
abstract = {Change is an essential characteristic of software development, as software systems must respond to evolving requirements, platforms, and other environmental pressures. In this paper, we discuss the concept of software evolution from several perspectives. We examine how it relates to and differs from software maintenance. We discuss insights about software evolution arising from Lehman's laws of software evolution and the staged lifecycle model of Bennett and Rajlich. We compare software evolution to other kinds of evolution, from science and social sciences, and we examine the forces that shape change. Finally, we discuss the changing nature of software in general as it relates to evolution, and we propose open challenges and future directions for software evolution research. {\textcopyright}2008 IEEE.},
address = {Beijing, China},
author = {Godfrey, Michael W and German, Daniel M},
booktitle = {Proceedings of the 2008 Frontiers of Software Maintenance},
doi = {10.1109/FOSM.2008.4659256},
isbn = {978-1-42-442655-3},
keywords = {software development management,software maintenan},
month = {oct},
pages = {129--138},
title = {{The past, present, and future of software evolution}},
year = {2008}
}
@article{Subramanian:1992ue,
author = {Subramanian, Girish H and Nosek, John and Raghunathan, Sankaran P and Kanitkar, Santosh S},
doi = {10.1145/129617.129621},
issn = {1557-7317},
journal = {Communications of the ACM},
keywords = {computer games,decision aids effectiveness,effectiveness of structured tools,human aspects of computing,human factors of experimentation},
number = {1},
pages = {89--94},
title = {{A comparison of the decision table and tree}},
volume = {35},
year = {1992}
}
@inproceedings{Schwabacher:2001wc,
abstract = {Pages: 489 - 496. Year of Publication: . ISBN:1-55860-778-1. Authors, Mark , Pat , Publisher, Morgan Kaufmann Publishers Inc.},
address = {Williamstown, MA, USA},
author = {Schwabacher, Mark and Langley, Pat},
booktitle = {Proceedings of the 18th International Conference on Machine Learning},
isbn = {978-1-55-860778-1},
month = {jun},
pages = {489--496},
publisher = {Morgan Kaufmann},
title = {{Discovering communicable scientific knowledge from spatio-temporal data}},
year = {2001}
}
@article{Sendak2020PresentingLabels,
abstract = {There is tremendous enthusiasm surrounding the potential for machine learning to improve medical prognosis and diagnosis. However, there are risks to translating a machine learning model into clinical care and clinical end users are often unaware of the potential harm to patients. This perspective presents the “Model Facts” label, a systematic effort to ensure that front-line clinicians actually know how, when, how not, and when not to incorporate model output into clinical decisions. The “Model Facts” label was designed for clinicians who make decisions supported by a machine learning model and its purpose is to collate relevant, actionable information in 1-page. Practitioners and regulators must work together to standardize presentation of machine learning model information to clinical end users in order to prevent harm to patients. Efforts to integrate a model into clinical practice should be accompanied by an effort to clearly communicate information about a machine learning model with a “Model Facts” label.},
author = {Sendak, Mark P and Gao, Michael and Brajer, Nathan and Balu, Suresh},
doi = {10.1038/s41746-020-0253-3},
issn = {2398-6352},
journal = {npj Digital Medicine},
number = {1},
pages = {41},
title = {{Presenting machine learning model information to clinical end users with model facts labels}},
volume = {3},
year = {2020}
}
@inproceedings{Aghajani:2018et,
abstract = {The concept of monolithic stand-Alone software systems developed completely from scratch has become obsolete, as modern systems nowadays leverage the abundant presence of Application Programming Interfaces (APIs) developed by third parties, which leads on the one hand to accelerated development, but on the other hand introduces potentially fragile dependencies on external resources. In this context, the design of any API strongly influences how developers write code utilizing it. A wrong design decision like a poorly chosen method name can lead to a steeper learning curve, due to misunderstandings, misuse and eventually bug-prone code in the client projects using the API. It is not unfrequent to find APIs with poorly expressive or misleading names, possibly lacking appropriate documentation. Such issues can manifest in what have been defined in the literature as Linguistic Antipatterns (LAs), i.e., inconsistencies among the naming, documentation, and implementation of a code entity. While previous studies showed the relevance of LAs for software developers, their impact on (developers of) client projects using APIs affected by LAs has not been investigated. This paper fills this gap by presenting a large-scale study conducted on 1.6k releases of popular Maven libraries, 14k open-source Java projects using these libraries, and 4.4k questions related to the investigated APIs asked on Stack Overflow. In particular, we investigate whether developers of client projects have higher chances of introducing bugs when using APIs affected by LAs and if these trigger more questions on Stack Overflow as compared to non-Affected APIs.},
address = {Madrid, Spain},
author = {Aghajani, Emad and Nagy, Csaba and Bavota, Gabriele and Lanza, Michele},
booktitle = {Proceedings of the 34th International Conference on Software Maintenance and Evolution},
doi = {10.1109/ICSME.2018.00012},
isbn = {978-1-53-867870-1},
keywords = {Application Programming Interfaces (APIs),Empirical Study,Linguistic Antipatterns},
month = {sep},
pages = {25--35},
publisher = {IEEE},
title = {{A Large-scale empirical study on linguistic antipatterns affecting apis}},
year = {2018}
}
@article{Bunge:1963jm,
abstract = {A mathematical theory is proposed and exemplified, which covers an extended class of black boxes. Every kind of stimulus and response is pictured by a channel connecting the box with its environment. The input-output relation is given by a postulate schema according to which the response is, in general, a nonlinear functional of the input. Several examples are worked out: the perfectly transmitting box, the damping box, and the amplifying box. The theory is shown to be (a) an extension of the S-matrix theory and the accompanying channel picture as developed in microphysics; (b) abstract and applicable to any problem involving the transactions of a system (physical, biological, social, etc.) with its milieu; (c) superficial, because unconcerned with either the structure of the box or the nature of the stimuli and responses. The motive for building the theory was to show the capabilities and limitations of the phenomenological approach.},
author = {Bunge, Mario},
doi = {10.1086/287954},
issn = {0031-8248},
journal = {Philosophy of Science},
month = {oct},
number = {4},
pages = {346--358},
title = {{A General Black Box Theory}},
volume = {30},
year = {1963}
}
@book{Creswell:2017vn,
author = {Creswell, John W},
edition = {4th},
isbn = {860-1-40-429618-5},
publisher = {SAGE},
title = {{Research design: Qualitative, quantitative, and mixed methods approaches}},
year = {2017}
}
@article{Huang:2005tc,
abstract = {The area under the ROC (Receiver Operating Characteristics) curve, or simply AUC, has been traditionally used in medical diagnosis since the 1970s. It has recently been proposed as an alternative single-number measure for evaluating the predictive ability of learning algorithms. However, no formal arguments were given as to why AUC should be preferred over accuracy. In this paper, we establish formal criteria for comparing two different measures for learning algorithms and we show theoretically and empirically that AUC is a better measure (defined precisely) than accuracy. We then reevaluate well-established claims in machine learning based on accuracy using AUC and obtain interesting and surprising new results. For example, it has been well-established and accepted that Naive Bayes and decision trees are very similar in predictive accuracy. We show, however, that Naive Bayes is significantly better than decision trees in AUC. The conclusions drawn in this paper may make a significant impact on machine learning and data mining applications. {\textcopyright}2005 IEEE.},
author = {Huang, Jin and Ling, Charles X},
doi = {10.1109/TKDE.2005.50},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {AUC of ROC,Accuracy,Evaluation of learning algorithms,ROC},
number = {3},
pages = {299--310},
title = {{Using AUC and accuracy in evaluating learning algorithms}},
volume = {17},
year = {2005}
}
@article{zurMuehlen:2005ci,
abstract = {This paper presents a case study of the development of standards in the area of cross-organizational workflows based on web services. We discuss two opposing types of standards: those based on SOAP, with tightly coupled designs similar to remote procedure calls, and those based on REST, with loosely coupled designs similar to the navigating of web links. We illustrate the standardization process, clarify the technical underpinnings of the conflict, and analyze the interests of stakeholders. The decision criteria for each group of stakeholders are discussed. Finally, we present implications for both the workflow and the wider Internet communities. {\textcopyright}2004 Elsevier B.V. All rights reserved.},
author = {{Zur Muehlen}, Michael and Nickerson, Jeffrey V and Swenson, Keith D},
doi = {10.1016/j.dss.2004.04.008},
issn = {0167-9236},
journal = {Decision Support Systems},
keywords = {Choreography,Integration,Interoperability,Process,REST,SOAP,Standards,Web services,Workflow},
month = {jul},
number = {1},
pages = {9--29},
title = {{Developing web services choreography standards - The case of REST vs. SOAP}},
volume = {40},
year = {2005}
}
@article{Kononenko:1993td,
abstract = {Although successful in medical diagnostic problems, inductive learning systems were not widely accepted in medical practice. In this paper two different approaches to machine learning in medical applications are compared: the system for inductive learning of decision trees Assistant, and the naive Bayesian classifier. Both methodologies were tested in four medical diagnostic problems: localization of primary tumor, prognostics of recurrence of breast cancer, diagnosis of thyroid diseases, and rheumatology. The accuracy of automatically acquired diagnostic knowledge from stored data records is compared, and the interpretation of the knowledge and the explanation ability of the classification process of each system is discussed. Surprisingly, the naive Bayesian classifier is superior to Assistant in classification accuracy and explanation ability, while the interpretation of the acquired knowledge seems to be equally valuable. In addition, two extensions to naive Bayesian classifier are briefly described: dealing with continuous attributes, and discovering the dependencies among attributes. {\textcopyright}1993 Taylor {\&} Francis Group, LLC.},
author = {Kononenko, Igor},
doi = {10.1080/08839519308949993},
issn = {1087-6545},
journal = {Applied Artificial Intelligence},
number = {4},
pages = {317--337},
title = {{Inductive and bayesian learning in medical diagnosis}},
volume = {7},
year = {1993}
}
@inproceedings{Goodman:2016wf,
abstract = {We summarize the potential impact that the European Union's new General Data Protection Regulation will have on the routine use of machine learning algorithms. Slated to take effect as law across the EU in 2018, it will restrict automated individual decision-making (that is, algorithms that make decisions based on user-level predictors) which "significantly affect" users. The law will also create a "right to explanation," whereby a user can ask for an explanation of an algorithmic decision that was made about them. We argue that while this law will pose large challenges for industry, it highlights opportunities for machine learning researchers to take the lead in designing algorithms and evaluation frameworks which avoid discrimination.},
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {1606.08813},
author = {{Wachter, Mitterlstadt}, Floridi},
booktitle = {Proceedings of the 2016 ICML Workshop on Human Interpretability in Machine Learning},
eprint = {1606.08813},
keywords = {machine learning},
month = {jun},
pages = {26--30},
title = {{EU regulations on algorithmic decision-making and a "right to explanation"}},
url = {http://arxiv.org/abs/1606.08813},
year = {2016}
}
@inproceedings{Inzunza:2018dn,
address = {Naples, Italy},
author = {Inzunza, Sergio and Ju{\'{a}}rez-Ram{\'{i}}rez, Reyes and Jim{\'{e}}nez, Samantha},
booktitle = {Proceedings of the 6th World Conference on Information Systems and Technologies},
doi = {10.1007/978-3-319-77712-2\_22},
month = {mar},
pages = {229--239},
publisher = {Springer},
title = {{API Documentation}},
year = {2018}
}
@article{Myers:2011bt,
abstract = {All software today is written using application programming interfaces (APIs). We performed a user study of the online documentation of a large and complex API for Enterprise Service-Oriented Architecture (eSOA), which identified many issues and recommendations for making API documentation easier to use. eSOA is an appropriate testbed because the target users include high-level business experts who do not have significant programming expertise and thus can be classified as “end-user developers.” Our study showed that the participants' background influenced how they navigated the documentation. Lack of familiarity with business terminology was a barrier for developers without business application experience. Both groups avoided areas of the documentation that had an inconsistent visual design. A new design for the documentation that supports flexible navigation strategies seems to be required to support the wide range of users for eSOA. This paper summarizes our study and provides recommendations for future documentation for APIs.},
author = {Myers, Brad A and Jeong, Sae Young and Xie, Yingyu and Beaton, Jack and Stylos, Jeff and Ehret, Ralf and Karstens, Jan and Efeoglu, Arkin and Busse, Daniela K},
doi = {10.4018/joeuc.2010101903},
issn = {1546-2234},
journal = {Journal of Organizational and End User Computing},
keywords = {Api design,Business solution architects,Documentation,Natural programming,Service-oriented architecture,Usability,Web services},
month = {jan},
number = {1},
pages = {23--51},
publisher = {IGI Global},
title = {{Studying the Documentation of an API for Enterprise Service-Oriented Architecture}},
volume = {22},
year = {2010}
}
@book{Weerawarana:2005wx,
abstract = {``Other books claim to present the complete Web services platform architecture, but this is the first one I've seen that really does. The authors have been intimately involved in the creation of the architecture. Who better to write this book?'' - Anne Thomas Manes, Vice President and Research Director, Burton Group ``This is a very important book, providing a lot of technical detail and background that very few (if any) other books will be able to provide. The list of authors includes some of the top experts in the various specifications covered, and they have done an excellent job explaining the background motivation for and pertinent details of each specification. The benefit of their perspectives and collective expertise alone make the book worth reading.'' - Eric Newcomer, CTO, IONA Technologies},
address = {Crawfordsville, IN, USA},
author = {Weerawarana, Sanjiva and Curbera, Francisco and Leymann, Frank and Storey, Tony and Ferguson, Donald F},
isbn = {0-13-148874-0},
pages = {456},
publisher = {Prentice-Hall},
title = {{Web Services Platform Architecture}},
year = {2005}
}
@article{Fung:2005we,
author = {Fung, Glenn and Sandilya, Sathyakama and Rao, R Bharat},
doi = {10.1007/978-3-540-75390-2_4},
journal = {Studies in Computational Intelligence},
number = {1},
pages = {83--107},
publisher = {Springer},
title = {{Rule extraction from linear support vector machines}},
volume = {80},
year = {2009}
}
@phdthesis{Kim:2015vo,
author = {Kim, Been},
school = {Massachusetts Institute of Technology},
title = {{Interactive and Interpretable Machine Learning Models for Human Machine Collaboration}},
year = {2015}
}
@phdthesis{vasa2010growth,
abstract = {In this thesis we address the problem of identifying where, in successful software systems, maintenance effort tends to be devoted. By examin-ing a larger data set of open source systems we show that maintenance effort is, in general, spent on addition new classes and interestingly, efforts to base new code on stable classes will make those classes less stable as they need to be modified to meet the needs of the new clients. This thesis advances the state of the art in terms of our understanding of how evolving software systems grow and change. We propose an innovative method to better understand growth dynamics in evolving software systems. Rather than relying on the commonly used method of analysing aggregate system size growth over time, we analyze how the probability distribution of a range of software metrics change over time. Using this approach we find that the process of evolution typically drives the popular classes within a software system to gain additional users over time and the increase in popularity makes these classes change-prone.},
address = {Hawthorn, VIC, Australia},
author = {Vasa, Rajesh},
school = {Swinburne University of Technology},
title = {{Growth and Change Dynamics in Open Source Software Systems}},
year = {2010}
}
@inproceedings{Santos2014,
abstract = {Handheld augmented reality (HAR) applications must be carefully designed and improved based on user feedback to sustain commercial use. However, no standard questionnaire considers perceptual and ergonomic issues found in HAR. We address this issue by creating a HAR Usability Scale (HARUS). To create HARUS, we performed a systematic literature review to enumerate user-reported issues in HAR applications. Based on these issues, we created a questionnaire measuring manipulability - the ease of handling the HAR system, and comprehensibility - the ease of understanding the information presented by HAR. We then provide evidences of validity and reliability of the HARUS questionnaire by applying it to three experiments. The results show that HARUS consistently correlates with other subjective and objective measures of usability, thereby supporting its concurrent validity. Moreover, HARUS obtained a good Cronbach's alpha in all three experiments, thereby demonstrating internally consistency. HARUS, as well as its decomposition into individual manipulability and comprehensibility scores, are evaluation tools that researchers and professionals can use to analyze their HAR applications. By providing such a tool, they can gain quality feedback from users to improve their HAR applications towards commercial success.},
author = {Santos, Marc Ericson C. and Polvi, Jarkko and Taketomi, Takafumi and Yamamoto, Goshiro and Sandor, Christian and Kato, Hirokazu},
booktitle = {Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST},
doi = {10.1145/2671015.2671019},
isbn = {9781450332538},
keywords = {Augmented reality,Evaluation method,Handheld devices,Usability,User studies},
title = {{Usability scale for handheld augmented reality}},
year = {2014}
}
@inproceedings{Pazzani:1997vp,
address = {Washington, DC, USA},
author = {Pazzani, M},
booktitle = {Proceedings of the First Federal Data Mining Conference and Exposition},
pages = {73--82},
title = {{Comprehensible knowledge discovery: gaining insight from data}},
year = {1997}
}
@book{Judd:1991ug,
author = {Judd, C M and Smith, E R and Kidder, L H},
editor = {Kidder, L H},
isbn = {978-0-03-031149-9},
publisher = {Holt, Rinehart, and Winston},
title = {{Research Methods in Social Relations}},
year = {1991}
}
@inproceedings{Jeong:2009tu,
abstract = {All software today is written using libraries, toolkits, frameworks and other application programming interfaces (APIs). We performed a user study of the online documentation a large and complex API for Enterprise Service-Oriented Architecture (eSOA), which identified many issues and recommendations for making API documentation easier to use. eSOA is an appropriate testbed because the target user groups range from high-level business experts who do not have significant programming expertise (and thus are end-participant developers), to professional programmers. Our study showed that the participants' background influenced how they navigated the documentation. Lack of familiarity with business terminology was a barrier we observed for developers without business application experience. Participants with business software experience had difficulty differentiating similarly named services. Both groups avoided areas of the documentation that had an inconsistent visual design. A new design for the documentation that supports flexible navigation strategies seem to be required to support the wide range of users for eSOA. This paper summarizes our study and provides recommendations for future documentation for developers. {\textcopyright} 2009 Springer Berlin Heidelberg.},
address = {Siegen, Germany},
author = {Jeong, Sae Young and Xie, Yingyu and Beaton, Jack and Myers, Brad A. and Stylos, Jeff and Ehret, Ralf and Karstens, Jan and Efeoglu, Arkin and Busse, Daniela K.},
booktitle = {Proceedings of the First International Symposium on End User Development},
doi = {10.1007/978-3-642-00427-8\_6},
issn = {0302-9743},
keywords = {API Design,Business Solution Architects,Documentation,Service-Oriented Architecture,Usability,Web Services},
month = {mar},
pages = {86--105},
publisher = {Springer},
title = {{Improving documentation for eSOA APIs through user studies}},
volume = {5435 LNCS},
year = {2009}
}
@inproceedings{Shepperd:2018hr,
abstract = {Context: There is growing interest in establishing software engineering as an evidence-based discipline. To that end, replication is often used to gain confidence in empirical findings, as opposed to reproduction where the goal is showing the correctness, or validity of the published results. Objective: To consider what is required for a replication study to confirm the original experiment and apply this understanding in software engineering. Method: Simulation is used to demonstrate why the prediction interval for confirmation can be surprisingly wide. This analysis is applied to three recent replications. Results: It is shown that because the prediction intervals are wide, almost all replications are confirmatory, so in that sense there is no 'replication crisis', however, the contributions to knowledge are negligible. Conclusion: Replicating empirical software engineering experiments, particularly if they are under-powered or under-reported, is a waste of scientific resources. By contrast, meta-analysis is strongly advocated so that all relevant experiments are combined to estimate the population effect.},
address = {Gothenburg, Sweden},
archivePrefix = {arXiv},
arxivId = {1802.04580},
author = {Shepperd, Martin},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
doi = {10.1145/3183399.3183423},
eprint = {1802.04580},
isbn = {978-1-45-035662-6},
issn = {0270-5257},
keywords = {Software engineering,empirical study,evidence,replication},
month = {may},
pages = {73--76},
publisher = {ACM},
title = {{Replication studies considered harmful}},
year = {2018}
}
@book{Jin:2006uf,
address = {Berlin, Heidelberg},
author = {Jin, Yaochu},
doi = {10.1007/3-540-33019-4},
isbn = {978-3-54-030676-4},
publisher = {Springer},
series = {Studies in Computational Intelligence},
title = {{Multi-Objective Machine Learning}},
year = {2006}
}
@inproceedings{Pautasso2008,
abstract = {Recent technology trends in the Web Services (WS) domain indicate that a solution eliminating the presumed complexity of the WS-* standards may be in sight: advocates of REpresentational State Transfer (REST) have come to believe that their ideas explaining why the World Wide Web works are just as applicable to solve enterprise application integration problems and to simplify the plumbing required to build service-oriented architectures. In this paper we objectify the WS-* vs. REST debate by giving a quantitative technical comparison based on architectural principles and decisions. We show that the two approaches differ in the number of architectural decisions that must be made and in the number of available alternatives. This discrepancy between freedom-from-choice and freedom-of-choice explains the complexity difference perceived. However, we also show that there are significant differences in the consequences of certain decisions in terms of resulting development and maintenance costs. Our comparison helps technical decision makers to assess the two integration styles and technologies more objectively and select the one that best fits their needs: REST is well suited for basic, ad hoc integration scenarios, WS-* is more flexible and addresses advanced quality of service requirements commonly occurring in enterprise computing.},
address = {Beijing, China},
author = {Pautasso, Cesare and Zimmermann, Olaf and Leymann, Frank},
booktitle = {Proceedings of the 17th International Conference on World Wide Web},
doi = {10.1145/1367497.1367606},
isbn = {978-1-60-558085-2},
keywords = {Architectural decision modeling,HTTP,REST,Resource oriented architecture,SOAP,Service oriented architecture,Technology comparison,WS-* vs. REST,WSDL,Web services},
month = {apr},
publisher = {ACM},
title = {{RESTful web services vs. "Big" web services: Making the right architectural decision}},
year = {2008}
}
@inproceedings{Petersen:2008td,
abstract = {BACKGROUND: A software engineering systematic map is a defined method to build a classification scheme and structure a software engineering field of interest. The analysis of results focuses on frequencies of publications for categories within the scheme. Thereby, the coverage of the research field can be determined. Different facets of the scheme can also be combined to answer more specific research questions. OBJECTIVE: We describe how to conduct a systematic mapping study in software engineering and provide guidelines. We also compare systematic maps and systematic reviews to clarify how to chose between them. This comparison leads to a set of guidelines for systematic maps. METHOD: We have defined a systematic mapping process and applied it to complete a systematic mapping study. Furthermore, we compare systematic maps with systematic reviews by systematically analyzing existing systematic reviews. RESULTS: We describe a process for software engineering systematic mapping studies and compare it to systematic reviews. Based on this, guidelines for conducting systematic maps are defined. CONCLUSIONS: Systematic maps and reviews are different in terms of goals, breadth, validity issues and implications. Thus, they should be used complementarily and require different methods (e.g., for analysis).},
author = {Petersen, Kai and Feldt, Robert and Mujtaba, Shahid and Mattsson, Michael},
booktitle = {Proceedings of the 12th International Conference on Evaluation and Assessment in Software Engineering, EASE 2008},
doi = {10.14236/ewic/ease2008.8},
keywords = {Evidence based software engineering,Systematic mapping studies,Systematic reviews},
pages = {68--77},
title = {{Systematic mapping studies in software engineering}},
year = {2008}
}
@book{Rokach:2008wc,
abstract = {This is the first comprehensive book dedicated entirely to the field of decision trees in data mining and covers all aspects of this important technique. Decision trees have become one of the most powerful and popular approaches in knowledge discovery and data mining, the science and technology of exploring large and complex bodies of data in order to discover useful patterns. The area is of great importance because it enables modeling and knowledge extraction from the abundance of data available. Both theoreticians and practitioners are continually seeking techniques to make the process more efficient, cost-effective and accurate. Decision trees, originally implemented in decision theory and statistics, are highly effective tools in other areas such as data mining, text mining, information extraction, machine learning, and pattern recognition.This book invites readers to explore the many benefits in data mining that decision trees offer: self-explanatory and easy to follow when compacted; able to handle a variety of input data: nominal, numeric and textual; able to process datasets that may have errors or missing values; high predictive performance for a relatively small computational effort; available in many data mining packages over a variety of platforms; and, useful for various tasks, such as classification, regression, clustering and feature selection.},
author = {Lori, Rokach and Oded, Maimon},
isbn = {978-9-81-277171-1},
pages = {244},
publisher = {World Scientific Publishing Company},
title = {{Data mining with decision trees}},
volume = {69},
year = {2008}
}
@article{Gamer:tj,
author = {Gamer, M and Lemon, J and Fellows, I and Singh, P},
journal = {R package version 0.83},
title = {{Irr: various coefficients of interrater reliability}},
year = {2010}
}
@article{rgensen:2016gl,
abstract = {Context The trustworthiness of research results is a growing concern in many empirical disciplines. Aim The goals of this paper are to assess how much the trustworthiness of results reported in software engineering experiments is affected by researcher and publication bias, given typical statistical power and significance levels, and to suggest improved research practices. Method First, we conducted a small-scale survey to document the presence of researcher and publication biases in software engineering experiments. Then, we built a model that estimates the proportion of correct results for different levels of researcher and publication bias. A review of 150 randomly selected software engineering experiments published in the period 2002-2013 was conducted to provide input to the model. Results The survey indicates that researcher and publication bias is quite common. This finding is supported by the observation that the actual proportion of statistically significant results reported in the reviewed papers was about twice as high as the one expected assuming no researcher and publication bias. Our models suggest a high proportion of incorrect results even with quite conservative assumptions. Conclusion Research practices must improve to increase the trustworthiness of software engineering experiments. A key to this improvement is to avoid conducting studies with unsatisfactory low statistical power.},
author = {J{\o}rgensen, Magne and Dyb{\aa}, Tore and Liest{\o}l, Knut and Sj{\o}berg, Dag I K},
doi = {10.1016/j.jss.2015.03.065},
issn = {0164-1212},
journal = {Journal of Systems and Software},
keywords = {Controlled experiments,Empirical software engineering,Statistical hypothesis testing},
pages = {133--145},
title = {{Incorrect results in software engineering experiments: How to improve research practices}},
volume = {116},
year = {2016}
}
@article{Friedman:1997vs,
abstract = {Recent work in supervised learning has shown that a surprisingly simple Bayesian classifier with strong assumptions of independence among features, called naive Bayes, is competitive with state-of-the-art classifiers such as C4.5. This fact raises the question of whether a classifier with less restrictive assumptions can perform even better. In this paper we evaluate approaches for inducing classifiers from data, based on the theory of learning Bayesian networks. These networks are factored representations of probability distributions that generalize the naive Bayesian classifier and explicitly represent statements about independence. Among these approaches we single out a method we call Tree Augmented Naive Bayes (TAN), which outperforms naive Bayes, yet at the same time maintains the computational simplicity (no search involved) and robustness that characterize naive Bayes. We experimentally tested these approaches, using problems from the University of California at Irvine repository, and compared them to C4.5, naive Bayes, and wrapper methods for feature selection.},
author = {Friedman, Nir and Geiger, Dan and Goldszmidt, Moises},
doi = {10.1002/9780470400531.eorms0099},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {Bayesian networks,Classification},
number = {2-3},
pages = {131--163},
title = {{Bayesian Network Classifiers}},
volume = {29},
year = {1997}
}
@inproceedings{StrapparavaWordNet-Affect:WordNet,
address = {Lisbon, Portugal},
author = {Strapparava, Carlo and Valitutti, Alessandro},
booktitle = {Proceedings of the 4th International Conference on Language Resources and Evaluation},
month = {may},
pages = {1083--1086},
publisher = {European Language Resources Association (ELRA)},
title = {{WordNet-Affect: an Affective Extension of WordNet}},
year = {2004}
}
@inproceedings{Abadi:2016vn,
abstract = {TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. TensorFlow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous "parameter server" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with particularly strong support for training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model in contrast to existing systems, and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.},
address = {Savannah, GA, USA},
archivePrefix = {arXiv},
arxivId = {1605.08695},
author = {Abadi, Mart{\'{i}}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
booktitle = {Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation},
eprint = {1605.08695},
isbn = {978-1-93-197133-1},
pages = {265--283},
publisher = {ACM},
title = {{TensorFlow: A system for large-scale machine learning}},
year = {2016}
}
@article{calefato2018,
author = {Calefato, Fabio and Lanubile, Filippo and Maiorano, Federico and Novielli, Nicole},
doi = {10.1007/s10664-017-9546-9},
journal = {Empirical Software Engineering},
number = {3},
pages = {1352--1382},
publisher = {Springer},
title = {{Sentiment polarity detection for software development}},
volume = {23},
year = {2018}
}
@book{Tassey:2002vu,
abstract = {N/A},
author = {Tassey, Gregory},
booktitle = {National Institute of Standards and Technology (NIST)},
doi = {10.1080/10438590500197315},
isbn = {978-0-75-672618-8},
month = {sep},
publisher = {National Institute of Standards and Technology},
title = {{The economic impacts of inadequate infrastructure for software testing}},
year = {2002}
}
@article{Geiger:2018fv,
abstract = {Computational research and data analytics increasingly relies on complex ecosystems of open source software (OSS) “libraries” – curated collections of reusable code that programmers import to perform a specific task. Software documentation for these libraries is crucial in helping programmers/analysts know what libraries are available and how to use them. Yet documentation for open source software libraries is widely considered low-quality. This article is a collaboration between CSCW researchers and contributors to data analytics OSS libraries, based on ethnographic fieldwork and qualitative interviews. We examine several issues around the formats, practices, and challenges around documentation in these largely volunteer-based projects. There are many different kinds and formats of documentation that exist around such libraries, which play a variety of educational, promotional, and organizational roles. The work behind documentation is similarly multifaceted, including writing, reviewing, maintaining, and organizing documentation. Different aspects of documentation work require contributors to have different sets of skills and overcome various social and technical barriers. Finally, most of our interviewees do not report high levels of intrinsic enjoyment for doing documentation work (compared to writing code). Their motivation is affected by personal and project-specific factors, such as the perceived level of credit for doing documentation work versus more ‘technical' tasks like adding new features or fixing bugs. In studying documentation work for data analytics OSS libraries, we gain a new window into the changing practices of data-intensive research, as well as help practitioners better understand how to support this often invisible and infrastructural work in their projects.},
author = {Geiger, R. Stuart and Varoquaux, Nelle and Mazel-Cabasse, Charlotte and Holdgraf, Chris},
doi = {10.1007/s10606-018-9333-1},
issn = {1573-7551},
journal = {Computer Supported Cooperative Work: CSCW: An International Journal},
keywords = {Collaboration,Documentation,Ethnography,Infrastructure,Invisible work,Motivations,Open source,Peer production,Standards},
month = {may},
number = {3-6},
pages = {767--802},
title = {{The Types, Roles, and Practices of Documentation in Data Analytics Open Source Software Libraries: A Collaborative Ethnography of Documentation Work}},
volume = {27},
year = {2018}
}
@inproceedings{Beyer:2014ec,
abstract = {While many tutorials, code examples, and documentation about Android APIs exist, developers still face various problems with the implementation of Android Apps. Many of these issues are discussed on Q{\&}A-sites, such as Stack Overflow. In this paper we present a manual categorization of 450 Android related posts of Stack Overflow concerning their question and problem types. The idea is to find dependencies between certain problems and question types to get better insights into issues of Android App development. The categorization is developed using card sorting with three experienced Android App developers. An initial approach to automate the classification of Stack Overflow posts using Lucene is also presented. The study highlights that the most common question types are 'How to⋯?' and 'What is the problem⋯?'. The problems that are discussed most often are related to 'User Interface' and 'Core Elements'. In particular, the problem category 'Layout' is often related to 'What is the problem⋯?' and 'Frameworks' issues often come with 'Is it possible⋯?' questions.},
address = {Victoria, BC, Canada},
author = {Beyer, Stefanie and Pinzger, Martin},
booktitle = {Proceedings of the 30th International Conference on Software Maintenance and Evolution},
doi = {10.1109/ICSME.2014.88},
isbn = {978-0-76-955303-0},
month = {sep},
pages = {531--535},
publisher = {IEEE},
title = {{A manual categorization of android app development issues on stack overflow}},
year = {2014}
}
@inproceedings{Craven:1995wg,
abstract = {A significant limitation of neural networks is that the representations they learn are usually incomprehensible to humans. We present a novel algorithm, Trepan, for extracting comprehensible, symbolic representations from trained neural networks. Our algorithm uses queries to induce a decision tree that approximates the concept represented by a given network. Our experiments demonstrate that Trepan is able to produce decision trees that maintain a high level of fidelity to their respective...},
address = {Denver, CO, USA},
author = {Craven, Mark W and Shavlik, Jude W},
booktitle = {Proceedings of the 8th International Conference on Neural Information Processing Systems},
isbn = {978-0-26-220107-0},
month = {dec},
pages = {24--30},
publisher = {MIT Press},
title = {{Extracting tree-structured representations of trained neural networks}},
volume = {8},
year = {1996}
}
@inproceedings{Cummaudo:2019esem,
abstract = {Background: Good API documentation facilitates the development process, improving productivity and quality. While the topic of API documentation quality has been of interest for the last two decades, there have been few studies to map the specific constructs needed to create a good document. In effect, we still need a structured taxonomy that captures such knowledge systematically.Aims: This study reports emerging results of a systematic mapping study. We capture key conclusions from previous studies that assess API documentation quality, and synthesise the results into a single framework.Method: By conducting a systematic review of 21 key works, we have developed a five dimensional taxonomy based on 34 categorised weighted recommendations.Results: All studies utilise field study techniques to arrive at their recommendations, with seven studies employing some form of interview and questionnaire, and four conducting documentation analysis. The taxonomy we synthesise reinforces that usage description details (code snippets, tutorials, and reference documents) are generally highly weighted as helpful in API documentation, in addition to design rationale and presentation.Conclusions: We propose extensions to this study aligned to developer utility for each of the taxonomy's categories.},
address = {Porto de Galinhas, Recife, Brazil},
author = {Cummaudo, Alex and Vasa, Rajesh and Grundy, John},
booktitle = {Proceedings of the 13th International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2019.8870148},
isbn = {978-1-72-812968-6},
issn = {1949-3789},
keywords = {API,DevX,documentation,systematic mapping study,taxonomy},
month = {oct},
pages = {1--6},
publisher = {IEEE},
title = {{What should I document? A preliminary systematic mapping study into API documentation knowledge}},
year = {2019}
}
@book{Calhoun:1995ww,
author = {Alway, Joan and Calhoun, Craig},
booktitle = {Contemporary Sociology},
doi = {10.2307/2076647},
issn = {0094-3061},
number = {1},
pages = {119--120},
publisher = {American Sociological Association},
title = {{Critical Social Theory: Culture, History, and the Challenge of Difference.}},
volume = {26},
year = {1997}
}
@misc{Ballinger:2014aa,
annote = {Accessed: 28 August 2018},
author = {Ballinger, Keith},
month = {dec},
title = {{Simplicity and Utility, or, Why SOAP Lost}},
url = {http://bit.ly/37vLms0},
year = {2014}
}
@inproceedings{Ribeiro:2016gg,
address = {San Francisco, CA, USA},
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {2939672.2939778},
month = {aug},
pages = {1135--1144},
publisher = {ACM},
title = {{`Why Should I Trust You?': Explaining the Predictions of Any Classifier}},
year = {2016}
}
@inproceedings{Ko:2011fb,
abstract = {While many studies have investigated the challenges that developers face in finding and using API documentation, few have considered the role of developers' conceptual knowledge in these tasks. We designed a study in which developers were asked to explore the feasibility of two requirements concerning networking protocols and application platforms that most participants were unfamiliar with, observing the effect that a lack of conceptual knowledge had on their use of documentation. Our results show that without conceptual knowledge, developers struggled to formulate effective queries and to evaluate the relevance or meaning of content they found. Our results suggest that API documentation should not only include detailed examples of API use, but also thorough introductions to the concepts, standards, and ideas manifested in an API's data structures and functionality. {\textcopyright}2011 IEEE.},
address = {Pittsburgh, PA, USA},
author = {Ko, Andrew J and Riche, Yann},
booktitle = {Proceedings of the 2011 IEEE Symposium on Visual Languages and Human Centric Computing},
doi = {10.1109/VLHCC.2011.6070395},
isbn = {978-1-45-771245-6},
keywords = {API usability,documentation,feasibility},
month = {sep},
pages = {173--176},
publisher = {IEEE},
title = {{The role of conceptual knowledge in API usability}},
year = {2011}
}
@inproceedings{Renzella2019,
author = {Renzella, J and Cummaudo, A and Cain, A and Grundy, J and Meyers, J},
booktitle = {Proceedings of 2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering, TALE 2018},
doi = {10.1109/TALE.2018.8615203},
title = {{SplashKit: A Development Framework for Motivating and Engaging Students in Introductory Programming}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-85062079204{\&}partnerID=MN8TOARS},
year = {2019}
}
@book{Yin:2017tf,
address = {Los Angeles, CA, USA},
author = {Yin, Robert K},
edition = {6th},
isbn = {978-1-50-633616-9},
publisher = {SAGE},
title = {{Case study research and applications: Design and methods}},
year = {2017}
}
@article{Hohman2018VisualAI,
abstract = {Deep learning has recently seen rapid development and received significant attention due to its state-of-the-art performance on previously-thought hard problems. However, because of the internal complexity and nonlinear structure of deep neural networks, the underlying decision making processes for why these models are achieving such performance are challenging and sometimes mystifying to interpret. As deep learning spreads across domains, it is of paramount importance that we equip users of deep learning with tools for understanding when a model works correctly, when it fails, and ultimately how to improve its performance. Standardized toolkits for building neural networks have helped democratize deep learning; visual analytics systems have now been developed to support model explanation, interpretation, debugging, and improvement. We present a survey of the role of visual analytics in deep learning research, which highlights its short yet impactful history and thoroughly summarizes the state-of-the-art using a human-centered interrogative framework, focusing on the Five W's and How (Why, Who, What, How, When, and Where). We conclude by highlighting research directions and open research problems. This survey helps researchers and practitioners in both visual analytics and deep learning to quickly learn key aspects of this young and rapidly growing body of research, whose impact spans a diverse range of domains.},
archivePrefix = {arXiv},
arxivId = {1801.06889},
author = {Hohman, Fred and Kahng, Minsuk and Pienta, Robert and Chau, Duen Horng},
doi = {10.1109/TVCG.2018.2843369},
eprint = {1801.06889},
issn = {1941-0506},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Deep learning,information visualization,neural networks,visual analytics},
number = {8},
pages = {2674--2693},
title = {{Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers}},
volume = {25},
year = {2019}
}
@article{Rosen:2016uk,
abstract = {The popularity of mobile devices has been steadily growing in recent years. These devices heavily depend on software from the underlying operating systems to the applications they run. Prior research showed that mobile software is different than traditional, large software systems. However, to date most of our research has been conducted on traditional software systems. Very little work has focused on the issues that mobile developers face. Therefore, in this paper, we use data from the popular online Q{\&}A site, Stack Overflow, and analyze 13,232,821 posts to examine what mobile developers ask about. We employ Latent Dirichlet allocation-based topic models to help us summarize the mobile-related questions. Our findings show that developers are asking about app distribution, mobile APIs, data management, sensors and context, mobile tools, and user interface development. We also determine what popular mobile-related issues are the most difficult, explore platform specific issues, and investigate the types (e.g., what, how, or why) of questions mobile developers ask. Our findings help highlight the challenges facing mobile developers that require more attention from the software engineering research and development communities in the future and establish a novel approach for analyzing questions asked on Q{\&}A forums.},
author = {Rosen, Christoffer and Shihab, Emad},
doi = {10.1007/s10664-015-9379-3},
issn = {1573-7616},
journal = {Empirical Software Engineering},
keywords = {Mobile issues,Mobile software development,Stack overflow},
number = {3},
pages = {1192--1223},
title = {{What are mobile developers asking about? A large scale study using stack overflow}},
volume = {21},
year = {2016}
}
@inproceedings{novielli2018,
address = {Gothenburg, Sweden},
author = {Novielli, Nicole and Calefato, Fabio and Lanubile, Filippo},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
doi = {10.1145/3196398.3196453},
isbn = {9781450357166},
month = {may},
pages = {14--17},
publisher = {ACM},
title = {{A gold standard for emotion annotation in stack overflow}},
year = {2018}
}
@article{Parasuraman:1988wh,
abstract = {This paper describes the development of a 22-item instrument (called SERVQUAL) for assessing customer perceptions of service quality in service and retailing organizations. After a discussion of the conceptualization and operationalization of the service quality construct, the procedures used in constructing and refining a multiple-item scale to measure the construct are described. Evidence of the scale's reliability, factor structure, and validity on the basis of analyzing data from four independent samples is presented next. The paper concludes with a discussion of potential applications of the scale.},
author = {Berry, Leonard L and Parasuraman, A and Zeithaml, Valarie A},
doi = {10.1016/S0148-2963(99)00084-3},
isbn = {00224359},
issn = {0022-4359},
journal = {Journal of Retailing},
number = {1},
pages = {12--40},
pmid = {6353339},
title = {{SERVQUAL: A multiple-item scale for measuring consumer perceptions of service quality}},
volume = {64},
year = {1988}
}
@inproceedings{Boz:2002uv,
abstract = {Neural Networks are successful in acquiring hidden knowledge in datasets. Their biggest weakness is that the knowledge they acquire is represented in a form not understandable to humans. Researchers tried to address this problem by extracting rules from trained Neural Networks. Most of the proposed rule extraction methods required specialized type of Neural Networks; some required binary inputs and some were computationally expensive. Craven proposed extracting MofN type Decision Trees from Neural Networks. We believe MofN type Decision Trees are only good for MofN type problems and trees created for regular high dimensional real world problems may be very complex. In this paper, we introduced a new method for extracting regular C4.5 like Decision Trees from trained Neural Networks. We showed that the new method (DecText) is effective in extracting high fidelity trees from trained networks. We also introduced a new discretization technique to make DecText be able to handle continuous features and a new pruning technique for finding simplest tree with the highest fidelity.},
address = {Edmonton, AB, Canada},
author = {Boz, Olcay},
booktitle = {Proceedings of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/775107.775113},
month = {jul},
pages = {456--461},
publisher = {ACM},
title = {{Extracting decision trees from trained neural networks}},
year = {2002}
}
@inproceedings{Lakkaraju:2016ka,
abstract = {One of the most important obstacles to deploying predictive models is the fact that humans do not understand and trust them. Knowing which variables are important in a model's prediction and how they are combined can be very powerful in helping people understand and trust automatic decision making systems. Here we propose interpretable decision sets, a framework for building predictive models that are highly accurate, yet also highly interpretable. Decision sets are sets of independent if-then rules. Because each rule can be applied independently, decision sets are simple, concise, and easily interpretable. We formalize decision set learning through an objective function that simultaneously optimizes accuracy and interpretability of the rules. In particular, our approach learns short, accurate, and non-overlapping rules that cover the whole feature space and pay attention to small but important classes. Moreover, we prove that our objective is a nonmonotone submodular function, which we efficiently optimize to find a near-optimal set of rules. Experiments show that interpretable decision sets are as accurate at classification as state-of-the-art machine learning techniques. They are also three times smaller on average than rule-based models learned by other methods. Finally, results of a user study show that people are able to answer multiple-choice questions about the decision boundaries of interpretable decision sets and write descriptions of classes based on them faster and more accurately than with other rule-based models that were designed for interpretability. Overall, our framework provides a new approach to interpretable machine learning that balances accuracy, interpretability, and computational efficiency.},
address = {San Francisco, CA, USA},
author = {Lakkaraju, Himabindu and Bach, Stephen H and Leskovec, Jure},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/2939672.2939874},
isbn = {978-1-45-034232-2},
month = {aug},
pages = {1675--1684},
publisher = {ACM},
title = {{Interpretable decision sets: A joint framework for description and prediction}},
year = {2016}
}
@article{Marshall:2018uj,
abstract = {This paper presents a cognitive computing model, based on artificial intelligence (AI) technologies, supporting task automation in the accounting industry. Drivers and consequences of task automation, globally and in accounting, are reviewed. A framework supporting cognitive task automation is discussed. The paper recognizes essential differences between cognitive computing and data analytics. Cognitive computing technologies that support task automation are incorporated into a model delivering federated knowledge. The impact of task automation on accounting job roles and the resulting creation of new accounting job roles supporting innovation are presented. The paper develops a hypothetical use case of building a cloud-based intelligent accounting application design, defined as cognitive services, using machine learning based on AI. The paper concludes by recognizing the significance of future research into task automation in accounting and suggests the federated knowledge model as a framework for future research into the process of digital transformation based on cognitive computing.},
author = {Marshall, Thomas Edward and Lambert, Sherwood Lane},
doi = {10.2308/jeta-52095},
issn = {1558-7940},
journal = {Journal of Emerging Technologies in Accounting},
keywords = {Artificial intelligence,Augmented intelligence,Cognitive computing,Task automation,Workforce},
number = {1},
pages = {199--215},
title = {{Cloud-based intelligent accounting applications: Accounting task automation using IBM watson cognitive computing}},
volume = {15},
year = {2018}
}
@inproceedings{covington2016deep,
abstract = {YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous userfacing impact.},
address = {Boston, MA, USA},
author = {Covington, Paul and Adams, Jay and Sargin, Emre},
booktitle = {Proceedings of the 10th ACM Conference on Recommender Systems},
doi = {10.1145/2959100.2959190},
isbn = {978-1-45-034035-9},
keywords = {Deep learning,Recommender system,Scalability},
month = {sep},
pages = {191--198},
publisher = {ACM},
title = {{Deep neural networks for youtube recommendations}},
year = {2016}
}
@inproceedings{Bottomley:2005fs,
abstract = {There are few resources geared to technical writers working on documentation for software developers. This paper presents the results of online surveys and telephone interviews that cover the experience, technical knowledge, and practices of technical writers in this area, with a large percentage of respondents who are Microsoft employees. Respondents value strong writing skills and the ability to learn quickly and continuously, with the amount and type of knowledge needed being specific to the subject area and audience for their work. {\textcopyright} 2005 IEEE.},
address = {Limerick, Ireland},
author = {Bottomley, Christina},
booktitle = {Proceedings of the 2005 IEEE International Professional Communication Conference},
doi = {10.1109/IPCC.2005.1494255},
keywords = {API Documentation,Developer documentation,Documentation,Programmer Writer,SDK Documentation,Technical Writer},
month = {jul},
pages = {802--812},
publisher = {IEEE},
title = {{What part writer? What part programmer? A survey of practices and knowledge used in programmer writing}},
year = {2005}
}
@article{WordNetMiller1995,
abstract = {This database links English nouns, verbs, adjectives, and adverbs to sets of synonyms that are in turn linked through semantic relations that determine word definitions. {\textcopyright}1995, ACM. All rights reserved.},
address = {New York, NY, USA},
author = {Miller, George A},
doi = {10.1145/219717.219748},
issn = {1557-7317},
journal = {Communications of the ACM},
month = {nov},
number = {11},
pages = {39--41},
publisher = {ACM},
title = {{WordNet: A Lexical Database for English}},
volume = {38},
year = {1995}
}
@inproceedings{Narayanan:2002ti,
abstract = {Web services - Web-accessible programs and devices - are a key application area for the Semantic Web. With the proliferation of Web services and the evolution towards the Semantic Web comes the opportunity to automate various Web services tasks. Our objective is to enable markup and automated reasoning technology to describe, simulate, compose, test, and verify compositions of Web services. We take as our starting point the DAML-S DAML+OIL ontology for describing the capabilities of Web services. We define the semantics for a relevant subset of DAML-S in terms of a first-order logical language. With the semantics in hand, we encode our service descriptions in a Petri Net formalism and provide decision procedures for Web service simulation, verification and composition. We also provide an analysis of the complexity of these tasks under different restrictions to the DAML-S composite services we can describe. Finally, we present an implementation of our analysis techniques. This implementation takes as input a DAML-S description of a Web service, automatically generates a Petri Net and performs the desired analysis. Such a tool has broad applicability both as a back end to existing manual Web service composition tools, and as a stand-alone tool for Web service developers.},
address = {Honolulu, HI, USA},
author = {Narayanan, Srini and McIlraith, Sheila A},
booktitle = {Proceedings of the 11th International Conference on World Wide Web},
doi = {10.1145/511446.511457},
isbn = {1-58-113449-5},
keywords = {Automated reasoning,DAML,Distributed systems,Ontologies,Semantic web,Web service composition,Web services},
month = {may},
pages = {77--88},
publisher = {ACM},
title = {{Simulation, verification and automated composition of web services}},
year = {2002}
}
@misc{ISO9126:1999,
author = {{International Organization for Standardization}},
month = {nov},
title = {{ISO/IEC 9126 Information Technology - Software Product Evaluation - Quality Characteristics and Guidelines for Their Use}},
url = {http://bit.ly/2tgMHUE},
year = {1999}
}
@article{Sun:2010ut,
abstract = {Null hypothesis significance testing has dominated quantitative research in education and psychology. However, the statistical significance of a test as indicated by a p-value does not speak to the practical significance of the study. Thus, reporting effect size to supplement p-value is highly recommended by scholars, journal editors, and academic associations. As a measure of practical significance, effect size quantifies the size of mean differences or strength of associations and directly answers the research questions. Furthermore, a comparison of effect sizes across studies facilitates meta-analytic assessment of the effect size and accumulation of knowledge. In the current comprehensive review, we investigated the most recent effect size reporting and interpreting practices in 1,243 articles published in 14 academic journals from 2005 to 2007. Overall, 49{\%} of the articles reported effect size-57{\%} of which interpreted effect size. As an empirical study for the sake of good research methodology in education and psychology, in the present study we provide an illustrative example of reporting and interpreting effect size in a published study. Furthermore, a 7-step guideline for quantitative researchers is also summarized along with some recommended resources on how to understand and interpret effect size. {\textcopyright}2010 American Psychological Association.},
author = {Sun, Shuyan and Pan, Wei and Wang, Lihshing Leigh},
doi = {10.1037/a0019507},
issn = {0022-0663},
journal = {Journal of Educational Psychology},
keywords = {Confidence intervals,Effect size,NHST,Practical significance,Statistical significance},
number = {4},
pages = {989--1004},
title = {{A Comprehensive Review of Effect Size Reporting and Interpreting Practices in Academic Journals in Education and Psychology}},
volume = {102},
year = {2010}
}
@inproceedings{Piccioni:2013em,
abstract = {Modern software development extensively involves reusing library components accessed through their Application Programming Interfaces (APIs). Usability is therefore a fundamental goal of API design, but rigorous empirical studies of API usability are still relatively uncommon. In this paper, we present the design of an API usability study which combines interview questions based on the cognitive dimensions framework, with systematic observations of programmer behavior while solving programming tasks based on ''tokens''. We also discuss the implementation of the study to assess the usability of a persistence library API (offering functionalities such as storing objects into relational databases). The study involved 25 programmers (including students, researchers, and professionals), and provided additional evidence to some critical features evidenced by related studies, such as the difficulty of finding good names for API features and of discovering relations between API types. It also discovered new issues relevant to API design, such as the impact of flexibility, and confirmed the crucial importance of accurate documentation for usability. {\textcopyright}2013 IEEE.},
address = {Baltimore, MD, USA},
author = {Piccioni, Marco and Furia, Carlo A and Meyer, Bertrand},
booktitle = {Proceedings of the 13th International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2013.14},
issn = {1949-3770},
keywords = {application programming interfaces},
month = {oct},
pages = {5--14},
publisher = {IEEE},
title = {{An empirical study of API usability}},
year = {2013}
}
@inproceedings{Ortiz:2017wg,
author = {Ortiz, Andres L Martinez},
booktitle = {EIAPortugal},
month = {jul},
title = {{Curating Content with Google Machine Learning Application Programming Interfaces}},
url = {http://bit.ly/2S40er8},
year = {2017}
}
@techreport{RightScaleInc:2018kJ,
abstract = {In January 2016, RightScale surveyed 1,060 technical professionals across a broad cross-section of organizations about their adoption of cloud computing. The company published its annual State of the Cloud Report on February 9, 2016. We also asked a number of additional questions about their adoption of DevOps and use of DevOps tools, including Docker. In this DevOps Trends report, we offer a deep dive into those responses as well as some additional analysis about DevOps. The 2016 State of the Cloud Survey identified several key findings: DevOps growing especially in the enterprise. • DevOps adoption increased from 66 percent in 2015 to 74 percent in 2016. • DevOps adoption is strongest in the enterprise (81 percent of enterprises adopting DevOps compared to 70 percent in SMBs). • Enterprises are adopting DevOps from the bottom up: projects or teams (29 percent) and business units or divisions (31 percent), company-wide (21 percent). Docker},
author = {{RightScale Inc.}},
pages = {1--19},
title = {{State of the Cloud Report: DevOps Trends}},
year = {2016}
}
@book{Grunwald:2007vg,
abstract = {A recent study of ovariectomized monkeys, treated with recombinant human parathyroid hormone (rhPTH)(1-34) at 1 or 5 mg/kg/day for 18 months or for 12 months followed by 6 months withdrawal from treatment, showed significant differences in the geometry and histomorphometry of cortical bone of the midshaft humerus. To determine the extent to which the rapid bone turnover and cortical porosity induced by rhPTH(1-34) in ovariectomized monkeys modified mineral content, mineral crystal maturity and collagen maturity (cross-link distribution) in the cortical periosteal and endosteal regions, cross-sections of the cortical bone of the mid-humerus, were examined using Fourier transform infrared imaging (FTIRI). FTIRI analyses demonstrated that rhPTH(1-34) altered bone mineral and collagen properties in a dose-dependent manner. Mineral crystal maturity and collagen cross-link ratio (pyridinoline/dehydro-dihydroxylysinonorleucine) on both endosteal and periosteal surfaces decreased relative to ovariectomized animals, consistent with new bone formation. These changes were partially sustained after withdrawal of the higher dose of rhPTH(1-34), suggesting a prolonged after-effect on bone properties for at least two bone remodeling cycles. In conclusion, treatment of ovariectomized monkeys with rhPTH(1-34) had significant effects on cortical bone mineral-to-matrix ratio, mineral crystal maturity, and collagen cross-link ratio. These were fully reversible when the 1-microg rhPTH(1-34) treatment was withdrawn, but only partially reversed when the 5-microg rhPTH(1-34) dose was withdrawn.},
author = {Gr{\"{u}}nwald, Peter D},
doi = {10.7551/mitpress/4643.001.0001},
publisher = {MIT press},
title = {{The Minimum Description Length Principle}},
year = {2019}
}
@inproceedings{VanAssche:2007wc,
abstract = {Ensemble methods are popular learning methods that are usually able to increase the predictive accuracy of a classifier. On the other hand, this comes at the cost of interpretability, and insight in the decision process of an ensemble is hard to obtain. This is a major reason why ensemble methods have not been extensively used in the setting of inductive logic programming. In this paper we aim to overcome this issue of comprehensibility by learning a single first order interpretable model that approximates the first order ensemble. The new model is obtained by exploiting the class distributions predicted by the ensemble. These are employed to compute heuristics for deciding which tests are to be used in the new model. As such we obtain a model that is able to give insight in the decision process of the ensemble, while being more accurate than the single model directly learned on the data. {\textcopyright}2008 Springer-Verlag Berlin Heidelberg.},
address = {Corvallis, OR, USA},
author = {{Van Assche}, Anneleen and Blockeel, Hendrik},
booktitle = {Proceedings of the 17th International Conference on Inductive Logic Programming},
doi = {10.1007/978-3-540-78469-2_26},
isbn = {3-54-078468-3},
issn = {0302-9743},
keywords = {Comprehensibility,Ensembles,First order decision trees},
month = {jun},
pages = {269--279},
publisher = {Springer},
title = {{Seeing the forest through the trees learning a comprehensible model from a first order ensemble}},
year = {2007}
}
@misc{Mandel:2008ww,
annote = {Accessed: 28 August 2018},
author = {Mandel, Lawrence},
month = {may},
title = {{Describe REST Web services with WSDL 2.0}},
url = {https://ibm.co/313RoNV},
year = {2008}
}
@inproceedings{Ribeiro:2015dz,
abstract = {The demand for knowledge extraction has been increasing. With the growing amount of data being generated by global data sources (e.g., social media and mobile apps) and the popularization of context-specific data (e.g., the Internet of Things), companies and researchers need to connect all these data and extract valuable information. Machine learning has been gaining much attention in data mining, leveraging the birth of new solutions. This paper proposes an architecture to create a flexible and scalable machine learning as a service. An open source solution was implemented and presented. As a case study, a forecast of electricity demand was generated using real-world sensor and weather data by running different algorithms at the same time.},
address = {Miami, FL, USA},
author = {Ribeiro, Mauro and Grolinger, Katarina and Capretz, Miriam A M},
booktitle = {Proceedings of the 14th International Conference on Machine Learning and Applications},
doi = {10.1109/ICMLA.2015.152},
isbn = {978-1-50-900287-0},
keywords = {Machine learning as a service,Platform as a service,Prediction,Regression,Service component architecture,Service oriented architecture,Supervised learning},
month = {dec},
pages = {896--902},
publisher = {IEEE},
title = {{MLaaS: Machine learning as a service}},
year = {2015}
}
@book{Dey:2003ty,
abstract = {This book comprehensively covers all major topics of Vygotskian educa- tional theory and its classroom applications. Particular attention is paid to the Vygotskian idea of child development as a consequence rather than premise of learning experiences. Such a reversal allows for new interpretations of the relationships between cognitive development and education at different junc- tions of the human life span. It also opens new perspectives on atypical de- velopment, learning disabilities, and assessment of children's learning poten- tial. Classroomapplications ofVygotskian theory, teacher preparation, and the changing role of a teacher in a sociocultural classroom are discussed in addi- tion to the issues of learning activities and peer interaction. Relevant research findings fromthe United States,Western Europe, and Russia are considered to- gether to clarify the possible new applications of Vygotskian ideas in different disciplinary areas. The sociocultural orientation of Vygotskian theory helps to reveal learning patterns that become obscured in more traditional research.},
address = {New York, NY},
author = {Dey, I},
doi = {10.4324/9780203412497},
isbn = {978-0-41-505852-0},
issn = {1367-6539},
pmid = {2539002},
publisher = {Routledge},
title = {{Qualitative Data Analysis: A User-Friendly Guide for Social Scientists}},
year = {1993}
}
@article{Weiss2004,
author = {Weiss, Gary M},
doi = {10.1145/1007730.1007734},
issn = {1931-0145},
journal = {ACM SIGKDD Explorations Newsletter},
number = {1},
pages = {7--19},
publisher = {Association for Computing Machinery (ACM)},
title = {{Mining with rarity}},
url = {https://dl.acm.org/doi/10.1145/1007730.1007734},
volume = {6},
year = {2004}
}
@inproceedings{Hosseini:2018jr,
abstract = {Google has recently introduced the Cloud Vision API for image analysis. According to the demonstration website, the API 'quickly classifies images into thousands of categories, detects individual objects and faces within images, and finds and reads printed words contained within images.' It can be also used to 'detect different types of inappropriate content from adult to violent content.' In this paper, we evaluate the robustness of Google Cloud Vision API to input perturbation. In particular, we show that by adding sufficient noise to the image, the API generates completely different outputs for the noisy image, while a human observer would perceive its original content. We show that the attack is consistently successful, by performing extensive experiments on different image types, including natural images, images containing faces and images with texts. For instance, using images from ImageNet dataset, we found that adding an average of 14.25{\%} impulse noise is enough to deceive the API. Our findings indicate the vulnerability of the API in adversarial environments. For example, an adversary can bypass an image filtering system by adding noise to inappropriate images. We then show that when a noise filter is applied on input images, the API generates mostly the same outputs for restored images as for original images. This observation suggests that cloud vision API can readily benefit from noise filtering, without the need for updating image analysis algorithms.},
address = {Cancun, Mexico},
archivePrefix = {arXiv},
arxivId = {1704.05051},
author = {Hosseini, Hossein and Xiao, Baicen and Poovendran, Radha},
booktitle = {Proceedings of the 16th IEEE International Conference on Machine Learning and Applications},
doi = {10.1109/ICMLA.2017.0-172},
eprint = {1704.05051},
isbn = {978-1-53-861417-4},
keywords = {Adversarial machine learning,Google Cloud Vision API,Image Noise,Machine learning},
month = {dec},
pages = {101--105},
publisher = {IEEE},
title = {{Google's cloud vision API is not robust to noise}},
year = {2017}
}
@inproceedings{Elazmeh:2007tp,
abstract = {The paper presents ongoing issues, challenges, and difficulties we face in applying machine learning methods to retrospectively collected clinical data. The objective of our research is to build a reliable prediction model for early assessment of emergency pediatric asthma exacerbations. This predictive model should be able to distinguish between patients with mild or moderate/severe asthma attacks at a medically acceptable level of performance. Our real-life data set presents us with some difficult challenges which we communicate in this paper. Our approach to overcoming some of these difficulties is to use external expert knowledge to aid with classification by decomposing the classification problem into a two-tier concept, where concepts can be explicitly described in terms of the external knowledge source. Such an approach also has the advantage of significantly reducing the size of the training set required. Copyright {\textcopyright}2007, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
address = {Vancouver, BC, Canada},
author = {Elazmeh, William and Matwin, Stan and O'Sullivan, Dympna and Michalowski, Wojtek and Farion, Ken},
booktitle = {Proceedings of the 22nd Conference on Artificial Intelligence},
isbn = {978-1-57-735332-4},
month = {jul},
pages = {10--15},
publisher = {AAAI},
title = {{Insights from predicting pediatric asthma exacerbations from retrospective clinical data}},
volume = {WS-07-05},
year = {2007}
}
@inproceedings{Treude:2011fh,
abstract = {Question and Answer (Q{\&}A) websites, such as Stack Overflow, use social media to facilitate knowledge exchange between programmers and fill archives with millions of entries that contribute to the body of knowledge in software development. Understanding the role of Q{\&}A websites in the documentation landscape will enable us to make recommendations on how individuals and companies can leverage this knowledge effectively. In this paper, we analyze data from Stack Overflow to categorize the kinds of questions that are asked, and to explore which questions are answered well and which ones remain unanswered. Our preliminary findings indicate that Q{\&}A websites are particularly effective at code reviews and conceptual questions. We pose research questions and suggest future work to explore the motivations of programmers that contribute to Q{\&}A websites, and to understand the implications of turning Q{\&}A exchanges into technical mini-blogs through the editing of questions and answers. {\textcopyright}2011 ACM.},
address = {Honolulu, HI, USA},
author = {Treude, Christoph and Barzilay, Ohad and Storey, Margaret Anne},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
doi = {10.1145/1985793.1985907},
isbn = {978-1-45-030445-0},
issn = {0270-5257},
keywords = {q{\&}a,questions,social media,stack overflow},
month = {may},
pages = {804--807},
publisher = {ACM},
title = {{How do programmers ask and answer questions on the web?}},
year = {2011}
}
@article{Brereton:2007by,
abstract = {A consequence of the growing number of empirical studies in software engineering is the need to adopt systematic approaches to assessing and aggregating research outcomes in order to provide a balanced and objective summary of research evidence for a particular topic. The paper reports experiences with applying one such approach, the practice of systematic literature review, to the published studies relevant to topics within the software engineering domain. The systematic literature review process is summarised, a number of reviews being undertaken by the authors and others are described and some lessons about the applicability of this practice to software engineering are extracted. The basic systematic literature review process seems appropriate to software engineering and the preparation and validation of a review protocol in advance of a review activity is especially valuable. The paper highlights areas where some adaptation of the process to accommodate the domain-specific characteristics of software engineering is needed as well as areas where improvements to current software engineering infrastructure and practices would enhance its applicability. In particular, infrastructure support provided by software engineering indexing databases is inadequate. Also, the quality of abstracts is poor; it is usually not possible to judge the relevance of a study from a review of the abstract alone. {\textcopyright}2006 Elsevier Inc. All rights reserved.},
author = {Brereton, Pearl and Kitchenham, Barbara A and Budgen, David and Turner, Mark and Khalil, Mohamed},
doi = {10.1016/j.jss.2006.07.009},
issn = {0164-1212},
journal = {Journal of Systems and Software},
keywords = {Empirical software engineering,Systematic literature review},
month = {apr},
number = {4},
pages = {571--583},
title = {{Lessons from applying the systematic literature review process within the software engineering domain}},
volume = {80},
year = {2007}
}
@book{Wong:2006ve,
abstract = {Data mining involves the non-trivial extraction of implicit, previously unknown, and potentially useful information from databases. Genetic Programming (GP) and Inductive Logic Programming (ILP) are two of the approaches for data mining. This book first sets the necessary backgrounds for the reader, including an overview of data mining, evolutionary algorithms and inductive logic programming. It then describes a framework, called GGP (Generic Genetic Programming), that integrates GP and ILP based on a formalism of logic grammars. The formalism is powerful enough to represent context- sensitive information and domain-dependent knowledge. This knowledge can be used to accelerate the learning speed and/or improve the quality of the knowledge induced. A grammar-based genetic programming system called LOGENPRO (The LOGic grammar based GENetic PROgramming system) is detailed and tested on many problems in data mining. It is found that LOGENPRO outperforms some ILP systems. We have also illustrated how to apply LOGENPRO to emulate Automatically Defined Functions (ADFs) to discover problem representation primitives automatically. By employing various knowledge about the problem being solved, LOGENPRO can find a solution much faster than ADFs and the computation required by LOGENPRO is much smaller than that of ADFs. Moreover, LOGENPRO can emulate the effects of Strongly Type Genetic Programming and ADFs simultaneously and effortlessly. Data Mining Using Grammar Based Genetic Programming and Applications is appropriate for researchers, practitioners and clinicians interested in genetic programming, data mining, and the extraction of data from databases.},
author = {Wong, Man Leung and Leung, Kwong Sak},
booktitle = {Data Mining Using Grammar Based Genetic Programming and Applications},
doi = {10.1007/b116131},
isbn = {978-0-79-237746-7},
publisher = {Springer},
title = {{Data Mining Using Grammar Based Genetic Programming and Applications}},
year = {2002}
}
@inproceedings{Suri:2007wl,
abstract = {In this paper we consider the task of prototype selection whose primary goal is to reduce the storage and computational requirements of the Nearest Neighbor classifier while achieving better classification accuracies. We propose a solution to the prototype selection problem using techniques from cooperative game theory and show its efficacy experimentally. {\textcopyright}Springer-Verlag Berlin Heidelberg 2007.},
address = {Warsaw, Poland},
author = {{Rama Suri}, N and Srinivas, V S and {Narasimha Murty}, M},
booktitle = {Proceedings of the 11th European Conference on Principles and Practice of Knowledge Discovery in Databases},
doi = {10.1007/978-3-540-74976-9_58},
isbn = {978-3-54-074975-2},
issn = {0302-9743},
month = {sep},
pages = {556--564},
publisher = {Springer},
title = {{A cooperative game theoretic approach to prototype selection}},
year = {2007}
}
@article{Barua:2012gz,
abstract = {Programming question and answer (Q{\&}A) websites, such as Stack Overflow, leverage the knowledge and expertise of users to provide answers to technical questions. Over time, these websites turn into repositories of software engineering knowledge. Such knowledge repositories can be invaluable for gaining insight into the use of specific technologies and the trends of developer discussions. Previous work has focused on analyzing the user activities or the social interactions in Q{\&}A websites. However, analyzing the actual textual content of these websites can help the software engineering community to better understand the thoughts and needs of developers. In the article, we present a methodology to analyze the textual content of Stack Overflow discussions. We use latent Dirichlet allocation (LDA), a statistical topic modeling technique, to automatically discover the main topics present in developer discussions. We analyze these discovered topics, as well as their relationships and trends over time, to gain insights into the development community. Our analysis allows us to make a number of interesting observations, including: the topics of interest to developers range widely from jobs to version control systems to C{\#} syntax; questions in some topics lead to discussions in other topics; and the topics gaining the most popularity over time are web development (especially jQuery), mobile applications (especially Android), Git, and MySQL. {\textcopyright}2012 Springer Science+Business Media New York.},
author = {Barua, Anton and Thomas, Stephen W and Hassan, Ahmed E},
doi = {10.1007/s10664-012-9231-y},
issn = {1573-7616},
journal = {Empirical Software Engineering},
keywords = {Knowledge repository,Latent Dirichlet allocation,Mining software repositories,Q{\&}A websites,Topic models,Trend analysis},
number = {3},
pages = {619--654},
title = {{What are developers talking about? An analysis of topics and trends in Stack Overflow}},
volume = {19},
year = {2014}
}
@article{Uddin:2015hn,
abstract = {Formal documentation can be a crucial resource for learning to how to use an API. However, producing high-quality documentation can be nontrivial. Researchers investigated how 10 common documentation problems manifested themselves in practice. The results are based on two surveys of a total of 323 professional software developers and analysis of 179 API documentation units. The three severest problems were ambiguity, incompleteness, and incorrectness of content. The respondents often mentioned six of the 10 problems as 'blockers" that forced them to use another API.},
author = {Uddin, Gias and Robillard, Martin P},
doi = {10.1109/MS.2014.80},
issn = {0740-7459},
journal = {IEEE Software},
keywords = {API,documentation,software development,software engineering,user study},
month = {jun},
number = {4},
pages = {68--75},
title = {{How API Documentation Fails}},
volume = {32},
year = {2015}
}
@article{Szafron:2004uf,
abstract = {Proteome Analyst (PA) (http://www.cs.ualberta.ca/{\~{}}bioinfo/PA/) is a publicly available, high-throughput, web-based system for predicting various properties of each protein in an entire proteome. Using machine-learned classifiers, PA can predict, for example, the GeneQuiz general function and Gene Ontology (GO) molecular function of a protein. In addition, PA is currently the most accurate and most comprehensive system for predicting subcellular localization, the location within a cell where a protein performs its main function. Two other capabilities of PA are notable. First, PA can create a custom classifier to predict a new property, without requiring any programming, based on labeled training data (i.e. a set of examples, each with the correct classification label) provided by a user. PA has been used to create custom classifiers for potassium-ion channel proteins and other general function ontologies. Second, PA provides a sophisticated explanation feature that shows why one prediction is chosen over another. The PA system produces a Na{\"{i}}ve Bayes classifier, which is amenable to a graphical and interactive approach to explanations for its predictions; transparent predictions increase the user's confidence in, and understanding of, PA. {\textcopyright}Oxford University Press 2004; all rights reserved.},
author = {Szafron, Duane and Lu, Paul and Greiner, Russell and Wishart, David S and Poulin, Brett and Eisner, Roman and Lu, Zhiyong and Anvik, John and Macdonell, Cam and Fyshe, Alona and Meeuwis, David},
doi = {10.1093/nar/gkh485},
issn = {0305-1048},
journal = {Nucleic Acids Research},
title = {{Proteome Analyst: Custom predictions with explanations in a web-based tool for high-throughput proteome annotations}},
volume = {32},
year = {2004}
}
@article{Arnold:2005vc,
author = {Arnold, Ken},
doi = {10.1145/1071713.1071731},
issn = {1542-7749},
journal = {ACM Queue},
number = {5},
pages = {54--59},
title = {{Programmers are People, Too}},
volume = {3},
year = {2005}
}
@inproceedings{Kim:2014ui,
abstract = {We present the Bayesian Case Model (BCM), a general framework for Bayesian case-based reasoning (CBR) and prototype classification and clustering. BCM brings the intuitive power of CBR to a Bayesian generative framework. The BCM learns prototypes, the "quintessential" observations that best represent clusters in a dataset, by performing joint inference on cluster labels, prototypes and important features. Simultaneously, BCM pursues sparsity by learning subspaces, the sets of features that play important roles in the characterization of the prototypes. The prototype and subspace representation provides quantitative benefits in inter-pretability while preserving classification accuracy. Human subject experiments verify statistically significant improvements to participants' understanding when using explanations produced by BCM, compared to those given by prior art.},
address = {Montreal, QC, Canada},
archivePrefix = {arXiv},
arxivId = {1503.01161},
author = {Kim, Been and Rudin, Cynthia and Shah, Julie},
booktitle = {Proceedings of the 28th Conference on Neural Information Processing Systems},
eprint = {1503.01161},
issn = {1049-5258},
month = {dec},
pages = {1952--1960},
title = {{The Bayesian case model: A generative approach for case-based reasoning and prototype classification}},
year = {2014}
}
@article{Drummond2006,
abstract = {This paper introduces cost curves, a graphical technique for visualizing the performance (error rate or expected cost) of 2-class classifiers over the full range of possible class distributions and misclassification costs. Cost curves are shown to be superior to ROC curves for visualizing classifier performance for most purposes. This is because they visually support several crucial types of performance assessment that cannot be done easily with ROC curves, such as showing confidence intervals on a classifier's performance, and visualizing the statistical significance of the difference in performance of two classifiers. A software tool supporting all the cost curve analysis described in this paper is available from the authors. {\textcopyright}Springer Science + Business Media, LLC 2006.},
author = {Drummond, Chris and Holte, Robert C},
doi = {10.1007/s10994-006-8199-5},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {Classifiers,Machine learning,Performance evaluation,ROC curves},
month = {oct},
number = {1},
pages = {95--130},
title = {{Cost curves: An improved method for visualizing classifier performance}},
volume = {65},
year = {2006}
}
@inproceedings{gachechiladze2017,
address = {Buenos Aires, Argentina},
author = {Gachechiladze, Daviti and Lanubile, Filippo and Novielli, Nicole and Serebrenik, Alexander},
booktitle = {Proceedings of the 39th International Conference on Software Engineering: New Ideas and Emerging Technologies Results Track},
doi = {10.1109/ICSE-NIER.2017.18},
month = {may},
organization = {IEEE},
pages = {11--14},
publisher = {IEEE},
title = {{Anger and its direction in collaborative software development}},
year = {2017}
}
@inproceedings{Durieux2018,
abstract = {Over the last few years, the complexity of web applications has increased to provide more dynamic web applications to users. The drawback of this complexity is the growing number of errors in the front-end applications. In this paper, we present BikiniProxy, a novel technique to provide self-healing for the web. BikiniProxy is designed as an HTTP proxy that uses five self-healing strategies to rewrite the buggy HTML and Javascript code. We evaluate BikiniProxy with a new benchmark of 555 reproducible Javascript errors, DeadClick. We create DeadClick by randomly crawling the Internet and collect all web pages that contain Javascript errors. Then, we observe how BikiniProxy heals those errors by collecting and comparing the traces of the original and healed pages. To sum up, BikiniProxy is a novel fully-automated self-healing approach that is specific to the web, evaluated on 555 real Javascript errors, and based on original self-healing rewriting strategies for HTML and Javascript.},
address = {Memphis, TN, USA},
author = {Durieux, Thomas and Hamadi, Youssef and Monperrus, Martin},
booktitle = {Proceedings of the 29th International Symposium on Software Reliability Engineering},
doi = {10.1109/ISSRE.2018.00012},
issn = {1071-9458},
keywords = {Failure oblivious computing,Javascript,Repair proxy,Self healing},
month = {oct},
pages = {1--12},
publisher = {IEEE},
title = {{Fully Automated HTML and Javascript Rewriting for Constructing a Self-Healing Web Proxy}},
year = {2018}
}
@inproceedings{Mitchell:2018in,
abstract = {Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type [15]) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model. To solidify the concept, we provide cards for two supervised models: One trained to detect smiling faces in images, and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related artificial intelligence technology, increasing transparency into how well artificial intelligence technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation.},
address = {Atlanta, GA, USA},
archivePrefix = {arXiv},
arxivId = {1810.03993},
author = {Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
booktitle = {Proceedings of the 2nd Conference on Fairness, Accountability, and Transparency},
doi = {10.1145/3287560.3287596},
eprint = {1810.03993},
isbn = {978-1-45-036125-5},
keywords = {Datasheets,Disaggregated evaluation,Documentation,Ethical considerations,Fairness evaluation,ML model evaluation,Model cards},
month = {jan},
pages = {220--229},
publisher = {ACM},
title = {{Model cards for model reporting}},
year = {2019}
}
@inproceedings{Dorn:2010wl,
abstract = {This paper reports on a study of professional web designers and developers. We provide a detailed characterization of their knowledge of fundamental programming concepts elicited through card sorting. Additionally, we present qualitative findings regarding their motivation to learn new concepts and the learning strategies they employ. We find a high level of recognition of basic concepts, but we identify a number of concepts that they do not fully understand, consider difficult to learn, and use infrequently. We also note that their learning process is motivated by work projects and often follows a pattern of trial and error. We conclude with implications for end-user programming researchers. {\textcopyright}2010 ACM.},
address = {Atlanta, GA, USA},
author = {Dorn, Brian and Guzdial, Mark},
booktitle = {Proceedings of the 28th ACM Conference on Human Factors in Computing Systems},
doi = {10.1145/1753326.1753430},
isbn = {978-1-60-558929-9},
keywords = {informal learning,web development},
month = {apr},
pages = {703--712},
publisher = {ACM},
title = {{Learning on the job: Characterizing the programming knowledge and learning strategies of web designers}},
volume = {2},
year = {2010}
}
@inproceedings{Ghazi2010HierarchicalTexts,
address = {Ottawa, ON, Canada},
author = {Ghazi, Diman and Inkpen, Diana and Szpakowicz, Stan},
booktitle = {Proceedings of the 23rd Canadian Conference on Artificial Intelligence},
doi = {10.1007/978-3-642-13059-5_7},
keywords = {Emotion in text,Emotion recognition,Hierarchical classification,Sentiment analysis,Text classification},
month = {may},
pages = {40--50},
publisher = {Springer},
title = {{Hierarchical approach to emotion recognition and classification in texts}},
volume = {6085 LNAI},
year = {2010}
}
@inproceedings{LinaresVasquez:2014vj,
abstract = {The growing number of questions related to mobile development in StackOverow highlights an increasing interest of software developers in mobile programming. For the Android platform, 213,836 questions were tagged with Android-related labels in StackOverow between July 2008 and August 2012. This paper aims at investigating how changes occurring to Android APIs trigger questions and activity in StackOverflow, and whether this is particularly true for certain kinds of changes. Our findings suggest that Android developers usually have more questions when the behavior of APIs is modified. In addition, deleting public methods from APIs is a trigger for questions that are (i) more discussed and of major interest for the community, and (ii) posted by more experienced developers. In general, results of this paper provide important insights about the use of social media to learn about changes in software ecosystems, and establish solid foundations for building new recommenders for notifying developers/managers about important changes and recommending them relevant crowdsourced solutions.},
address = {Hyderabad, India},
author = {Linares-V{\'{a}}squez, Mario and Bavota, Gabriele and {Di Penta}, Massimiliano and Oliveto, Rocco and Poshyvanyk, Denys},
booktitle = {Proceedings of the 22nd International Conference on Program Comprehension},
doi = {10.1145/2597008.2597155},
isbn = {978-1-45-032879-1},
keywords = {API Changes,Android,Social Media,StackOverflow},
month = {jun},
pages = {83--94},
publisher = {ACM},
title = {{How do API changes trigger stack overflow discussions? A study on the android SDK}},
year = {2014}
}
@book{Rutten:2004a,
author = {Rutten, J and Kwiatkowska, M and Norman, G and Parker, D},
editor = {Panangaden, P and van Breugel, F},
publisher = {American Mathematical Society},
series = {CRM Monograph Series},
title = {{Mathematical techniques for analyzing concurrent and probabilistic systems}},
volume = {23},
year = {2004}
}
@article{Dejaeger:2012up,
abstract = {As a consequence of the heightened competition on the education market, the management of educational institutions often attempts to collect information on what drives student satisfaction by e.g. organizing large scale surveys amongst the student population. Until now, this source of potentially very valuable information remains largely untapped. In this study, we address this issue by investigating the applicability of different data mining techniques to identify the main drivers of student satisfaction in two business education institutions. In the end, the resulting models are to be used by the management to support the strategic decision making process. Hence, the aspect of model comprehensibility is considered to be at least equally important as model performance. It is found that data mining techniques are able to select a surprisingly small number of constructs that require attention in order to manage student satisfaction. {\textcopyright}2011 Elsevier B.V. All rights reserved.},
author = {Dejaeger, Karel and Goethals, Frank and Giangreco, Antonio and Mola, Lapo and Baesens, Bart},
doi = {10.1016/j.ejor.2011.11.022},
issn = {0377-2217},
journal = {European Journal of Operational Research},
keywords = {Comprehensibility,Data mining,Education evaluation,Multi class classification},
number = {2},
pages = {548--562},
title = {{Gaining insight into student satisfaction using comprehensible data mining techniques}},
volume = {218},
year = {2012}
}
@inproceedings{Barnett:2015ec,
abstract = {Quality attributes are essential in software architecture and they are determined by identifying the concerns of the stakeholders of a system. The concerns of constructing mobile applications (apps) are quite specific due to the characteristics of mobile devices. These concerns have not been adequately addressed in industry standards and practices. In this paper, we present a mobile app development conceptual model comprising six key concepts that impact quality. Using two case studies, we show that these interrelated concepts influence the architectural decisions of mobile apps and their tradeoffs need to be well considered. As such, we suggest that these concepts should be first class entities when designing mobile app architecture to ensure that the quality attributes are satisfied.},
address = {Montreal, QC, Canada},
author = {Barnett, Scott and Vasa, Rajesh and Tang, Antony},
booktitle = {Proceedings of the 12th Working IEEE/IFIP Conference on Software Architecture},
doi = {10.1109/WICSA.2015.28},
isbn = {978-1-47-991922-2},
keywords = {Mobile Software Architecture,Quality Model},
month = {may},
pages = {105--114},
publisher = {IEEE},
title = {{A Conceptual Model for Architecting Mobile Applications}},
year = {2015}
}
@article{Wettschereck:1997vw,
abstract = {Many lazy learning algorithms are derivatives of the k-nearest neighbor (k-NN) classifier, which uses a distance function to generate predictions from stored instances. Several studies have shown that k-NN's performance is highly sensitive to the definition of its distance function. Many k-NN variants have been proposed to reduce this sensitivity by parameterizing the distance function with feature weights. However, these variants have not been categorized nor empirically compared. This paper reviews a class of weight-setting methods for lazy learning algorithms. We introduce a framework for distinguishing these methods and empirically compare them. We observed four trends from our experiments and conducted further studies to highlight them. Our results suggest that methods which use performance feedback to assign weight settings demonstrated three advantages over other methods: they require less pre-processing, perform better in the presence of interacting features, and generally require less training data to learn good settings. We also found that continuous weighting methods tend to outperform feature selection algorithms for tasks where some features are useful but less important than others.},
author = {Wettschereck, Dietrich and Aha, David W and Mohri, Takao},
doi = {10.1007/978-94-017-2053-3_11},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
keywords = {Comparison,Feature weights,Lazy learning,k-nearest neighbor},
number = {1-5},
pages = {273--314},
title = {{A Review and Empirical Evaluation of Feature Weighting Methods for a Class of Lazy Learning Algorithms}},
volume = {11},
year = {1997}
}
@article{Zupan:2000tp,
author = {Zupan, Blaz and Dem{\v{s}}ar, Janez and Kattan, Michael W and Beck, J Robert and Bratko, Ivan},
journal = {Artificial intelligence in medicine},
number = {1},
pages = {59--75},
title = {{Machine learning for survival analysis: a case study on recurrence of prostate cancer}},
volume = {20},
year = {2000}
}
@book{Bass:2003wi,
abstract = {This report is another in a series of Software Engineering Institute (SEISM) case studies of organizations that have adopted the software product line approach for developing systems. It details the story of Salion, Inc., an enterprise software company providing Revenue Acquisition Management solutions tailored to the unique needs of automotive suppliers. Salion's solutions enable suppliers to organize and manage their disparate customer-interfacing activities as one coordinated business process, resulting in higher revenues, profit margins, and customer satisfaction. This case study is unique in that Salion did not have substantial experience in its application area, although its key designers and strategists were knowledgeable about related domains. Salion pursued a reactive approach to its product line that let it respond flexibly to spontaneous business opportunities and that significantly lowered the cost of adopting the product line paradigm to its software system development. This case study describes relevant dimensions of Salion's context, how it approached several product line practice areas that were key to its strategy, the benefits gained through its product line, lessons learned, and the major thematic aspects of the Salion story.},
author = {Bass, Len and Clements, Paul and Kazman, Rick},
booktitle = {Software Architecture},
edition = {2nd},
isbn = {0-32-115495-9},
pages = {560},
publisher = {Addison-Wesley},
title = {{Software Architecture in Practice}},
year = {2003}
}
@inproceedings{Nybom:2018ef,
abstract = {Background: Application Programming Interfaces (APIs) are key to software reuse. Software developers can link functionality and behaviour found in other software with their own software by taking an API into use. However, figuring out how an API works is usually demanding, and may require that the developers spend a notable amount of time familiarizing themselves with the API. Good API documentation is of key importance to simplify this task. Objective: To present a comprehensive, unbiased overview of the state-of-the-art on tools and approaches for API documentation generation. Method: A systematic mapping study on published tools and approaches that can be used for generating API documentation, or for assisting in the API documentation process. Results: 36 studies on API documentation generation tools and approaches analyzed and categorized in a variety of ways. Among other things, the paper presents an overview of what kind of tools have been developed, what kind of documentation they generate, and what sources the documentation approaches require. Conclusion: Out of the identified approaches, many contribute to API documentation in the areas of natural language documentation and code examples and templates. Many of the approaches contribute to ease API users' understanding and learning of the API, but also to the maintenance and generation of API documentation. Most of the approaches are automatic, simplifying the API documentation generation notably, under the assumption that relevant sources for the generation are available. Most of the API documentation approaches are evaluated either by exercise of the approach followed by analysis of the results, or by empirical evaluation methods.},
address = {Prague, Czech Republic},
author = {Nybom, Kristian and Ashraf, Adnan and Porres, Ivan},
booktitle = {Proceedings of the 44th Euromicro Conference on Software Engineering and Advanced Applications},
doi = {10.1109/SEAA.2018.00081},
isbn = {978-1-53-867382-9},
keywords = {API,API documentation,Systematic mapping study},
month = {aug},
pages = {462--469},
publisher = {IEEE},
title = {{A systematic mapping study on API documentation generation approaches}},
year = {2018}
}
@inproceedings{Martins2015,
abstract = {The System Usability Scale (SUS) is a widely used self-administered instrument for the evaluation of usability of a wide range of products and user interfaces. The principal value of the SUS is that it provides a single reference score for participants' view of the usability of a product or service. This paper presents the translation, cultural adaptation and a contribution to the validation of the European Portuguese version of SUS. The conducted work comprised two phases, the scale translation, and the scale validation. The first phase resulted in a European Portuguese version equivalent to the original in terms of semantic and content. The second phase involved the assessment of the validity and reliability of the scale. The instrument has construct validity as it presents a high and significant correlation with other two usability metrics, the Post-Study System Usability Questionnaire (PSSUQ) (r = 0.70) and a general usability question (r = 0.48). The reliability results show less than satisfactory ICC values (ICC = 0.36), however the percentage of agreement is satisfactory (76.67{\%}). Further studies are needed to investigate the reliability of the Portuguese version.},
author = {Martins, Ana Isabel and Rosa, Ana Filipa and Queir{\'{o}}s, Alexandra and Silva, Anabela and Rocha, Nelson Pacheco},
booktitle = {Procedia Computer Science},
doi = {10.1016/j.procs.2015.09.273},
issn = {18770509},
keywords = {European Portuguese validation,System Usability Scale,usability evaluation,user tests},
title = {{European Portuguese Validation of the System Usability Scale (SUS)}},
year = {2015}
}
@inproceedings{Garousi:2017:EGE:3084226.3084238,
abstract = {To systematically collect evidence and to structure a given area in software engineering (SE), Systematic Literature Reviews (SLR) and Systematic Mapping (SM) studies have become common. Data extraction is one of the main phases (activities) when conducting an SM or an SLR, whose objective is to extract required data from the primary studies and to accurately record the information researchers need to answer the questions of the SM/SLR study. Based on experience in a large number of SM/SLR studies, we and many other researchers have found the data extraction in SLRs to be time consuming and error-prone, thus raising the real need for heuristics and guidelines for effective and efficient data extraction in these studies, especially to be learnt by junior and young researchers. As a 'guideline' paper, this paper contributes a synthesized list of challenges usually faced during SLRs' data extraction phase and the corresponding solutions (guidelines). For our synthesis, we consider two data sources: (1) the pool of 16 SLR studies in which the authors have been involved in, as well as (2) a review of challenges and guidelines in the existing literature. Our experience in utilizing the presented guidelines in the near past have helped our junior colleagues to conduct data extractions more effectively and efficiently.},
address = {Karlskrona, Sweden},
author = {Garousi, Vahid and Felderer, Michael},
booktitle = {Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering},
doi = {10.1145/3084226.3084238},
isbn = {978-1-45-034804-1},
keywords = {Data extraction,Empirical software engineering,Research methodology,SLR,SM,Systematic literature reviews,Systematic mapping studies},
month = {jun},
pages = {170--179},
publisher = {ACM},
title = {{Experience-based guidelines for effective and efficient data extraction in systematic reviews in software engineering}},
volume = {Part F1286},
year = {2017}
}
@inproceedings{Cummaudo:2020fse-demo,
annote = {Unpublished},
author = {Cummaudo, Alex and Barnett, Scott and Vasa, Rajesh and Grundy, John},
keywords = {InReview},
mendeley-tags = {InReview},
title = {{Threshy: Supporting Safe Usage of Intelligent Web Services}},
year = {2020}
}
@book{Hastie:2001wp,
author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome H},
edition = {2nd},
month = {jan},
publisher = {Springer},
series = {Data Mining, Inference, and Prediction},
title = {{The Elements of Statistical Learning}},
year = {2001}
}
@inproceedings{Kitchenham:2004vj,
address = {Edinburgh, Scotland, UK},
author = {Kitchenham, Barbara A and Dyb{\aa}, Tore and Jorgensen, Magne},
booktitle = {Proceedings of the 26th International Conference on Software Engineering},
isbn = {978-0-76-952163-3},
month = {may},
pages = {273--281},
publisher = {IEEE},
title = {{Evidence-Based Software Engineering}},
year = {2004}
}
@misc{Albrecht2013,
abstract = {Background: Communication between patients and medical staff can be challenging if both parties have different cultural and linguistic backgrounds. Specialized applications can potentially alleviate these problems and significantly contribute to an effective, improved care process when foreign language patients are involved. Objective: The objective for this paper was to discuss the experiences gained from a study carried out at the Hannover Medical School regarding the use of a mobile translation application in hospital wards. The conditions for successfully integrating these technologies in the care process are discussed. Methods: iPads with a preinstalled copy of an exemplary multilingual assistance tool ('xprompt') designed for use in medical care were deployed on 10 wards. Over a period of 6 weeks, approximately 160 employees of the care staff had the opportunity to gather experiences with the devices while putting them to use during their work. Afterwards, the participants were asked to fill out an anonymous, paper-based questionnaire (17 questions) covering the usability of the iPads, translation apps in general, and the exemplary chosen application specifically. For questions requiring a rating, Likert scales were employed. The retained data were entered into an electronic survey system and exported to Microsoft Excel 2007 for further descriptive analysis. Results: Of 160 possible participants, 42 returned the questionnaire and 39 completed the questions concerning the chosen app. The demographic data acquired via the questionnaire (ie, age, professional experience, gender) corresponded to the values for the entire care staff at the Hannover Medical School. Most respondents (35/39, 90{\%}) had no previous experience with an iPad. On a 7-point scale, the participants generally rated mobile translation tools as helpful for communicating with foreign language patients (36/39, 92{\%}; median=5, IQR=2). They were less enthusiastic about xprompt's practical use (36/39, median=4, IQR=2.5), although the app was perceived as easy-to-use (36/39, median=6, IQR=3) and there were no obvious problems with the usability of the device (36/39, median=6, IQR=2). Conclusions: The discrepancy between the expert ratings for xprompt (collected from the App Store and online) and the opinions of the study's participants can probably be explained by the differing approaches of the two user groups. The experts had clear expectations, whereas, without a more thorough introduction, our study participants perceived using the app as too time consuming in relation to the expected benefit. The introduction of such tools in today's busy care settings should therefore be more carefully planned to heighten acceptance of new tools. Still, the low return rate of the questionnaires only allows for speculations on the data, and further research is necessary. Trial Registration: This study was approved by the local institutional review board (IRB), Trial ID number: 1145-2011.},
author = {Albrecht, Urs Vito and Behrends, Marianne and Matthies, Herbert K. and {Von Jan}, Ute},
booktitle = {Journal of Medical Internet Research},
doi = {10.2196/mhealth.2268},
issn = {14388871},
keywords = {Cultural deprivation,Medical informatics applications,Nursing care},
title = {{Usage of multilingual mobile translation applications in clinical settings}},
year = {2013}
}
@misc{FileShad33:online,
annote = {Accessed: 25 January 2019},
author = {BusinessWire},
month = {jul},
title = {{FileShadow Delivers Machine Learning to End Users with Google Vision API | Business Wire}},
url = {https://bwnews.pr/2O5qv78},
year = {2018}
}
@phdthesis{Nelson:1981ue,
author = {Nelson, Bruce Jay},
school = {Carnegie Mellon University},
title = {{Remote Procedure Call}},
year = {1981}
}
@article{Liu:2018fa,
abstract = {CONTEXT.— Nodal metastasis of a primary tumor influences therapy decisions for a variety of cancers. Histologic identification of tumor cells in lymph nodes can be laborious and error-prone, especially for small tumor foci. OBJECTIVE.— To evaluate the application and clinical implementation of a state-of-the-art deep learning-based artificial intelligence algorithm (LYmph Node Assistant or LYNA) for detection of metastatic breast cancer in sentinel lymph node biopsies. DESIGN.— Whole slide images were obtained from hematoxylin-eosin-stained lymph nodes from 399 patients (publicly available Camelyon16 challenge dataset). LYNA was developed by using 270 slides and evaluated on the remaining 129 slides. We compared the findings to those obtained from an independent laboratory (108 slides from 20 patients/86 blocks) using a different scanner to measure reproducibility. RESULTS.— LYNA achieved a slide-level area under the receiver operating characteristic (AUC) of 99{\%} and a tumor-level sensitivity of 91{\%} at 1 false positive per patient on the Camelyon16 evaluation dataset. We also identified 2 "normal" slides that contained micrometastases. When applied to our second dataset, LYNA achieved an AUC of 99.6{\%}. LYNA was not affected by common histology artifacts such as overfixation, poor staining, and air bubbles. CONCLUSIONS.— Artificial intelligence algorithms can exhaustively evaluate every tissue patch on a slide, achieving higher tumor-level sensitivity than, and comparable slide-level performance to, pathologists. These techniques may improve the pathologist's productivity and reduce the number of false negatives associated with morphologic detection of tumor cells. We provide a framework to aid practicing pathologists in assessing such algorithms for adoption into their workflow (akin to how a pathologist assesses immunohistochemistry results).},
author = {Liu, Yun and Kohlberger, Timo and Norouzi, Mohammad and Dahl, George E and Smith, Jenny L and Mohtashamian, Arash and Olson, Niels and Peng, Lily H and Hipp, Jason D and Stumpe, Martin C},
doi = {10.5858/arpa.2018-0147-OA},
issn = {1543-2165},
journal = {Archives of Pathology {\&} Laboratory Medicine},
month = {jul},
number = {7},
pages = {859--868},
pmid = {30295070},
title = {{Artificial Intelligence-Based Breast Cancer Nodal Metastasis Detection.}},
volume = {143},
year = {2017}
}
@inproceedings{Bigham2008,
abstract = {People often use computers other than their own to access web content, but blind users are restricted to using only computers equipped with expensive, special-purpose screen reading programs that they use to access the web. Web-Anywhere is a web-based, self-voicing web browser that enables blind web users to access the web from almost any computer that can produce sound without installing new software. The system could serve as a convenient, low-cost solution for blind users on-the-go. for blind users unable to afford a full screen reader and for web developers targeting accessible design. This paper overviews existing solutions for mobile web access for blind users and presents the design of the WebAnywhere system. WebAnywhere generates speech remotely and uses prefetching strategies designed to reduce perceived latency. A user evaluation of the system is presented showing that blind users can use Web-Anywhere to complete tasks representative of what users might want to complete on computers that are not their own. A survey of public computer terminals shows that WebAnywhere can run on most. Copyright 2008 ACM.},
address = {Beijing, China},
author = {Bigham, Jeffrey P. and Prince, Craig M. and Ladner, Richard E.},
booktitle = {Proceedings of the 2008 International Cross-Disciplinary Conference on Web Accessibility},
doi = {10.1145/1368044.1368060},
keywords = {Blind users,Screen reader,Web accessibility,Webanywhere},
month = {apr},
pages = {73--82},
publisher = {ACM},
title = {{WebAnywhere}},
year = {2008}
}
@incollection{Kitchenham:2007ux,
author = {Kitchenham, Barbara A and Pfleeger, Shari L},
booktitle = {Guide to Advanced Empirical Software Engineering},
chapter = {3},
doi = {10.1007/978-1-84800-044-5},
editor = {Shull, Forrest and Singer, Janice and Sj{\o}berg, Dag I. K.},
isbn = {978-1-84-800043-8},
month = {nov},
pages = {63--92},
publisher = {Springer},
title = {{Personal opinion surveys}},
year = {2007}
}
@inproceedings{Garg:2011gw,
abstract = {With the growth of Cloud Computing, more and more companies are offering different cloud services. From the customer's point of view, it is always difficult to decide whose services they should use, based on users' requirements. Currently there is no software framework which can automatically index cloud providers based on their needs. In this work, we propose a framework and a mechanism, which measure the quality and prioritize Cloud services. Such framework can make significant impact and will create healthy competition among Cloud providers to satisfy their Service Level Agreement (SLA) and improve their Quality of Services (QoS). {\textcopyright}2011 IEEE.},
address = {Melbourne, Australia},
author = {Garg, Saurabh Kumar and Versteeg, Steve and Buyya, Rajkumar},
booktitle = {Proceedings of the 4th IEEE International Conference on Utility and Cloud Computing},
doi = {10.1109/UCC.2011.36},
isbn = {978-0-76-954592-9},
keywords = {Cloud Computing,Quality of Service,Service Measurement},
month = {dec},
pages = {210--218},
publisher = {IEEE},
title = {{SMICloud: A framework for comparing and ranking cloud services}},
year = {2011}
}
@book{Pham:2000ua,
author = {Pham, Hoang},
edition = {1st},
isbn = {978-1-84-628295-9},
publisher = {Springer},
title = {{System Software Reliability}},
year = {2000}
}
@article{Fleiss:1971ff,
author = {Fleiss, Joseph L},
doi = {10.1037/h0031619},
journal = {Psychological Bulletin},
number = {5},
pages = {378--382},
title = {{Measuring nominal scale agreement among many raters}},
volume = {76},
year = {1971}
}
@article{Jaspers:2011hy,
abstract = {Objective: To synthesize the literature on clinical decision-support systems' (CDSS) impact on healthcare practitioner performance and patient outcomes. Design: Literature search on Medline, Embase, Inspec, Cinahl, Cochrane/Dare and analysis of high-quality systematic reviews (SRs) on CDSS in hospital settings. Two-stage inclusion procedure: (1) selection of publications on predefined inclusion criteria; (2) independent methodological assessment of preincluded SRs by the 11-item measurement tool, AMSTAR. Inclusion of SRs with AMSTAR score 9 or above. SRs were thereafter rated on level of evidence. Each stage was performed by two independent reviewers. Results: 17 out of 35 preincluded SRs were of high methodological quality and further analyzed. Evidence that CDSS significantly impacted practitioner performance was found in 52 out of 91 unique studies of the 16 SRs examining this effect (57{\%}). Only 25 out of 82 unique studies of the 16 SRs reported evidence that CDSS positively impacted patient outcomes (30{\%}). Conclusions: Few studies have found any benefits on patient outcomes, though many of these have been too small in sample size or too short in time to reveal clinically important effects. There is significant evidence that CDSS can positively impact healthcare providers' performance with drug ordering and preventive care reminder systems as most clear examples. These outcomes may be explained by the fact that these types of CDSS require a minimum of patient data that are largely available before the advice is (to be) generated: at the time clinicians make the decisions.},
author = {Jaspers, Monique W M and Smeulers, Marian and Vermeulen, Hester and Peute, Linda W},
doi = {10.1136/amiajnl-2011-000094},
issn = {1067-5027},
journal = {Journal of the American Medical Informatics Association},
number = {3},
pages = {327--334},
pmid = {21422100},
title = {{Effects of clinical decision-support systems on practitioner performance and patient outcomes: A synthesis of high-quality systematic review findings}},
volume = {18},
year = {2011}
}
@article{Usman:2017hn,
abstract = {Context: Software Engineering (SE) is an evolving discipline with new subareas being continuously developed and added. To structure and better understand the SE body of knowledge, taxonomies have been proposed in all SE knowledge areas. Objective: The objective of this paper is to characterize the state-of-the-art research on SE taxonomies. Method: A systematic mapping study was conducted, based on 270 primary studies. Results: An increasing number of SE taxonomies have been published since 2000 in a broad range of venues, including the top SE journals and conferences. The majority of taxonomies can be grouped into the following SWEBOK knowledge areas: construction (19.55{\%}), design (19.55{\%}), requirements (15.50{\%}) and maintenance (11.81{\%}). Illustration (45.76{\%}) is the most frequently used approach for taxonomy validation. Hierarchy (53.14{\%}) and faceted analysis (39.48{\%}) are the most frequently used classification structures. Most taxonomies rely on qualitative procedures to classify subject matter instances, but in most cases (86.53{\%}) these procedures are not described in sufficient detail. The majority of the taxonomies (97{\%}) target unique subject matters and many taxonomy-papers are cited frequently. Most SE taxonomies are designed in an ad-hoc way. To address this issue, we have revised an existing method for developing taxonomies in a more systematic way. Conclusion: There is a strong interest in taxonomies in SE, but few taxonomies are extended or revised. Taxonomy design decisions regarding the used classification structures, procedures and descriptive bases are usually not well described and motivated.},
author = {Usman, Muhammad and Britto, Ricardo and B{\"{o}}rstler, J{\"{u}}rgen and Mendes, Emilia},
doi = {10.1016/j.infsof.2017.01.006},
issn = {0950-5849},
journal = {Information and Software Technology},
keywords = {Classification,Software engineering,Systematic mapping study,Taxonomy},
month = {may},
pages = {43--59},
title = {{Taxonomies in software engineering: A Systematic mapping study and a revised taxonomy development method}},
volume = {85},
year = {2017}
}
@inproceedings{murphy2007approach,
abstract = {Some machine learning applications are intended to learn properties of data sets where the correct answers are not already known to human users. It is challenging to test such ML software, because there is no reliable test oracle. We describe a software testing approach aimed at addressing this problem. We present our findings from testing implementations of two different ML ranking algorithms: Support Vector Machines and Marti Rank. Copyright {\textcopyright}(2007) by Knowledge Systems Institute (KSI).},
address = {Boston, MA, USA},
author = {Murphy, Christian and Kaiser, Gail and Arias, Marta},
booktitle = {Proceedings of the 19th International Conference on Software Engineering and Knowledge Engineering},
isbn = {978-1-62-748661-3},
month = {jul},
pages = {167--172},
title = {{An approach to software testing of machine learning applications}},
year = {2007}
}
@article{Boehm:2005vj,
author = {Boehm, Barry and Basili, Victor R},
chapter = {12},
doi = {10.1109/9780470049167.ch12},
isbn = {978-0-47-004916-7},
journal = {Software Management},
pages = {419--421},
title = {{Software defect reduction top 10 list}},
year = {2007}
}
@article{Singh:2016wu,
abstract = {Recent work in model-agnostic explanations of black-box machine learning has demonstrated that interpretability of complex models does not have to come at the cost of accuracy or model flexibility. However, it is not clear what kind of explanations, such as linear models, decision trees, and rule lists, are the appropriate family to consider, and different tasks and models may benefit from different kinds of explanations. Instead of picking a single family of representations, in this work we propose to use "programs" as model-agnostic explanations. We show that small programs can be expressive yet intuitive as explanations, and generalize over a number of existing interpretable families. We propose a prototype program induction method based on simulated annealing that approximates the local behavior of black-box classifiers around a specific prediction using random perturbations. Finally, we present preliminary application on small datasets and show that the generated explanations are intuitive and accurate for a number of classifiers.},
archivePrefix = {arXiv},
arxivId = {1611.07579},
author = {Singh, Sameer and Ribeiro, Marco Tulio and Guestrin, Carlos},
eprint = {1611.07579},
journal = {arXiv preprint arXiv:1611.07579},
month = {nov},
title = {{Programs as Black-Box Explanations}},
url = {http://arxiv.org/abs/1611.07579},
year = {2016}
}
@article{Heckerman:2000uw,
abstract = {We describe a graphical model for probabilistic relationships - an alternative to the Bayesian network - called a dependency network. The graph of a dependency network, unlike a Bayesian network, is potentially cyclic. The probability component of a dependency network, like a Bayesian network, is a set of conditional distributions, one for each node given its parents. We identify several basic properties of this representation and describe a computationally efficient procedure for learning the graph and probability components from data. We describe the application of this representation to probabilistic inference, collaborative filtering (the task of predicting preferences), and the visualization of acausal predictive relationships. {\textcopyright}2000 David Heckerman, David Maxwell Chickering, Christopher Meek, Robert Rounthwaite, {\&} Carl Kadie.},
author = {Heckerman, David and Chickering, David Maxwell and Meek, Christopher and Rounthwaite, Robert and Kadie, Carl},
doi = {10.1162/153244301753344614},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {Bayesian networks,Collaborative filtering,Data visualization,Dependency networks,Exploratory data analysis,Gibbs sampling,Graphical models,Probabilistic inference},
number = {1},
pages = {49--75},
title = {{Dependency networks for inference, collaborative filtering, and data visualization}},
volume = {1},
year = {2001}
}
@article{996017,
abstract = {Multiobjective evolutionary algorithms (EAs) that use nondominated sorting and sharing have been criticized mainly for their: 1) O(MN3) computational complexity (where M is the number of objectives and N is the population size); 2) nonelitism approach; and 3) the need for specifying a sharing parameter. In this paper, we suggest a nondominated sorting-based multiobjective EA (MOEA), called nondominated sorting genetic algorithm II (NSGA-II), which alleviates all the above three difficulties. Specifically, a fast nondominated sorting approach with O(MN2) computational complexity is presented. Also, a selection operator is presented that creates a mating pool by combining the parent and offspring populations and selecting the best (with respect to fitness and spread) N solutions. Simulation results on difficult test problems show that the proposed NSGA-II, in most problems, is able to find much better spread of solutions and better convergence near the true Pareto-optimal front compared to Pareto-archived evolution strategy and strength-Pareto EA - two other elitist MOEAs that pay special attention to creating a diverse Pareto-optimal front. Moreover, we modify the definition of dominance in order to solve constrained multiobjective problems efficiently. Simulation results of the constrained NSGA-II on a number of test problems, including a five-objective seven-constraint nonlinear problem, are compared with another constrained multiobjective optimizer and much better performance of NSGA-II is observed.},
author = {Deb, Kalyanmoy and Pratap, Amrit and Agarwal, Sameer and Meyarivan, T},
doi = {10.1109/4235.996017},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Constraint handling,Elitism,Genetic algorithms,Multicriterion decision making,Multiobjective optimization,Pareto-optimal solutions},
month = {apr},
number = {2},
pages = {182--197},
title = {{A fast and elitist multiobjective genetic algorithm: NSGA-II}},
volume = {6},
year = {2002}
}
@inproceedings{Sculley2015,
abstract = {Machine learning offers a fantastically powerful toolkit for building useful complex prediction systems quickly. This paper argues it is dangerous to think of these quick wins as coming for free. Using the software engineering framework of technical debt, we find it is common to incur massive ongoing maintenance costs in real-world ML systems. We explore several ML-specific risk factors to account for in system design. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, configuration issues, changes in the external world, and a variety of system-level anti-patterns.},
address = {Montreal, QC, Canada},
author = {Sculley, D and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Crespo, Jean Fran{\c{c}}ois and Dennison, Dan},
booktitle = {Proceedings of the 29th Conference on Neural Information Processing Systems},
isbn = {0262017091, 9780262017091},
issn = {1049-5258},
month = {dec},
pages = {2503--2511},
title = {{Hidden technical debt in machine learning systems}},
year = {2015}
}
@article{Martens:2011uh,
abstract = {This paper proposes a complete framework to assess the overall performance of classification models from a user perspective in terms of accuracy, comprehensibility, and justifiability. A review is provided of accuracy and comprehensibility measures, and a novel metric is introduced that allows one to measure the justifiability of classification models. Furthermore, taxonomy of domain constraints is introduced, and an overview of the existing approaches to impose constraints and include domain knowledge in data mining techniques is presented. Finally, justifiability metric is applied to a credit scoring and customer churn prediction case. {\textcopyright}2011 Elsevier B.V. All rights reserved.},
author = {Martens, David and Vanthienen, Jan and Verbeke, Wouter and Baesens, Bart},
doi = {10.1016/j.dss.2011.01.013},
issn = {0167-9236},
journal = {Decision Support Systems},
keywords = {Classification,Comprehensibility,Data mining,Justifiability,Metrics},
number = {4},
pages = {782--793},
title = {{Performance of classification models from a user perspective}},
volume = {51},
year = {2011}
}
@article{daMotaSilveira:2017vp,
abstract = {This paper brings to light an important discussion on how to create better assistive technologies for visually impaired people with the new advances in the computer vision field. Until very recently, assistive technology solutions required large and expensive hardware, as well as complex software. However, this scenario seems to be changing with web services on cloud that turns available computer vision features, offering image and video content analysis. The challenge is on how the results of these analyses will be processed and which will be the action or interaction displayed afterwards, showing the importance of appropriate user interface to visually impaired.},
author = {{da Mota Silveira}, Henrique and Martini, Luiz C{\'{e}}sar},
doi = {10.20897/jisem.201709},
issn = {2468-4376},
journal = {Journal of Information Systems Engineering {\&} Management},
number = {2},
pages = {1--3},
title = {{How the New Approaches on Cloud Computer Vision can Contribute to Growth of Assistive Technologies to Visually Impaired in the Following Years?}},
volume = {2},
year = {2017}
}
@book{Casati:2003vi,
author = {Casati, Fabio and Kuno, Harumi and Alonso, G and Machiraju, V},
isbn = {978-3-64-207888-0},
title = {{Web Services-Concepts, Architectures and Applications}},
year = {2004}
}
@phdthesis{curumsing2017,
address = {Hawthorn, VIC, Australia},
author = {Curumsing, Maheswaree Kissoon},
school = {Swinburne University of Technology},
title = {{Emotion-Oriented Requirements Engineering}},
year = {2017}
}
@inproceedings{Zhang:2017,
address = {Denver, CO, USA},
author = {Zhang, Xiaoyi and Ross, Anne Spencer and Caspi, Anat and Fogarty, James and Wobbrock, Jacob O},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3025453.3025846},
isbn = {978-1-4503-4655-9},
keywords = {accessibility,interaction proxies,runtime modification},
month = {may},
pages = {6024--6037},
publisher = {ACM},
series = {CHI '17},
title = {{Interaction Proxies for Runtime Repair and Enhancement of Mobile Application Accessibility}},
url = {https://doi.org/10.1145/3025453.3025846},
year = {2017}
}
@inproceedings{Arpteg2018,
abstract = {Surprisingly promising results have been achieved by deep learning (DL) systems in recent years. Many of these achievements have been reached in academic settings, or by large technology companies with highly skilled research groups and advanced supporting infrastructure. For companies without large research groups or advanced infrastructure, building high-quality production-ready systems with DL components has proven challenging. There is a clear lack of well-functioning tools and best practices for building DL systems. It is the goal of this research to identify what the main challenges are, by applying an interpretive research approach in close collaboration with companies of varying size and type. A set of seven projects have been selected to describe the potential with this new technology and to identify associated main challenges. A set of 12 main challenges has been identified and categorized into the three areas of development, production, and organizational challenges. Furthermore, a mapping between the challenges and the projects is defined, together with selected motivating descriptions of how and why the challenges apply to specific projects. Compared to other areas such as software engineering or database technologies, it is clear that DL is still rather immature and in need of further work to facilitate development of high-quality systems. The challenges identified in this paper can be used to guide future research by the software engineering and DL communities. Together, we could enable a large number of companies to start taking advantage of the high potential of the DL technology.},
address = {Prague, Czech Republic},
archivePrefix = {arXiv},
arxivId = {1810.12034},
author = {Arpteg, Anders and Brinne, Bj{\"{o}}rn and Crnkovic-Friis, Luka and Bosch, Jan},
booktitle = {Proceedings of the 44th Euromicro Conference on Software Engineering and Advanced Applications},
doi = {10.1109/SEAA.2018.00018},
eprint = {1810.12034},
isbn = {978-1-53-867382-9},
keywords = {Artificial intelligence,Deep learning,Machine learning,Software engineering challenges},
month = {aug},
pages = {50--59},
publisher = {IEEE},
title = {{Software engineering challenges of deep learning}},
year = {2018}
}
@inproceedings{Meyers2019,
author = {Meyers, J and Cain, A and Renzella, J and Cummaudo, A},
booktitle = {Proceedings of 2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering, TALE 2018},
doi = {10.1109/TALE.2018.8615174},
title = {{A Proposal for Integrating Gamification into Task-Oriented Portfolio Assessment}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-85062099873{\&}partnerID=MN8TOARS},
year = {2019}
}
@article{Brooke:2013vt,
author = {Brooke, John},
issn = {1931-3357},
journal = {Journal of Usability Studies},
number = {2},
pages = {29--40},
title = {{SUS: a retrospective}},
volume = {8},
year = {2013}
}
@inproceedings{Quinlan:1999ue,
address = {Bled, Slovenia},
author = {Quinlan, J R},
booktitle = {Proceedings of the 9th International Workshop on Inductive Logic Programming},
doi = {10.1007/3-540-48751-4_3},
isbn = {3-54-066109-3},
issn = {1611-3349},
month = {jun},
pages = {15--18},
publisher = {Springer},
title = {{Some elements of machine learning}},
volume = {1634},
year = {1999}
}
@article{Lima:2009tm,
abstract = {Companies' interest in customer relationship modelling and key issues such as customer lifetime value and churn has substantially increased over the years. However, the complexity of building, interpreting and applying these models creates obstacles for their implementation. The main contribution of this paper is to show how domain knowledge can be incorporated in the data mining process for churn prediction, viz. through the evaluation of coefficient signs in a logistic regression model, and secondly, by analysing a decision table (DT) extracted from a decision tree or rule-based classifier. An algorithm to check DTs for violations of monotonicity constraints is presented, which involves the repeated application of condition reordering and table contraction to detect counter-intuitive patterns. Both approaches are applied to two telecom data sets to empirically demonstrate how domain knowledge can be used to ensure the interpretability of the resulting models.Journal of the Operational Research Society (2009) 60, 1096-1106. doi:10.1057/jors.2008.161; published online 18 February 2009 {\textcopyright}2009 Operational Research Society Ltd.},
author = {Lima, E and Mues, C and Baesens, B},
doi = {10.1057/jors.2008.161},
issn = {0160-5682},
journal = {Journal of the Operational Research Society},
keywords = {Churn,Data mining,Decision tables,Domain knowledge},
number = {8},
pages = {1096--1106},
title = {{Domain knowledge integration in data mining using decision tables: Case studies in churn prediction}},
volume = {60},
year = {2009}
}
@book{Sommerville:2011uc,
address = {Boston, MA, USA},
author = {Sommerville, Ian},
edition = {9th},
isbn = {978-0-13-703515-1},
publisher = {Addison-Wesley},
title = {{Software Engineering}},
year = {2011}
}
@book{Quinlan:1993vi,
address = {San Francisco, CA, USA},
author = {Quinlan, J Ross},
isbn = {978-1-55-860238-0},
publisher = {Morgan Kauffmann},
title = {{C4.5: Programs for machine learning}},
year = {1993}
}
@inproceedings{10.1007/978-3-319-08976-8_16,
abstract = {In the information era, enormous amounts of data have become available on hand to decision makers. Big data refers to datasets that are not only big, but also high in variety and velocity, which makes them difficult to handle using traditional tools and techniques. Due to the rapid growth of such data, solutions need to be studied and provided in order to handle and extract value and knowledge from these datasets. Furthermore, decision makers need to be able to gain valuable insights from such varied and rapidly changing data, ranging from daily transactions to customer interactions and social network data. Such value can be provided using big data analytics, which is the application of advanced analytics techniques on big data. This paper aims to analyze some of the different analytics methods and tools which can be applied to big data, as well as the opportunities provided by the application of big data analytics in various decision domains. {\textcopyright} 2014 Springer International Publishing Switzerland.},
address = {St. Petersburg, Russia},
author = {Elgendy, Nada and Elragal, Ahmed},
booktitle = {Proceedings of the 10th Industrial Conference on Data Mining},
doi = {10.1007/978-3-319-08976-8_16},
issn = {1611-3349},
keywords = {analytics,big data,data mining,decision making},
month = {jul},
pages = {214--227},
publisher = {Springer},
title = {{Big data analytics: A literature review paper}},
year = {2014}
}
@article{boyd2018just,
abstract = {Objective To compare voice-activated internet searches by smartphone (two digital assistants) with laptop ones for information and advice related to smoking cessation. Design Responses to 80 questions on a range of topics related to smoking cessation (including the FAQ from a NHS website), compared for quality. Setting Smartphone and internet searches as performed in New Zealand. Main outcome measures Ranked responses to the questions. Results Google laptop internet searches came first (or first equal) for best quality smoking cessation advice for 83{\%} (66/80) of the responses. Voiced questions to Google Assistant (“OK Google”) came first/first equal 76{\%} of the time vs Siri (Apple) at 28{\%}. Google and Google Assistant were statistically significantly better than Siri searches (odds ratio 12.4 and 8.5 respectively, p{\textless}0.0001 in each comparison). When asked FAQs from the National Health Service website, or to find information the Centers for Disease Control has made videos on, the best search results used expert sources 59{\%} (31/52) of the time, “some expertise” (eg, Wikipedia) 18{\%} of the time, but also magazines and other low quality sources 19{\%} of the time. Using all three methods failed to find relevant information 8{\%} (6/80) of the time, with Siri having the most failed responses (53{\%} of the time). Conclusion Google internet searches and Google Assistant were found to be significantly superior to the Siri digital assistant for smoking cessation information. While expert content was returned over half the time, there is still substantial room for improvement in how these software systems deliver smoking cessation advice.},
author = {Boyd, Matt and Wilson, Nick},
doi = {10.1371/journal.pone.0194811},
issn = {1932-6203},
journal = {PLoS ONE},
number = {3},
publisher = {Public Library of Science},
title = {{Just ask Siri? A pilot study comparing smartphone digital assistants and laptop Google searches for smoking cessation advice}},
volume = {13},
year = {2018}
}
@article{Augasta:2012wx,
abstract = {Artificial neural networks often achieve high classification accuracy rates, but they are considered as black boxes due to their lack of explanation capability. This paper proposes the new rule extraction algorithm RxREN to overcome this drawback. In pedagogical approach the proposed algorithm extracts the rules from trained neural networks for datasets with mixed mode attributes. The algorithm relies on reverse engineering technique to prune the insignificant input neurons and to discover the technological principles of each significant input neuron of neural network in classification. The novelty of this algorithm lies in the simplicity of the extracted rules and conditions in rule are involving both discrete and continuous mode of attributes. Experimentation using six different real datasets namely iris, wbc, hepatitis, pid, ionosphere and creditg show that the proposed algorithm is quite efficient in extracting smallest set of rules with high classification accuracy than those generated by other neural network rule extraction methods. {\textcopyright}Springer Science+Business Media, LLC. 2011.},
author = {{Gethsiyal Augasta}, M and Kathirvalavakumar, T},
doi = {10.1007/s11063-011-9207-8},
issn = {1370-4621},
journal = {Neural Processing Letters},
keywords = {Classification,Neural networks,Pedagogical,Pruning,Reverse engineering,Rule extraction},
number = {2},
pages = {131--150},
title = {{Reverse engineering the neural networks for rule extraction in classification problems}},
volume = {35},
year = {2012}
}
@article{Glass:2002wa,
abstract = {This article is a background report describing a comprehensive study of research in the three computing disciplines Computer Science, Software Engineering, and Information Systems. Findings relate to research topics, approaches, methods, reference disciplines, and levels of analysis. The article informally describes the process used and the research products produced. {\textcopyright}2008 Elsevier B.V. All rights reserved.},
author = {Glass, Robert L and Vessey, Iris and Ramesh, V},
doi = {10.1016/j.infsof.2008.09.015},
issn = {0950-5849},
journal = {Information and Software Technology},
keywords = {Computing research,Literature search,Research taxonomy},
number = {1},
pages = {68--70},
title = {{RESRES: The story behind the paper "Research in software engineering: An analysis of the literature"}},
volume = {51},
year = {2009}
}
@article{Freitas:2010vk,
abstract = {The literature on protein function prediction is currently dominated by works aimed at maximizing predictive accuracy, ignoring the important issues of validation and interpretation of discovered knowledge, which can lead to new insights and hypotheses that are biologically meaningful and advance the understanding of protein functions by biologists. The overall goal of this paper is to critically evaluate this approach, offering a refreshing new perspective on this issue, focusing not only on predictive accuracy but also on the comprehensibility of the induced protein function prediction models. More specifically, this paper aims to offer two main contributions to the area of protein function prediction. First, it presents the case for discovering comprehensible protein function prediction models from data, discussing in detail the advantages of such models, namely, increasing the confidence of the biologist in the system's predictions, leading to new insights about the data and the formulation of new biological hypotheses, and detecting errors in the data. Second, it presents a critical review of the pros and cons of several different knowledge representations that can be used in order to support the discovery of comprehensible protein function prediction models. {\textcopyright}2006 IEEE.},
author = {Freitas, Alex A and Wieser, Daniela C and Apweiler, Rolf},
doi = {10.1109/TCBB.2008.47},
issn = {1545-5963},
journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
keywords = {Biology,Classifier design and evaluation,Induction,Machine learning,Machine learning.},
number = {1},
pages = {172--182},
title = {{On the importance of comprehensible classification models for protein function prediction}},
volume = {7},
year = {2010}
}
@inproceedings{Zhang:2008vfa,
abstract = {Text extraction in video documents, as an important research field of content-based information indexing and retrieval, has been developing rapidly since 1990s. This has led to much progress in text extraction, performance evaluation, and related applications. By reviewing the approaches proposed during the past five years, this paper introduces the progress made in this area and discusses promising directions for future research.},
address = {Nara, Japan},
author = {Zhang, Jing and Kasturi, Rangachar},
booktitle = {Proceedings of the 8th International Workshop on Document Analysis Systems},
doi = {10.1109/das.2008.49},
month = {sep},
pages = {5--17},
publisher = {IEEE},
title = {{Extraction of Text Objects in Video Documents: Recent Progress}},
year = {2008}
}
@article{IBMTripleModularRedendancy,
abstract = {One of the proposed techniques for meeting the severe reliability requirements inherent in certain future computer applications is described. This technique involves the use of triple-modular redundancy, which is essentially the use of the two-out-of-three voting concept at a low level. Effects of imperfect voting circuitry and of various interconnections of logical elements are assessed. A hypothetical triple-modular redundant computer is subjected to a Monte Carlo program on the IBM 704, which simulates component failures. Reliability is thereby determined and compared with reliability obtained by analytical calculations based on simplifying assumptions.},
author = {Lyons, R E and Vanderkulk, W},
doi = {10.1147/rd.62.0200},
issn = {0018-8646},
journal = {IBM Journal of Research and Development},
month = {apr},
number = {2},
pages = {200--209},
title = {{The Use of Triple-Modular Redundancy to Improve Computer Reliability}},
volume = {6},
year = {2010}
}
@inproceedings{Szegedy:2016ws,
abstract = {Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2{\%} top-1 and 5:6{\%} top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3:5{\%} top-5 error and 17:3{\%} top-1 error on the validation set and 3:6{\%} top-5 error on the official test set.},
address = {Las Vegas, NV, USA},
archivePrefix = {arXiv},
arxivId = {1512.00567},
author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
booktitle = {Proceedings of the 2016 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2016.308},
eprint = {1512.00567},
isbn = {978-1-46-738850-4},
issn = {1063-6919},
month = {jun},
pages = {2818--2826},
publisher = {IEEE},
title = {{Rethinking the Inception Architecture for Computer Vision}},
year = {2016}
}
@article{Kotula:1998wp,
author = {Kotula, Jeffrey},
doi = {10.1109/52.663791},
issn = {0740-7459},
journal = {IEEE Software},
number = {2},
pages = {84--92},
title = {{Using patterns to create component documentation}},
volume = {15},
year = {1998}
}
@inproceedings{Ahasanuzzaman:2018kv,
abstract = {The design and maintenance of APIs are complex tasks due to the constantly changing requirements of its users. Despite the efforts of its designers, APIs may suffer from a number of issues (such as incomplete or erroneous documentation, poor performance, and backward incompatibility). To maintain a healthy client base, API designers must learn these issues to fix them. Question answering sites, such as Stack Overflow (SO), has become a popular place for discussing API issues. These posts about API issues are invaluable to API designers, not only because they can help to learn more about the problem but also because they can facilitate learning the requirements of API users. However, the unstructured nature of posts and the abundance of non-issue posts make the task of detecting SO posts concerning API issues difficult and challenging. In this paper, we first develop a supervised learning approach using a Conditional Random Field (CRF), a statistical modeling method, to identify API issue-related sentences. We use the above information together with different features of posts and experience of users to build a technique, called CAPS, that can classify SO posts concerning API issues. Evaluation of CAPS using carefully curated SO posts on three popular API types reveals that the technique outperforms all three baseline approaches we consider in this study. We also conduct studies to test the generalizability of CAPS results and to understand the effects of different sources of information on it.},
address = {Campobasso, Italy},
author = {Ahasanuzzaman, Md and Asaduzzaman, Muhammad and Roy, Chanchal K and Schneider, Kevin A},
booktitle = {Proceedings of the 25th International Conference on Software Analysis, Evolution and Reengineering},
doi = {10.1109/SANER.2018.8330213},
isbn = {978-1-53-864969-5},
keywords = {API Issue,Stack Overflow,feature extraction,text classification,unstructured data mining},
month = {mar},
pages = {244--254},
publisher = {IEEE},
title = {{Classifying stack overflow posts on API issues}},
year = {2018}
}
@incollection{Seaman:2007wa,
author = {Seaman, Carolyn B},
booktitle = {Guide to Advanced Empirical Software Engineering},
chapter = {2},
doi = {10.1007/978-1-84800-044-5},
editor = {Shull, Forrest and Singer, Janice and Sj{\o}berg, Dag I. K.},
isbn = {978-1-84-800043-8},
month = {nov},
pages = {35--62},
publisher = {Springer},
title = {{Qualitative methods}},
year = {2007}
}
@techreport{murphy2008improving,
abstract = {—As machine learning (ML) applications become prevalent in various aspects of everyday life, their dependability takes on increasing importance. It is challenging to test such applications, however, because they are intended to learn properties of data sets where the correct answers are not already known. Our work is not concerned with testing how well an ML algorithm learns, but rather seeks to ensure that an application using the algorithm implements the specification correctly and fulfills the users' expectations. These are critical to ensuring the application's dependability. This paper presents three approaches to testing these types of applications. In the first, we create a set of limited test cases for which it is, in fact, possible to predict what the correct output should be. In the second approach, we use random testing to generate large data sets according to parameterization based on the application's equivalence classes. Our third approach is based on metamorphic testing, in which properties of the application are exploited to define transformation functions on the input, such that the new output can easily be predicted based on the original output. Here we discuss these approaches, and our findings from testing the dependability of three real-world ML applications.},
address = {New York, NY, USA},
author = {Murphy, Christian and Kaiser, Gail},
doi = {10.7916/D8RF62VN},
institution = {Department of Computer Science, Columbia University},
keywords = {Index Terms—Machine Learning,Metamorphic Testing,Non-Testable Programs,Oracle Problem,Quality Assurance,Random Testing,Software Dependability,Software Testing},
number = {Ml},
pages = {1--21},
title = {{Improving the Dependability of Machine Learning Applications}},
year = {2008}
}
@inproceedings{Baesens:2003we,
abstract = {Credit scoring, decision tables, rule extraction, neural networks Abstract: Accuracy and comprehensibility are two important criteria when developing decision support systems for credit scoring. In this paper, we focus on the second criterion and propose the use of decision tables as an alternative knowledge visualisation formalism which lends itself very well to building intelligent and userfriendly credit scoring systems. Starting from a set of propositional if-then rules extracted by a neural network rule extraction algorithm, we construct decision tables and demonstrate their efficiency and user-friendliness for two real-life credit scoring cases.},
address = {Angers, France},
author = {Baesens, Bart and Mues, Christophe and {De Backer}, Manu and Vanthienen, Jan and Setiono, Rudy},
booktitle = {Proceedings of the 5th International Conference on Enterprise Information Systems},
doi = {10.1007/1-4020-2673-0_15},
isbn = {9-72-988161-8},
month = {apr},
pages = {19--25},
publisher = {IEEE},
title = {{Building intelligent credit scoring systems using decision tables}},
volume = {2},
year = {2003}
}
@book{Horch:2003uv,
author = {Horch, John W},
isbn = {978-1-58-053604-2},
pages = {286},
publisher = {Artech House},
title = {{Practical Guide To Software Quality Management}},
year = {2003}
}
@book{SWEBOK,
address = {Washington, DC, USA},
edition = {3rd},
editor = {Bourque, Pierre and Fairley, Richard E},
isbn = {978-0-7695-5166-1},
pages = {346},
publisher = {IEEE},
title = {{Guide to the Software Engineering Body of Knowledge}},
year = {2014}
}
@article{Ashby:1957db,
author = {Ashby, W Ross and Pierce, J R},
journal = {Physics Today},
month = {jul},
number = {7},
pages = {34--36},
title = {{An Introduction to Cybernetics}},
volume = {10},
year = {1957}
}
@article{Robillard:2011uv,
abstract = {Large APIs can be hard to learn, and this can lead to decreased programmer productivity. But what makes APIs hard to learn? We conducted a mixed approach, multi-phased study of the obstacles faced by Microsoft developers learning a wide variety of new APIs. The study involved a combination of surveys and in-person interviews, and collected the opinions and experiences of over 440 professional developers. We found that some of the most severe obstacles faced by developers learning new APIs pertained to the documentation and other learning resources. We report on the obstacles developers face when learning new APIs, with a special focus on obstacles related to API documentation. Our qualitative analysis elicited five important factors to consider when designing API documentation: documentation of intent; code examples; matching APIs with scenarios; penetrability of the API; and format and presentation. We analyzed how these factors can be interpreted to prioritize API documentation development efforts {\textcopyright}2010 Springer Science+Business Media, LLC.},
author = {Robillard, Martin P and Deline, Robert},
doi = {10.1007/s10664-010-9150-8},
issn = {1382-3256},
journal = {Empirical Software Engineering},
keywords = {Application programming interfaces,Documentation,Programming,Software libraries},
number = {6},
pages = {703--732},
title = {{A field study of API learning obstacles}},
volume = {16},
year = {2011}
}
@inproceedings{Shaw:2003aa,
address = {Portland, OR, USA},
author = {Shaw, M},
booktitle = {Proceedings of the 25th International Conference on Software Engineering},
isbn = {978-0-76-951877-0},
month = {may},
pages = {726--736},
publisher = {IEEE},
title = {{Writing good software engineering research papers}},
year = {2003}
}
@article{Michie:1994wi,
abstract = {Statistical, machine learning and neural network approaches to classification are all covered in this volume. Contributions have been integrated to provide an objective assessment of the potential for machine learning algorithms in solving significant commercial and industrial problems, widening the foundation for exploitation of these and related algorithms.},
author = {{F. Elder} and Michie, Donald and Spiegelhalter, David J and Taylor, Charles C},
doi = {10.2307/2291432},
isbn = {978-0-13-106360-0},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
number = {433},
pages = {436--438},
title = {{Machine Learning, Neural, and Statistical Classification.}},
volume = {91},
year = {1996}
}
@inproceedings{Cheng:2001vw,
abstract = {This paper investigates the methods for learning predictive classifiers based on Bayesian belief networks (BN)-primarily unrestricted Bayesian networks and Bayesian multi-nets. We present our algorithms for learning these classifiers, and discuss how these methods address the overfitting problem and provide a natural method for feature subset selection. Using a set of standard classification problems, we empirically evaluate the performance of various BN-based classifiers. The results show that the proposed BN and Bayes multinet classifiers are competitive with (or superior to) the best known classifiers, based on both BN and other formalisms; and that the computational time for learning and using these classifiers is relatively small. These results argue that BN-based classifiers deserve more attention in the data mining community.},
address = {Ottawa, ON, Canada},
author = {Cheng, Jie and Greiner, Russell},
booktitle = {Proceedings of the 14th Biennial Conference of the Canadian Society for Computational Studies of Intelligence},
doi = {10.1007/3-540-45153-6_14},
isbn = {3-54-042144-0},
issn = {1611-3349},
month = {jun},
pages = {141--151},
publisher = {Springer},
title = {{Learning bayesian belief network classifiers: Algorithms and system}},
volume = {2056},
year = {2001}
}
@book{Ekman1978,
address = {Palo Alto, CA, USA},
author = {Ekman, P and Friesen, W V and Hager, J},
publisher = {Consulting Pyschologists Press},
title = {{Facial Action Coding System: A Technique for the Measurement of Facial Movement}},
year = {1978}
}
@article{THOMAS2014457,
abstract = {Topic models are generative probabilistic models which have been applied to information retrieval to automatically organize and provide structure to a text corpus. Topic models discover topics in the corpus, which represent real world concepts by frequently co-occurring words. Recently, researchers found topics to be effective tools for structuring various software artifacts, such as source code, requirements documents, and bug reports. This research also hypothesized that using topics to describe the evolution of software repositories could be useful for maintenance and understanding tasks. However, research has yet to determine whether these automatically discovered topic evolutions describe the evolution of source code in a way that is relevant or meaningful to project stakeholders, and thus it is not clear whether topic models are a suitable tool for this task. In this paper, we take a first step towards evaluating topic models in the analysis of software evolution by performing a detailed manual analysis on the source code histories of two well-known and well-documented systems, JHotDraw and jEdit. We define and compute various metrics on the discovered topic evolutions and manually investigate how and why the metrics evolve over time. We find that the large majority (87{\%}-89{\%}) of topic evolutions correspond well with actual code change activities by developers. We are thus encouraged to use topic models as tools for studying the evolution of a software system. {\textcopyright}2012 Elsevier B.V. All rights reserved.},
author = {Thomas, Stephen W and Adams, Bram and Hassan, Ahmed E and Blostein, Dorothea},
doi = {10.1016/j.scico.2012.08.003},
issn = {0167-6423},
journal = {Science of Computer Programming},
keywords = {Latent Dirichlet allocation,Mining software repositories,Software evolution,Topic model},
pages = {457--479},
title = {{Studying software evolution using topic models}},
volume = {80},
year = {2014}
}
@article{Blake:1998vd,
abstract = {This paper describes the hardware implementations of fuzzy systems, neural networks and fuzzy neural networks (FNNs) using Xilinx Field Programmable Gate Arrays (FPGAs). The validity of these approaches is demonstrated by their application to a non-linear function approximation problem. The various elements of each system are discussed and implemented in hardware. The architectures were also implemented in software using the MATLAB neural network toolbox. The results are analysed in terms of an accuracy performance index and in the dimensions of the hardware required. {\textcopyright}1998 Elsevier Science Inc. All rights reserved.},
author = {Blake, J J and Maguire, L P and McGinnity, T M and Roche, B and McDaid, L J},
doi = {10.1016/S0020-0255(98)10029-4},
issn = {0020-0255},
journal = {Information Sciences},
number = {1-4},
pages = {151--168},
title = {{The implementation of fuzzy systems, neural networks and fuzzy neural networks using FPGAs}},
volume = {112},
year = {1998}
}
@article{Seaman:1999vc,
abstract = {While empirical studies in software engineering are beginning to gain recognition in the research community, this subarea is also entering a new level of maturity by beginning to address the human aspects of software development. This added focus has added a new layer of complexity to an already challenging area of research. Along with new research questions, new research methods are needed to study nontechnical aspects of software engineering. In many other disciplines, qualitative research methods have been developed and are commonly used to handle the complexity of issues involving human behavior. This paper presents several qualitative methods for data collection and analysis and describes them in terms of how they might be incorporated into empirical studies of software engineering, in particular how they might be combined with quantitative methods. To illustrate this use of qualitative methods, examples from real software engineering studies are used throughout. Index Terms - Qualitative methods, data collection, data analysis, experimental design, empirical software engineering, participant observation, interviewing. {\textcopyright}1999 IEEE.},
author = {Seaman, Carolyn B},
doi = {10.1109/32.799955},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
number = {4},
pages = {557--572},
title = {{Qualitative methods in empirical studies of software engineering}},
volume = {25},
year = {1999}
}
@article{mcleod2011factors,
abstract = {Determining the factors that have an influence on software systems development and deployment project outcomes has been the focus of extensive and ongoing research for more than 30 years. We provide here a survey of the research literature that has addressed this topic in the period 1996-2006, with a particular focus on empirical analyses. On the basis of this survey we present a new classification framework that represents an abstracted and synthesized view of the types of factors that have been asserted as influencing project outcomes. {\textcopyright}2011 ACM.},
author = {McLeod, Laurie and MacDonell, Stephen G},
doi = {10.1145/1978802.1978803},
issn = {0360-0300},
journal = {ACM Computing Surveys},
keywords = {Development processes,Institutional context,People and action,Project content,Project outcomes},
number = {4},
pages = {24},
publisher = {ACM},
title = {{Factors that affect software systems development project outcomes: A survey of research}},
volume = {43},
year = {2011}
}
@article{Taylor:1968tq,
author = {Taylor, R S},
doi = {10.5860/crl_29_03_178},
journal = {College and Research Libraries},
number = {3},
title = {{Question-Negotiation and Information Seeking in Libraries}},
volume = {29},
year = {1968}
}
@incollection{Easterbrook:2007ws,
author = {Easterbrook, Steve and Singer, Janice and Storey, Margaret-Anne and Damian, Daniela},
booktitle = {Guide to Advanced Empirical Software Engineering},
chapter = {11},
doi = {10.1007/978-1-84800-044-5},
editor = {Shull, Forrest and Singer, Janice and Sj{\o}berg, Dag I. K.},
isbn = {978-1-84-800043-8},
month = {nov},
pages = {285--311},
publisher = {Springer},
title = {{Selecting empirical methods for software engineering research}},
year = {2007}
}
@techreport{Kitchenham:2007dd,
address = {Keele, UK},
author = {Kitchenham, Barbara and Charters, S},
booktitle = {EBSE Technical Report},
institution = {Software Engineering Group, Keele University and Department of Computer Science, University of Durham},
title = {{Guidelines for performing Systematic Literature Reviews in Software Engineering}},
year = {2007}
}
@inproceedings{Ridgeway:1998ud,
abstract = {Voting methods such as boosting and bagging provide substantial improvements in classification performance in many problem domains. However, the resulting predictions can prove inscrutable to end-users. This is especially problematic in domains such as medicine, where end-user acceptance often depends on the ability of a classifier to explain its reasoning. Here we propose a variant of the boosted na{\"{i}}ve Bayes classifier that facilitates explanations while retaining predictive performance.},
address = {New York, NY, USA},
author = {Ridgeway, Greg and Madigan, David and Richardson, Thomas and O'Kane, John},
booktitle = {Proceedings of the 4th International Conference on Knowledge Discovery and Data Mining},
pages = {101--104},
publisher = {AAAI},
title = {{Interpretable Boosted Na{\"{i}}ve Bayes Classification}},
year = {1998}
}
@inproceedings{Thrun:1996wh,
abstract = {This paper investigates learning in a lifelong context. Lifelong learning addresses situations in which a learner faces a whole stream of learning tasks. Such scenarios provide the opportunity to transfer knowledge across multiple learning tasks, in order to generalize more accurately from less training data. In this paper, several different approaches to lifelong learning are described, and applied in an object recognition domain. It is shown that across the board, lifelong learning approaches generalize consistently more accurately from less training data, by their ability to transfer knowledge across learning tasks.},
address = {Denver, CO, USA},
author = {Thrun, Sebastian},
booktitle = {Proceedings of the 8th International Conference on Neural Information Processing Systems},
issn = {1049-5258},
month = {nov},
pages = {7},
publisher = {MIT Press},
title = {{Is Learning The n-th Thing Any Easier Than Learning The First?}},
year = {1996}
}
@article{Karwath:2002tv,
abstract = {Background: The inference of homology between proteins is a key problem in molecular biology The current best approaches only identify ∼50{\%} of homologies (with a false positive rate set at 1/1000). Results: We present Homology Induction (HI), a new approach to inferring homology. HI uses machine learning to bootstrap from standard sequence similarity search methods. First a standard method is run, then HI learns rules which are true for sequences of high similarity to the target (assumed homologues) and not true for general sequences, these rules are then used to discriminate sequences in the twilight zone. To learn the rules HI describes the sequences in a novel way based on a bioinformatic knowledge base, and the machine learning method of inductive logic programming. To evaluate HI we used the PDB40D benchmark which lists sequences of known homology but low sequence similarity. We compared the HI methodoly with PSI-BLAST alone and found HI performed significantly better. In addition, Receiver Operating Characteristic (ROC) curve analysis showed that these improvements were robust for all reasonable error costs. The predictive homology rules learnt by HI by can be interpreted biologically to provide insight into conserved features of homologous protein families. Conclusions: HI is a new technique for the detection of remote protein homolgy - a central bioinformatic problem. HI with PSI-BLAST is shown to outperform PSI-BLAST for all error costs. It is expect that similar improvements would be obtained using HI with any sequence similarity method. {\textcopyright}2002 Karwath and King; licensee BioMed Central Ltd.},
author = {Karwath, Andreas and King, Ross D},
doi = {10.1186/1471-2105-3-11},
issn = {1471-2105},
journal = {BMC Bioinformatics},
number = {1},
pages = {11},
title = {{Homology induction: The use of machine learning to improve sequence similarity searches}},
volume = {3},
year = {2002}
}
@misc{Classifi7:online,
annote = {Accessed: 5 February 2020},
author = {{Google LLC}},
title = {{Classification: Thresholding | Machine Learning Crash Course}},
url = {http://bit.ly/36oMgWb},
year = {2019}
}
@misc{Hadley:2006vv,
abstract = {This article describes the Web Application Description Language (WADL). An increasing number of Web-based enterprises (Google, Yahoo, Amazon, Flickr - to name but a few) are developing HTTP-based applications that provide access to their internal data using XML. Typically these applications are described using a combination of textual protocol descriptions combined with XML schema-based data format descriptions; WADL is designed to provide a machine processable protocol description format for use with such HTTP-based Web applications, especially those using XML.},
author = {Hadley, Marc J and Marc, Hadley},
booktitle = {Search},
month = {aug},
publisher = {W3C},
title = {{Web Application Description Language}},
url = {http://bit.ly/2RXRhQ1},
year = {2009}
}
@inproceedings{Watson:2012uy,
abstract = {Computer technology has made amazing advances in the past few decades; however, the software documentation of today still looks strikingly similar to the software documentation used 30 years ago. If this continues into the 21st century, more and more soft-ware developers could be using 20 th-century-style documentation to solve 21 st-century problems with 21 st-century technologies. Is 20 th-century- style documentation up to the challenge? How can that be measured? This paper seeks to answer those questions by developing a heuristic to identify whether the documentation set for an application programming interface (API) contains the key elements of API reference documentation that help software developers learn an API. The resulting heuristic was tested on a collection of software documentation that was chosen to provide a diverse set of examples with which to validate the heuristic. In the course of testing the heuristic, interesting patterns in the API documentation were observed. For example, twenty-five percent of the documentation sets studied did not have any overview information, which, according to studies, is one of the most basic elements an API documentation set needs to help software developers learn to use the API. The heuristic produced by this research can be used to evaluate large sets of API documentation, track trends in API documentation, and facilitate additional research. Copyright {\textcopyright}2012 ACM.},
address = {Seattle, WA, USA},
author = {Watson, Robert},
booktitle = {Proceedings of the 30th ACM International Conference on Design of Communication},
doi = {10.1145/2379057.2379112},
isbn = {978-1-45-031497-8},
keywords = {API,API reference documentation,Application programming interface,Software documentation,Software libraries},
month = {oct},
pages = {295--302},
publisher = {ACM},
title = {{Development and application of a heuristic to assess trends in API documentation}},
year = {2012}
}
@article{Bellazzi:2008tv,
abstract = {Background: The widespread availability of new computational methods and tools for data analysis and predictive modeling requires medical informatics researchers and practitioners to systematically select the most appropriate strategy to cope with clinical prediction problems. In particular, the collection of methods known as 'data mining' offers methodological and technical solutions to deal with the analysis of medical data and construction of prediction models. A large variety of these methods requires general and simple guidelines that may help practitioners in the appropriate selection of data mining tools, construction and validation of predictive models, along with the dissemination of predictive models within clinical environments. Purpose: The goal of this review is to discuss the extent and role of the research area of predictive data mining and to propose a framework to cope with the problems of constructing, assessing and exploiting data mining models in clinical medicine. Methods: We review the recent relevant work published in the area of predictive data mining in clinical medicine, highlighting critical issues and summarizing the approaches in a set of learned lessons. Results: The paper provides a comprehensive review of the state of the art of predictive data mining in clinical medicine and gives guidelines to carry out data mining studies in this field. Conclusions: Predictive data mining is becoming an essential instrument for researchers and clinical practitioners in medicine. Understanding the main issues underlying these methods and the application of agreed and standardized procedures is mandatory for their deployment and the dissemination of results. Thanks to the integration of molecular and clinical data taking place within genomic medicine, the area has recently not only gained a fresh impulse but also a new set of complex problems it needs to address. {\textcopyright}2006 Elsevier Ireland Ltd. All rights reserved.},
author = {Bellazzi, Riccardo and Zupan, Blaz},
doi = {10.1016/j.ijmedinf.2006.11.006},
issn = {1386-5056},
journal = {International Journal of Medical Informatics},
keywords = {Clinical medicine,Data analysis,Data mining,Data mining process,Predictive models},
number = {2},
pages = {81--97},
title = {{Predictive data mining in clinical medicine: Current issues and guidelines}},
volume = {77},
year = {2008}
}
@inproceedings{Stevens:2013vf,
address = {San Francisco, CA, USA},
author = {Stevens, Ryan and Ganz, Jonathan and Filkov, Vladimir and Devanbu, Premkumar and Chen, Hao},
booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
isbn = {978-1-46-732936-1},
month = {may},
pages = {31--40},
publisher = {IEEE},
title = {{Asking for (and about) permissions used by Android apps}},
year = {2013}
}
@inproceedings{Pal:2012te,
abstract = {Community Question Answering (CQA) services thrive as a result of a small number of highly active users, typically called experts, who provide a large number of high quality useful answers. Understanding the temporal dynamics and interactions between experts can present key insights into how community members evolve over time. In this paper, we present a temporal study of experts in CQA and analyze the changes in their behavioral patterns over time. Further, using unsupervised machine learning methods, we show the interesting evolution patterns that can help us distinguish experts from one another. Using supervised classification methods, we show that the models based on evolutionary data of users can be more effective at expert identification than the models that ignore evolution. We run our experiments on two large online CQA to show the generality of our proposed approach. Copyright {\textcopyright}2012, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
address = {Dublin, Ireland},
author = {Pal, Aditya and Chang, Shuo and Konstan, Joseph A},
booktitle = {Proceedings of the 6th International AAAI Conference on Weblogs and Social Media},
isbn = {978-1-57-735556-4},
month = {jun},
pages = {274--281},
publisher = {AAAI},
title = {{Evolution of experts in question answering communities}},
year = {2012}
}
@inproceedings{Otero:2013ul,
abstract = {Most ant colony optimization (ACO) algorithms for inducing classification rules use a ACO-based procedure to create a rule in a one-at-a-time fashion. An improved search strategy has been proposed in the cAnt-MinerPB algorithm, where an ACO-based procedure is used to create a complete list of rules (ordered rules), i.e., the ACO search is guided by the quality of a list of rules instead of an individual rule. In this paper we propose an extension of the cAnt-MinerPB algorithm to discover a set of rules (unordered rules). The main motivations for this work are to improve the interpretation of individual rules by discovering a set of rules and to evaluate the impact on the predictive accuracy of the algorithm. We also propose a new measure to evaluate the interpretability of the discovered rules to mitigate the fact that the commonly used model size measure ignores how the rules are used to make a class prediction. Comparisons with state-of-the-art rule induction algorithms, support vector machines, and the cAnt-MinerPB producing ordered rules are also presented.},
author = {Otero, Fernando E B and Freitas, Alex A},
booktitle = {Evolutionary Computation},
doi = {10.1162/EVCO_a_00155},
issn = {1530-9304},
keywords = {Ant colony optimization,Classification,Comprehensibility,Data mining,Sequential covering,Unordered rules},
number = {3},
pages = {385--409},
pmid = {26066807},
publisher = {ACM},
title = {{Improving the interpretability of classification rules discovered by an ant colony algorithm: Extended results}},
volume = {24},
year = {2016}
}
@article{DoshiVelez:2017wu,
abstract = {As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.},
archivePrefix = {arXiv},
arxivId = {1702.08608},
author = {Doshi-Velez, Finale and Kim, Been},
eprint = {1702.08608},
journal = {arXiv preprint arXiv:1702.08608},
title = {{Towards A Rigorous Science of Interpretable Machine Learning}},
url = {http://arxiv.org/abs/1702.08608},
year = {2017}
}
@inproceedings{Lopez2014,
address = {Hong Kong, China},
author = {Lopez-Lorca, Antonio A and Miller, Tim and Pedell, Sonja and Mendoza, Antonette and Keirnan, Alen and Sterling, Leon},
booktitle = {Proceedings of the 6th International Workshop on Social Software Engineering},
doi = {10.1145/2661685.2661691},
month = {nov},
pages = {25--32},
publisher = {ACM},
title = {{One size doesn't fit all: diversifying the user using personas and emotional scenarios}},
year = {2014}
}
@article{Jiang:2005ua,
abstract = {Background: Determining the functions of uncharacterized proteins is one of the most pressing problems in the post-genomic era. Large scale protein-protein interaction assays, global mRNA expression analyses and systematic protein localization studies provide experimental information that can be used for this purpose. The data from such experiments contain many false positives and false negatives, but can be processed using computational methods to provide reliable information about protein-protein relationships and protein function. An outstanding and important goal is to predict detailed functional annotation for all uncharacterized proteins that is reliable enough to effectively guide experiments. Results: We present AVID, a computational method that uses a multi-stage learning framework to integrate experimental results with sequence information, generating networks reflecting functional similarities among proteins. We illustrate use of the networks by making predictions of detailed Gene Ontology (GO) annotations in three categories: molecular function, biological process, and cellular component. Applied to the yeast Saccharomyces cerevisiae, AVID provides 37,451 pair-wise functional linkages between 4,191 proteins. These relationships are ∼65-78{\%} accurate, as assessed by cross-validation testing. Assignments of highly detailed functional descriptors to proteins, based on the networks, are estimated to be ∼67{\%} accurate for GO categories describing molecular function and cellular component and ∼52{\%} accurate for terms describing biological process. The predictions cover 1,490 proteins with no previous annotation in GO and also assign more detailed functions to many proteins annotated only with less descriptive terms. Predictions made by AVID are largely distinct from those made by other methods. Out of 37,451 predicted pair-wise relationships, the greatest number shared in common with another method is 3,413. Conclusions: AVID provides three networks reflecting functional associations among proteins. We use these networks to generate new, highly detailed functional predictions for roughly half of the yeast proteome that are reliable enough to drive targeted experimental investigations. The predictions suggest many specific, testable hypotheses. All of the data are available as downloadable files as well as through an interactive website at http://bmc-140.mit.edu/avid. Thus, AVID will be a valuable resource for experimental biologists. {\textcopyright}2005 Jiang and Keating, licensee BioMed Central Ltd.},
author = {Jiang, Taijiao and Keating, Amy E},
doi = {10.1186/1471-2105-6-136},
issn = {1471-2105},
journal = {BMC Bioinformatics},
number = {1},
pages = {136},
title = {{AVID: An integrative framework for discovering functional relationship among proteins}},
volume = {6},
year = {2005}
}
@article{Freitas:2014ic,
abstract = {The vast majority of the literature evaluates the performance of classification models using only the criterion of predictive accuracy. This paper reviews the case for considering also the comprehensibility (interpretability) of classification models, and discusses the interpretability of five types of classification models, namely decision trees, classification rules, decision tables, nearest neighbors and Bayesian network classifiers. We discuss both interpretability issues which are specific to each of those model types and more generic interpretability issues, namely the drawbacks of using model size as the only criterion to evaluate the comprehensibility of a model, and the use of monotonicity constraints to improve the comprehensibility and acceptance of classification models by users.},
author = {Freitas, Alex A},
doi = {10.1145/2594473.2594475},
issn = {1931-0145},
journal = {ACM SIGKDD Explorations Newsletter},
month = {mar},
number = {1},
pages = {1--10},
title = {{Comprehensible classification models}},
volume = {15},
year = {2014}
}
@inproceedings{Paszke2017,
abstract = {In this article, we describe an automatic differentiation module of PyTorch — a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua Torch, Chainer, and HIPS Autograd, and provides a high performance environment with easy access to automatic differentiation of models executed on different devices (CPU and GPU). To make prototyping easier, PyTorch does not follow the symbolic approach used in many other deep learning frameworks, but focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead. Note that this preprint is a draft of certain sections from an upcoming paper covering all PyTorch features.},
address = {Long Beach, CA, USA},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Paszke, Adam and Chanan, Gregory and Lin, Zeming and Gross, Sam and Yang, Edward and Antiga, Luca and Devito, Zachary},
booktitle = {Proceedings of the 31st Conference on Neural Information Processing Systems},
doi = {10.1017/CBO9781107707221.009},
eprint = {arXiv:1011.1669v3},
month = {dec},
publisher = {Curran Associates Inc.},
title = {{Automatic differentiation in PyTorch}},
year = {2017}
}
@book{Sheskin:2003tx,
abstract = {Called the "bible of applied statistics," the first two editions of the Handbook of Parametric and Nonparametric Statistical Procedures were unsurpassed in accessibility, practicality, and scope. Now author David Sheskin has gone several steps further and added even more tests, more examples, and more background information-more than 200 pages of new material.The Third Edition provides unparalleled, up-to-date coverage of over 130 parametric and nonparametric statistical procedures as well as many practical and theoretical issues relevant to statistical analysis. If you need toDecide what method of analysis to useUse a particular test for the first timeDistinguish acceptable from unacceptable researchInterpret and better understand the results of pubished studiesthe Handbook of Parametric and Nonparametric Statistical Procedures will help you get the job done.},
address = {New York, NY, USA},
author = {Sheskin, David J},
doi = {10.4324/9780203489536},
publisher = {Chapman and Hall/CRC},
title = {{Handbook of Parametric and Nonparametric Statistical Procedures}},
year = {2004}
}
@article{Shannon:1963ti,
address = {Urbana, IL, USA},
author = {Shannon, Claude E and Weaver, Warren},
doi = {10.1002/j.1538-7305.1948.tb01338.x},
journal = {The Bell System Technical Journal},
number = {3},
pages = {379--423},
publisher = {The University of Illinois Press},
title = {{The mathematical theory of communication}},
volume = {27},
year = {1948}
}
@article{Gebru:2018wh,
abstract = {Currently there is no standard way to identify how a dataset was created, and what characteristics, motivations, and potential skews it represents. To begin to address this issue, we propose the concept of a datasheet for datasets, a short document to accompany public datasets, commercial APIs, and pretrained models. The goal of this proposal is to enable better communication between dataset creators and users, and help the AI community move toward greater transparency and accountability. By analogy, in computer hardware, it has become industry standard to accompany everything from the simplest components (e.g., resistors), to the most complex microprocessor chips, with datasheets detailing standard operating characteristics, test results, recommended usage, and other information. We outline some of the questions a datasheet for datasets should answer. These questions focus on when, where, and how the training data was gathered, its recommended use cases, and, in the case of human-centric datasets, information regarding the subjects' demographics and consent as applicable. We develop prototypes of datasheets for two well-known datasets: Labeled Faces in The Wild and the Pang {\$}\backslashbackslashbackslash{\{}\backslash{\{}{\}}\backslashbackslash{\{}\backslash{\$}{\}}{\{}$\backslash${\}}{\}}{\&} Lee Polarity Dataset.},
archivePrefix = {arXiv},
arxivId = {1803.09010},
author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Daume{\'{e}}, Hal and Crawford, Kate},
eprint = {1803.09010},
journal = {arXiv preprint arXiv:1803.09010},
title = {{Datasheets for Datasets}},
url = {http://arxiv.org/abs/1803.09010},
year = {2018}
}
@article{McHugh:2012up,
abstract = {The kappa statistic is frequently used to test interrater reliability. The importance of rater reliability lies in the fact that it represents the extent to which the data collected in the study are correct representations of the variables measured. Measurement of the extent to which data collectors (raters) assign the same score to the same variable is called interrater reliability. While there have been a variety of methods to measure interrater reliability, traditionally it was measured as percent agreement, calculated as the number of agreement scores divided by the total number of scores. In 1960, Jacob Cohen critiqued use of percent agreement due to its inability to account for chance agreement. He introduced the Cohen's kappa, developed to account for the possibility that raters actually guess on at least some variables due to uncertainty. Like most correlation statistics, the kappa can range from -1 to +1. While the kappa is one of the most commonly used statistics to test interrater reliability, it has limitations. Judgments about what level of kappa should be acceptable for health research are questioned. Cohen's suggested interpretation may be too lenient for health related studies because it implies that a score as low as 0.41 might be acceptable. Kappa and percent agreement are compared, and levels for both kappa and percent agreement that should be demanded in healthcare studies are suggested.},
author = {McHugh, Mary L},
doi = {10.11613/bm.2012.031},
issn = {1330-0962},
journal = {Biochemia Medica},
keywords = {Interrater,Kappa,Rater,Reliability},
number = {3},
pages = {276--282},
pmid = {23092060},
title = {{Interrater reliability: The kappa statistic}},
volume = {22},
year = {2012}
}
@inproceedings{breck2016s,
abstract = {Using machine learning in real-world production systems is complicated by a host of issues not found in small toy examples or even large offline research experiments. Testing and monitoring are key considerations for assessing the production-readiness of an ML system. But how much testing and monitoring is enough? We present an ML Test Score rubric based on a set of actionable tests to help quantify these issues.},
address = {Barcelona, Spain},
author = {Breck, Eric and Cai, Shanqing and Nielsen, Eric and Salib, Michael and Sculley, D},
booktitle = {Proceedings of the 30th Annual Conference on Neural Information Processing Systems},
month = {dec},
publisher = {Curran Associates Inc.},
title = {{What's your ML Test Score? A rubric for ML production systems}},
year = {2016}
}
@article{Venners:2003vw,
author = {Venners, B},
journal = {Artima Developer},
title = {{Design by Contract: A Conversation with Bertrand Meyer}},
url = {http://bit.ly/31bzGZ1},
year = {2003}
}
@article{Pazzani:2001tw,
abstract = {Objectives: The aim was to evaluate the potential for monotonicity constraints to bias machine learning systems to learn rules that were both accurate and meaningful. Methods: Two data sets, taken from problems as diverse as screening for dementia and assessing the risk of mental retardation, were collected and a rule learning system, with and without monotonicity constraints, was run on each. The rules were shown to experts, who were asked how willing they would be to use such rules in practice. The accuracy of the rules was also evaluated. Results: Rules learned with monotonicity constraints were at least as accurate as rules learned without such constraints. Experts were, on average, more willing to use the rules learned with the monotonicity constraints. Conclusions: The analysis of medical databases has the potential of improving patient outcomes and/or lowering the cost of health care delivery. Various techniques, from statistics, pattern recognition, machine learning, and neural networks, have been proposed to "mine" this data by uncovering patterns that may be used to guide decision making. This study suggests cognitive factors make learned models coherent and, therefore, credible to experts. One factor that influences the acceptance of learned models is consistency with existing medical knowledge.},
author = {Pazzani, M J and Mani, S and Shankle, W R},
doi = {10.1055/s-0038-1634196},
issn = {0026-1270},
journal = {Methods of Information in Medicine},
keywords = {Alzheimer Disease,Artificial Intelligence,Mental Retardation},
number = {5},
pages = {380--385},
pmid = {11776735},
title = {{Acceptance of rules generated by machine learning among medical experts}},
volume = {40},
year = {2001}
}
@article{Doderer:2006vt,
abstract = {In silico prediction of protein subcellular localization based on amino acid sequence can reveal valuable information about the protein's innate roles in the cell. Unfortunately, such prediction is made difficult because of complex protein sorting signals. Some prediction methods are based on searching for similar proteins with known localization, assuming that known homologs exist. However, it may not perform well on proteins with no known homolog. In contrast, machine learning-based approaches attempt to infer a predictive model that describes the protein sorting signals. Alas, in doing so, it does not take advantage of known homologs (if they exist) by doing a simple "table lookup". Here, we capture the best of both worlds by combining both approaches. On a dataset with 12 locations, similarity-based and machine learning independently achieve an accuracy of 83.8{\%} and 72.6{\%}, respectively. Our hybrid approach yields an improved accuracy of 85.9{\%}. We compared our method with three other methods' published results. For two of the methods, we used their published datasets for comparison. For the third we used the 12 location dataset. The Error Correcting Output Code algorithm was used to construct our predictive model. This algorithm gives attention to all the classes regardless of number of instances and led to high accuracy among each of the classes and a high prediction rate overall. We also illustrated how the machine learning classifier we use, built over a meaningful set of features can produce interpretable rules that may provide valuable insights into complex protein sorting mechanisms. {\textcopyright}2006 IOS Press. All rights reserved.},
author = {Doderer, Mark and Yoon, Kihoon and Salinas, John and Kwek, Stephen},
issn = {1386-6338},
journal = {In Silico Biology},
keywords = {Blast,Decision tree,Error correcting output code,Similarity search,Subcellular localization prediction},
number = {5},
pages = {419--433},
title = {{Protein subcellular localization prediction using a hybrid of similarity search and Error-Correcting Output Code techniques that produces interpretable results}},
volume = {6},
year = {2006}
}
@misc{ISO25010:2011,
author = {{International Organization for Standardization}},
title = {{ISO/IEC 25010:2011 Systems and software engineering – Systems and software Quality Requirements and Evaluation (SQuaRE) – System and software quality models}},
url = {http://bit.ly/2S4yzGs},
year = {2011}
}
@article{Baehrens:2010tj,
abstract = {After building a classifier with modern tools of machine learning we typically have a black box at hand that is able to predict well for unseen data. Thus, we get an answer to the question what is the most likely label of a given unseen data point. However, most methods will provide no answer why the model predicted a particular label for a single instance and what features were most influential for that particular instance. The only method that is currently able to provide such explanations are decision trees. This paper proposes a procedure which (based on a set of assumptions) allows to explain the decisions of any classification method. {\textcopyright}2010 David Baehrens, Timon Schroeter, Stefan Harmeling, Motoaki Kawanabe, Katja Hansen and Klaus-Robert M{\"{u}}ller.},
author = {Baehrens, David and Schroeter, Timon and Harmeling, Stefan and Kawanabe, Motoaki and Hansen, Katja and M{\"{u}}ller, Klaus Robert},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {Ames mutagenicity,Black box model,Explaining,Kernel methods,Nonlinear},
pages = {1803--1831},
title = {{How to explain individual classification decisions}},
volume = {11},
year = {2010}
}
@inproceedings{Reboucas:2016tw,
abstract = {Recently, Apple released Swift, a modern programming language built to be the successor of Objective-C. In less than a year and a half after its first release, Swift became one of the most popular programming languages in the world, considering different popularity measures. A significant part of this success is due to Apple's strict control over its ecosystem, and the clear message that it will replace Objective-C in a near future. According to Apple, "Swift is a powerful and intuitive programming language[...]. Writing Swift code is interactive and fun, the syntax is concise yet expressive." However, little is known about how Swift developers perceive these benefits. In this paper, we conducted two studies aimed at uncovering the questions and strains that arise from this early adoption. First, we perform a thorough analysis on 59,156 questions asked about Swift on StackOverflow. Second, we interviewed 12 Swift developers to cross-validate the initial results. Our study reveals that developers do seem to find the language easy to understand and adopt, although 17.5{\%} of the questions are about basic elements of the language. Still, there are many questions about problems in the toolset (compiler, Xcode, libraries). Some of our interviewees reinforced these problems.},
address = {Suita, Japan},
author = {Reboucas, Marcel and Pinto, Gustavo and Ebert, Felipe and Torres, Weslley and Serebrenik, Alexander and Castor, Fernando},
booktitle = {Proceedings of the 23rd International Conference on Software Analysis, Evolution, and Reengineering},
doi = {10.1109/saner.2016.66},
month = {mar},
pages = {634--638},
publisher = {IEEE},
title = {{An Empirical Study on the Usage of the Swift Programming Language}},
year = {2016}
}
@book{Ingeno:2018,
address = {Birmingham, England, UK},
author = {Ingeno, Joseph},
isbn = {978-1-78862-406-0},
publisher = {Packt Publishing, Ltd.},
title = {{Software Architect's Handbook: Become a Successful Software Architect by Implementing Effective Architecture Concepts}},
year = {2018}
}
@article{Zahalka:2011ux,
abstract = {A widely persisting interpretation of Occam's razor is that given two classifiers with the same training error, the simpler classifier is more likely to generalize better. Within a long-lasting debate in the machine learning community over Occam's razor, Domingos (Data Min. Knowl. Discov. 3:409-425, 1999) rejects this interpretation and proposes that model complexity is only a confounding factor usually correlated with the number of models from which the learner selects. It is thus hypothesized that the risk of overfitting (poor generalization) follows only from the number of model tests rather than the complexity of the selected model. We test this hypothesis on 30 UCI data sets using polynomial classification models. The results confirm Domingos' hypothesis on the 0.05 significance level and thus refutes the above interpretation of Occam's razor. Our experiments however also illustrate that decoupling the two factors (model complexity and number of model tests) is problematic. {\textcopyright}The Author(s) 2010.},
author = {Zah{\'{a}}lka, Jan and {\v{Z}}elezn{\'{y}}, Filip},
doi = {10.1007/s10994-010-5227-2},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {Empirical evaluation,Generalization,Model complexity},
number = {3},
pages = {475--481},
title = {{An experimental test of Occam's razor in classification}},
volume = {82},
year = {2011}
}
@article{Freitas:2004vv,
abstract = {This paper addresses the problem of how to evaluate the quality of a model built from the data in a multi-objective optimization scenario, where two or more quality criteria must be simultaneously optimized. A typical example is a scenario where one wants to maximize both the accuracy and the simplicity of a classification model or a candidate attribute subset in attribute selection. One reviews three very different approaches to cope with this problem, namely: (a) transforming the original multi-objective problem into a single-objective problem by using a weighted formula; (b) the lexicographical approach, where the objectives are ranked in order of priority; and (c) the Pareto approach, which consists of finding as many non-dominated solutions as possible and returning the set of non-dominated solutions to the user. One also presents a critical review of the case for and against each of these approaches. The general conclusions are that the weighted formula approach -- which is by far the most used in the data mining literature -- is to a large extent an ad-hoc approach for multi-objective optimization, whereas the lexicographic and the Pareto approach are more principled approaches, and therefore deserve more attention from the data mining community.},
author = {Freitas, Alex A},
doi = {10.1145/1046456.1046467},
issn = {1931-0145},
journal = {ACM SIGKDD Explorations Newsletter},
number = {2},
pages = {77},
title = {{A critical review of multi-objective optimization in data mining}},
volume = {6},
year = {2004}
}
@inproceedings{Nykaza:2002td,
abstract = {This paper steps the reader through a needs assessment of programmers that was conducted by instructional designers. The assessment's purpose was to identify what learning support programmers need and want to successfully use a new software development kit (SDK). The paper includes the challenges the researchers encountered, the questions asked and the responses, the types of individuals interviewed, and the conclusions reached from the research. Recommendations also are presented. Those responsible with developing documentation, training, and other learning support systems for programmers may find this assessment helpful. Marketing, product development and customer support people may also find value in learning more about the needs of this unique audience.},
address = {Toronto, ON, Canada},
author = {Nykaza, Janet and Messinger, Rhonda and Boehme, Fran and Norman, Cherie L and Mace, Matthew and Gordon, Manuel},
booktitle = {Proceedings of the 20th Annual International Conference on Computer Documentation},
doi = {10.1145/584955.584976},
keywords = {API documentation,Developer documentation,Needs analysis,Needs assessment,Programmer documentation,SDK documentation},
month = {oct},
pages = {133--141},
publisher = {ACM},
title = {{What programmers really want: Results of a needs assessment for SDK documentation}},
year = {2002}
}
@inproceedings{Cavano:1978gz,
abstract = {Research in software metrics incorporated in a framework established for software quality measurement can potentially provide significant benefits to software quality assurance programs. The research described has been conducted by General Electric Company for the Air Force Systems Command Rome Air Development Center. The problems encountered defining software quality and the approach taken to establish a framework for the measurement of software quality are described in this paper.},
author = {Cavano, Joseph P and McCall, James A},
booktitle = {Proceedings of the Software Quality Assurance Workshop on Functional and Performance Issues},
doi = {10.1145/800283.811113},
month = {nov},
number = {5},
pages = {133--139},
title = {{A framework for the measurement of software quality}},
volume = {3},
year = {1978}
}
@misc{ISO9000:2015,
author = {{International Organization for Standardization}},
title = {{ISO 9000:2015 Quality management systems – Fundamentals and vocabulary}},
url = {http://bit.ly/37O4oKo},
year = {2015}
}
@article{Wohlin:2014jq,
abstract = {Several factors make empirical research in software engineering particularly challenging as it requires studying not only technology but its stakeholders' activities while drawing concepts and theories from social science. Researchers, in general, agree that selecting a research design in empirical software engineering research is challenging, because the implications of using individual research methods are not well recorded. The main objective of this article is to make researchers aware and support them in their research design, by providing a foundation of knowledge about empirical software engineering research decisions, in order to ensure that researchers make well-founded and informed decisions about their research designs. This article provides a decision-making structure containing a number of decision points, each one of them representing a specific aspect on empirical software engineering research. The article provides an introduction to each decision point and its constituents, as well as to the relationships between the different parts in the decision-making structure. The intention is the structure should act as a starting point for the research design before going into the details of the research design chosen. The article provides an in-depth discussion of decision points in relation to the research design when conducting empirical research.},
author = {Wohlin, Claes and Aurum, Ayb{\"{u}}ke},
doi = {10.1007/s10664-014-9319-7},
issn = {1573-7616},
journal = {Empirical Software Engineering},
keywords = {Empirical software engineering research,Research design,Research methods,Selecting research method},
month = {may},
number = {6},
pages = {1427--1455},
title = {{Towards a decision-making structure for selecting a research design in empirical software engineering}},
volume = {20},
year = {2015}
}
@misc{IEEE:1990wp,
abstract = {Describes the IEEE Std 610.12-1990, IEEE standard glossary of software engineering terminology, which identifies terms currently in use in the field of software engineering. Standard definitions for those terms are established.},
author = {IEEE},
doi = {10.1109/IEEESTD.1990.101064},
keywords = {definitions,dictionary,glossary,software engineering,terminology},
title = {{IEEE Standard Glossary of Software Engineering Terminology}},
year = {1990}
}
@article{Verbeke:2011vo,
abstract = {Customer churn prediction models aim to detect customers with a high propensity to attrite. Predictive accuracy, comprehensibility, and justifiability are three key aspects of a churn prediction model. An accurate model permits to correctly target future churners in a retention marketing campaign, while a comprehensible and intuitive rule-set allows to identify the main drivers for customers to churn, and to develop an effective retention strategy in accordance with domain knowledge. This paper provides an extended overview of the literature on the use of data mining in customer churn prediction modeling. It is shown that only limited attention has been paid to the comprehensibility and the intuitiveness of churn prediction models. Therefore, two novel data mining techniques are applied to churn prediction modeling, and benchmarked to traditional rule induction techniques such as C4.5 and RIPPER. Both AntMiner+ and ALBA are shown to induce accurate as well as comprehensible classification rule-sets. AntMiner+ is a high performing data mining technique based on the principles of Ant Colony Optimization that allows to include domain knowledge by imposing monotonicity constraints on the final rule-set. ALBA on the other hand combines the high predictive accuracy of a non-linear support vector machine model with the comprehensibility of the rule-set format. The results of the benchmarking experiments show that ALBA improves learning of classification techniques, resulting in comprehensible models with increased performance. AntMiner+ results in accurate, comprehensible, but most importantly justifiable models, unlike the other modeling techniques included in this study. {\textcopyright}2010 Elsevier Ltd. All rights reserved.},
author = {Verbeke, Wouter and Martens, David and Mues, Christophe and Baesens, Bart},
doi = {10.1016/j.eswa.2010.08.023},
issn = {0957-4174},
journal = {Expert Systems with Applications},
keywords = {ALBA,Ant Colony Optimization,Churn prediction,Classification,Comprehensible rule induction,Data mining},
number = {3},
pages = {2354--2364},
title = {{Building comprehensible customer churn prediction models with advanced rule induction techniques}},
volume = {38},
year = {2011}
}
@article{Ondrej:2016,
author = {Bruna, O and Avetisyan, H and Holub, J},
doi = {10.1088/1742-6596/772/1/012063},
journal = {Journal of Physics: Conference Series},
month = {nov},
pages = {12063},
publisher = {IOP Publishing},
title = {{Emotion models for textual emotion classification}},
volume = {772},
year = {2016}
}
@article{Gilmore:1974um,
abstract = {"Quality is the degree to which a specific product conforms to a design or specification"},
author = {Gilmore, Harold L},
journal = {Quality progress},
number = {5},
pages = {16--19},
title = {{Product conformance cost}},
volume = {7},
year = {1974}
}
@inproceedings{Wang:2018vl,
abstract = {Transfer learning is a powerful approach that allows users to quickly build accurate deep-learning (Student) models by "learning" from centralized (Teacher) models pretrained with large datasets, e.g. Google's Inception V3. We hypothesize that the centralization of model training increases their vulnerability to misclas-sification attacks leveraging knowledge of publicly accessible Teacher models. In this paper, we describe our efforts to understand and experimentally validate such attacks in the context of image recognition. We identify techniques that allow attackers to associate Student models with their Teacher counterparts, and launch highly effective misclassification attacks on black-box Student models. We validate this on widely used Teacher models in the wild. Finally, we propose and evaluate multiple approaches for defense, including a neuron-distance technique that successfully defends against these attacks while also obfuscates the link between Teacher and Student models.},
address = {Baltimore, MD, USA},
author = {Wang, Bolun and Yao, Yuanshun and Viswanath, Bimal and Zheng, Haitao and Zhao, Ben Y},
booktitle = {Proceedings of the 27th USENIX Security Symposium},
isbn = {978-1-93-913304-5},
month = {jul},
pages = {1281--1297},
publisher = {USENIX Association},
title = {{With great training comes great vulnerability: Practical attacks against transfer learning}},
year = {2018}
}
@article{Reis:2018cp,
abstract = {The visually impaired must face several well-known difficulties on their daily life. The use of technology in assistive systems can greatly improve their lives by helping with navigation and orientation, for which several approaches and technologies have been proposed. Lately, it has been introduced powerful online image processing services, based on machine learning and deep learning, promising truly cognitive assessment capacities. Google and Microsoft are two of these main players. In this work we built a device to be used by the blind in order to test the usage of the Google and Microsoft services to assist the blind. The online services were tested by researchers in a laboratory environment and by blind users on a large meeting room, familiar to them. This work reports on our findings regarding the online services effectiveness, the user interface and system latency.},
author = {Reis, Ars{\'{e}}nio and Paulino, Dennis and Filipe, Vitor and Barroso, Jo{\~{a}}o},
doi = {10.1007/978-3-319-77712-2_17},
isbn = {978-3-31-977711-5},
issn = {2194-5357},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Assistive systems,Cognitive services,Human-computer interaction,Visually impaired},
number = {12},
pages = {174--184},
title = {{Using online artificial vision services to assist the blind - An assessment of Microsoft Cognitive Services and Google Cloud Vision}},
volume = {746},
year = {2018}
}
@book{Juristo:2013vj,
abstract = {Basics of Software Engineering Experimentation is a practical guide to experimentation in a field which has long been underpinned by suppositions, assumptions, speculations and beliefs. It demonstrates to software engineers how Experimental Design and Analysis can be used to validate their beliefs and ideas. The book does not assume its readers have an in-depth knowledge of mathematics, specifying the conceptual essence of the techniques to use in the design and analysis of experiments and keeping the mathematical calculations clear and simple. Basics of Software Engineering Experimentation is practically oriented and is specially written for software engineers, all the examples being based on real and fictitious software engineering experiments.},
address = {Boston, MA, USA},
author = {Juristo, Natalia and Moreno, Ana M},
doi = {10.1007/978-1-4757-3304-4},
month = {mar},
publisher = {Springer},
title = {{Basics of Software Engineering Experimentation}},
year = {2001}
}
@article{Wickham:2010hy,
abstract = {A grammar of graphics is a tool that enables us to concisely describe the components of a graphic. Such a grammar allows us to move beyond named graphics (e.g., the "scatterplot") and gain insight into the deep structure that underlies statistical graphics. This article builds on Wilkinson, Anand, and Grossman (2005), describing extensions and refinements developed while building an open source implementation of the grammar of graphics for R, ggplot2. The topics in this article include an introduction to the grammar by working through the process of creating a plot, and discussing the components that we need. The grammar is then presented formally and compared toWilkinson's grammar, highlighting the hierarchy of defaults, and the implications of embedding a graphical grammar into a programming language. The power of the grammar is illustrated with a selection of examples that explore different components and their interactions, in more detail. The article concludes by discussing some perceptual issues, and thinking about how we can build on the grammar to learn how to create graphical "poems." Supplemental materials are available online. Copyright {\textcopyright}2010 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America.},
author = {Wickham, Hadley},
doi = {10.1198/jcgs.2009.07098},
issn = {1061-8600},
journal = {Journal of Computational and Graphical Statistics},
keywords = {Grammar of graphics,Statistical graphics},
month = {jan},
number = {1},
pages = {3--28},
title = {{A Layered grammar of graphics}},
volume = {19},
year = {2010}
}
@article{Hallgren:2012kt,
abstract = {Many research designs require the assessment of inter-rater reliability (IRR) to demonstrate consistency among observational ratings provided by multiple coders. However, many studies use incorrect statistical procedures, fail to fully report the information necessary to interpret their results, or do not address how IRR affects the power of their subsequent analyses for hypothesis testing. This paper provides an overview of methodological issues related to the assessment of IRR with a focus on study design, selection of appropriate statistics, and the computation, interpretation, and reporting of some commonly-used IRR statistics. Computational examples include SPSS and R syntax for computing Cohen's kappa and intra-class correlations to assess IRR.},
author = {Hallgren, Kevin A},
doi = {10.20982/tqmp.08.1.p023},
issn = {1913-4126},
journal = {Tutorials in Quantitative Methods for Psychology},
month = {feb},
number = {1},
pages = {23--34},
pmid = {22833776},
title = {{Computing Inter-Rater Reliability for Observational Data: An Overview and Tutorial}},
volume = {8},
year = {2012}
}
@article{Richards:2001vw,
abstract = {This paper describes the analysis of a database of diabetic patients' clinical records and death certificates. The objective of the study was to find rules that describe associations between observations made of patients at their first visit to the hospital and early mortality. Pre-processing was carried out and a knowledge discovery in databases (KDD) package, developed by the Lanner Group and the University of East Anglia, was used for rule induction using simulated annealing. The most significant discovered rules describe an association that was not generally known or accepted by the medical community, however, recent independent studies confirm their validity. {\textcopyright}2001 Elsevier Science B.V.},
author = {Richards, G and Rayward-Smith, V J and S{\"{o}}nksen, P H and Carey, S and Weng, C},
doi = {10.1016/S0933-3657(00)00110-X},
issn = {0933-3657},
journal = {Artificial Intelligence in Medicine},
keywords = {Data mining,Diabetes,Neuropathy,Rule induction},
number = {3},
pages = {215--231},
title = {{Data mining for indicators of early mortality in a database of clinical records}},
volume = {22},
year = {2001}
}
@book{Wohlin:2012bu,
abstract = {Like other sciences and engineering disciplines, software engineering requires a cycle of model building, experimentation, and learning. Experiments are valuable tools for all software engineers who are involved in evaluating and choosing between different methods, techniques, languages and tools. The purpose of Experimentation in Software Engineering is to introduce students, teachers, researchers, and practitioners to empirical studies in software engineering, using controlled experiments. The introduction to experimentation is provided through a process perspective, and the focus is on the steps that we have to go through to perform an experiment. The book is divided into three parts. The first part provides a background of theories and methods used in experimentation. Part II then devotes one chapter to each of the five experiment steps: scoping, planning, execution, analysis, and result presentation. Part III completes the presentation with two examples. Assignments and statistical material are provided in appendixes. Overall the book provides indispensable information regarding empirical studies in particular for experiments, but also for case studies, systematic literature reviews, and surveys. It is a revision of the authors' book, which was published in 2000. In addition, substantial new material, e.g. concerning systematic literature reviews and case study research, is introduced. The book is self-contained and it is suitable as a course book in undergraduate or graduate studies where the need for empirical studies in software engineering is stressed. Exercises and assignments are included to combine the more theoretical material with practical aspects. Researchers will also benefit from the book, learning more about how to conduct empirical studies, and likewise practitioners may use it as a "cookbook" when evaluating new methods or techniques before implementing them in their organization.},
address = {Berlin, Heidelberg},
author = {Wohlin, Claes and Runeson, Per and H{\"{o}}st, Martin and Ohlsson, Magnus C and Regnell, Bj{\"{o}}rn and Wessl{\'{e}}n, Anders},
doi = {10.1007/978-3-642-29044-2},
isbn = {978-3-64-229044-2},
issn = {0098-5589},
publisher = {Springer},
title = {{Experimentation in Software Engineering}},
year = {2012}
}
@inproceedings{10.1145/2370216.2370437,
address = {Pittsburgh, PA, USA},
author = {Ba{\~{n}}os, Oresti and Damas, Miguel and Pomares, H{\'{e}}ctor and Rojas, Ignacio and T{\'{o}}th, M{\'{a}}t{\'{e}} Attila and Amft, Oliver},
booktitle = {Proceedings of the 2012 ACM Conference on Ubiquitous Computing},
doi = {10.1145/2370216.2370437},
isbn = {9781450312240},
keywords = {activity recognition,benchmark dataset,fitness exercises,motion sensors,sensor displacement},
pages = {1026--1035},
publisher = {ACM},
title = {{A Benchmark Dataset to Evaluate Sensor Displacement in Activity Recognition}},
year = {2012}
}
@article{Pearl:2018uv,
abstract = {THE DRAMATIC SUCCESS In machine learning has led to an explosion of artificial intelligence (AI) applications and increasing expectations for autonomous systems that exhibit human-level intelligence. These expectations have, however, met with fundamental obstacles that cut across many application areas. One such obstacle is adaptability, or robustness. Machine learning researchers have noted current systems lack the ability to recognize or react to new circumstances they have not been specifically programmed or trained for.},
author = {Pearl, Judea},
doi = {10.1145/3241036},
issn = {1557-7317},
journal = {Communications of the ACM},
number = {3},
pages = {54--60},
title = {{The seven tools of causal inference, with reflections on machine learning}},
volume = {62},
year = {2019}
}
@book{Shull:2007vh,
abstract = {Empirical studies have become an integral element of software engineering research and practice. This unique text/reference includes chapters from some of the top international empirical software engineering researchers and focuses on the practical knowledge necessary for conducting, reporting and using empirical methods in software engineering. Part 1, 'Research Methods and Techniques', examines the proper use of various strategies for collecting and analysing data, and the uses for which those strategies are most appropriate. Part 2, 'Practical Foundations', provides a discussion of several important global issues that need to be considered from the very beginning of research planning. Finally, 'Knowledge Creation' offers insight on using a set of disparate studies to provide useful decision support. Topics and features: Offers information across a range of techniques, methods, and qualitative and quantitative issues, providing a toolkit for the reader that is applicable across the diversity of software development contexts Presents reference material with concrete software engineering examples Provides guidance on how to design, conduct, analyse, interpret and report empirical studies, taking into account the common difficulties and challenges encountered in the field Arms researchers with the information necessary to avoid fundamental risks Tackles appropriate techniques for addressing disparate studies - ensuring the relevance of empirical software engineering, and showing its practical impact Describes methods that are less often used in the field, providing less conventional but still rigorous and useful ways of collecting data Supplies detailed information on topics (such as surveys) that often contain methodological errors This broad-ranging, practical guide will prove an invaluable and useful reference for practising software engineers and researchers. In addition, it will be suitable for graduate students studying empirical methods in software development. {\textcopyright}Springer-Verlag London Limited 2008.},
author = {Shull, Forrest and Singer, Janice and Sj{\o}berg, Dag I K},
doi = {10.1007/978-1-84800-044-5},
editor = {Shull, Forrest and Singer, Janice and Sj{\o}berg, Dag I K},
isbn = {978-1-84-800043-8},
month = {nov},
publisher = {Springer},
title = {{Guide to Advanced Empirical Software Engineering}},
year = {2008}
}
@inproceedings{Cummaudo:2020icse,
address = {Seoul, Republic of Korea},
annote = {In Press},
author = {Cummaudo, Alex and Vasa, Rajesh and Barnett, Scott and Grundy, John and Abdelrazek, Mohamed},
booktitle = {Proceedings of the 42nd International Conference on Software Engineering},
keywords = {InPress},
mendeley-tags = {InPress},
month = {jul},
publisher = {ACM},
title = {{Interpreting Cloud Computer Vision Pain-Points: A Mining Study of Stack Overflow}},
year = {2020}
}
@inproceedings{Lei:2016wi,
abstract = {Prediction without justification has limited applicability. As a remedy, we learn to extract pieces of input text as justifications - rationales - that are tailored to be short and coherent, yet sufficient for making the same prediction. Our approach combines two modular components, generator and encoder, which are trained to operate well together. The generator specifies a distribution over text fragments as candidate rationales and these are passed through the encoder for prediction. Rationales are never given during training. Instead, the model is regularized by desiderata for rationales. We evaluate the approach on multi-aspect sentiment analysis against manually annotated test cases. Our approach outperforms attention-based baseline by a significant margin. We also successfully illustrate the method on the question retrieval task.},
address = {Austin, TX, USA},
archivePrefix = {arXiv},
arxivId = {1606.04155},
author = {Lei, Tao and Barzilay, Regina and Jaakkola, Tommi},
booktitle = {Proceedings of the 9th International Joint Conference on Natural Language Processing and Conference on Empirical Methods in Natural Language Processing},
doi = {10.18653/v1/d16-1011},
eprint = {1606.04155},
isbn = {978-1-94-562625-8},
month = {nov},
pages = {107--117},
publisher = {Association for Computational Linguistics},
title = {{Rationalizing neural predictions}},
year = {2016}
}
@book{Krippendorff:2018tda,
author = {Krippendorff, Klaus},
isbn = {978-1-50-639566-1},
publisher = {SAGE},
series = {An Introduction to Its Methodology},
title = {{Content Analysis}},
year = {1980}
}
@inproceedings{Michie:1988te,
address = {Glasgow, Scotland, UK},
author = {Michie, D},
booktitle = {Proceedings of the 3rd European Conference on European Working Session on Learning},
isbn = {978-0-27-308800-4},
month = {oct},
pages = {107--122},
publisher = {Pitman Publishing, Inc.},
title = {{Machine learning in the next five years}},
year = {1988}
}
@inproceedings{7180082,
abstract = {API design is known to be a challenging craft, as API designers must balance their elegant ideals against 'real-world' concerns, such as utility, performance, backwards compatibility, and unforeseen emergent uses. However, to date, there is no principled method to collect or analyze API usability information that incorporates input from typical developers. In practice, developers often turn to Q{\&}A websites such as stackoverflow.com (SO) when seeking expert advice on API use, the popularity of such sites has thus led to a very large volume of unstructured information that can be searched with diligence for answers to specific questions. The collected wisdom within such sites could, in principle, be of great help to API designers to better support developer needs, if only it could be collected, analyzed, and distilled for practical use. In this paper, we present a methodology that combines several techniques, including social network analysis and topic mining, to recommend SO posts that are likely to concern API design-related issues. To establish a comparison baseline, we introduce two more recommendation approaches: a reputation-based recommender and a random recommender. We have found that when applied to Q{\&}A discussion of two popular mobile platforms, Android and iOS, our methodology achieves up to 93{\%} accuracy and is more stable with its recommendations when compared to the two baseline techniques.},
address = {Florence, Italy},
author = {Wang, Wei and Malik, Haroon and Godfrey, Michael W},
booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
doi = {10.1109/MSR.2015.28},
isbn = {978-0-7695-5594-2},
issn = {2160-1860},
keywords = {API usability,Application program interfaces,Online Q{\&}A,Recommendation systems,Software ecosystems,Stackoverflow},
month = {may},
pages = {224--234},
publisher = {IEEE},
title = {{Recommending Posts concerning API Issues in Developer Q{\&}A Sites}},
year = {2015}
}
@inproceedings{Parnas:2007fb,
abstract = {This experience and research based paper discusses the reasons that software cannot be trusted and then explains how the use of greatly improved documentation can make software more trustworthy. It shows how tabular expressions can be used to prepare software documents that are both precise and easily used by developers, inspectors, and testers. The paper reviews a number of "tried and true" ideas and illustrates some new refinements in the methods that resulted from recent research. It is intended both to tell developers of techniques available to them and to suggest new research areas. {\textcopyright} 2007 IEEE.},
address = {Plano, TX, USA},
author = {Parnas, David L. and Vilkomir, Sergiy A.},
booktitle = {Proceedings of 10th IEEE International Symposium on High Assurance Systems Engineering},
doi = {10.1109/HASE.2007.63},
issn = {1530-2059},
keywords = {Critical software,Documentation,Specifications,Testing},
month = {nov},
pages = {237--244},
publisher = {IEEE},
title = {{Precise documentation of critical software}},
year = {2007}
}
@inproceedings{Yi:2004ve,
abstract = {Web services aim to support efficient integration of applications over Web. Most Web services are stateful, such as services for business processes, and they converse with each other via properly ordered interactions, instead of individual unrelated invocations. In order to address efficient integration of conversational Web services, we create a unified specification model for both conversation protocol and composition; we propose methods to integrate a partner service with complex conversation protocol into a composition of Web services; assure the correctness of composition by formal verification. The mapping between our model and BPEL4WS is also discussed.},
address = {San Diego, CA, USA},
author = {Yi, Xiaochuan and Kochut, Krys J},
booktitle = {Proceedings of the 2004 IEEE International Conference on Web Services},
doi = {10.1109/icws.2004.1314810},
isbn = {0-76-952167-3},
month = {jul},
pages = {756--760},
publisher = {IEEE},
title = {{A CP-nets-based design and verification framework for web services composition}},
year = {2004}
}
@article{Kitchenham:2010wy,
abstract = {Systematic literature reviews (SLRs) are a major tool for supporting evidence-based software engineering. Adapting the procedures involved in such a review to meet the needs of software engineering and its literature remains an ongoing process. As part of this process of refinement, we undertook two case studies which aimed 1) to compare the use of targeted manual searches with broad automated searches and 2) to compare different methods of reaching a consensus on quality. For Case 1, we compared a tertiary study of systematic literature reviews published between January 1, 2004 and June 30, 2007 which used a manual search of selected journals and conferences and a replication of that study based on a broad automated search. We found that broad automated searches find more studies than manual restricted searches, but they may be of poor quality. Researchers undertaking SLRs may be justified in using targeted manual searches if they intend to omit low quality papers, or they are assessing research trends in research methodologies. For Case 2, we analyzed the process used to evaluate the quality of SLRs. We conclude that if quality evaluation of primary studies is a critical component of a specific SLR, assessments should be based on three independent evaluators incorporating at least two rounds of discussion. {\textcopyright}2010 Springer Science+Business Media, LLC.},
author = {Kitchenham, Barbara A and Brereton, Pearl and Turner, Mark and Niazi, Mahmood K and Linkman, Stephen and Pretorius, Rialette and Budgen, David},
doi = {10.1007/s10664-010-9134-8},
issn = {1382-3256},
journal = {Empirical Software Engineering},
keywords = {Automated search,Broad search,Case study,Manual search,Mapping studies,Quality evaluation process,Systematic literature review,Targeted search},
number = {6},
pages = {618--653},
title = {{Refining the systematic literature review process-two participant-observer case studies}},
volume = {15},
year = {2010}
}
@book{Sugiyama:2017ud,
address = {Cambridge, MA, USA},
author = {Schwaighofer, Anton and Lawrence, Neil D},
editor = {Qui{\~{n}}onero-Candela, Joaquin and Sugiyama, Masashi},
isbn = {978-0-26-217005-5},
publisher = {The MIT Press},
title = {{Dataset shift in machine learning}},
year = {2008}
}
@article{Bratthall2002,
abstract = {As the demand for empirical evidence for claims of improvements in software development and evolution has increased, the use of empirical methods such as case studies has grown. In case study methodology various types of triangulation is a commonly recommended technique for increasing validity. This study investigates a multiple data source case study with the objective of identifying whether more findings, trustworthier findings and other findings are made using multiple data source triangulation, than had a single data source been used. The case study investigated analyses key lead-time success factors for a software evolution project in a large organization developing eBusiness systems with high-availability high throughput transaction characteristics. By tracing each finding in that study to the individual evidences motivating the finding, it is suggested that a multiple data source explorative case study can have a higher validity than a single data source study. It is concluded that a careful case study design with multiple sources of evidence can result in not only better justified findings than a single data source study, but also other findings. Thus this study provides empirically derived evidence that a multiple data source case study is more trustworthy than a comparable single data source case study.},
author = {Bratthall, Lars and J{\o}rgensen, Magne},
doi = {10.1023/A:1014866909191},
issn = {1382-3256},
journal = {Empirical Software Engineering},
keywords = {Case study,Evidence,Research method,Triangulation,Trustworthiness,Validity},
title = {{Can you trust a single data source exploratory software engineering case study?}},
year = {2002}
}
@book{RamanAnandHoder2015,
address = {Sebastopol, CA, USA},
author = {{Raman Anand; Hoder}, Chris},
booktitle = {Building Intelligent Apps with Cognitive APIs},
edition = {1st},
isbn = {978-1-49-205862-5},
pages = {97},
publisher = {O'Reilly Media, Inc.},
title = {{Building Intelligent Apps with Cognitive APIs}},
year = {2019}
}
@inproceedings{Tahir:2018ks,
abstract = {This paper investigates how developers discuss code smells and anti-patterns over Stack Overflow to understand better their perceptions and understanding of these two concepts. Understanding developers' perceptions of these issues are important in order to inform and align future research efforts and direct tools vendors in the area of code smells and anti-patterns. In addition, such insights could lead the creation of solutions to code smells and anti-patterns that are better fit to the realities developers face in practice. We applied both quantitative and qualitative techniques to analyse discussions containing terms associated with code smells and anti-patterns. Our findings show that developers widely use Stack Overflow to ask for general assessments of code smells or anti-patterns, instead of asking for particular refactoring solutions. An interesting finding is that developers very often ask their peers 'to smell their code' (i.e., ask whether their own code 'smells' or not), and thus, utilize Stack Overflow as an informal, crowd-based code smell/anti-pattern detector. We conjecture that the crowd-based detection approach considers contextual factors, and thus, tends to be more trusted by developers over automated detection tools. We also found that developers often discuss the downsides of implementing specific design patterns, and 'flag' them as potential anti-patterns to be avoided. Conversely, we found discussions on why some anti-patterns previously considered harmful should not be flagged as anti-patterns. Our results suggest that there is a need for: 1) more context-based evaluations of code smells and anti-patterns, and 2) better guidelines for making trade-offs when applying design patterns or eliminating smells/anti-patterns in industry.},
address = {Christchurch, New Zealand},
author = {Tahir, Amjed and Yamashita, Aiko and Licorish, Sherlock and Dietrich, Jens and Counsell, Steve},
booktitle = {Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering},
doi = {10.1145/3210459.3210466},
isbn = {978-1-45-036403-4},
keywords = {Anti-patterns,Code smells,Empirical study,Mining software repositories,Stack Overflow},
month = {jun},
pages = {68--78},
publisher = {ACM},
title = {{Can you tell me if it smells? A study on how developers discuss code smells and anti-patterns in Stack Overflow}},
year = {2018}
}
@article{Miles:1994ty,
abstract = {The latest edition of this best-selling textbook by Miles and Huberman not only is considerably expanded in content, but is now available in paperback. Bringing the art of qualitative analysis up-to-date, this edition adds hundreds of new techniques, ideas and references developed in the past decade. The increase in the use of computers in qualitative analysis is also reflected in this volume. There is an extensive appendix on criteria to choose from among the currently available analysis packages. Through examples from a host of social science and professional disciplines, Qualitative Data Analysis remains the most comprehensive and complete treatment of this topic currently available to scholars and applied researchers.},
author = {Schwandt, Thomas A},
doi = {10.1016/0149-7189(96)88232-2},
issn = {0149-7189},
journal = {Evaluation and Program Planning},
number = {1},
pages = {106--107},
title = {{Qualitative data analysis: An expanded sourcebook}},
volume = {19},
year = {1996}
}
@article{McLellan:1998vu,
abstract = {Imagine hypothetically, just for a moment, that programmers are humans," writes Steven Pemberton in a July 1997 magazine devoted to human-computer interaction design and development. "Now suppose for a moment, also for the sake of the argument, that their chief method of communicating and interacting with computers was with programming languages. What would we, as HCI people, then do? Run screaming in the other direction...." 1 It is a good question and, unfortunately, an all too common response. It's hard enough for us to ensure that product interfaces, like those for Excel or Word, are easy to use and learn. But programmers are users, too. They need application and system libraries that are just as easy to learn and use as the products they build from these libraries. Listen to this customer: "I think it would be worthwhile if all developers would spend maybe a couple of hours a year seeing how the[ir] product is used by...customers. Just watching them. And while they're watching ...the customer would say, 'I don't like the way this works....'You need to see how they use it." 2 Now ask yourself: why is it easier to visualize the customer who's purchased a financial accounting package from a neighborhood computer outlet, rather than a programmer whose company has just purchased a new Java class library? Wouldn't the developer of this library find it worthwhile to watch programmers work with it?},
author = {McLellan, Samuel G. and Roesler, Alvin W. and Tempest, Joseph T. and Spinuzzi, Clay I.},
doi = {10.1109/52.676963},
issn = {0740-7459},
journal = {IEEE Software},
number = {3},
pages = {78--86},
title = {{Building more usable APIs}},
volume = {15},
year = {1998}
}
@article{Klein:1999uv,
abstract = {This article discusses the conduct and evaluation of interpretive research in information systems. While the conventions for evaluating information systems case studies conducted according to the natural science model of social science are now widely accepted, this is not the case for interpretive field studies. A set of principles for the conduct and evaluation of interpretive field research in information systems is proposed, along with their philosophical rationale. The usefulness of the principles is illustrated by evaluating three published interpretive field studies drawn from the IS research literature. The intention of the paper is to further reflection and debate on the important subject of grounding interpretive research methodology.},
author = {Klein, Heinz K and Myers, Michael D},
doi = {10.2307/249410},
issn = {0276-7783},
journal = {MIS Quarterly: Management Information Systems},
keywords = {Case study,Critical perspective,Ethnography,Field study,Hermeneutics,IS research methodologies,Interpretivist perspective},
number = {1},
pages = {67--94},
title = {{A set of principles for conducting and evaluating interpretive field studies in information systems}},
volume = {23},
year = {1999}
}
@article{Arnold2019FactSheets:Conformity,
author = {Arnold, M and Piorkowski, D and Reimer, D and Richards, J and Tsay, J and Varshney, K R and Bellamy, R K E and Hind, M and Houde, S and Mehta, S and Mojsilovic, A and Nair, R and Ramamurthy, K Natesan and Olteanu, A},
doi = {10.1147/JRD.2019.2942288},
journal = {IBM Journal of Research and Development},
number = {4-5},
pages = {6:1 -- 6:13},
publisher = {IBM Corporation},
title = {{FactSheets: Increasing trust in AI services through supplier's declarations of conformity}},
volume = {63},
year = {2019}
}
@inproceedings{Alm2005EmotionsText,
address = {Vancouver, BC, Canada},
author = {Alm, Cecilia Ovesdotter and Roth, Dan and Sproat, Richard},
booktitle = {Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing},
doi = {10.3115/1220575.1220648},
month = {oct},
pages = {579--586},
publisher = {Association for Computational Linguistics},
title = {{Emotions from Text: Machine Learning for Text-Based Emotion Prediction}},
year = {2005}
}
@book{Witten:2016ut,
abstract = {Data Mining: Practical Machine Learning Tools and Techniques, Fourth Edition, offers a thorough grounding in machine learning concepts, along with practical advice on applying these tools and techniques in real-world data mining situations. This highly anticipated fourth edition of the most acclaimed work on data mining and machine learning teaches readers everything they need to know to get going, from preparing inputs, interpreting outputs, evaluating results, to the algorithmic methods at the heart of successful data mining approaches. Extensive updates reflect the technical changes and modernizations that have taken place in the field since the last edition, including substantial new chapters on probabilistic methods and on deep learning. Accompanying the book is a new version of the popular WEKA machine learning software from the University of Waikato. Authors Witten, Frank, Hall, and Pal include today's techniques coupled with the methods at the leading edge of contemporary research. Please visit the book companion website at http://www.cs.waikato.ac.nz/ml/weka/book.html It contains Powerpoint slides for Chapters 1-12. This is a very comprehensive teaching resource, with many PPT slides covering each chapter of the book Online Appendix on the Weka workbench; again a very comprehensive learning aid for the open source software that goes with the book Table of contents, highlighting the many new sections in the 4th edition, along with reviews of the 1st edition, errata, etc. Provides a thorough grounding in machine learning concepts, as well as practical advice on applying the tools and techniques to data mining projects Presents concrete tips and techniques for performance improvement that work by transforming the input or output in machine learning methods Includes a downloadable WEKA software toolkit, a comprehensive collection of machine learning algorithms for data mining tasks-in an easy-to-use interactive interface Includes open-access online courses that introduce practical applications of the material in the book.},
author = {Witten, Ian H and Frank, Eibe and Hall, Mark A and Pal, Christopher J},
booktitle = {Data Mining: Practical Machine Learning Tools and Techniques},
doi = {10.1016/c2009-0-19715-5},
isbn = {978-0-12-804291-5},
pages = {1--621},
publisher = {Morgan Kaufmann},
title = {{Data Mining: Practical Machine Learning Tools and Techniques}},
year = {2016}
}
@article{Uddin:2019cz,
abstract = {With the proliferation of online developer forums, developers share their opinions about the APIs they use. The plethora of such information can present challenges to the developers to get quick but informed insights about the APIs. To understand the potential benefits of such API reviews, we conducted a case study of opinions in Stack Overflow using a benchmark dataset of 4522 sentences. We observed that opinions about diverse API aspects (e.g., usability) are prevalent and offer insights that can shape developers{\&}{\#}x0027; perception and decisions related to software development. Motivated by the finding, we built a suite of techniques to automatically mine and categorize opinions about APIs from forum posts. First, we detect opinionated sentences in the forum posts. Second, we associate the opinionated sentences to the API mentions. Third, we detect API aspects (e.g., performance, usability) in the reviews. We developed and deployed a tool called Opiner, supporting the above techniques. Opiner is available online as a search engine, where developers can search for APIs by their names to see all the aggregated opinions about the APIs that are automatically mined and summarized from developer forums.},
annote = {In Press},
author = {Uddin, Gias and Khomh, Foutse},
doi = {10.1109/TSE.2019.2900245},
issn = {1939-3520},
journal = {IEEE Transactions on Software Engineering},
keywords = {API,API Aspect,API Review Mining,Benchmark testing,Categorization,Data mining,InPress,Java,Opinion,Review,Search engines,Tools,Usability},
mendeley-tags = {InPress},
month = {feb},
title = {{Automatic Mining of Opinions Expressed About APIs in Stack Overflow}},
year = {2019}
}
@misc{Draper:vb,
address = {Glasgow, Scotland, UK},
author = {Draper, Stephen W},
booktitle = {University of Glasgow},
publisher = {University of Glasgow},
title = {{The Hawthorne, Pygmalion, Placebo and other effects of expectation: some notes}},
url = {http://bit.ly/2uO2Kth},
year = {2006}
}
@incollection{OpenSoftwareFoundation:1991vp,
author = {{Open Software Foundation}},
booktitle = {OSF DCE application development guide: revision 1.0},
month = {dec},
publisher = {Prentice Hall},
title = {{Part 3: DCE Remote Procedure Call (RPC)}},
year = {1991}
}
@misc{Howard:2018tz,
annote = {Accessed: 28 August 2018},
author = {Howard, Christian},
month = {may},
title = {{Introducing Google AI}},
url = {http://bit.ly/2uI6vAr},
year = {2018}
}
@misc{McGowen:2019vt,
author = {McGowen, Bret},
month = {jan},
title = {{Machine learning with Google APIs}},
url = {http://bit.ly/3aUQpo2},
year = {2019}
}
@inproceedings{Kurakin:2016vw,
abstract = {Most existing machine learning classifiers are highly vulnerable to adversarial examples. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake. Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model. Up to now, all previous work has assumed a threat model in which the adversary can feed data directly into the machine learning classifier. This is not always the case for systems operating in the physical world, for example those which are using signals from cameras and other sensors as input. This paper shows that even in such physical world scenarios, machine learning systems are vulnerable to adversarial examples. We demonstrate this by feeding adversarial images obtained from a cell-phone camera to an ImageNet Inception classifier and measuring the classification accuracy of the system. We find that a large fraction of adversarial examples are classified incorrectly even when perceived through the camera.},
address = {Toulon, France},
archivePrefix = {arXiv},
arxivId = {1607.02533},
author = {Kurakin, Alexey and Goodfellow, Ian J and Bengio, Samy},
booktitle = {Proceedings of the 5th International Conference on Learning Representations},
eprint = {1607.02533},
month = {apr},
title = {{Adversarial examples in the physical world}},
year = {2017}
}
@inproceedings{Kavaler:2013uh,
abstract = {Programming is knowledge intensive. While it is well understood that programmers spend lots of time looking for information, with few exceptions, there is a significant lack of data on what information they seek, and why. Modern platforms, like Android, comprise complex APIs that often perplex programmers. We ask: which elements are confusing, and why? Increasingly, when programmers need answers, they turn to StackOverflow. This provides a novel opportunity. There are a vast number of applications for Android devices, which can be readily analyzed, and many traces of interactions on StackOverflow. These provide a complementary perspective on using and asking, and allow the two phenomena to be studied together. How does the market demand for the USE of an API drive the market for knowledge about it? Here, we analyze data from Android applications and StackOverflow together, to find out what it is that programmers want to know and why. {\textcopyright}2013 Springer International Publishing.},
address = {Kyoto, Japan},
author = {Kavaler, David and Posnett, Daryl and Gibler, Clint and Chen, Hao and Devanbu, Premkumar and Filkov, Vladimir},
booktitle = {Proceedings of the 5th International Conference on Social Infomatics},
doi = {10.1007/978-3-319-03260-3_35},
isbn = {978-3-31-903259-7},
issn = {0302-9743},
month = {nov},
pages = {405--418},
publisher = {Springer},
title = {{Using and asking: APIs used in the Android market and asked about in StackOverflow}},
year = {2013}
}
@inproceedings{Head:2018baa,
abstract = {Without usable and accurate documentation of how to use an API, developers can find themselves deterred from reusing relevant code. In C++, one place developers can find documentation is in a header file. When information is missing, they may look at the corresponding implementation code. To understand what's missing from C++ API documentation and the factors influencing whether it will be fixed, we conducted a mixed-methods study involving two experience sampling surveys with hundreds of developers at the moment they visited implementation code, interviews with 18 of those developers, and interviews with 8 API maintainers. In many cases, updating documentation may provide only limited value for developers, while requiring effort maintainers don't want to invest. We identify a set of questions maintainers and tool developers should consider when improving API-level documentation.},
address = {Gothenburg, Sweden},
author = {Head, Andrew and Sadowski, Caitlin and Murphy-Hill, Emerson and Knight, Andrea},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
doi = {10.1145/3180155.3180176},
issn = {0270-5257},
month = {may},
pages = {643--653},
publisher = {ACM},
series = {questions and tradeoffs with API documentation for C++ projects},
title = {{When not to comment: Questions and tradeoffs with API documentation for C++ projects}},
year = {2018}
}
@inproceedings{Johansson:2009uo,
abstract = {Some data mining problems require predictive models to be not only accurate but also comprehensible. Comprehensibility enables human inspection and understanding of the model, making it possible to trace why individual predictions are made. Since most high-accuracy techniques produce opaque models, accuracy is, in practice, regularly sacrificed for comprehensibility. One frequently studied technique, often able to reduce this accuracy vs. comprehensibility tradeoff, is rule extraction, i.e., the activity where another, transparent, model is generated from the opaque. In this paper, it is argued that techniques producing transparent models, either directly from the dataset, or from an opaque model, could benefit from using an oracle guide. In the experiments, genetic programming is used to evolve decision trees, and a neural network ensemble is used as the oracle guide. More specifically, the datasets used by the genetic programming when evolving the decision trees, consist of several different combinations of the original training data and "oracle data", i.e., training or test data instances, together with corresponding predictions from the oracle. In total, seven different ways of combining regular training data with oracle data were evaluated, and the results, obtained on 26 UCI datasets, clearly show that the use of an oracle guide improved the performance. As a matter of fact, trees evolved using training data only had the worst test set accuracy of all setups evaluated. Furthermore, statistical tests show that two setups, both using the oracle guide, produced significantly more accurate trees, compared to the setup using training data only. {\textcopyright}2009 IEEE.},
address = {Nashville, TN, USA},
author = {Johansson, Ulf and Niklasson, Lars},
booktitle = {Proceedings of the 2009 IEEE Symposium on Computational Intelligence and Data Mining},
doi = {10.1109/CIDM.2009.4938655},
isbn = {978-1-42-442765-9},
month = {may},
pages = {238--244},
publisher = {IEEE},
title = {{Evolving decision trees using oracle guides}},
year = {2009}
}
@inproceedings{wrobel2013,
address = {Sopot, Poland},
author = {Wrobel, Michal R},
booktitle = {Proceedings of 6th International Conference on Human System Interactions},
doi = {10.1109/HSI.2013.6577875},
month = {jun},
pages = {518--523},
publisher = {IEEE},
title = {{Emotions in the software development process}},
year = {2013}
}
@article{Abdalkareem2017WhatOverflow,
author = {Abdalkareem, R and Shihab, E and Rilling, J},
doi = {10.1109/MS.2017.31},
journal = {IEEE Software},
number = {2},
pages = {53--60},
title = {{What Do Developers Use the Crowd For? A Study Using Stack Overflow}},
volume = {34},
year = {2017}
}
@book{Spector:1992uj,
abstract = {Summated scales have four characteristics: multiple items; quantitative measurement; no right answer; and, each item of scale is a statement. Mutliple item scales are used for reliability and precision. "Reliability assures that a scale can consistently measure something, but it does not assure that it will measure what it is designed to measure. This property (that a scale measures its intended construct) is validity" (6-7). While reliability is evaluated with test-retest, internal consistency or other types of reliability tests, validity if evaluated in reference to theoretical context and hypothesized relationships with the construct and other variables. The theory of summated rating scales is described in chapter 2, where it is noted that one of the most troublesome sources of biases (or non-random error) is social desirability. Another is acquiescence responses, where people tend to agree with all items regardless of content. Chapter 3 addresses the importance of defining the construct to be measured, and chapter 4 desiging a scale. Approach recommended is inductive one in which theoretical ideas guide validation strategy. The deductive approach is more exploratory and leaves much room for misinterpretation. Constructs vary from being specific and narrow to being multi-dimensional and involving sub-scales."Locus of control" reserach is used as an example throughout this monograph to discuss scale construction. Three types of response choices are described: agreement, evaluation, and frequency. Scales can be unipolar or bipolar. Attitudes are often bipolar because there is a positive, neutral, negative response. These scales can be numbered from 1to x or from -x to +x. Five rules for good items are: express only one idea; use both positively and negatively worded items; avoid expressions, jargon, etc.; consider reading level of respondents; and, avoid use of negatives to reverse wording. Chapter 5 discusses conducting the item analysis, in order to determine internal consistency of the scale and eliminate inconsistent items. The item-remainder (or part-whole or item-whole) coefficient measures how well each item relates to other items in the analysis. Items should be scaled in same direction, so some scales may need to be reversed before the analysis. Two methods can be used to decide if items should be retained: m-items chosen or criterion for coefficient (e.g., 0.40). Coefficient alpha also measures consistency, and is a function of number of items and their degree of correlation. Note that internal consistency can result if more than one highly corrrelated measure constructs comprise the scale. In choosing scale items, both item-remainder and alpha coefficient are used. Items may also be deleted based on their correlations with external variables (such as a social desirability measure). When item analysis results in too few items, it may be helpful to estimate number of items needed to achieve acceptable level of internal consistency, using, e.g., Spearman-Brown prophesy formula. Multidimensional scales are discussed starting on pg. 39. Many constructs are broad and may contain multiple aspects. Attitudes toward complex things wuch as gov't often contain many dimensions. Subscales are useful for these constructs. Shared items in scales may cause problems because relationships among the sub-scale constructs may be due to a real relationship or to shared items. Chapter 6 discusses validation. Typical strategy involves testing scale in context of hypothesized interrelations between construct and other variables. This is similar to testing a theory, in that validity cannot be proven. Evidence is simply collected to support or refute validity. As with a theory, a construct is tentatively accepted because it is useful. A few methods of validity evaluation are described: criterion-related validity, discrimnant and convergent validities, and factor analysis. For criterion-related validity, scale is validated in relation to theoretically-based hypotheses. Concurrent validity involve simultaneously collected data on scale and related variables, while predictive validity involves collecting data on scale of interest prior to criterion variables. Known-groups validity assess hypothesized differences between certain groups using t-tests, ANOVA, etc. Convergent validity means different measures of same construct are strongly related, while discriminant validity means measures of different constructs should relate only modestly. An example of Multitrait-Multimethod Matrix is presented. Two types of factor analysis are discussed: confirmatory, where there is a hypothesized structure, and exploratory. Basic idea of factor analysis is to reduce number of items to smaller number of underlying gorups of items, called factors. For multidimensional scales, additional items tend to produce stronger factors that account for more variable. Poor items and response biases can wreak havoc on factor solution. The eigenvalue represents relative proportion of variance accounted for by factor. If items don't correlate, eigenvalues will reflect only variance in original items and will equal 1. If perfectly correlated, single factor is produced with eigenvalue equal to number of items and other eigenvalues with equal 0. If items for several factors, each will have eigenvalue greater than one, meaning it is accounting for more variance than a single item. Once factors identified, orthogonal rotation procedure is applied, in order to produce clusters of items based on mathematical criteria. Loading matrix produces factor loadings that are correlations of item with each factor. Minimum value of {\~{}}0.30-.35 suggests that an item loads significantly onto a factor. One difficulty is the subjective judgement necessary to determine number of factors. Note that factor analysis can be sensitive to total set of items, and adding/deleting single item can have profound effects. Factor analysis is not likely to be useful for scales with few items. With exploratory factor analysis, best fitting factor structure is fit to data. With confirmatory factor analsyis, structure is hypothesized in advance. Covariance structure modeling structures such as LISREL and EQS are described. Lastly, reliability and norms are discussed in chapter 7.},
address = {Newbury Park, CA, USA},
author = {Spector, Paul},
booktitle = {Summated Rating Scale Construction},
doi = {10.4135/9781412986038},
isbn = {978-0-80-394341-4},
publisher = {SAGE},
title = {{Summated Rating Scale Construction}},
year = {1992}
}
@book{Pirsig:1974vs,
author = {Pirsig, Robert M},
edition = {1st},
isbn = {9-780-06-058946-2},
publisher = {HarperTorch},
title = {{Zen and the art of motorcycle maintenance: An inquiry into values}},
year = {1974}
}
@article{Cummaudo:2020tse,
annote = {Unpublished},
author = {Cummaudo, Alex and Vasa, Rajesh and Grundy, John},
keywords = {InReview},
mendeley-tags = {InReview},
title = {{Assessing API documentation knowledge for computer vision services}},
year = {2020}
}
@inproceedings{Kaufman:1999vg,
abstract = {In concept learning or data mining tasks, the learner is typically faced with a choice of many possible hypotheses characterizing the data. If one can assume that the training data are noise-free, then the generated hypothesis should be complete and consistent with regard to the data. In real-world problems, however, data are often noisy, and an insistence on full completeness and consistency is no longer valid. The problem then is to determine a hypothesis that represents the “best” trade-off between completeness and consistency. This paper presents an approach to this problem in which a learner seeks rules optimizing a description quality criterion that combines completeness and consistency gain, a measure based on consistency that reflects the rule's benefit. The method has been implemented in the AQ18 learning and data mining system and compared to several other methods. Experiments have indicated the flexibility and power of the proposed method.},
address = {Warsaw, Poland},
author = {Kaufman, Kenneth A and Michalski, Ryszard S},
booktitle = {Proceedings of the 11th European Conference on Principles and Practice of Knowledge Discovery in Databases},
doi = {10.1007/BFb0095128},
isbn = {3-540-65965-X},
issn = {1611-3349},
month = {sep},
pages = {411--419},
publisher = {Springer},
title = {{Learning from inconsistent and noisy data: The AQ18 approach}},
volume = {1609},
year = {1999}
}
@techreport{LoGiudice:2016wf,
author = {{Lo Giudice}, Diego and Mines, Christopher and LeClair, Amanda and Curran, Rowan and Homan, Amy},
institution = {Forrester Research, Inc.},
month = {nov},
title = {{How AI Will Change Software Development And Applications}},
url = {http://bit.ly/38RiAlN},
year = {2016}
}
@misc{wiki:dataset-list,
author = {{Wikipedia Contributors}},
title = {{List of datasets for machine-learning research — Wikipedia, The Free Encyclopedia}},
url = {https://bit.ly/3cZgwLb},
year = {2020}
}
@article{Chambers:1991uh,
abstract = {Less than 20 percent of elderly and other high-risk persons targeted for annual influenza vaccination are immunized each year. In most busy practice settings, it is difficult for primary care physicians to identify every patient in need of preventive health interventions. The purpose of this study was to assess the effect of microcomputer-generated reminders on influenza vaccination rates in a university-based family practice center. The practice uses an interactive encounter form system from which updated clinical information is routinely entered into a cumulative database. During a 2-month period, 686 patients were identified in the database as eligible to receive influenza vaccine according to accepted criteria. Practice physicians (n = 32) were stratified by level of training and randomized to one of three groups, thereby receiving printed reminders on the encounter forms of all, none, or half of their eligible patients. Patients of physicians who always received reminders were more likely to receive influenza vaccine during the study period than patients of the never-reminded physicians (51 percent versus 30 percent, P less than 0.001). Patients whose physicians received reminders for only half their patients had an intermediate likelihood of receiving a vaccination if a reminder was printed (38 percent) but were less likely than the patients of never-reminded physicians to receive the vaccine if no reminder was printed (20 percent, P less than 0.001). This study suggests that physicians learn to depend on reminders for preventive health activities and that reminders are most effective when they are provided at every patient encounter.},
author = {Chambers, C V and Balaban, D J and Carlson, B L and Grasberger, D M},
doi = {10.3122/jabfm.4.1.19},
issn = {0893-8652},
journal = {The Journal of the American Board of Family Practice / American Board of Family Practice},
number = {1},
pages = {19--26},
title = {{The effect of microcomputer-generated reminders on influenza vaccination rates in a university-based family practice center.}},
volume = {4},
year = {1991}
}
@book{Crosby:1979uy,
abstract = {Nontechnical in approach, this how-to manual for managers with accountability for product performance specifies ways in which quality problems can be prevented at each stage of production},
author = {Crosby, Philip B},
isbn = {978-0-07-014512-2},
publisher = {McGraw-Hill},
title = {{Quality is free: The art of making quality certain}},
year = {1979}
}
@article{Henning:2009hz,
author = {Henning, Michi},
doi = {10.1145/1506409.1506424},
issn = {0001-0782},
journal = {Communications of the ACM},
number = {5},
pages = {46--56},
title = {{API design matters}},
volume = {52},
year = {2009}
}
@techreport{Kazman2000,
address = {Pittsburgh, PA, USA},
author = {Kazman, Rick and Klein, Mark and Clements, Paul},
institution = {Software Engineering Institute},
publisher = {Carnegie-Mellon University},
title = {{ATAM: Method for architecture evaluation}},
year = {2000}
}
@article{Narayanan:2018ud,
abstract = {Recent years have seen a boom in interest in machine learning systems that can provide a human-understandable rationale for their predictions or decisions. However, exactly what kinds of explanation are truly human-interpretable remains poorly understood. This work advances our understanding of what makes explanations interpretable in the specific context of verification. Suppose we have a machine learning system that predicts X, and we provide rationale for this prediction X. Given an input, an explanation, and an output, is the output consistent with the input and the supposed rationale? Via a series of user-studies, we identify what kinds of increases in complexity have the greatest effect on the time it takes for humans to verify the rationale, and which seem relatively insensitive.},
annote = {In Press},
archivePrefix = {arXiv},
arxivId = {1802.00682},
author = {Narayanan, Menaka and Chen, Emily and He, Jeffrey and Kim, Been and Gershman, Sam and Doshi-Velez, Finale},
eprint = {1802.00682},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {InPress},
mendeley-tags = {InPress},
title = {{How do Humans Understand Explanations from Machine Learning Systems? An Evaluation of the Human-Interpretability of Explanation}},
year = {2018}
}
@article{Davison:2004wo,
abstract = {Despite the growing prominence of canonical action research (CAR) in the information systems discipline, a paucity of methodological guidance continues to hamper those conducting and evaluating such studies. This article elicits a set of five principles and associated criteria to help assure both the rigor and the relevance of CAR in information systems. The first principle relates to the development of an agreement that facilitates collaboration between the action researcher and the client. The second principle is based upon a cyclical process model for action research that consists of five stages: diagnosis, planning, intervention, evaluation and reflection. Additional principles highlight the critical roles of theory, change through action, and the specification of learning in terms of implications for both research and practice. The five principles are illustrated through the analysis of one recently published CAR study.},
author = {Davison, Robert M and Martinsons, Maris G and Kock, Ned},
doi = {10.1111/j.1365-2575.2004.00162.x},
issn = {1350-1917},
journal = {Information Systems Journal},
keywords = {Canonical action research,Interpretivism,Meta-analysis,Organizational change,Organizational learning,Research frameworks},
number = {1},
pages = {65--86},
title = {{Principles of canonical action research}},
volume = {14},
year = {2004}
}
@article{Borsci2009,
abstract = {The System Usability Scale (SUS), developed by Brooke (Usability evaluation in industry, Taylor {\&} Francis, London, pp 189-194, 1996), had a great success among usability practitioners since it is a quick and easy to use measure for collecting users' usability evaluation of a system. Recently, Lewis and Sauro (Proceedings of the human computer interaction international conference (HCII 2009), San Diego CA, USA, 2009) have proposed a two-factor structure-Usability (8 items) and Learnability (2 items)-suggesting that practitioners might take advantage of these new factors to extract additional information from SUS data. In order to verify the dimensionality in the SUS' two-component structure, we estimated the parameters and tested with a structural equation model the SUS structure on a sample of 196 university users. Our data indicated that both the unidimensional model and the two-factor model with uncorrelated factors proposed by Lewis and Sauro (Proceedings of the human computer interaction international conference (HCII 2009), San Diego CA, USA, 2009) had a not satisfactory fit to the data. We thus released the hypothesis that Usability and Learnability are independent components of SUS ratings and tested a less restrictive model with correlated factors. This model not only yielded a good fit to the data, but it was also significantly more appropriate to represent the structure of SUS ratings. {\textcopyright} 2009 Marta Olivetti Belardinelli and Springer-Verlag.},
author = {Borsci, Simone and Federici, Stefano and Lauriola, Marco},
doi = {10.1007/s10339-009-0268-9},
issn = {16124782},
journal = {Cognitive Processing},
keywords = {Questionnaire,System Usability Scale,Usability evaluation},
title = {{On the dimensionality of the System Usability Scale: A test of alternative measurement models}},
year = {2009}
}
@inproceedings{Iyengar:2017fb,
abstract = {A wide variety of services are available over the Web which can dramatically improve the functionality of applications. These services include information retrieval (including data lookups from a variety of sources and Web searches), natural language understanding, visual recognition, and data storage. A key problem is how to provide support for applications which use these services. This paper presents a rich software development kit (SDK) which accesses these services and provides a variety of features applications need to use these services, optimize performance, and compare them. A key aspect of our SDK is its support for natural language understanding services. We also present a personalized knowledge base built on top of our rich SDK that uses publically available data sources as well as private information. The knowledge base supports data analysis and reasoning over data.},
address = {Atlanta, GA, USA},
author = {Iyengar, Arun},
booktitle = {Proceedings of the 37th International Conference on Distributed Computing Systems},
doi = {10.1109/ICDCS.2017.172},
isbn = {978-1-53-861791-5},
keywords = {Cloud client,Cloud service ranking,Cognitive client,Cognitive services,Service ranking,Software development kit},
month = {jun},
pages = {1856--1864},
publisher = {IEEE},
title = {{Supporting Data Analytics Applications Which Utilize Cognitive Services}},
year = {2017}
}
@article{Bangor2008,
abstract = {This article presents nearly 10 year's worth of System Usability Scale (SUS) data collected on numerous products in all phases of the development lifecycle. The SUS, developed by Brooke (1996), reflected a strong need in the usability community for a tool that could quickly and easily collect a user's subjective rating of a product's usability. The data in this study indicate that the SUS fulfills that need. Results from the analysis of this large number of SUS scores show that the SUS is a highly robust and versatile tool for usability professionals. The article presents these results and discusses their implications, describes nontraditional uses of the SUS, explains a proposed modification to the SUS to provide an adjective rating that correlates with a given score, and provides details of what constitutes an acceptable SUS score. Copyright {\textcopyright} Taylor {\&} Francis Group, LLC.},
author = {Bangor, Aaron and Kortum, Philip T. and Miller, James T.},
doi = {10.1080/10447310802205776},
issn = {10447318},
journal = {International Journal of Human-Computer Interaction},
title = {{An empirical evaluation of the system usability scale}},
year = {2008}
}
@article{Ritzer:1991ge,
abstract = {"The contributors and editor of this work are to be commended for their successful efforts in delineating many of the concerns current within education and in calling for frank debate on these issues by all interested parties. Furthermore, they have stimulated good scholarship by readily admitting to the current state of affairs being one of more questions than answers and more confusion than clarity. They thus remind us that the search for knowledge is one fraught with conflict in a public arena. "The appropriate audience for this volume is assessed to be the reader who derives satisfaction from critical thinking. It would be appropriate for graduate students in education, human services, social sciences, or theology, or any person committed to the endeavor and process of education. "The Paradigm Dialog is one of those rare books that simultaneously stretches the mind while projecting one into self-reflection. For the applied practitioner, whether teacher, counselor, or consultant, the possibility of gaining further insight into the underlying assumptions which constrain one's pedagogy or practice is highly possible upon a critical reading." -The Journal of Applied Rehabilitation Counseling Is scientific positivism, long the reigning paradigm for research in the social sciences, the "best way" to conduct social research? This is the central question examined in The Paradigm Dialog. Recently three key challengers have appeared-postpositivism, critical theory, and constructivism. All three offer researchers new methodological approaches, and all three present fundamental questions that must be addressed. Can research be conducted between paradigms? Are they equally useful in answering questions of applied research? What constitutes good, or ethical, research in each? In this volume, these and other significant questions are examined by a multidisciplinary group of leading figures in qualitative research. Not surprisingly, there is no agreement on the "best" paradigm question, but the dialog offered in this compelling volume deftly explores important issues in selecting the proper paradigm for tackling a variety of research questions. With a group of contributors that reads like a veritable who's who in qualitative research, The Paradigm Dialog is a must for anyone conducting research in the social sciences.},
author = {Ritzer, George and Guba, Egon},
doi = {10.2307/3340973},
issn = {0318-6431},
journal = {Canadian Journal of Sociology},
number = {4},
pages = {446},
title = {{The Paradigm Dialog}},
volume = {16},
year = {1991}
}
@inproceedings{Bajaj:2014wg,
abstract = {Modern web applications consist of a significant amount of clientside code, written in JavaScript, HTML, and CSS. In this paper, we present a study of common challenges and misconceptions among web developers, by mining related questions asked on Stack Overflow. We use unsupervised learning to categorize the mined questions and define a ranking algorithm to rank all the Stack Overflow questions based on their importance. We analyze the top 50 questions qualitatively. The results indicate that (1) the overall share of web development related discussions is increasing among developers, (2) browser related discussions are prevalent; however, this share is decreasing with time, (3) form validation and other DOM related discussions have been discussed consistently over time, (4) web related discussions are becoming more prevalent in mobile development, and (5) developers face implementation issues with new HTML5 features such as Canvas. We examine the implications of the results on the development, research, and standardization communities. Copyright is held by the author/owner(s). Publication rights licensed to ACM.},
address = {Hyderabad, India},
author = {Bajaj, Kartik and Pattabiraman, Karthik and Mesbah, Ali},
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
doi = {10.1145/2597073.2597083},
isbn = {978-1-45-032863-0},
keywords = {Stack Overflow,Text mining,Topic modeling,Web developers},
month = {may},
pages = {112--121},
publisher = {ACM},
title = {{Mining questions asked by web developers}},
year = {2014}
}
@article{Frey:2007hs,
abstract = {Clustering data by identifying a subset of representative examples is important for processing sensory signals and detecting patterns in data. Such "exemplars" can be found by randomly choosing an initial subset of data points and then iteratively refining it, but this works well only if that initial choice is close to a good solution. We devised a method called "affinity propagation," which takes as input measures of similarity between pairs of data points. Real-valued messages are exchanged between data points until a high-quality set of exemplars and corresponding clusters gradually emerges. We used affinity propagation to cluster images of faces, detect genes in microarray data, identify representative sentences in this manuscript, and identify cities that are efficiently accessed by airline travel. Affinity propagation found clusters with much lower error than other methods, and it did so in less than one-hundredth the amount of time.},
author = {Frey, Brendan J and Dueck, Delbert},
doi = {10.1126/science.1136800},
issn = {0036-8075},
journal = {Science},
month = {feb},
number = {5814},
pages = {972--976},
title = {{Clustering by passing messages between data points}},
volume = {315},
year = {2007}
}
@article{SiMergeSearchEngineResults,
abstract = {The proliferation of searchable text databases on local area networks and the Internet causes the problem of finding information that may be distributed among many disjoint text databases (distributed information retrieval). How to merge the results returned by selected databases is an important subproblem of the distributed information retrieval task. Previous research assumed that either resource providers cooperate to provide normalizing statistics or search clients down-load all retrieved documents and compute normalized scores without cooperation from resource providers. This article presents a semisupervised learning solution to the result merging problem. The key contribution is the observation that information used to create resource descriptions for resource selection can also be used to create a centralized sample database to guide the normalization of document scores returned by different databases. At retrieval time, the query is sent to the selected databases, which return database-specific document scores, and to a centralized sample database, which returns database-independent document scores. Documents that have both a database-specific score and a database-independent score serve as training data for learning to normalize the scores of other documents. An extensive set of experiments demonstrates that this method is more effective than the well-known CORI result-merging algorithm under a variety of conditions.},
address = {New York, NY, USA},
author = {Si, Luo and Callan, Jamie},
doi = {10.1145/944012.944017},
issn = {1046-8188},
journal = {ACM Transactions on Information Systems},
keywords = {Distributed information retrieval,Resource ranking,Resource selection,Results merging,Semisupervised learning method,Server selection},
month = {oct},
number = {4},
pages = {457--491},
publisher = {ACM},
title = {{A semisupervised learning method to merge search engine results}},
volume = {21},
year = {2003}
}
@inproceedings{Ko:2004td,
abstract = {As programming skills increase in demand and utility, the learnability of end-user programming systems is of utmost importance. However, research on learning barriers in programming systems has primarily focused on languages, overlooking potential barriers in the environment and accompanying libraries. To address this, a study of beginning programmers learning Visual Basic. MET was performed. This identified six types of barriers: design, selection, coordination, use, understanding, and information. These barriers inspire a new metaphor of computation, which provides a more learner-centric view of programming system design. {\textcopyright}2004 IEEE.},
address = {Rome, Italy},
author = {Ko, Andrew J and Myers, Brad A and Aung, Htet Htet},
booktitle = {Proceedings of the 2004 IEEE Symposium on Visual Languages and Human Centric Computing},
doi = {10.1109/vlhcc.2004.47},
isbn = {0-78-038696-5},
month = {sep},
pages = {199--206},
publisher = {IEEE},
title = {{Six learning barriers in end-user programming systems}},
year = {2004}
}
@article{Turhan2012OnModels,
author = {Turhan, Burak and Shepperd, Martin and Menzies, Tim},
doi = {10.1007/s10664-011-9182-8},
journal = {Empirical Software Engineering},
pages = {62--74},
title = {{On the dataset shift problem in software engineering prediction models}},
volume = {17},
year = {2012}
}
@inproceedings{Lin:2014vma,
abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model. {\textcopyright}2014 Springer International Publishing.},
address = {Zurich, Germany},
archivePrefix = {arXiv},
arxivId = {1405.0312},
author = {Lin, Tsung Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'{a}}r, Piotr and Zitnick, C Lawrence},
booktitle = {Proceedings of the 13th European Conference on Computer Vision},
doi = {10.1007/978-3-319-10602-1_48},
editor = {Fleet, David and Pajdla, Tom{\'{a}}s and Schiele, Bernt and Tuytelaars, Tinne},
eprint = {1405.0312},
issn = {1611-3349},
month = {sep},
number = {PART 5},
pages = {740--755},
publisher = {Springer},
title = {{Microsoft COCO: Common objects in context}},
volume = {8693 LNCS},
year = {2014}
}
@article{braiek2018testing,
abstract = {Nowadays, we are witnessing a wide adoption of Machine learning (ML) models in many safety-critical systems, thanks to recent breakthroughs in deep learning and reinforcement learning. Many people are now interacting with systems based on ML every day, e.g., voice recognition systems used by virtual personal assistants like Amazon Alexa or Google Home. As the field of ML continues to grow, we are likely to witness transformative advances in a wide range of areas, from finance, energy, to health and transportation. Given this growing importance of ML-based systems in our daily life, it is becoming utterly important to ensure their reliability. Recently, software researchers have started adapting concepts from the software testing domain (e.g., code coverage, mutation testing, or property-based testing) to help ML engineers detect and correct faults in ML programs. This paper reviews current existing testing practices for ML programs. First, we identify and explain challenges that should be addressed when testing ML programs. Next, we report existing solutions found in the literature for testing ML programs. Finally, we identify gaps in the literature related to the testing of ML programs and make recommendations of future research directions for the scientific community. We hope that this comprehensive review of software testing practices will help ML engineers identify the right approach to improve the reliability of their ML-based systems. We also hope that the research community will act on our proposed research directions to advance the state of the art of testing for ML programs.},
archivePrefix = {arXiv},
arxivId = {1812.02257},
author = {Braiek, Houssem Ben and Khomh, Foutse},
eprint = {1812.02257},
journal = {arXiv preprint arXiv:1812.02257},
month = {dec},
title = {{On Testing Machine Learning Programs}},
url = {http://arxiv.org/abs/1812.02257},
year = {2018}
}
@article{Oreskes:1994gn,
abstract = {Verification and validation of numerical models of natural systems is impossible. This is because natural systems are never closed and because model results are always non-unique. Models can be confirmed by the demonstration of agreement between observation and prediction, but confirmation is inherently partial. Complete confirmation is logically precluded by the fallacy of affirming the consequent and by incomplete access to natural phenomena. Models can only be evaluated in relative terms, and their predictive value is always open to question. The primary value of models is heuristic.},
author = {Oreskes, Naomi and Shrader-Frechette, Kristin and Belitz, Kenneth},
doi = {10.1126/science.263.5147.641},
issn = {0036-8075},
journal = {Science},
number = {5147},
pages = {641--646},
title = {{Verification, validation, and confirmation of numerical models in the earth sciences}},
volume = {263},
year = {1994}
}
@article{Canfora:2006vk,
author = {Canfora, Gerardo and {Di Penta}, Massimiliano},
doi = {10.1109/MITP.2006.51},
issn = {1520-9202},
journal = {IT Professional},
number = {2},
pages = {10--17},
title = {{Testing services and service-centric systems: Challenges and opportunities}},
volume = {8},
year = {2006}
}
@inproceedings{Law2017,
author = {Law, C.-Y. and Grundy, J and Cain, A and Vasa, R and Cummaudo, A},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3013499.3013502},
title = {{User perceptions of using an open learner model visualisation tool for facilitating self-regulated learning}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-85014894003{\&}partnerID=MN8TOARS},
year = {2017}
}
@article{Lethbridge:2005jv,
abstract = {Software engineering is an intensively people-oriented activity, yet too little is known about how designers, maintainers, requirements analysts and all other types of software engineers perform their work. In order to improve software engineering tools and practice, it is therefore essential to conduct field studies, i.e. to study real practitioners as they solve real problems. To do so effectively, however, requires an understanding of the techniques most suited to each type of field study task. In this paper, we provide a taxonomy of techniques, focusing on those for data collection. The taxonomy is organized according to the degree of human intervention each requires. For each technique, we provide examples from the literature, an analysis of some of its advantages and disadvantages, and a discussion of how to use it effectively. We also briefly talk about field study design in general, and data analysis. {\textcopyright}2005 Springer Science + Business Media, Inc.},
author = {Lethbridge, Timothy C and Sim, Susan Elliott and Singer, Janice},
doi = {10.1007/s10664-005-1290-x},
issn = {1382-3256},
journal = {Empirical Software Engineering},
keywords = {Empirical software engineering,Field studies,Work practices},
month = {jul},
number = {3},
pages = {311--341},
title = {{Studying software engineers: Data collection techniques for software field studies}},
volume = {10},
year = {2005}
}
@article{5416726,
abstract = {BACKGROUND-The systematic review is becoming a more commonly employed research instrument in empirical software engineering. Before undue reliance is placed on the outcomes of such reviews it would seem useful to consider the robustness of the approach in this particular research context. OBJECTIVE-The aim of this study is to assess the reliability of systematic reviews as a research instrument. In particular, we wish to investigate the consistency of process and the stability of outcomes. METHOD-We compare the results of two independent reviews undertaken with a common research question. RESULTS-The two reviews find similar answers to the research question, although the means of arriving at those answers vary. CONCLUSIONS-In addressing a well-bounded research question, groups of researchers with similar domain experience can arrive at the same review outcomes, even though they may do so in different ways. This provides evidence that, in this context at least, the systematic review is a robust research method. {\textcopyright}2010 IEEE.},
author = {MacDonell, Stephen and Shepperd, Martin and Kitchenham, Barbara and Mendes, Emilia},
doi = {10.1109/TSE.2010.28},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Empirical software engineering,cost estimation,meta-analysis,systematic review},
month = {sep},
number = {5},
pages = {676--687},
title = {{How reliable are systematic reviews in empirical software engineering?}},
volume = {36},
year = {2010}
}
@article{Aversano:2017ic,
abstract = {Software documentation is a basic component of the software development process and it is very important in all the phases of a software system life cycle. It is plays a very important role from the point of view of both the software engineer and user. Software documentation usually includes textual documentation required by the Software engineering standards, API documentation, Wiki pages and source code comments. Surveys and studies indicate that the documentation is not always available and, if available, only partially addresses the developers' needs, as it is often wrong, incomplete, out-of-date and ambiguous. In the context of ERP - Enterprise Resource Planning, the relevance of the software documentation is even more important due to the complexity of such a kind of software systems and the strategic role they have within operative organizations. This paper focuses on the quality assessment of the documentation of ERP open source systems with the aim of understanding if they include high quality documentation for adequately support anyone want to adopt them and/or executing maintenance activities. Specifically, a quality model is defined and its application to three Open source software system is performed.},
author = {Aversano, Lerina and Guardabascio, Daniela and Tortorella, Maria},
doi = {10.1016/j.procs.2017.11.057},
issn = {1877-0509},
journal = {Procedia Computer Science},
keywords = {Documentation Quality,Documentation maintenance,ERP Open source software,Software documentation,Software metrics},
month = {jan},
pages = {423--430},
title = {{Analysis of the Documentation of ERP Software Projects}},
volume = {121},
year = {2017}
}
@inproceedings{amershi2015modeltracker,
abstract = {Model building in machine learning is an iterative process. The performance analysis and debugging step typically involves a disruptive cognitive switch from model building to error analysis, discouraging an informed approach to model building. We present Model Tracker, an interactive visualization that subsumes information contained in numerous traditional summary statistics and graphs while displaying example-level performance and enabling direct error examination and debugging. Usage analysis from machine learning practitioners building real models with Model Tracker over six months shows Model Tracker is used often and throughout model building. A controlled experiment focusing on Model Tracker's debugging capabilities shows participants prefer Model Tracker over traditional tools without a loss in model performance.},
address = {Seoul, Republic of Korea},
author = {Amershi, Saleema and Chickering, Max and Drucker, Steven M and Lee, Bongshin and Simard, Patrice and Suh, Jina},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
doi = {10.1145/2702123.2702509},
isbn = {978-1-45-033145-6},
keywords = {Debugging,Interactive visualization,Machine learning,Performance analysis},
month = {apr},
pages = {337--346},
publisher = {ACM},
title = {{Modeltracker: Redesigning performance analysis tools for machine learning}},
year = {2015}
}
@article{Haenssle:2018bz,
abstract = {Background: Deep learning convolutional neural networks (CNN) May facilitate melanoma detection, but data comparing a CNN's diagnostic performance to larger groups of dermatologists are lacking. Methods: Google's Inception v4 CNN architecture was trained and validated using dermoscopic images and corresponding diagnoses. In a comparative cross-sectional reader study a 100-image test-set was used (level-I: dermoscopy only; level-II: dermoscopy plus clinical information and images). Main outcome measures were sensitivity, specificity and area under the curve (AUC) of receiver operating characteristics (ROC) for diagnostic classification (dichotomous) of lesions by the CNN versus an international group of 58 dermatologists during level-I or -II of the reader study. Secondary end points included the dermatologists' diagnostic performance in their management decisions and differences in the diagnostic performance of dermatologists during level-I and -II of the reader study. Additionally, the CNN's performance was compared with the top-five algorithms of the 2016 International Symposium on Biomedical Imaging (ISBI) challenge. Results: In level-I dermatologists achieved a mean (6standard deviation) sensitivity and specificity for lesion classification of 86.6{\%} (69.3{\%}) and 71.3{\%} (611.2{\%}), respectively. More clinical information (level-II) improved the sensitivity to 88.9{\%} (69.6{\%}, P ¼ 0.19) and specificity to 75.7{\%} (611.7{\%}, P {\textless}0.05). The CNN ROC curve revealed a higher specificity of 82.5{\%} when compared with dermatologists in level-I (71.3{\%}, P {\textless}0.01) and level-II (75.7{\%}, P {\textless}0.01) at their sensitivities of 86.6{\%} and 88.9{\%}, respectively. The CNN ROC AUC was greater than the mean ROC area of dermatologists (0.86 versus 0.79, P {\textless}0.01). The CNN scored results close to the top three algorithms of the ISBI 2016 challenge. Conclusions: For the first time we compared a CNN's diagnostic performance with a large international group of 58 dermatologists, including 30 experts. Most dermatologists were outperformed by the CNN. Irrespective of any physicians' experience, they May benefit from assistance by a CNN's image classification.},
author = {Haenssle, H A and Fink, C and Schneiderbauer, R and Toberer, F and Buhl, T and Blum, A and Kalloo, A and {Ben Hadj Hassen}, A and Thomas, L and Enk, A and Uhlmann, L and Alt, Christina and Arenbergerova, Monika and Bakos, Renato and Baltzer, Anne and Bertlich, Ines and Blum, Andreas and Bokor-Billmann, Therezia and Bowling, Jonathan and Braghiroli, Naira and Braun, Ralph and Buder-Bakhaya, Kristina and Buhl, Timo and Cabo, Horacio and Cabrijan, Leo and Cevic, Naciye and Classen, Anna and Deltgen, David and Fink, Christine and Georgieva, Ivelina and Hakim-Meibodi, Lara Elena and Hanner, Susanne and Hartmann, Franziska and Hartmann, Julia and Haus, Georg and Hoxha, Elti and Karls, Raimonds and Koga, Hiroshi and Kreusch, Ju¨rgen and Lallas, Aimilios and Majenka, Pawel and Marghoob, Ash and Massone, Cesare and Mekokishvili, Lali and Mestel, Dominik and Meyer, Volker and Neuberger, Anna and Nielsen, Kari and Oliviero, Margaret and Pampena, Riccardo and Paoli, John and Pawlik, Erika and Rao, Barbar and Rendon, Adriana and Russo, Teresa and Sadek, Ahmed and Samhaber, Kinga and Schneiderbauer, Roland and Schweizer, Anissa and Toberer, Ferdinand and Trennheuser, Lukas and Vlahova, Lyobomira and Wald, Alexander and Winkler, Julia and Wo¨lbing, Priscila and Zalaudek, Iris},
doi = {10.1093/annonc/mdy166},
issn = {1569-8041},
journal = {Annals of Oncology},
keywords = {Automated melanoma detection,Computer algorithm,Deep learning convolutional neural network,Dermoscopy,Melanocytic nevi,Melanoma},
month = {may},
number = {8},
pages = {1836--1842},
title = {{Man against Machine: Diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists}},
volume = {29},
year = {2018}
}
@article{Robinson:2007tp,
abstract = {Over the past decade we have performed a sustained series of qualitative studies of software development practice, focusing on social factors. Using an ethnographically-informed approach, we have addressed four areas of software practice: software quality management systems, the emergence of object technology, professional end user development and agile development. Several issues have arisen from this experience, including the nature of research questions that such studies can address, the advantages and challenges associated with being a member of the community under study, and how to maintain rigour in data collection. In this paper, we will draw on our studies to illustrate our approach and to discuss these and other issues. {\textcopyright}2007 Elsevier B.V. All rights reserved.},
author = {Robinson, Hugh and Segal, Judith and Sharp, Helen},
doi = {10.1016/j.infsof.2007.02.007},
issn = {0950-5849},
journal = {Information and Software Technology},
keywords = {Field studies,Qualitative analysis,Software practice},
number = {6},
pages = {540--551},
title = {{Ethnographically-informed empirical studies of software practice}},
volume = {49},
year = {2007}
}
@inproceedings{murgia2014,
address = {Hyderabad, India},
author = {Murgia, Alessandro and Tourani, Parastou and Adams, Bram and Ortu, Marco},
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
doi = {10.1145/2597073.2597086},
month = {may},
pages = {262--271},
publisher = {ACM},
title = {{Do developers feel emotions? an exploratory analysis of emotions in software artifacts}},
year = {2014}
}
@inproceedings{Bigham2006,
abstract = {Images without alternative text are a barrier to equal web access for blind users. To illustrate the problem, we conducted a series of studies that conclusively show that a large fraction of significant images have no alternative text. To ameliorate this problem, we introduce WebInSight, a system that automatically creates and inserts alternative text into web pages on-the-fly. To formulate alternative text for images, we present three labeling modules based on web context analysis, enhanced optical character recognition (OCR) and human labeling. The system caches alternative text in a local database and can add new labels seamlessly after a web page is downloaded, resulting in minimal impact to the browsing experience. Copyright 2006 ACM.},
address = {Portland, OR, USA},
author = {Bigham, Jeffrey P. and Kaminsky, Ryan S. and Ladner, Richard E. and Danielsson, Oscar M. and Hempton, Gordon L.},
booktitle = {Proceedings of the 8th International ACM SIGACCESS Conference on Computers and Accessibility},
doi = {10.1145/1168987.1169018},
keywords = {Optical character recognition,Transformation proxy,Web accessibility,Web studies},
month = {oct},
pages = {181--188},
publisher = {ACM},
title = {{WebInSight: Making web images accessible}},
year = {2006}
}
@inproceedings{Brandt:2009tm,
abstract = {This paper investigates the role of online resources in problem solving. We look specifically at how programmers-an exemplar form of knowledge workers-opportunistically interleave Web foraging, learning, and writing code. We describe two studies of how programmers use online resources. The first, conductcd in the lab. observed participants' Web u*e while building an online chat room. We found that programmers leverage online resources with a range of intentions: They engage in just-in-time learning of new skills and approaches, clarify and extend their existing knowledge, and remind themselves of details deemed not worth remembering. The results also suggest that queries for different purposes have different styles and durations. Do programmers' queries "in the wild" have the same range of intentions, or is this result an artifact of the particular lab setting? We analyzed a month of queries to an online programming portal, examining the lexical structure, refinements made, and result pages visited. Here we also saw traits that suggest the Web is being used for learning and reminding. These results contribute to a theory of online resource usage in programming, and suggest opportunities for tools to facilitate online knowledge work. Copyright 2009 ACM.},
address = {Boston, MA, USA},
author = {Brandt, Joel and Guo, Philip J and Lewenstein, Joel and Dontcheva, Mira and Klemmer, Scott R},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing System},
doi = {10.1145/1518701.1518944},
isbn = {978-1-60-558247-4},
keywords = {Copy-and-paste,Opportunistic programming,Prototyping},
month = {apr},
pages = {1589--1598},
publisher = {ACM},
title = {{Two studies of opportunistic programming: Interleaving web foraging, learning, and writing code}},
year = {2009}
}
@book{Litwin:1995wt,
abstract = {This Second Edition Has Been Thoroughly Revised And Updated And Efforts Have Been Made To Enhance The Usefulness Of The Book. In This Edition A New Chapter The Computer : Its Role In Research Have Been Added Keeping In View Of The Fact That Computers By Now Become A Indispensable Part Of Research Equipment. The Other Salient Feature Of This Revised Edition, Subject Contents Have Been Developed And Restructured At Several Places. New Problems Have Also Been Added In Various Chapters.Adoption Of Appropriate Methodology Is An Essential Characteristic Of Quality Research Studies Irrespective Of The Discipline With Which They Are Related. The Present Book Provides The Basic Tenets Of Methodological Research So That Researchers May Become Familiar With The Art Of Using Research Methods And Techniques.The Book Contains Introductory Explanations Of Several Quantitative Methods Enjoying Wide Use In Social Sciences. It Covers A Fairly Wide Range, Related To Research Methodology. The Presentations Are Uniformly Economical And Cogent. Illustrations Given Are Meaningful And Relevant. The Book Can Be Taken As A Well-Organised Guide For Researchers Whose Methodological Background Is Not Extensive.The Book Is Primarily Intended To Serve As A Textbook For Social Science Students Of All Indian Universities. It Will Also Serve As A Text For The Students Of M.Phil, Management, And Students Of Various Institutes. It Will Serve All Practitioners Doing Research Of One Form Or Other In A General Way.},
address = {Thousand Oaks, CA, USA},
author = {Litwin, Mark},
doi = {10.4135/9781483348957},
isbn = {978-0-80-395704-6},
publisher = {SAGE},
title = {{How to Measure Survey Reliability and Validity}},
volume = {7},
year = {1995}
}
@article{Bouwers2010,
abstract = {Architecture evaluations offer many benefits, including the early detection of problems and a better understanding of a system's possibilities. Although many methods for evaluating architectures are available, studies have shown that industry's adoption of architecture evaluations is low. A reason for this lack of adoption is the limited out-of-the-box process and tool support available to start performing architecture reviews. This article introduces the lightweight sanity check for implemented architectures (LiSCIA) evaluation method. LiSCIA can be used out of the box to perform a first architectural evaluation of a system. The check is based on years of experience in evaluating the maintainability of software systems. By periodically performing this check, developers and project managers can control the implemented architecture's erosion as the system (and its requirements) evolves over time. {\textcopyright} 2006 IEEE.},
author = {Bouwers, Eric and van Deursen, Arie},
doi = {10.1109/MS.2010.60},
issn = {0740-7459},
journal = {IEEE Software},
keywords = {Architecture erosion,Software architecture evaluation,Software architectures,Software quality},
month = {jul},
number = {4},
pages = {44--50},
title = {{A Lightweight Sanity Check for Implemented Architectures}},
volume = {27},
year = {2010}
}
@article{shaver1987,
author = {Shaver, Phillip and Schwartz, Judith and Kirson, Donald and O'Connor, Cary},
doi = {10.1037/0022-3514.52.6.1061},
journal = {Journal of Personality and Social Psychology},
number = {6},
pages = {1061--1086},
title = {{Emotion knowledge: Further exploration of a prototype approach}},
type = {Journal Article},
volume = {52},
year = {1987}
}
@article{Dromey:1995wy,
abstract = {A model for software product quality is defined. It has been formulated by associating a set of quality-carrying properties with each of the structural forms that are used to define the statements and statement components of a programming language. These quality-carrying properties are in turn linked to the high-level quality attributes of the International Standard for Software Product Evaluation ISO-9126. The model supports building quality into software, definition of language-specific coding standards, systematically classifying quality defects, and the development of automated code auditors for detecting defects in software.},
author = {Dromey, R Geoff},
doi = {10.1109/32.345830},
isbn = {978-1-11-815666-7},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
number = {2},
pages = {146--162},
title = {{A model for software product quality}},
volume = {21},
year = {1995}
}
@inproceedings{hohman2019gamut,
abstract = {Without good models and the right tools to interpret them, data scientists risk making decisions based on hidden biases, spurious correlations, and false generalizations. This has led to a rallying cry for model interpretability. Yet the concept of interpretability remains nebulous, such that researchers and tool designers lack actionable guidelines for how to incorporate interpretability into models and accompanying tools. Through an iterative design process with expert machine learning researchers and practitioners, we designed a visual analytics system, Gamut, to explore how interactive interfaces could better support model interpretation. Using Gamut as a probe, we investigated why and how professional data scientists interpret models, and how interface affordances can support data scientists in answering questions about model interpretability. Our investigation showed that interpretability is not a monolithic concept: data scientists have different reasons to interpret models and tailor explanations for specific audiences, often balancing competing concerns of simplicity and completeness. Participants also asked to use Gamut in their work, highlighting its potential to help data scientists understand their own data.},
address = {Glasgow, Scotland, UK},
author = {Hohman, Fred and Head, Andrew and Caruana, Rich and DeLine, Robert and Drucker, Steven M},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3290605.3300809},
isbn = {978-1-45-035970-2},
keywords = {Data visualization,Design probe,Interactive interfaces,Machine learning interpretability,Visual analytics},
month = {may},
publisher = {ACM},
title = {{Gamut: A design probe to understand how data scientists understand machine learning models}},
year = {2019}
}
@book{Parrott2001,
address = {Philadelphia},
editor = {Parrott, W. Gerrod},
isbn = {978-0-86-377682-3},
publisher = {Psychology Press},
title = {{Emotions in Social Psychology: Essential Readings}},
type = {Book},
year = {2001}
}
@inproceedings{Bussone:2015wm,
abstract = {Clinical decision support systems (CDSS) are increasingly used by healthcare professionals for evidence-based diagnosis and treatment support. However, research has suggested that users often over-rely on system suggestions - even if the suggestions are wrong. Providing explanations could potentially mitigate misplaced trust in the system and over-reliance. In this paper, we explore how explanations are related to user trust and reliance, as well as what information users would find helpful to better understand the reliability of a system's decision-making. We investigated these questions through an exploratory user study in which healthcare professionals were observed using a CDSS prototype to diagnose hypothetic cases using fictional patients suffering from a balance-related disorder. Our results show that the amount of system confidence had only a slight effect on trust and reliance. More importantly, giving a fuller explanation of the facts used in making a diagnosis had a positive effect on trust but also led to over-reliance issues, whereas less detailed explanations made participants question the system's reliability and led to self-reliance problems. To help them in their assessment of the reliability of the system's decisions, study participants wanted better explanations to help them interpret the system's confidence, to verify that the disorder fit the suggestion, to better understand the reasoning chain of the decision model, and to make differential diagnoses. Our work is a first step toward improved CDSS design that better supports clinicians in making correct diagnoses.},
address = {Dallas, TX, USA},
author = {Bussone, Adrian and Stumpf, Simone and O'Sullivan, Dympna},
booktitle = {Proceedings of the 2015 IEEE International Conference on Healthcare Informatics},
doi = {10.1109/ICHI.2015.26},
isbn = {978-1-46-739548-9},
keywords = {CDSS,Explanations,Reliability,Reliance,Trust,User study},
month = {oct},
pages = {160--169},
publisher = {IEEE},
title = {{The role of explanations on trust and reliance in clinical decision support systems}},
year = {2015}
}
@inproceedings{Juristo:2012bp,
abstract = {Experimentation has played a major role in scientific advancement. Replication is one of the essentials of the experimental methods. In replications, experiments are repeated aiming to check their results. Successful replication increases the validity and reliability of the outcomes observed in an experiment. There is debate about the best way of running replications of Software Engineering (SE) experiments. Some of the questions that have cropped up in this debate are, "Should replicators reuse the baseline experiment materials? Which is the adequate sort of communication among experimenters and replicators if any? What elements of the experimental structure can be changed and still be considered a replication instead of a new experiment?". A deeper understanding of the concept of replication should help to clarify these issues as well as increase and improve replications in SE experimental practices. In this chapter, we study the concept of replication in order to gain insight. The chapter starts with an introduction to the importance of replication and the state of replication in ESE. Then we discuss replication from both the statistical and scientific viewpoint. Based on a review of the diverse types of replication used in other scientific disciplines, we identify the different types of replication that are feasible to be run in our discipline. Finally, we present the different purposes that replication can serve in Experimental Software Engineering (ESE). {\textcopyright}2012 Springer-Verlag Berlin Heidelberg.},
address = {Elba Island, Italy},
author = {Juristo, Natalia and G{\'{o}}mez, Omar S},
booktitle = {Proceedings of the LASER Summer School on Software Engineering},
doi = {10.1007/978-3-642-25231-0_2},
isbn = {978-3-64-225230-3},
issn = {0302-9743},
keywords = {Empirical Software Engineering,Experimental Replicaction,Experimental Software Engineering,Types of Replication},
pages = {60--88},
publisher = {Springer},
title = {{Replication of software engineering experiments}},
year = {2011}
}
@inproceedings{Dibia:2017iy,
abstract = {Existing research highlight the myriad of benefits realized when technology is sufficiently democratized and made accessible to non-technical or novice users. However, democratizing complex technologies such as artificial intelligence (AI) remains hard. In this work, we draw on theoretical underpinnings from the democratization of innovation, in exploring the design of maker kits that help introduce novice users to complex technologies. We report on our work designing TJBot: an open source cardboard robot that can be programmed using pre-built AI services. We highlight principles we adopted in this process (approachable design, simplicity, extensibility and accessibility), insights we learned from showing the kit at workshops (66 participants) and how users interacted with the project on GitHub over a 12-month period (Nov 2016 - Nov 2017). We find that the project succeeds in attracting novice users (40{\%} of users who forked the project are new to GitHub) and a variety of demographics are interested in prototyping use cases such as home automation, task delegation, teaching and learning.},
address = {Denver, CO, USA},
archivePrefix = {arXiv},
arxivId = {1805.10723},
author = {Dibia, Victor and Cox, Aaron and Weisz, Justin},
booktitle = {Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
eprint = {1805.10723},
month = {may},
pages = {381--384},
publisher = {ACM},
title = {{Designing for Democratization: Introducing Novices to Artificial Intelligence Via Maker Kits}},
year = {2017}
}
@article{AlQutaish:2010vua,
abstract = {The quality of the software is critical and essential in different types of organizations. In some types of software, poor quality of the software product in sensitive systems (such as: real-time systems, control systems, etc.) may lead to loss of human life, permanent injury, mission failure, or financial loss. In software engineering literature, there are a number of quality models in which they contain a number of quality characteristics (or factors, as called in some models). These quality characteristics could be used to reflect the quality of the software product from the view of that characteristic. Selecting which one of the quality models to use is a real challenge. In this paper, we will discuss the contents of the following quality models: McCall's quality model, Boehm's quality model, Dromey's quality model, FURPS quality model and ISO 9126 quality model. In addition, we will focus on a comparison between these quality models, and find the key differences between them. [Journal},
author = {Al-Qutaish, Rafa E},
journal = {Journal of American Science},
keywords = {Boehm's Quality Model,Dromey's Quality Model,FURPS Quality Model,ISO 9126,McCall's Quality Model,Quality Engineering,Quality Models,Software Quality},
number = {3},
pages = {166--175},
title = {{Quality Models in Software Engineering Literature: An Analytical and Comparative Study}},
volume = {6},
year = {2010}
}
@inproceedings{Allamanis:2013is,
abstract = {Questions from Stack Overflow provide a unique opportunity to gain insight into what programming concepts are the most confusing. We present a topic modeling analysis that combines question concepts, types, and code. Using topic modeling, we are able to associate programming concepts and identifiers (like the String class) with particular types of questions, such as, "how to perform encoding". {\textcopyright}2013 IEEE.},
address = {San Francisco, CA, USA},
author = {Allamanis, Miltiadis and Sutton, Charles},
booktitle = {Proceedings of the 10th IEEE International Working Conference on Mining Software Repositories},
doi = {10.1109/MSR.2013.6624004},
isbn = {978-1-46-732936-1},
issn = {2160-1852},
month = {may},
pages = {53--56},
publisher = {IEEE},
title = {{Why, when, and what: Analyzing stack overflow questions by topic, type, and code}},
year = {2013}
}
@inproceedings{lin2018sentiment,
address = {Gothenburg, Sweden},
author = {Lin, Bin and Zampetti, Fiorella and Bavota, Gabriele and {Di Penta}, Massimiliano and Lanza, Michele and Oliveto, Rocco},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
doi = {10.1145/3180155.3180195},
month = {may},
pages = {94--104},
publisher = {ACM},
title = {{Sentiment analysis for software engineering: How far can we go?}},
year = {2018}
}
@inproceedings{Bai:2007tl,
abstract = {A key issue with Web Services (WS) is the verification and validation (V{\&}V) of services to build trust between service providers and service users. This paper proposed a test-broker architecture so that all stakeholder within WS can contribute to improve the testing of the services. The test broker supports the submission, indexing, and querying of test artifacts such as test cases, defect reports and evaluations. It can also provide the services for the test generation, test coordination, and distributed testing services. The DCV{\&}V (Decentralized, Collaborative, Verification and Validation) framework is proposed with a set of distributed and collaborated test brokers dedicated to different V{\&}V tasks to enable scalable and flexible test collaborations. The paper explores the concept of design-by-contract and applies the principle to DCV{\&}V. It identifies two categories of testing contracts including TSC (Testing Service Contracts) and TCC (Test Collaboration Contracts). It illustrates the application of TSC with contract-based test generation based on WS OWL-S specification. It elaborates TCC with the analysis of the test artifacts definitions. {\textcopyright}Springer-Verlag Berlin Heidelberg 2007.},
address = {Medford, MA, USA},
author = {Bai, Xiaoying and Wang, Yongbo and Dai, Guilan and Tsai, Wei Tek and Chen, Yinong},
booktitle = {Proceedings of the 10th International Symposium of Component-Based Software Engineering},
doi = {10.1007/978-3-540-73551-9_18},
isbn = {978-3-54-073550-2},
issn = {0302-9743},
keywords = {Contract-based,Verification and validation,Web services},
month = {jul},
pages = {258--273},
publisher = {Springer},
title = {{A framework for contract-based collaborative verification and validation of Web services}},
year = {2007}
}
@article{Krizhevsky:2012wl,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%}, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used nonsaturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
doi = {10.1145/3065386},
issn = {1557-7317},
journal = {Communications of the ACM},
number = {6},
pages = {84--90},
title = {{ImageNet classification with deep convolutional neural networks}},
volume = {60},
year = {2017}
}
@article{Baruch:1999vf,
abstract = {A study was conducted to explore what could and should be a reasonable response rate in academic studies. One hundred and forty-one papers which included 175 different studies were examined. They were published in the Academy of Management Journal, Human Relations, Journal of Applied Psychology, Organizational Behavior and Human Decision Processes, and Journal of International Business Studies in the years 1975, 1985, and 1995, covering about 200,000 respondents. The average response rate was 55.6 with a standard deviation of 19.7. Variations among the journals such as the year of publication and other variables were discussed. Most notable is the decline through the years (average 48.4, standard deviation of 20.1, in 1995), the lower level found in studies involving top management or organizational representatives (average 36.1, standard deviation of 13.3), and the predominance of North American studies. It is suggested that the average and standard deviation found in this stud)' should be used as a norm for future studies, bearing in mind the specific reference group. It is also recommended that a distinction is made between surveys directed at individual participants and those targeting organizational representatives.},
author = {Baruch, Yehuda},
doi = {10.1177/001872679905200401},
issn = {0018-7267},
journal = {Human Relations},
keywords = {Empirical studies,Questionnaires,Research methods,Response rate,Return rate},
number = {4},
pages = {421--438},
title = {{Response rate in academic studies - A comparative analysis}},
volume = {52},
year = {1999}
}
@inproceedings{Barnett:2015ut,
abstract = {Modern IDEs provide limited support for developers when starting a new data-driven mobile app. App developers are currently required to write copious amounts of boilerplate code, scripts, organise complex directories, and author actual functionality. Although this scenario is ripe for automation, current tools are yet to address it adequately. In this paper we present RAPPT, a tool that generates the scaffolding of a mobile app based on a high level description specified in a Domain Specific Language (DSL). We demonstrate the feasibility of our approach by an example case study and feedback from a professional development team. Demo at: https://www.youtube.com/watch?v=ffquVgBYpLM.},
address = {Florence, Italy},
author = {Barnett, Scott and Vasa, Rajesh and Grundy, John},
booktitle = {Proceedings of the 37th International Conference on Software Engineering},
doi = {10.1109/ICSE.2015.216},
isbn = {978-1-47-991934-5},
issn = {0270-5257},
keywords = {Code Generation,Mobile App Prototyping,Model Driven Development},
month = {may},
pages = {657--660},
publisher = {IEEE},
title = {{Bootstrapping Mobile App Development}},
year = {2015}
}
@inproceedings{Robillard:hk,
abstract = {We advocate for a paradigm shift in supporting the information needs of developers, centered around the concept of automated on-demand developer documentation. Currently, developer information needs are fulfilled by asking experts or consulting documentation. Unfortunately, traditional documentation practices are inefficient because of, among others, the manual nature of its creation and the gap between the creators and consumers. We discuss the major challenges we face in realizing such a paradigm shift, highlight existing research that can be leveraged to this end, and promote opportunities for increased convergence in research on software documentation.},
address = {Shanghai, China},
author = {Robillard, Martin P. and Marcus, Andrian and Treude, Christoph and Bavota, Gabriele and Chaparro, Oscar and Ernst, Neil and Gerosall, Marco Aur{\'{e}}lio and Godfrey, Michael and Lanza, Michele and Linares-V{\'{a}}squez, Mario and Murphy, Gail C. and Moreno, Laura and Shepherd, David and Wong, Edmund},
booktitle = {Proceedings of the 33rd IEEE International Conference on Software Maintenance and Evolution},
doi = {10.1109/ICSME.2017.17},
month = {sep},
pages = {479--483},
publisher = {IEEE},
title = {{On-demand developer documentation}},
year = {2017}
}
@article{Krosnick:1999wt,
author = {Krosnick, Jon A},
doi = {10.1146/annurev.psych.50.1.537},
issn = {0066-4308},
journal = {Annual Review of Psychology},
month = {feb},
number = {1},
pages = {537--567},
title = {{Survey Research}},
volume = {50},
year = {1999}
}
@inproceedings{Wang:2013ub,
abstract = {Software frameworks provide sets of generic functionalities that can be later customized for a specific task. When developers invoke API methods in a framework, they often encounter obstacles in finding the correct usage of the API, let alone to employ best practices. Previous research addresses this line of questions by mining API usage patterns to induce API usage templates, by conducting and compiling interviews of developers, and by inferring correlations among APIs. In this paper, we analyze API-related posts regarding iOS and Android development from a Q{\&}A website, stackoverflow.com. Assuming that API-related posts are primarily about API usage obstacles, we find several iOS and Android API classes that appear to be particularly likely to challenge developers, even after we factor out API usage hotspots, inferred by modelling API usage of open source iOS and Android applications. For each API with usage obstacles, we further apply a topic mining tool to posts that are tagged with the API, and we discover several repetitive scenarios in which API usage obstacles occur. We consider our work as a stepping stone towards understanding API usage challenges based on forum-based input from a multitude of developers, input that is prohibitively expensive to collect through interviews. Our method helps to motivate future research in API usage, and can allow designers of platforms - such as iOS and Android - to better understand the problems developers have in using their platforms, and to make corresponding improvements. {\textcopyright}2013 IEEE.},
address = {San Francisco, CA, USA},
author = {Wang, Wei and Godfrey, Michael W},
booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
doi = {10.1109/MSR.2013.6624006},
isbn = {978-1-46-732936-1},
issn = {2160-1852},
month = {may},
pages = {61--64},
publisher = {IEEE},
title = {{Detecting API usage obstacles: A study of iOS and android developer questions}},
year = {2013}
}
@inproceedings{Beyer:2018fm,
abstract = {Software developers frequently solve development issues with the help of question and answer web forums, such as Stack Overflow (SO). While tags exist to support question searching and browsing, they are more related to technological aspects than to the question purposes. Tagging questions with their purpose can add a new dimension to the investigation of topics discussed in posts on SO. In this paper, we aim to automate such a classification of SO posts into seven question categories. As a first step, we have manually created a curated data set of 500 SO posts, classified into the seven categories. Using this data set, we apply machine learning algorithms (Random Forest and Support Vector Machines) to build a classification model for SO questions. We then experiment with 82 different configurations regarding the preprocessing of the text and representation of the input data. The results of the best performing models show that our models can classify posts into the correct question category with an average precision and recall of 0.88 and 0.87 when using Random Forest and the phrases indicating a question category as input data for the training. The obtained model can be used to aid developers in browsing SO discussions or researchers in building recommenders based on SO.},
address = {Gothenburg, Sweden},
author = {Beyer, Stefanie and MacHo, Christian and Pinzger, Martin and {Di Penta}, Massimiliano},
booktitle = {Proceedings of the 26th International Conference on Program Comprehension},
doi = {10.1145/3196321.3196333},
isbn = {978-1-45-035714-2},
issn = {0270-5257},
month = {may},
pages = {211--221},
publisher = {ACM},
title = {{Automatically classifying posts into question categories on stack overflow}},
year = {2018}
}
@incollection{Jick:1979el,
abstract = {This article describes and discusses issues related to research design and data analysis in the mixing of qualitative and quantitative methods. It is increasingly desirable to use multiple methods in research, but questions arise as to how best to design and analyze the data generated by mixed methods projects. I offer a conceptualization for such design, discuss issues of sampling, and describe a strategy for processing qualitative data in ways that allow for more sophisticated and dynamic integration with quantita- tive data. Finally, drawing on data from previous research, I describe tools and strategies for this dynamic data integration and illustrate how effective strategy and use of tools allow for more efficient and sophisticated analysis, interpretation, and presentation.},
author = {Mayring, Philipp},
booktitle = {Mixed Methodology in Psychological Research},
chapter = {6},
doi = {10.1163/9789087903503_007},
isbn = {978-9-07-787473-8},
pages = {27--36},
publisher = {Sense Publishers},
title = {{Mixing Qualitative and Quantitative Methods}},
year = {2007}
}
@inproceedings{Foster:2003ur,
abstract = {In this paper, we discuss a model-based approach to verifying Web service compositions for Web service implementations. The approach supports verification against specification models and assigns semantics to the behavior of implementation model so as to confirm expected results for both the designer and implementer. Specifications of the design are modeled in UML (Unified Modeling Language), in the form of message sequence charts (MSC), and mechanically compiled into the finite state process notation (FSP) to concisely describe and reason about the concurrent programs. Implementations are mechanically translated to FSP to allow a trace equivalence verification process to be performed. By providing early design verification, the implementation, testing, and deployment of Web service compositions can be eased through the understanding of the differences, limitations and undesirable traces allowed by the composition. The approach is supported by a suite of cooperating tools for specification, formal modeling and trace animation of the composition workflow.},
address = {Linz, Austria},
author = {Foster, H and Uchitel, S and Magee, J and Kramer, J},
booktitle = {Proceedings of the 18th International Conference on Automated Software Engineering},
doi = {10.1109/ase.2003.1240303},
month = {sep},
pages = {152--161},
publisher = {IEEE},
title = {{Model-based verification of Web service compositions}},
year = {2004}
}
@article{Lecun:1998hy,
abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient-based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of two dimensional (2-D) shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation, recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN's), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank check is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal checks. It is deployed commercially and reads several million checks per day. {\textcopyright} 1998 IEEE.},
author = {LeCun, Yann and Bottou, L{\'{e}}on and Bengio, Yoshua and Haffner, Patrick},
doi = {10.1109/5.726791},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
keywords = {Convolutional neural networks,Document recognition,Finite state transducers,Gradient-based learning,Graph transformer networks,Machine learning,Neural networks,Optical character recognition (OCR)},
number = {11},
pages = {2278--2324},
title = {{Gradient-based learning applied to document recognition}},
volume = {86},
year = {1998}
}
@inproceedings{Petersen:2019ji,
abstract = {Background - Validity threats should be considered and consistently reported to judge the value of an empirical software engineering research study. The relevance of specific threats for a particular research study depends on the worldview or philosophical worldview of the researchers of the study. Problem/Gap - In software engineering, different categorizations exist, which leads to inconsistent reporting and consideration of threats. Contribution - In this paper, we relate different worldviews to software engineering research methods, identify generic categories for validity threats, and provide a categorization of validity threats with respect to their relevance for different world views. Thereafter, we provide a checklist aiding researchers in identifying relevant threats. Method - Different threat categorizations and threats have been identified in literature, and are reflected on in relation to software engineering research. Results - Software engineering is dominated by the pragmatist worldviews, and therefore use multiple methods in research. Maxwell's categorization of validity threats has been chosen as very suitable for reporting validity threats in software engineering research. Conclusion - We recommend to follow a checklist approach, and reporting first the philosophical worldview of the researcher when doing the research, the research methods and all threats relevant, including open, reduced, and mitigated threats. {\textcopyright}2013 IEEE.},
address = {Ankara, Turkey},
author = {Petersen, Kai and Gencel, Cigdem},
booktitle = {Proceedings of the Joint Conference of the 23rd International Workshop on Software Measurement and the 8th International Conference on Software Process and Product Measurement},
doi = {10.1109/IWSM-Mensura.2013.22},
isbn = {978-0-76-955078-7},
month = {oct},
pages = {81--89},
publisher = {IEEE},
title = {{Worldviews, research methods, and their relationship to validity in empirical software engineering research}},
year = {2013}
}
@book{Hwang:2017tr,
address = {Cambridge, MA, USA},
author = {Wang, Kai},
isbn = {978-0-26-203641-2},
pages = {624},
publisher = {MIT Press},
title = {{Cloud Computing for Machine Learning and Cognitive Applications: A Machine Learning Approach}},
year = {2017}
}
@inproceedings{Boehm:1978vv,
abstract = {The study reported in this paper establishes a conceptual framework and some key initial results in the analysis of the characteristics of software quality. Its main results and conclusions are: • Explicit attention to characteristics of software quality can lead to significant savings in software life-cycle costs. • The current software state-of-the-art imposes specific limitations on our ability to automatically and quantitatively evaluate the quality of software. • A definitive hierarchy of well-defined, well-differentiated characteristics of software quality is developed. Its higher-level structure reflects the actual uses to which software quality evaluation would be put; its lower-level characteristics are closely correlated with actual software metric evaluations which can be performed. • A large number of software quality-evaluation metrics have been defined, classified, and evaluated with respect to their potential benefits, quantifiability, and ease of automation. • Particular software life-cycle activities have been identified which have significant leverage on software quality. Most importantly, we believe that the study reported in this paper provides for the first time a clear, well-defined framework for assessing the often slippery issues associated with software quality, via the consistent and mutually supportive sets of definitions, distinctions, guidelines, and experiences cited. This framework is certainly not complete, but it has been brought to a point sufficient to serve as a viable basis for future refinements and extensions.},
address = {San Francisco, California, USA},
author = {Boehm, B W and Brown, J R and Lipow, M},
booktitle = {Proceedings of the 2nd International Conference on Software Engineering},
issn = {0270-5257},
keywords = {Management by objectives,Quality assurance,Quality characteristics,Quality metrics,Software engineering,Software measurement and evaluation,Software quality,Software reliability,Software standards,Testing},
month = {oct},
pages = {592--605},
publisher = {IEEE},
title = {{Quantitative evaluation of software quality}},
year = {1976}
}
@inproceedings{Hasan2014UsingMessages,
address = {New York, NY, USA},
author = {Hasan, Maryam and Agu, Emmanuel and Rundensteiner, Elke},
booktitle = {Proceedings of the 2014 ACM SIGKDD Workshop on Healthcare Informatics},
month = {aug},
pages = {187--193},
publisher = {ACM},
title = {{Using Hashtags as Labels for Supervised Learning of Emotions in Twitter Messages}},
year = {2014}
}
@inproceedings{Clark:1991vi,
abstract = {The CN2 algorithm induces an ordered list of classification rules from examples using entropy as its search heuristic. In this short paper, we describe two improvements to this algorithm. Firstly, we present the use of the Laplacian error estimate as an alternative evaluation function and secondly, we show how unordered as well as ordered rules can be generated. We experimentally demonstrate significantly improved performances resulting from these changes, thus enhancing the usefulness of CN2 as an inductive tool. Comparisons with Quinlan's C4.5 are also made.},
address = {Porto, Portugal},
author = {Clark, Peter and Boswell, Robin},
booktitle = {Proceedings of the 1991 European Working Session on Learning},
doi = {10.1007/BFb0017011},
isbn = {978-3-54-053816-5},
issn = {1611-3349},
keywords = {CN2,Laplace,Learning,Noise,Rule induction},
month = {mar},
pages = {151--163},
publisher = {Springer},
title = {{Rule induction with CN2: Some recent improvements}},
year = {1991}
}
@article{Dhar:2000vo,
abstract = {Prediction in financial domains is notoriously difficult for a number of reasons. First, theories tend to be weak or non-existent, which makes problem formulation open ended by forcing us to consider a large number of independent variables and thereby increasing the dimensionality of the search space. Second, the weak relationships among variables tend to be nonlinear, and may hold only in limited areas of the search space. Third, in financial practice, where analysts conduct extensive manual analysis of historically well performing indicators, a key is to find the hidden interactions among variables that perform well in combination. Unfortunately, these are exactly the patterns that the greedy search biases incorporated by many standard rule learning algorithms will miss. In this paper, we describe and evaluate several variations of a new genetic learning algorithm (GLOWER) on a variety of data sets. The design of GLOWER has been motivated by financial prediction problems, but incorporates successful ideas from tree induction and rule learning. We examine the performance of several GLOWER variants on two UCI data sets as well as on a standard financial prediction problem (S{\&}P500 stock returns), using the results to identify one of the better variants for further comparisons. We introduce a new (to KDD) financial prediction problem (predicting positive and negative earnings surprises), and experiment with GLOWER, contrasting it with tree- and rule-induction approaches. Our results are encouraging, showing that GLOWER has the ability to uncover effective patterns for difficult problems that have weak structure and significant nonlinearities. {\textcopyright}2000 Kluwer Academic Publishers.},
author = {Dhar, Vasant and Chou, Dashin and Provost, Foster},
doi = {10.1023/A:1009848126475},
issn = {1384-5810},
journal = {Data Mining and Knowledge Discovery},
keywords = {Data mining,Financial prediction,Genetic algorithms,Investment decision making,Knowledge discovery,Machine learning,Rule learning,Systematic trading},
number = {4},
pages = {69--80},
title = {{Discovering interesting patterns for investment decision making with GLOWER - A genetic learner overlaid with entropy reduction}},
volume = {4},
year = {2000}
}
@inproceedings{Takagi2000,
abstract = {These days, the web has been coming to play various types of roles, so each site has been designed in a complex way to integrate as many roles as possible. Web authors tend to cram various functions and many links into one page to improve usability for sighted users. This authoring trend makes nonvisual Web access harder. To solve this problem, we decided to develop a system to transcode already-existing Web pages to be accessible, which works as an intermediary (proxy) between a Web server and a user. Our transcoding proxy consists of 5 modules using 3 kinds of annotations. The user interface of the system is characterized by three transcoding modes: simplification, full-text and original page. In this paper, we will describe an overview of our transcoding proxy as well as the user interface of the system.},
address = {Arlington, VA, USA},
author = {Takagi, H. and Asakawa, C.},
booktitle = {Proceedings of the 2000 ACM Conference on Assistive Technologies},
doi = {10.1145/354324.354371},
keywords = {Annotations,Blind,Differential,Portal,Transcoding,Web Accessibility},
month = {nov},
pages = {164--171},
publisher = {ACM},
title = {{Transcoding proxy for nonvisual Web access}},
year = {2000}
}
@inproceedings{Nakajima:2002ut,
abstract = {Model-checking is a promising technique for the verification and validation of software systems. Web service, an emerging technology in the Internet, is an autonomous server that may offer an individual service. It sometimes requires to combine more than one to meet our requirements. WSFL(Web Services Flow Language) is proposed as a language to provide means to describe Web service aggregation. We are interested in how much the software modelchecking technique can be used as a basis for raising reliability of Web service, Web service flow descriptions in particular. Our experience shows that faulty flow descriptions can be identified with the proposed method. The method is also very helpful in studying an alternative semantics of the WSFL in regard to the handling of dataflows.},
address = {Montreal, QC, Canada},
author = {Nakajima, Shin},
booktitle = {Proceedings of the First International Symposium on Cyber World},
isbn = {978-0-76-951862-6},
month = {nov},
pages = {378--385},
publisher = {IEEE},
title = {{Model-Checking Verification for Reliable Web Service}},
year = {2002}
}
@incollection{Barzilay:2013cn,
abstract = {The open source community, as well as numerous technical blogs and community web sites, put online vast quantities of free source code, ranging from snippets to full-blown products. This code embodies the software development community's domain knowledge, and mirrors the structure of the Internet: it is distributed rather than hierarchical; it is chaotic, incomplete, and inconsistent. StackOverflow.com is a Question and Answer (Q{\&}A) website which uses social media to facilitate knowledge exchange between programmers by mitigating the pitfalls involved in using code from the Internet. Its design nurtures a community of developers, and enables crowd sourced software engineering activities ranging from documentation to providing useful, high quality code snippets to be used in production. In this chapter we review Stack Overflow from three perspectives: (1) its design and its social media characteristics, (2) the role it plays in the software documentation landscape, and (3) the use of Stack Overflow in the context of the example centric programming paradigm.},
author = {Barzilay, Ohad and Treude, Christoph and Zagalsky, Alexey},
booktitle = {Finding Source Code on the Web for Remix and Reuse},
doi = {10.1007/978-1-4614-6596-6_15},
isbn = {978-1-46-146596-6},
number = {4},
pages = {289--308},
title = {{Facilitating crowd sourced software engineering via stack overflow}},
year = {2014}
}
@book{Meltzoff:1998wg,
abstract = {Could the research you read be fundamentally flawed? Could crucial effects in methodology slip by you undetected? To become an informed, interactive consumer of research, you may need an attitude adjustment: from acceptance to inquiry, from reverence to skepticism. Critical Thinking About Research: Psychology and Related Fields equips you with those tools needed to identify errors in others' research and to reduce them to a minimum in your own work. (PsycINFO Database Record (c) 2019 APA, all rights reserved) (Source: publicity materials)},
author = {Meltzoff, Julian and Cooper, Harris},
doi = {10.1037/0000052-000},
edition = {2nd},
publisher = {American Psychological Association},
title = {{Critical thinking about research: Psychology and related fields}},
year = {2018}
}
@inproceedings{myers2018patterns,
abstract = {Voice User Interfaces (VUIs) are growing in popularity. However, even the most current VUIs regularly cause frustration for their users. Very few studies exist on what people do to overcome VUI problems they encounter, or how VUIs can be designed to aid people when these problems occur. In this paper, we analyze empirical data on how users (n=12) interact with our VUI calendar system, DiscoverCal, over three sessions. In particular, we identify the main obstacle categories and types of tactics our participants employ to overcome them. We analyzed the patterns of how different tactics are used in each obstacle category. We found that while NLP Error obstacles occurred the most, other obstacles are more likely to frustrate or confuse the user. We also found patterns that suggest participants were more likely to employ a "guessing" approach rather than rely on visual AIDS or knowledge recall.},
address = {Montreal, QC, Canada},
author = {Myers, Chelsea and Furqan, Anushay and Nebolsky, Jessica and Caro, Karina and Zhu, Jichen},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3173574.3173580},
isbn = {978-1-45-035620-6},
keywords = {User experience,Voice User Interfaces,Voice control},
month = {apr},
pages = {6},
publisher = {ACM},
title = {{Patterns for how users overcome obstacles in Voice User Interfaces}},
volume = {2018-April},
year = {2018}
}
@inproceedings{McCarthy:1960:PCS:889202,
abstract = {Interesting work is being done in programming computers to solve problems which require a high degree of intelligence in humans. However, certain elementary verbal reasoning processes so simple that they can be carried out by any non-feeble minded human have yet to be simulated by machine programs.},
address = {Cambridge, MA, USA},
author = {McCarthy, J},
booktitle = {Proceedings of the Symposium on the Mechanization of Thought Processes},
pages = {1--15},
title = {{Programs with common sense}},
year = {1963}
}
@book{Japkowicz:2011vy,
abstract = {The field of machine learning has matured to the point where many sophisticated learning approaches can be applied to practical applications. Thus it is of critical importance that researchers have the proper tools to evaluate learning approaches and understand the underlying issues. This book examines various aspects of the evaluation process with an emphasis on classification algorithms. The authors describe several techniques for classifier performance assessment, error estimation and resampling, obtaining statistical significance as well as selecting appropriate domains for evaluation. They also present a unified evaluation framework and highlight how different components of evaluation are both significantly interrelated and interdependent. The techniques presented in the book are illustrated using R and WEKA facilitating better practical insight as well as implementation. Aimed at researchers in the theory and applications of machine learning, this book offers a solid basis for conducting performance evaluations of algorithms in practical settings.},
author = {Japkowicz, Nathalie and Shah, Mohak},
booktitle = {Evaluating Learning Algorithms: A Classification Perspective},
doi = {10.1017/CBO9780511921803},
isbn = {978-0-51-192180-3},
pages = {1--406},
publisher = {Cambridge University Press},
title = {{Evaluating learning algorithms: A classification perspective}},
volume = {9780521196},
year = {2011}
}
@misc{Bessin:2004vc,
author = {Bessin, J},
month = {jun},
publisher = {IBM developerWorks},
title = {{The Business Value of Quality}},
url = {https://ibm.co/2u0UDK0},
volume = {15},
year = {2004}
}
@inproceedings{Sinha:2013tt,
abstract = {Success of a Q{\&}A forum depends on volume of content (questions and answers) and quality of content (are the questions asked relevant, answers provided correct etc). Community participation is essential to create and curate content. Since their inception in 2008, stack exchange based forums have been able to engage a large number of users to create a rich repository of good quality questions and answers. In this paper, we wish to investigate the "activeness" of users in the stackexchange network particularly from a perspective of content creation. We also attempt to measure how the forums' incentive mechanism has enabled user's activeness. Further, we investigate how user's have diffused to other parts of the stack exchange network over time, hence bootstrapping new forums. {\textcopyright}2013 IEEE.},
address = {San Francisco, CA, USA},
author = {Sinha, Vibha Singhal and Mani, Senthil and Gupta, Monika},
booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
doi = {10.1109/MSR.2013.6624010},
isbn = {978-1-46-732936-1},
issn = {2160-1852},
month = {may},
pages = {77--80},
publisher = {IEEE},
title = {{Exploring activeness of users in QA forums}},
year = {2013}
}
@inproceedings{Domingos:1998ug,
abstract = {Occam's razor has been the subject of much controversy. This paper argues that this is partly because it has been interpreted in two quite different ways, the first of which (simplicity is a goal in itself) is essentially correct, while the second (simplicity leads to greater accuracy) is not. The paper reviews the large variety of theoretical arguments and empirical evidence for and against the "second razor", and concludes that the balance is strongly against it. In particular, it builds on the case of (Schaffer, 1993) and (Webb, 1996) by considering additional theoretical arguments and recent empirical evidence that the second razor fails in most domains. A version of the first razor more appropriate to KDD is proposed, and we argue that continuing to apply the second razor risks causing significant opportunities to be missed.},
address = {New York, NY, USA},
author = {Domingos, P},
booktitle = {Proceedings of the 4th International Conference on Knowledge Discovery and Data Mining},
doi = {10.1.1.40.3278},
month = {aug},
pages = {37--43},
publisher = {AAAI},
title = {{Occam's Two Razors: The Sharp and the Blunt}},
year = {1998}
}
@techreport{McCall:1977uy,
abstract = {An hierarchical definition of factors affecting software quality was compiled after an extensive literature search. The definition covers the complete range of software development and is broken down into non-oriented and software-oriented characteristics. For the lowest level of the software-oriented factors, metrics were developed that would be independent of the programming language. These measurable criteria were collected and validated using actual Air Force data bases. A handbook was generated that will be useful to Air Force acquisition managers for specifying the overall quality of a software system.},
address = {Griffiss Air Force Base, NY, USA},
author = {McCall, Jim A and Richards, Paul K and Walters, Gene F},
booktitle = {Technical Report: Rome Air Development Center, Air Force Systems Command},
institution = {General Electric Company},
month = {nov},
number = {RADC-TR-77-369},
pages = {689--1699},
title = {{Factors in Software Quality: Concept and Definitions of Software Quality}},
volume = {1},
year = {1977}
}
@phdthesis{Fielding:2000vh,
author = {Fielding, Roy Thomas},
doi = {978-0-599-87118-2},
school = {University of California, Irvine},
title = {{Architectural Styles and the Design of Network-based Software Architectures}},
year = {2000}
}
@book{Juran:1988tg,
address = {New York, NY, USA},
author = {Juran, Joseph M.},
isbn = {978-0-02-916681-9},
publisher = {The Free Press},
title = {{Juran on Planning for Quality}},
year = {1988}
}
@article{Wachter:2017hx,
abstract = {The aim of this contribution is to analyse the real borderlines of the 'right to explanation' in the GDPR and to discretely distinguish between dif ferent levels of information and of consumers' awareness in the 'black box society. In order to combine transparency and comprehensibility we propose the new concept of algorithm 'legibility'. We argue that a systemic interpretation is needed in this field, since it can be beneficial not only for individuals but also for businesses. This may be an opportunity for auditing algorithms and correcting unknown machine biases, thus similarly enhancing the quality of decision-making outputs. Accordingly, we show how a systemic interpretation of Articles 13-15 and 22 GDPR is necessary, considering in particular that: The threshold of minimum human intervention required so that the decision-making is 'solely' automated (Article 22(1)) can also include nominal human intervention; the envisaged 'significant effects' on individuals (Article 22(1)) can encompass as well marketing manipulation, price discrimination, etc; 'meaningful information' that should be pro-vided to data subjects about the logic, signifi-cance and consequences of decision-making (Article 15(1 )(h){\textgreater}should be read as 'legibility' of 'architecture' and 'implementation' of algorith-mic processing; trade secret protection might limit the right of access of data subjects, but there is a general legal favour for data protection rights that should reduce the impact of trade secrets protection. In addition, we recommend a 'legibility test' that data controllers should perform in order to com-ply with the duty to provide meaningful information about the logic involved in an automated decision-making.},
author = {Malgieri, Gianclaudio and Comand{\'{e}}, Giovanni},
doi = {10.1093/idpl/ipx019},
issn = {2044-4001},
journal = {International Data Privacy Law},
month = {jun},
number = {4},
pages = {243--265},
title = {{Why a right to legibility of automated decision-making exists in the general data protection regulation}},
volume = {7},
year = {2017}
}
@incollection{Brooke:1996ua,
abstract = {Usability does not exist in any absolute sense; it can only be defined with reference to particular contexts. This, in turn, means that there are no absolute measures of usability, since, if the usability of an artefact is defined by the context in which that artefact is used, measures of usability must of necessity be defined by that context too. Despite this, there is a need for broad general measures which can be used to compare usability across a range of contexts. In addition, there is a need for " quick and dirty " methods to allow low cost assessments of usability in industrial systems evaluation. This chapter describes the System Usability Scale (SUS) a reliable, low-cost usability scale that can be used for global assessments of systems usability.},
address = {Cornwall, England, UK},
author = {Brooke, John},
booktitle = {Usability Evaluation in Industry},
chapter = {21},
isbn = {978-0-74-840460-5},
pages = {189--194},
publisher = {Taylor {\&} Francis Ltd},
title = {{SUS-A quick and dirty usability scale}},
year = {1996}
}
@article{Taulavuori:2004el,
abstract = {Product lines embody a strategic reuse of both intellectual effort and existing artefacts, such as software architectures and components. Third-party components are increasingly being used in product line based software engineering, in which case the integration is controlled by the product line architecture. However, the software integrators have difficulties in finding out the capabilities of components, because components are not documented in a standard way. Documentation is often the only way of assessing the applicability, credibility and quality of a third-party component. Our contribution is a standard documentation pattern for software components. The pattern provides guidelines and structure for component documentation and ensures the quality of documentation. The pattern has been validated by applying and analysing it in practice. {\textcopyright} 2004 Elsevier B.V. All rights reserved.},
author = {Taulavuori, Anne and Niemel{\"{a}}, Eila and Kallio, P{\"{a}}ivi},
doi = {10.1016/j.infsof.2003.10.004},
issn = {0950-5849},
journal = {Information and Software Technology},
keywords = {Component documentation,Software product line,Third-party component},
month = {jun},
number = {8},
pages = {535--546},
title = {{Component documentation - A key issue in software product lines}},
volume = {46},
year = {2004}
}
@inproceedings{Pezzementi:2018tq,
abstract = {We introduce a method to evaluate the robustness of perception systems to the wide variety of conditions that a deployed system will encounter. Using person detection as a sample safety-critical application, we evaluate the robustness of several state-of-the-art perception systems to a variety of common image perturbations and degradations. We introduce two novel image perturbations that use 'contextual information' (in the form of stereo image data) to perform more physically-realistic simulation of haze and defocus effects. For both standard and contextual mutations, we show cases where performance drops catastrophically in response to barely-perceptible changes. We also show how robustness to contextual mutators can be predicted without the associated contextual information in some cases.},
address = {Philadelphia, PA, USA},
author = {Pezzementi, Zachary and Tabor, Trenton and Yim, Samuel and Chang, Jonathan K and Drozd, Bill and Guttendorf, David and Wagner, Michael and Koopman, Philip},
booktitle = {Proceedings of the 15th IEEE International Symposium on Safety, Security, and Rescue Robotics},
doi = {10.1109/SSRR.2018.8468619},
isbn = {978-1-53-865572-6},
month = {aug},
pages = {1--8},
publisher = {IEEE},
title = {{Putting Image Manipulations in Context: Robustness Testing for Safe Perception}},
year = {2018}
}
@article{Garvin:1984vf,
author = {Garvin, David A},
issn = {0019-848X},
journal = {MIT Sloan Management Review},
number = {1},
pages = {25--43},
title = {{What Does `Product Quality' Really Mean?}},
volume = {26},
year = {1984}
}
@article{Chillarege:1992tm,
abstract = {This paper describes orthogonal defect classification (ODC), a concept that enables in-process feedback to developers by extracting signatures on the development process from defects. The ideas are evolved from an earlier finding that demonstrates the use of semantic information from defects to extract cause-effect relationships in the development process. This finding is leveraged to develop a systematic framework for building measurement and analysis methods. This paper • defines ODC and discusses the necessary and sufficient conditions required to provide feedback to a developer; • illustrates the use of the defect type distribution to measure the progress of a product through a process; • illustrates the use of the defect trigger distribution to evaluate the effectiveness and eventually the completeness of verification processes such as inspection or testing; • provides sample results from pilot projects using ODC; •opens the doors to a wide variety of analysis techniques for providing effective and fast feedback based on the concepts of ODC. {\textcopyright}1992 IEEE},
author = {Chillarege, Ram and Bhandari, Inderpal S and Chaar, Jarir K and Halliday, Michael J and Ray, Bonnie K and Moebus, Diane S},
doi = {10.1109/32.177364},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
number = {11},
pages = {943--956},
title = {{Orthogonal Defect Classification—A Concept for In-Process Measurements}},
volume = {18},
year = {1992}
}
@article{DoshiVelez:2017vm,
abstract = {The ubiquity of systems using artificial intelligence or "AI" has brought increasing attention to how those systems should be regulated. The choice of how to regulate AI systems will require care. AI systems have the potential to synthesize large amounts of data, allowing for greater levels of personalization and precision than ever before|applications range from clinical decision support to autonomous driving and predictive policing. That said, common sense reasoning [McCarthy, 1960] remains one of the holy grails of AI, and there exist legitimate concerns about the intentional and unintentional negative consequences of AI systems [Bostrom, 2003, Amodei et al., 2016, Sculley et al., 2014]. There are many ways to hold AI systems accountable. In this work, we focus on one: explanation. Questions about a legal right to explanation from AI systems was recently debated in the EU General Data Protection Regulation [Goodman and Flaxman, 2016, Wachter et al., 2017], and thus thinking carefully about when and how explanation from AI systems might improve accountability is timely. Good choices about when to demand explanation can help prevent negative consequences from AI systems, while poor choices may not only fail to hold AI systems accountable but also hamper the development of much-needed beneficial AI systems. Below, we briefly review current societal, moral, and legal norms around explanation, and then focus on the different contexts under which explanation is currently required under the law. We find that there exists great variation around when explanation is demanded, but there also exists important consistencies: when demanding explanation from humans, what we typically want to know is how and whether certain input factors affected the final decision or outcome. These consistencies allow us to list the technical considerations that must be considered if we desired AI systems that could provide kinds of explanations that are currently required of humans under the law. Contrary to popular wisdom of AI systems as indecipherable black boxes, we find that this level of explanation should often be technically feasible but may sometimes be practically onerous|there are certain aspects of explanation that may be simple for humans to provide but challenging for AI systems, and vice versa. As an interdisciplinary team of legal scholars, computer scientists, and cognitive scientists, we recommend that for the present, AI systems can and should be held to a similar standard of explanation as humans currently are; in the future we may wish to hold an AI to a different standard.},
annote = {In Press},
archivePrefix = {arXiv},
arxivId = {1711.01134},
author = {Doshi-Velez, Finale and Kortz, Mason and Budish, Ryan and Bavitz, Christopher and Gershman, Samuel J and O'Brien, David and Shieber, Stuart and Waldo, Jim and Weinberger, David and Wood, Alexandra},
doi = {10.2139/ssrn.3064761},
eprint = {1711.01134},
journal = {SSRN Electronic Journal},
month = {nov},
title = {{Accountability of AI Under the Law: The Role of Explanation}},
year = {2017}
}
@inproceedings{Wang:2013ue,
address = {Coimbra, Portugal},
author = {Wang, Shaowei and Lo, David and Jiang, Lingxiao},
booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},
doi = {10.1145/2480362.2480557},
month = {mar},
pages = {1019--1024},
publisher = {ACM},
title = {{An empirical study on developer interactions in StackOverflow}},
year = {2013}
}
@misc{ISO25010:2011,
author = {{International Organization for Standardization}},
title = {{ISO25010:2011 - Systems and software engineering -- Systems and software Quality Requirements and Evaluation (SQuaRE) -- System and software quality models}},
year = {2011}
}
@article{Meng:2017cx,
abstract = {The success of an application programming interface (API) crucially depends on how well its documentation meets the information needs of software developers. Previous research suggests that these information needs have not been sufficiently understood. This article presents the results of a series of semistructured interviews and a follow-up questionnaire conducted to explore the learning goals and learning strategies of software developers, the information resources they turn to and the quality criteria they apply to API documentation. Our results show that developers initially try to form a global understanding regarding the overall purpose and main features of an API, but then adopt either a concepts-oriented or a code-oriented learning strategy that API documentation both needs to address. Our results also show that general quality criteria such as completeness and clarity are relevant to API documentation as well. Developing and maintaining API documentation therefore need to involve the expertise of communication professionals.},
author = {Meng, Michael and Steinhardt, Stephanie and Schubert, Andreas},
doi = {10.1177/0047281617721853},
issn = {1541-3780},
journal = {Journal of Technical Writing and Communication},
keywords = {Application programming interface documentation,Audience analysis,Information design,Technical documentation,Usability},
month = {aug},
number = {3},
pages = {295--330},
title = {{Application programming interface documentation: What do software developers want?}},
volume = {48},
year = {2018}
}
@article{Su:2017uw,
abstract = {Recent research has revealed that the output of deep neural networks (DNNs) can be easily altered by adding relatively small perturbations to the input vector. In this paper, we analyze an attack in an extremely limited scenario where only one pixel can be modified. For that we propose a novel method for generating one-pixel adversarial perturbations based on differential evolution (DE). It requires less adversarial information (a black-box attack) and can fool more types of networks due to the inherent features of DE. The results show that 67.97{\%} of the natural images in Kaggle CIFAR-10 test dataset and 16.04{\%} of the ImageNet (ILSVRC 2012) test images can be perturbed to at least one target class by modifying just one pixel with 74.03{\%} and 22.91{\%} confidence on average. We also show the same vulnerability on the original CIFAR-10 dataset. Thus, the proposed attack explores a different take on adversarial machine learning in an extreme limited scenario, showing that current DNNs are also vulnerable to such low dimension attacks. Besides, we also illustrate an important application of DE (or broadly speaking, evolutionary computation) in the domain of adversarial machine learning: creating tools that can effectively generate low-cost adversarial attacks against neural networks for evaluating robustness.},
archivePrefix = {arXiv},
arxivId = {1710.08864},
author = {Su, Jiawei and Vargas, Danilo Vasconcellos and Sakurai, Kouichi},
doi = {10.1109/TEVC.2019.2890858},
eprint = {1710.08864},
issn = {1941-0026},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Convolutional neural network,differential evolution (DE),image recognition,information security},
number = {5},
pages = {828--841},
title = {{One Pixel Attack for Fooling Deep Neural Networks}},
volume = {23},
year = {2019}
}
@article{Graziontin:2017,
abstract = {The growing literature on affect among software developers mostly reports on the linkage between happiness, software quality, and developer productivity. Understanding happiness and unhappiness in all its components – positive and negative emotions and moods – is an attractive and important endeavor. Scholars in industrial and organizational psychology have suggested that understanding happiness and unhappiness could lead to cost-effective ways of enhancing working conditions, job performance, and to limiting the occurrence of psychological disorders. Our comprehension of the consequences of (un)happiness among developers is still too shallow, being mainly expressed in terms of development productivity and software quality. In this paper, we study what happens when developers are happy and unhappy while developing software. Qualitative data analysis of responses given by 317 questionnaire participants identified 42 consequences of unhappiness and 32 of happiness. We found consequences of happiness and unhappiness that are beneficial and detrimental for developers' mental well-being, the software development process, and the produced artifacts. Our classification scheme, available as open data enables new happiness research opportunities of cause-effect type, and it can act as a guideline for practitioners for identifying damaging effects of unhappiness and for fostering happiness on the job.},
author = {Graziotin, Daniel and Fagerholm, Fabian and Wang, Xiaofeng and Abrahamsson, Pekka},
doi = {10.1016/j.jss.2018.02.041},
issn = {0164-1212},
journal = {Journal of Systems and Software},
keywords = {Affect,Behavioral software engineering,Developer experience,Emotion,Happiness,Human aspects},
title = {{What happens when software developers are (un)happy}},
year = {2018}
}
@article{Selvaraju:2017bk,
abstract = {We propose a technique for producing ‘visual explanations' for decisions from a large class of Convolutional Neural Network (CNN)-based models, making them more transparent and explainable. Our approach—Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept (say ‘dog' in a classification network or a sequence of words in captioning network) flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Unlike previous approaches, Grad-CAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g.VGG), (2) CNNs used for structured outputs (e.g.captioning), (3) CNNs used in tasks with multi-modal inputs (e.g.visual question answering) or reinforcement learning, all without architectural changes or re-training. We combine Grad-CAM with existing fine-grained visualizations to create a high-resolution class-discriminative visualization, Guided Grad-CAM, and apply it to image classification, image captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classification models, our visualizations (a) lend insights into failure modes of these models (showing that seemingly unreasonable predictions have reasonable explanations), (b) outperform previous methods on the ILSVRC-15 weakly-supervised localization task, (c) are robust to adversarial perturbations, (d) are more faithful to the underlying model, and (e) help achieve model generalization by identifying dataset bias. For image captioning and VQA, our visualizations show that even non-attention based models learn to localize discriminative regions of input image. We devise a way to identify important neurons through Grad-CAM and combine it with neuron names (Bau et al. in Computer vision and pattern recognition, 2017) to provide textual explanations for model decisions. Finally, we design and conduct human studies to measure if Grad-CAM explanations help users establish appropriate trust in predictions from deep networks and show that Grad-CAM helps untrained users successfully discern a ‘stronger' deep network from a ‘weaker' one even when both make identical predictions. Our code is available at https://github.com/ramprs/grad-cam/, along with a demo on CloudCV (Agrawal et al., in: Mobile cloud visual media computing, pp 265–290. Springer, 2015) (http://gradcam.cloudcv.org) and a video at http://youtu.be/COjUB9Izk6E.},
author = {Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
doi = {10.1007/s11263-019-01228-7},
issn = {1573-1405},
journal = {International Journal of Computer Vision},
keywords = {Explanations,Grad-CAM,Interpretability,Transparency,Visual explanations,Visualizations},
pages = {618--626},
publisher = {IEEE},
title = {{Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization}},
year = {2019}
}
@inproceedings{Haselbock:2018jd,
abstract = {Design space analysis is a method for identifying and organizing potential design options and related concepts. So far, we have used decision models for the design space analysis of various areas of microservice design. Based on the feedback we have received, we refine our approach for design space analysis and extend it to support decision documentation. To validate the refined design space analysis approach and the approach we developed for decision documentation, we conduct a case study of microservice API management together with an industry partner. We present the identified design spaces and decision models created during the design space analysis, and show how the decision models were used for decision documentation. In addition, we draw general conclusions from applying the presented approach and concepts in an industrial context.},
address = {Paris, France},
author = {Haselbock, Stefan and Weinreich, Rainer and Buchgeher, Georg and Kriechbaum, Thomas},
booktitle = {Proceedings of the 11th International Conference on Service-Oriented Computing and Applications, SOCA 2018},
doi = {10.1109/SOCA.2018.00008},
keywords = {Decision models,Design decision documentation,Design space analysis,Microservices API management},
month = {nov},
pages = {1--8},
title = {{Microservice Design Space Analysis and Decision Documentation: A Case Study on API Management}},
year = {2019}
}
@book{Robbins:2014tr,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-{\$}\backslashbackslashalpha{\{}\backslash{\{}{\}}\backslashbackslash{\{}\backslash{\$}{\}}{\{}$\backslash${\}}{\}}-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA}for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
author = {Robbins, Stephen P},
edition = {14th},
isbn = {978-0-13-452470-2},
publisher = {Pearson},
title = {{Essentials of organizational behavior}},
year = {2017}
}
@incollection{Singer:2007tu,
author = {Singer, Janice and Sim, Susan E and Lethbridge, Timothy C},
booktitle = {Guide to Advanced Empirical Software Engineering},
chapter = {1},
doi = {10.1007/978-1-84800-044-5},
editor = {Shull, Forrest and Singer, Janice and Sj{\o}berg, Dag I. K.},
isbn = {978-1-84-800043-8},
month = {nov},
pages = {9--34},
publisher = {Springer},
title = {{Software engineering data collection for field studies}},
year = {2007}
}
@inproceedings{Sauro:2011aj,
abstract = {When designing questionnaires there is a tradition of including items with both positive and negative wording to minimize acquiescence and extreme response biases. Two disadvantages of this approach are respondents accidentally agreeing with negative items (mistakes) and researchers forgetting to reverse the scales (miscoding). The original System Usability Scale (SUS) and an all positively worded version were administered in two experiments (n=161 and n=213) across eleven websites. There was no evidence for differences in the response biases between the different versions. A review of 27 SUS datasets found 3 (11{\%}) were miscoded by researchers and 21 out of 158 questionnaires (13{\%}) contained mistakes from users. We found no evidence that the purported advantages of including negative and positive items in usability questionnaires outweigh the disadvantages of mistakes and miscoding. It is recommended that researchers using the standard SUS verify the proper coding of scores and include procedural steps to ensure error-free completion of the SUS by users. Researchers can use the all positive version with confidence because respondents are less likely to make mistakes when responding, researchers are less likely to make errors in coding, and the scores will be similar to the standard SUS. Copyright 2011 ACM.},
address = {Vancouver, BC, Canada},
author = {Sauro, Jeff and Lewis, James R.},
booktitle = {Proceedings of the 2011 SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/1978942.1979266},
keywords = {Acquiescent bias,Satisfaction measures,Standardized questionnaires,System Usability Scale (SUS),Usability evaluation},
month = {may},
pages = {2215--2223},
title = {{When designing usability questionnaires, does it hurt to be positive?}},
year = {2011}
}
@article{Maalej2013,
abstract = {Reading reference documentation is an important part of programming with application programming interfaces (APIs). Reference documentation complements the API by providing information not obvious from the API syntax. To improve the quality of reference documentation and the efficiency with which the relevant information it contains can be accessed, we must first understand its content. We report on a study of the nature and organization of knowledge contained in the reference documentation of the hundreds of APIs provided as a part of two major technology platforms: Java SDK 6 and.NET 4.0. Our study involved the development of a taxonomy of knowledge types based on grounded methods and independent empirical validation. Seventeen trained coders used the taxonomy to rate a total of 5,574 randomly sampled documentation units to assess the knowledge they contain. Our results provide a comprehensive perspective on the patterns of knowledge in API documentation: observations about the types of knowledge it contains and how this knowledge is distributed throughout the documentation. The taxonomy and patterns of knowledge we present in this paper can be used to help practitioners evaluate the content of their API documentation, better organize their documentation, and limit the amount of low-value content. They also provide a vocabulary that can help structure and facilitate discussions about the content of APIs. {\textcopyright}1976-2012 IEEE.},
author = {Maalej, Walid and Robillard, Martin P},
doi = {10.1109/TSE.2013.12},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {.NET,API documentation,Java,content analysis,data mining,empirical study,grounded method,pattern mining,software documentation},
title = {{Patterns of knowledge in API reference documentation}},
year = {2013}
}
@misc{Cigital:2003tl,
author = {Cigital},
title = {{Case Study: Finding defects earlier yields enormous savings}},
url = {http://bit.ly/36Il2cE},
year = {2003}
}
@inproceedings{Storey2014,
address = {Hyderabad, India},
author = {Storey, Margaret Anne and Singer, Leif and Cleary, Brendan and Filho, Fernando Figueira and Zagalsky, Alexey},
booktitle = {Future of Software Engineering Proceedings},
doi = {10.1145/2593882.2593887},
keywords = {Collaboration,Social Media,Software Engineering},
month = {may},
pages = {100--116},
publisher = {ACM},
title = {{The (R)evolution of social media in software engineering}},
year = {2014}
}
@inproceedings{1572302,
abstract = {Today's information technology society increasingly relies on software at all levels. Nevertheless, software quality generally continues to fall short of expectations, and software systems continue to suffer from symptoms of aging as they are adapted to changing requirements and environments. The only way to overcome or avoid the negative effects of software aging is by placing change and evolution in the center of the software development process. In this article we describe what we believe to be some of the most important research challenges in software evolution. The goal of this document is to provide novel research directions in the software evolution domain. {\textcopyright}2005 IEEE.},
address = {Lisbon, Portugal},
author = {Mens, Tom and Demeyer, Serge and Wermelinger, Michel and Hirschfeld, Robert and Ducasse, St{\'{e}}phane and Jazayeri, Mehdi},
booktitle = {Proceedings of the 8th International Workshop on Principles of Software Evolution},
doi = {10.1109/IWPSE.2005.7},
isbn = {0-76-952349-8},
issn = {1550-4077},
keywords = {Aging,Business,Collaborative software,Computer industry,Conferences,Information technology,Programming,Software quality,Software systems,Software tools,formal specification,formal verification,information technology society,requirements analysis,software aging,software development process,software evolution,software maintenance,software quality,software system},
month = {sep},
pages = {13--22},
publisher = {IEEE},
title = {{Challenges in software evolution}},
volume = {2005},
year = {2005}
}
@article{Landis:1977kv,
abstract = {This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.},
author = {Landis, J Richard and Koch, Gary G},
doi = {10.2307/2529310},
issn = {0006-341X},
journal = {Biometrics},
month = {mar},
number = {1},
pages = {159},
title = {{The Measurement of Observer Agreement for Categorical Data}},
volume = {33},
year = {1977}
}
@article{Wieringa:2006vd,
author = {Wieringa, Roel and Maiden, Neil and Mead, Nancy and Rolland, Colette},
doi = {10.1007/s00766-005-0021-6},
issn = {0947-3602},
journal = {Requirements Engineering},
keywords = {Paper classification,Paper evaluation criteria,Requirements engineering research,Research methods},
month = {mar},
number = {1},
pages = {102--107},
title = {{Requirements engineering paper classification and evaluation criteria: a proposal and a discussion}},
volume = {11},
year = {2006}
}
@article{Lau:1999vs,
abstract = {Based on recent reviews regarding its use in information systems (IS) studies, this paper argues that action research is still not well recognized by IS researchers and mainstream IS journals especially in North America. To make the situation worse, existing criteria used to assess the quality of action research studies are found to be inadequate when applied to IS. In order to advance its understanding and use by IS researchers and practitioners, the IS action research framework proposed recently by Lau is refined and presented as a set of guidelines in this paper. The implications of this refined framework on IS research and practice are discussed. {\textcopyright}1999, MCB UP Limited},
author = {Lau, Francis},
doi = {10.1108/09593849910267206},
issn = {0959-3845},
journal = {Information Technology {\&} People},
keywords = {Action research,Assessment,Information systems,Methodology,Quality,Research},
number = {2},
pages = {148--176},
title = {{Toward a framework for action research in information systems studies}},
volume = {12},
year = {1999}
}
@inproceedings{Novielli:2015vda,
abstract = {A recent research trend has emerged to study the role of affect in in the social programmer ecosystem, by applying sentiment analysis to the content available in sites such as GitHub and Stack Overflow. In this paper, we aim at assessing the suitability of a state-of-the-art sentiment analysis tool, already applied in social computing, for detecting affective expressions in Stack Overflow. We also aim at verifying the construct validity of choosing sentiment polarity and strength as an appropriate way to operationalize affective states in empirical studies on Stack Overflow. Finally, we underline the need to overcome the limitations induced by domain-dependent use of lexicon that may produce unreliable results.},
address = {Bergamo, Italy},
author = {Novielli, Nicole and Calefato, Fabio and Lanubile, Filippo},
booktitle = {Proceedings of the 7th International Workshop on Social Software Engineering},
doi = {10.1145/2804381.2804387},
isbn = {978-1-45-033818-9},
keywords = {Online Q and A,Overflow,Sentiment Analysis,Social Programmer,Social Software Engineering,Stack,Technical Forum},
month = {aug},
pages = {33--40},
publisher = {ACM},
title = {{The challenges of sentiment detection in the social programmer ecosystem}},
year = {2015}
}
@inproceedings{Aghajani:2019bo,
abstract = {(Good) Software documentation provides developers and users with a description of what a software system does, how it operates, and how it should be used. For example, technical documentation (e.g., an API reference guide) aids developers during evolution/maintenance activities, while a user manual explains how users are to interact with a system. Despite its intrinsic value, the creation and the maintenance of documentation is often neglected, negatively impacting its quality and usefulness, ultimately leading to a generally unfavourable take on documentation. Previous studies investigating documentation issues have been based on surveying developers, which naturally leads to a somewhat biased view of problems affecting documentation. We present a large scale empirical study, where we mined, analyzed, and categorized 878 documentation-related artifacts stemming from four different sources, namely mailing lists, Stack Overflow discussions, issue repositories, and pull requests. The result is a detailed taxonomy of documentation issues from which we infer a series of actionable proposals both for researchers and practitioners.},
address = {Montreal, QC, Canada},
author = {Aghajani, Emad and Nagy, Csaba and Vega-Marquez, Olga Lucero and Linares-Vasquez, Mario and Moreno, Laura and Bavota, Gabriele and Lanza, Michele},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
doi = {10.1109/ICSE.2019.00122},
isbn = {978-1-72-810869-8},
issn = {0270-5257},
keywords = {Documentation,Empirical Study},
month = {may},
pages = {1199--1210},
publisher = {IEEE},
title = {{Software Documentation Issues Unveiled}},
year = {2019}
}
@inproceedings{Szegedy:2013vw,
abstract = {Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains the semantic information in the high layers of neural networks. Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extent. We can cause the network to misclassify an image by applying a certain hardly perceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.},
address = {Banff, AB, Canada},
archivePrefix = {arXiv},
arxivId = {1312.6199},
author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
booktitle = {Proceedings of the 2nd International Conference on Learning Representations},
eprint = {1312.6199},
month = {apr},
publisher = {ACM},
title = {{Intriguing properties of neural networks}},
year = {2014}
}
@book{Breiman:1984tu,
abstract = {The methodology used to construct tree structured rules is the focus of this monograph. Unlike many other statistical procedures, which moved from pencil and paper to calculators, this text's use of trees was unthinkable before computers. Both the practical and theoretical sides have been developed in the authors' study of tree methods. Classification and Regression Trees reflects these two sides, covering the use of trees as a data analysis method, and in a more mathematical framework, proving some of their fundamental properties.},
address = {New York, NY, USA},
author = {Breiman, Leo and Friedman, Jerome H and Olshen, Richard A and Stone, Charles J},
booktitle = {Classification and Regression Trees},
doi = {10.1201/9781315139470},
isbn = {978-1-35-146049-1},
issn = {1661-8564},
pages = {1--358},
publisher = {CRC press},
title = {{Classification and regression trees}},
year = {1984}
}
@article{Robillard:2009uk,
abstract = {Most software projects reuse components exposed through APIs, which provide developers access to implemented functionality. APIs have grown large and diverse, which raises questions regarding their usability. This article reports on a study of the obstacles professional developers at Microsoft faced when learning how to use APIs. The study was grounded in developers' experience, collected through a survey and interviews. The resulting data showed that learning resources for APIs are critically important and shed light on three issues: the need to discover the design and rationale of the API when needed, the challenge of finding credible usage API examples at the right level of complexity, and the challenge of understanding inexplicable API behavior. The article describes each of these challenges in detail and discusses associated implications for API users and designers. {\textcopyright}2009 IEEE.},
author = {Robillard, Martin P},
doi = {10.1109/MS.2009.193},
issn = {0740-7459},
journal = {IEEE Software},
keywords = {API design,API usability,Application interfaces,Code examples,Context,Data mining,Documentation,Empirical study,Software documentation,Usability},
number = {6},
pages = {27--34},
title = {{What makes APIs hard to learn? Answers from developers}},
volume = {26},
year = {2009}
}
@article{Polyzotis2018a,
abstract = {Machine learning has become an essential tool for gleaning knowledge from data and tackling a diverse set of computationally hard tasks. However, the accuracy of a machine learned model is deeply tied to the data that it is trained on. Designing and building robust processes and tools that make it easier to analyze, validate, and transform data that is fed into large-scale machine learning systems poses data management challenges. Drawn from our experience in developing data-centric infrastructure for a production machine learning platform at Google, we summarize some of the interesting research challenges that we encountered, and survey some of the relevant literature from the data management and machine learning communities. Specifically, we explore challenges in three main areas of focus - data understanding, data validation and cleaning, and data preparation. In each of these areas, we try to explore how different constraints are imposed on the solutions depending on where in the lifecycle of a model the problems are encountered and who encounters them.},
author = {Polyzotis, Neoklis and Roy, Sudip and Whang, Steven Euijong and Zinkevich, Martin},
doi = {10.1145/3299887.3299891},
issn = {01635808},
journal = {SIGMOD Record},
title = {{Data lifecycle challenges in production machine learning: A survey}},
year = {2018}
}
@inproceedings{nishi2018test,
abstract = {As machine learning (ML) technology continues to spread by rapid evolution, the system or service using Machine Learning technology, called ML product, makes big impact on our life, society and economy. Meanwhile, Quality Assurance (QA) for ML product is quite more difficult than hardware, non-ML software and service because performance of ML technology is much better than non-ML technology in exchange for the characteristics of ML product, e.g. low explainability. We must keep rapid evolution and reduce quality risk of ML product simultaneously. In this paper, we show a Quality Assurance Framework for Machine Learning product. Scope of QA in this paper is limited to product evaluation. First, a policy of QA for ML Product is proposed. General principles of product evaluation is introduced and applied to ML product evaluation as a part of the policy. They are composed of A-ARAI: Allowability, Achievability, Robustness, Avoidability and Improvability. A strategy of ML Product Evaluation is constructed as another part of the policy. Quality Integrity Level for ML product is also modelled. Second, we propose a test architecture of ML product testing. It consists of test levels and fundamental test types of ML product testing, including snapshot testing, learning testing and confrontation testing. Finally, we defines QA activity levels for ML product.},
address = {V{\"{a}}ster{\aa}s, Sweden},
author = {Nishi, Yasuharu and Masuda, Satoshi and Ogawa, Hideto and Uetsuki, Keiji},
booktitle = {Proceedings of the 11th International Conference on Software Testing, Verification and Validation Workshops},
doi = {10.1109/ICSTW.2018.00060},
isbn = {978-1-53-866352-3},
keywords = {Artificial intelligence,Functional safety,Machine learning,Quality assurance,Test architecture,Test design,Test level,Test type},
month = {apr},
pages = {273--278},
publisher = {IEEE},
title = {{A test architecture for machine learning product}},
year = {2018}
}
@article{Heckel:2005uk,
author = {Heckel, Reiko and Lohmann, Marc},
doi = {10.1016/j.entcs.2004.02.073},
issn = {1571-0661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {jan},
pages = {145--156},
title = {{Towards Contract-based Testing of Web Services}},
volume = {116},
year = {2005}
}
@book{Boehm:1981ua,
address = {Englewood Cliffs, NJ, USA},
author = {Boehm, Barry W},
isbn = {0-13-822122-7},
publisher = {Prentice-Hall},
title = {{Software engineering economics}},
year = {1981}
}
@article{Light:1971vz,
abstract = {Notes that various procedures are available for measuring agreement among 2 or more os who classify responses among nominal categories, but that different problem situations require different measures. The general model of a contingency table with fixed margins is used to suggest (a) a measure of level of agreement among several os when compared internally, (b) a conditional measurement of agreement for several os compared internally, (c) a test for the joint agreement of several os when compared with a standard, and (d) a statistic for evaluating the pattern of agreement between 2 os. Illustrations are presented for each situation, and results of a monte carlo study of the behavior of the pattern agreement statistic are discussed. (19 ref.) (PsycINFO Database Record (c) 2006 APA, all rights reserved). {\textcopyright}1971 American Psychological Association.},
author = {Light, Richard J},
doi = {10.1037/h0031643},
issn = {0033-2909},
journal = {Psychological Bulletin},
keywords = {response agreement measurement among 2 or more Os},
number = {5},
pages = {365--377},
title = {{Measures of response agreement for qualitative data: Some generalizations and alternatives}},
volume = {76},
year = {1971}
}
@book{Simon:1996uw,
abstract = {Continuing his exploration of the organization of complexity and the science of design, this new edition of Herbert Simon's classic work on artificial intelligence adds a chapter that sorts out the current themes and tools—chaos, adaptive systems, genetic algorithms—for analyzing complexity and complex systems. There are updates throughout the book as well. These take into account important advances in cognitive psychology and the science of design while confirming and extending the book's basic thesis: that a physical symbol system has the necessary and sufficient means for intelligent action. The chapter "Economic Reality" has also been revised to reflect a change in emphasis in Simon's thinking about the respective roles of organizations and markets in economic systems.},
author = {Michalos, Alex C and Simon, Herbert A},
booktitle = {Technology and Culture},
doi = {10.2307/3102825},
issn = {0040165X},
number = {1},
pages = {118},
publisher = {MIT press},
title = {{The Sciences of the Artificial}},
volume = {11},
year = {1970}
}
@inproceedings{Hou:2013jf,
abstract = {Text categorization, automatically labeling natural language text with pre-defined semantic categories, is an essential task for managing the abundant online data. An example of such data in Software Engineering is the large, ever-growing volume of forum discussions on how to use particular APIs. We have conducted a study to explore the question as to how well machine learning algorithms can be applied to categorize API discussions based on their content. Our goal is two-fold: (1) Can a relatively straightforward algorithm such as Naive Bayes work sufficiently well for this task? (2) If yes, how can we control its performance? We have achieved the best test accuracy mean (TAM) of 94.1{\%} with our largest training data set for the AWT/Swing API, which consists of 833 forum discussions distributed over eight categories/topics. We have also investigated factors that impact classification accuracy, with the most important two being the size of the training set and multi-label documents (the phenomenon that some discussions involve more than one category). {\textcopyright}2013 IEEE.},
address = {Eindhoven, Netherlands},
author = {Hou, Daqing and Mo, Lingfeng},
booktitle = {Proceedings of the 29th International Conference on Software Maintenance},
doi = {10.1109/ICSM.2013.17},
keywords = {APIs,AWT/Swing,MALLET,Naive Bayes,Online Forums,Text Categorization},
month = {sep},
pages = {60--69},
publisher = {IEEE},
title = {{Content categorization of API discussions}},
year = {2013}
}
@misc{ISO8402:1986,
author = {{International Organization for Standardization}},
title = {{ISO 8402:1986 Information Technology - Software Product Evaluation - Quality Characteristics and Guidelines for Their Use}},
url = {http://bit.ly/37SK4HP},
year = {1986}
}
@inproceedings{guo2016ms,
address = {Amsterdam, The Netherlands},
author = {Guo, Yandong and Zhang, Lei and Hu, Yuxiao and He, Xiaodong and Gao, Jianfeng},
booktitle = {Proceedings of the 16th European Conference on Computer Vision},
doi = {10.1007/978-3-319-46487-9_6},
pages = {87--102},
publisher = {Springer},
title = {{MS-Celeb-1M: A Dataset and Benchmark for Large-Scale Face Recognition}},
year = {2016}
}
@inproceedings{Hayete:2005tn,
abstract = {The Gene Ontology (GO) offers a comprehensive and standardized way to describe a protein's biological role. Proteins are annotated with GO terms based on direct or indirect experimental evidence. Term assignments are also inferred from homology and literature mining. Regardless of the type of evidence used, GO assignments are manually curated or electronic. Unfortunately, manual curation cannot keep pace with the data, available from publications and various large experimental datasets. Automated literature-based annotation methods have been developed in order to speed up the annotation. However, they only apply to proteins that have been experimentally investigated or have close homologs with sufficient and consistent annotation. One of the homology-based electronic methods for GO annotation is provided by the InterPro database. The InterPro2GO/PFAM2GO associates individual protein domains with GO terms and thus can be used to annotate the less studied proteins. However, protein classification via a single functional domain demands stringency to avoid large number of false positives. This work broadens the basic approach. We model proteins via their entire functional domain content and train individual decision tree classifiers for each GO term using known protein assignments. We demonstrate that our approach is sensitive, specific and precise, as well as fairly robust to sparse data. We have found that our method is more sensitive when compared to the InterPro2GO performance and suffers only some precision decrease. In comparison to the InterPro2GO we have improved the sensitivity by 22{\%}, 27{\%} and 50{\%} for Molecular Function, Biological Process and Cellular GO terms respectively.},
address = {Hawaii, USA},
author = {Hayete, Boris and Bienkowska, Jadwiga R},
booktitle = {Proceedings of the Pacific Symposium on Biocomputing 2005, PSB 2005},
doi = {10.1142/9789812702456_0013},
isbn = {9-81-256046-7},
month = {jan},
pages = {127--138},
publisher = {World Scientific Publishing Company},
title = {{Gotrees: Predicting go associations from protein domain composition using decision trees}},
year = {2005}
}
@book{demeyer2008software,
abstract = {Software has become omnipresent and vital in our information-based society, so all software producers should assume responsibility for its reliability. While "reliable" originally assumed implementations that were effective and mainly error-free, additional issues like adaptability and maintainability have gained equal importance recently. For example, the 2004 ACM/IEEE Software Engineering Curriculum Guidelines list software evolution as one of ten key areas of software engineering education.Mens and Demeyer, both international authorities in the field of software evolution, together with the invited contributors, focus on novel trends in software evolution research and its relations with other emerging disciplines such as model-driven software engineering, service-oriented software development, and aspect-oriented software development. They do not restrict themselves to the evolution of source code but also address the evolution of other, equally important software artifacts such as databases and database schemas, design models, software architectures, and process management. The contributing authors provide broad overviews of related work, and they also contribute to a comprehensive glossary, a list of acronyms, and a list of books, journals, websites, standards and conferences that together represent the community's body of knowledge. Combining all these features, this book is the indispensable source for researchers and professionals looking for an introduction and comprehensive overview of the state of the art. In addition, it is an ideal basis for an advanced course on software evolution. {\textcopyright}Springer-Verlag Berlin Heidelberg 2008.},
address = {Berlin, Heidelberg},
author = {Mens, Tom and Demeyer, Serge},
doi = {10.1007/978-3-540-76440-3},
isbn = {978-3-54-076439-7},
publisher = {Springer},
title = {{Software Evolution}},
year = {2008}
}
@article{Aalst:2015gv,
abstract = {As more and more companies are embracing Big data, it has become apparent that the ultimate challenge is to relate massive amounts of event data to processes that are highly dynamic. To unleash the value of event data, events need to be tightly connected to the control and management of operational processes. However, the primary focus of Big data technologies is currently on storage, processing, and rather simple analytical tasks. Big data initiatives rarely focus on the improvement of end-to-end processes. To address this mismatch, we advocate a better integration of data science, data technology and process science. Data science approaches tend to be process agonistic whereas process science approaches tend to be model-driven without considering the 'evidence' hidden in the data. Process mining aims to bridge this gap. This editorial discusses the interplay between data science and process science and relates process mining to Big data technologies, service orientation, and cloud computing.},
author = {{Van Der Aalst}, Wil and Damiani, Ernesto},
doi = {10.1109/TSC.2015.2493732},
issn = {1939-1374},
journal = {IEEE Transactions on Services Computing},
keywords = {Big Data,Cloud Computing,Data Science,Process Mining,Process Science,Service Orientation},
month = {nov},
number = {6},
pages = {810--819},
title = {{Processes Meet Big Data: Connecting Data Science with Process Science}},
volume = {8},
year = {2015}
}
@book{Krathwohl:2001wr,
author = {Bloom, Benjamin Samuel},
edition = {2nd},
isbn = {978-0-58-228010-6},
publisher = {Addison-Wesley Longman},
title = {{Taxonomy of Educational Objectives, Handbook 1: Cognitive Domain}},
year = {1956}
}
@article{Lavrac:1999tf,
abstract = {Widespread use of medical information systems and explosive growth of medical databases require traditional manual data analysis to be coupled with methods for efficient computer-assisted analysis. This paper presents selected data mining techniques that can be applied in medicine, and in particular some machine learning techniques including the mechanisms that make them better suited for the analysis of medical databases (derivation of symbolic rules, use of background knowledge, sensitivity and specificity of induced descriptions). The importance of the interpretability of results of data analysis is discussed and illustrated on selected medical applications.},
author = {Lavra{\v{c}}, Nada},
doi = {10.1016/S0933-3657(98)00062-1},
issn = {0933-3657},
journal = {Artificial Intelligence in Medicine},
keywords = {Data mining,Machine learning,Medical applications},
number = {1},
pages = {3--23},
pmid = {10225344},
title = {{Selected techniques for data mining in medicine}},
volume = {16},
year = {1999}
}
@book{Bramer:2007vg,
address = {London, England, UK},
author = {Bramer, Max},
doi = {10.1007/978-1-4471-7307-6},
isbn = {978-1-44-717306-9},
publisher = {Springer},
series = {Undergraduate Topics in Computer Science},
title = {{Principles of Data Mining}},
volume = {180},
year = {2016}
}
@inproceedings{Parekh:2017hx,
address = {Halifax, NS, Canada},
author = {Parekh, Rajesh},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/3097983.3105815},
month = {aug},
pages = {27},
publisher = {ACM},
title = {{Designing AI at Scale to Power Everyday Life}},
year = {2017}
}
@inproceedings{Cummaudo:2020fse,
address = {Sacramento, CA, USA},
annote = {In Press},
author = {Cummaudo, Alex and Barnett, Scott and Vasa, Rajesh and Grundy, John and Abdelrazek, Mohamed},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
keywords = {InPress},
mendeley-tags = {InPress},
month = {nov},
publisher = {ACM},
title = {{Beware the evolving ‘intelligent' web service! An integration architecture tactic to guard AI-first components}},
year = {2020}
}
@inproceedings{ortu2016,
address = {Austin, TX, USA},
author = {Ortu, Marco and Murgia, Alessandro and Destefanis, Giuseppe and Tourani, Parastou and Tonelli, Roberto and Marchesi, Michele and Adams, Bram},
booktitle = {Proceedings of the 13th International Conference on Mining Software Repositories},
doi = {10.1145/2901739.2903505},
month = {may},
organization = {ACM},
pages = {480--483},
publisher = {ACM},
title = {{The emotional side of software developers in JIRA}},
year = {2016}
}
@inproceedings{Feelders:2000ve,
abstract = {A common form of prior knowledge in economic modelling concerns the monotonicity of relations between the dependent and explanatory variables. Monotonicity may also be an important requirement with a view toward explaining and justifying decisions based on such models. We explore the use of monotonicity constraints in classification tree algorithms.We present an application of monotonic classification trees to a problem in house pricing. In this preliminary study we found that the monotonic trees were only slightly worse in classification performance, but were much simpler than their non-monotonic counterparts.},
address = {Lyon, France},
author = {Feelders, A J},
booktitle = {Proceedings of the 4th European Conference on Principles of Data Mining and Knowledge Discovery},
doi = {10.1007/3-540-45372-5_42},
isbn = {978-3-54-041066-9},
issn = {1611-3349},
month = {sep},
pages = {395--400},
publisher = {Springer},
title = {{Prior knowledge in economic applications of data mining}},
volume = {1910},
year = {2000}
}
@article{Khurana2017,
abstract = {Feature engineering involves constructing novel features from given data with the goal of improving predictive learning performance. Feature engineering is predominantly a human-intensive and time consuming step that is central to the data science workflow. In this paper, we present a novel system called 'Cognito', that performs automatic feature engineering on a given dataset for supervised learning. The system explores various feature construction choices in a hierarchical and non-exhaustive manner, while progressively maximizing the accuracy of the model through a greedy exploration strategy. Additionally, the system allows users to specify domain or data specific choices to prioritize the exploration. Cognito is capable of handling large datasets through sampling and built-in parallelism, and integrates well with a state-of-The-Art model selection strategy. We present the design and operation of Cognito, along with experimental results on eight real datasets to demonstrate its efficacy. {\textcopyright} 2016 IEEE.},
author = {Khurana, Udayan and Turaga, Deepak and Samulowitz, Horst and Parthasrathy, Srinivasan},
doi = {10.1109/ICDMW.2016.0190},
file = {::},
isbn = {9781509054725},
issn = {23759259},
journal = {IEEE International Conference on Data Mining Workshops, ICDMW},
keywords = {Data Science,Feature Construction,Feature Engineering,Machine Learning},
pages = {1304--1307},
publisher = {IEEE},
title = {{Cognito: Automated Feature Engineering for Supervised Learning}},
year = {2017}
}
@article{Vercoulen1994,
abstract = {The absence of laboratory tests and clear criteria to identify homogeneous (sub)groups in patients presenting with unexplained fatigue, and to assess clinical status and disability in these patients, calls for further assessment methods. In the present study, a multi-dimensional approach to the assessment of chronic fatigue syndrome (CFS) is evaluated. Two-hundred and ninety-eight patients with CFS completed a set of postal questionnaires that assessed the behavioural, emotional, social, and cognitive aspects of CFS. By means of statistical analyses nine relatively independent dimensions of CFS were identified along which CFS-assessment and CFS-research can be directed. These dimensions were named: psychological well-being, functional impairment in daily life, sleep disturbances, avoidance of physical activity, neuropsychological impairment, causal attributions related to the complaints, social functioning, self-efficacy expectations, and subjective experience of the personal situation. A description of the study sample on these dimensions is presented. {\textcopyright} 1994.},
author = {Vercoulen, Jan H.M.M. and Swanink, Caroline M.A. and Fennis, Jan F.M. and Galama, Joep M.D. and van der Meer, Jos W.M. and Bleijenberg, Gijs},
doi = {10.1016/0022-3999(94)90099-X},
issn = {00223999},
journal = {Journal of Psychosomatic Research},
month = {jul},
number = {5},
pages = {383--392},
pmid = {7965927},
publisher = {Elsevier},
title = {{Dimensional assessment of chronic fatigue syndrome}},
url = {https://linkinghub.elsevier.com/retrieve/pii/002239999490099X},
volume = {38},
year = {1994}
}
@article{Zanaty2018,
abstract = {Background: Code review is a well-established software quality practice where developers critique each others' changes. A shift towards automated detection of low-level issues (e.g., integration with linters) has, in theory, freed reviewers up to focus on higher level issues, such as software design. Yet in practice, little is known about the extent to which design is discussed during code review. Aim: To bridge this gap, in this paper, we set out to study the frequency and nature of design discussions in code reviews. Method: We perform an empirical study on the code reviews of the OpenStack Nova (provisioning management) and Neutron (networking abstraction) projects. We manually classify 2,817 review comments from a randomly selected sample of 220 code reviews. We then train and evaluate classifiers to automatically label review comments as design related or not. Finally, we apply the classifiers to a larger sample of 2,506,308 review comments to study the characteristics of reviews that include design discussions. Results: Our manual analysis indicates that (1) design discussions are still quite rare, with only 9{\%} and 14{\%} of Nova and Neutron review comments being related to software design, respectively; and (2) design feedback is often constructive, with 73{\%} of the design-related comments also providing suggestions to address the concerns. Furthermore, our classifiers achieve a precision of 59{\%}-66{\%} and a recall of 70{\%}-78{\%}, outperforming baselines like zeroR by 43 percentage points in terms of F1-score. Finally, code changes that have design-related feedback have a statistically significantly increased rate of abandonment (Pearson 2 test, DF=1, p {\textless} 0.001). Conclusion: Design-related discussion during code review is still rare. Since design discussion is a primary motivation for conducting code review, more may need to be done to encourage such discussions among contributors.},
annote = {A good paper for automatic text labelling},
author = {Zanaty, Farida El and Hirao, Toshiki and McIntosh, Shane and Ihara, Akinori and Matsumoto, Kenichi},
doi = {10.1145/3239235.3239525},
file = {::},
isbn = {9781450358231},
issn = {19493789},
journal = {International Symposium on Empirical Software Engineering and Measurement},
keywords = {Code review,Mining software repositories,Software design},
title = {{An empirical study of design discussions in code review}},
year = {2018}
}
@article{Hussain2018,
abstract = {{\textcopyright} 2018 Springer Science+Business Media B.V., part of Springer Nature Epilepsy is a neurological disorder produced due to abnormal excitability of neurons in the brain. The research reveals that brain activity is monitored through electroencephalogram (EEG) of patients suffered from seizure to detect the epileptic seizure. The performance of EEG detection based epilepsy require feature extracting strategies. In this research, we have extracted varying features extracting strategies based on time and frequency domain characteristics, nonlinear, wavelet based entropy and few statistical features. A deeper study was undertaken using novel machine learning classifiers by considering multiple factors. The support vector machine kernels are evaluated based on multiclass kernel and box constraint level. Likewise, for K-nearest neighbors (KNN), we computed the different distance metrics, Neighbor weights and Neighbors. Similarly, the decision trees we tuned the paramours based on maximum splits and split criteria and ensemble classifiers are evaluated based on different ensemble methods and learning rate. For training/testing tenfold Cross validation was employed and performance was evaluated in form of TPR, NPR, PPV, accuracy and AUC. In this research, a deeper analysis approach was performed using diverse features extracting strategies using robust machine learning classifiers with more advanced optimal options. Support Vector Machine linear kernel and KNN with City block distance metric give the overall highest accuracy of 99.5{\%} which was higher than using the default parameters for these classifiers. Moreover, highest separation (AUC = 0.9991, 0.9990) were obtained at different kernel scales using SVM. Additionally, the K-nearest neighbors with inverse squared distance weight give higher performance at different Neighbors. Moreover, to distinguish the postictal heart rate oscillations from epileptic ictal subjects, and highest performance of 100{\%} was obtained using different machine learning classifiers.},
author = {Hussain, Lal},
doi = {10.1007/s11571-018-9477-1},
file = {::},
issn = {18714099},
journal = {Cognitive Neurodynamics},
keywords = {Classification,Decision tree,Ensemble classifier,Epilepsy,K-nearest neighbors,Seizure detection,Support vector machine},
month = {jun},
number = {3},
pages = {271--294},
publisher = {Springer Netherlands},
title = {{Detecting epileptic seizure with different feature extracting strategies using robust machine learning classification techniques by applying advance parameter optimization approach}},
volume = {12},
year = {2018}
}
@article{Inkpen2019,
abstract = {In recent years, AI systems have become both more powerful and increasingly promising for integration in a variety of application areas. Attention has also been called to the social challenges these systems bring, particularly in how they might fail or even actively disadvantage marginalised social groups, or how their opacity might make them difficult to oversee and challenge. In the context of these and other challenges, the roles of humans working in tandem with these systems will be important, yet the HCI community has been only a quiet voice in these debates to date. This workshop aims to catalyse and crystallise an agenda around HCI's engagement with AI systems. Topics of interest include explainable and explorable AI; documentation and review; integrating artificial and human intelligence; collaborative decision making; AI/ML in HCI Design; diverse human roles and relationships in AI systems; and critical views of AI.},
author = {Inkpen, Kori and Veale, Michael and Chancellor, Stevie and {De Choudhury}, Munmun and Baumer, Eric P.S.},
doi = {10.1145/3290607.3299002},
file = {::},
isbn = {9781450359719},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Artificial intelligence,Human computer interaction},
pages = {1--9},
title = {{Where is the human? Bridging the gap between AI and HCI}},
year = {2019}
}
@article{Wojciechowski2017,
abstract = {In this paper we describe results of an experimental study where we checked the impact of various difficulty factors in imbalanced data sets on the performance of selected classifiers applied alone or combined with several preprocessing methods. In the study we used artificial data sets in order to systematically check factors such as dimensionality, class imbalance ratio or distribution of specific types of examples (safe, borderline, rare and outliers) in the minority class. The results revealed that the latter factor was the most critical one and it exacerbated other factors (in particular class imbalance). The best classification performance was demonstrated by non-symbolic classifiers, particular by k-NN classifiers (with 1 or 3 neighbors - 1NN and 3NN, respectively) and by SVM. Moreover, they benefited from different preprocessing methods - SVM and 1NN worked best with undersampling, while oversampling was more beneficial for 3NN.},
annote = {Created a data generator to produce data that represents the different types of challenges. 

I wonder if we can create a simple text generator to handle class imbalance.},
author = {Wojciechowski, Szymon and Wilk, Szymon},
doi = {10.1515/fcds-2017-0007},
file = {::},
journal = {Foundations of Computing and Decision Sciences},
keywords = {difficulty factors,imbalanced data,learning,preprocessing methods},
number = {2},
pages = {149--176},
title = {{Difficulty Factors and Preprocessing in Imbalanced Data Sets: An Experimental Study on Artificial Data}},
volume = {42},
year = {2017}
}
@article{Kim2019,
abstract = {People naturally bring their prior beliefs to bear on how they interpret the new information, yet few formal models exist for accounting for the influence of users' prior beliefs in interactions with data presentations like visualizations. We demonstrate a Bayesian cognitive model for understanding how people interpret visualizations in light of prior beliefs and show how this model provides a guide for improving visualization evaluation. In a first study, we show how applying a Bayesian cognition model to a simple visualization scenario indicates that people's judgments are consistent with a hypothesis that they are doing approximate Bayesian inference. In a second study, we evaluate how sensitive our observations of Bayesian behavior are to different techniques for eliciting people subjective distributions, and to different datasets. We find that people don't behave consistently with Bayesian predictions for large sample size datasets, and this difference cannot be explained by elicitation technique. In a final study, we show how normative Bayesian inference can be used as an evaluation framework for visualizations, including of uncertainty.},
archivePrefix = {arXiv},
arxivId = {1901.02949},
author = {Kim, Yea Seul and Walls, Logan A. and Krafft, Peter and Hullman, Jessica},
doi = {10.1145/3290605.3300912},
eprint = {1901.02949},
file = {::},
isbn = {9781450359702},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Bayesian cognition,Uncertainty elicitation,Visualization},
title = {{A Bayesian cognition approach to improve data visualization}},
year = {2019}
}
@book{fenton2014software,
author = {Fenton, Norman and Bieman, James},
publisher = {CRC press},
title = {{Software metrics: a rigorous and practical approach}},
year = {2014}
}
@article{Kristensson2019,
abstract = {This course introduces computational methods in human-computer interaction. Computational interaction methods use computational thinking-abstraction, automation, and analysis-to explain and enhance interaction. This course introduces the theory of practice of computational interaction by teaching Bayesian methods for interaction across four wide areas of interest when designing computationally-driven user interfaces: decoding, adaptation, learning and optimization. The lectures center on hands-on Python programming interleaved with theory and practical examples grounded in problems of wide interest in human-computer interaction.},
author = {Kristensson, Per Ola and Oulasvirta, Antti and Banovic, Nikola and Williamson, John},
doi = {10.1145/3290607.3298820},
file = {::},
isbn = {9781450359719},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Computational interaction,Inference,Machine learning,Optimization},
pages = {1--6},
title = {{Computational interaction with Bayesian methods}},
year = {2019}
}
@article{Gibaldi2017,
abstract = {The Tobii Eyex Controller is a new low-cost binocular eye tracker marketed for integration in gaming and consumer applications. The manufacturers claim that the system was conceived for natural eye gaze interaction, does not require continuous recalibration, and allows moderate head movements. The Controller is provided with a SDK to foster the development of new eye tracking applications. We review the characteristics of the device for its possible use in scientific research. We develop and evaluate an open source Matlab Toolkit that can be employed to interface with the EyeX device for gaze recording in behavioral experiments. The Toolkit provides calibration procedures tailored to both binocular and monocular experiments, as well as procedures to evaluate other eye tracking devices. The observed performance of the EyeX (i.e. accuracy {\textless} 0.6°, precision {\textless} 0.25°, latency {\textless} 50 ms and sampling frequency ≈55 Hz), is sufficient for some classes of research application. The device can be successfully employed to measure fixation parameters, saccadic, smooth pursuit and vergence eye movements. However, the relatively low sampling rate and moderate precision limit the suitability of the EyeX for monitoring micro-saccadic eye movements or for real-time gaze-contingent stimulus control. For these applications, research grade, high-cost eye tracking technology may still be necessary. Therefore, despite its limitations with respect to high-end devices, the EyeX has the potential to further the dissemination of eye tracking technology to a broad audience, and could be a valuable asset in consumer and gaming applications as well as a subset of basic and clinical research settings.},
author = {Gibaldi, Agostino and Vanegas, Mauricio and Bex, Peter J. and Maiello, Guido},
doi = {10.3758/s13428-016-0762-9},
file = {::},
issn = {15543528},
journal = {Behavior Research Methods},
keywords = {Binocular,Eye movements,Eye tracking,Low cost,Saccade,Smooth pursuit,Vergence},
number = {3},
pages = {923--946},
title = {{Evaluation of the Tobii EyeX Eye tracking controller and Matlab toolkit for research}},
volume = {49},
year = {2017}
}
@misc{SunMicrosystems1999,
author = {{Sun Microsystems}},
title = {{Code Conventions for the Java Programming Language: Contents}},
url = {https://www.oracle.com/technetwork/java/javase/documentation/codeconvtoc-136057.html},
urldate = {2019-12-13},
year = {1999}
}
@inproceedings{Ohtake:2019vi,
abstract = {Intelligent APIs, such as Google Cloud Vision or Amazon Rekognition, are becoming evermore pervasive and easily accessible to developers to build applications. Because of the stochastic nature that machine learning entails and disparate datasets used in their training, the output from different APIs varies over time, with low reliability in some cases when compared against each other. Merging multiple unreliable API responses from multiple vendors may increase the reliability of the overall response, and thus the reliability of the intelligent end-product. We introduce a novel methodology – inspired by the proportional representation used in electoral systems – to merge outputs of different intelligent computer vision APIs provided by multiple vendors. Experiments show that our method outperforms both naive merge methods and traditional proportional representation methods by 0.015 F-measure.},
address = {Daejeon, Republic of Korea},
author = {Ohtake, Tomohiro and Cummaudo, Alex and Abdelrazek, Mohamed and Vasa, Rajesh and Grundy, John},
booktitle = {Proceedings of the 19th International Conference on Web Engineering},
doi = {10.1007/978-3-030-19274-7\_28},
isbn = {978-3-03-019273-0},
issn = {1611-3349},
keywords = {Application programming interfaces,Artificial intelligence,Data integration,Supervised learning,Web services},
month = {jun},
pages = {391--406},
publisher = {Springer},
title = {{Merging intelligent API responses using a proportional representation approach}},
year = {2019}
}
@article{Tristan2014,
abstract = {Implementing inference procedures for each new probabilistic model is time-consuming and error-prone. Probabilistic programming addresses this problem by allowing a user to specify the model and then automatically generating the inference procedure. To make this practical it is important to generate high per-formance inference code. In turn, on modern architectures, high performance re-quires parallel execution. In this paper we present Augur, a probabilistic modeling language and compiler for Bayesian networks designed to make effective use of data-parallel architectures such as GPUs. We show that the compiler can generate data-parallel inference code scalable to thousands of GPU cores by making use of the conditional independence relationships in the Bayesian network.},
author = {Tristan, JB and Huang, Daniel},
file = {::},
journal = {Advances in Neural {\ldots}},
pages = {1--9},
title = {{Augur: Data-Parallel Probabilistic Modeling}},
url = {http://papers.nips.cc/paper/5531-augur-data-parallel-probabilistic-modeling},
year = {2014}
}
@article{Dix2017,
abstract = {Many find statistics confusing, and perhaps more so given recent publicity of problems with traditional pvalues and alternative statistical techniques including confidence intervals and Bayesian statistics. This course aims to help attendees navigate this morass: to understand the debates and more importantly make appropriate choices when designing and analysing experiments, empirical studies and other forms of quantitative data.},
author = {Dix, Alan},
doi = {10.1145/3027063.3027109},
file = {::},
isbn = {9781450346566},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Bayesian statistics,Evaluation, hypothesis testing,Human-computer interaction,Statistics},
pages = {1236--1239},
title = {{Making sense of statistics in HCI: From P to Bayes and beyond}},
volume = {Part F1276},
year = {2017}
}
@inproceedings{leff2001web,
author = {Leff, Avraham and Rayfield, James T},
booktitle = {Proceedings fifth ieee international enterprise distributed object computing conference},
organization = {IEEE},
pages = {118--127},
title = {{Web-application development using the model/view/controller design pattern}},
year = {2001}
}
@article{Seo2014,
abstract = {Building is an integral part of the software development process. However, little is known about the compiler errors that occur in this process. In this paper, we present an empirical study of 26.6 million builds produced during a period of nine months by thousands of developers. We describe the workflow through which those builds are generated, and we analyze failure frequency, compiler error types, and resolution efforts to fix those compiler errors. The results provide insights on how a largeorganization build process works, and pinpoints errors for which further developer support would be most effective.},
author = {Seo, Hyunmin and Sadowski, Caitlin and Elbaum, Sebastian and Aftandilian, Edward and Bowdidge, Robert},
doi = {10.1145/2568225.2568255},
file = {::},
isbn = {9781450327565},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
keywords = {Software builds,build errors,empirical analysis},
number = {1},
pages = {724--734},
title = {{Programmers' build errors: A case study (at google)}},
year = {2014}
}
@article{Colusso2019,
abstract = {Using scientific discoveries to inform design practice is an important, but difficult, objective in HCI. In this paper, we provide an overview of Translational Science in HCI by triangulating literature related to the research-practice gap with interview data from many parties engaged (or not) in translating HCI knowledge. We propose a model for Translational Science in HCI based on the concept of a continuum to describe how knowledge progresses (or stalls) through multiple steps and translations until it can influence design practice. The model offers a conceptual framework that can be used by researchers and practitioners to visualize and describe the progression of HCI knowledge through a sequence of translations. Additionally, the model may facilitate a precise identification of translational barriers, which allows devising more effective strategies to increase the use of scientific findings in design practice.},
author = {Colusso, Lucas and Munson, Sean A. and Jones, Ridley and Hsieh, Gary},
doi = {10.1145/3290605.3300231},
file = {::},
isbn = {9781450359702},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Research-practice gap,Translational research,Translational science},
pages = {1--13},
title = {{A translational science model for HCI}},
year = {2019}
}
@inproceedings{Markovtsev2019,
author = {Markovtsev, Vadim and Long, Waren and Mougard, Hugo and Slavnov, Konstantin and Bulychev, Egor},
booktitle = {2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)},
doi = {10.1109/MSR.2019.00073},
file = {::},
isbn = {978-1-7281-3412-3},
month = {may},
pages = {468--478},
publisher = {IEEE},
title = {{Style-Analyzer: Fixing Code Style Inconsistencies with Interpretable Unsupervised Algorithms}},
url = {https://2019.msrconf.org/details/msr-2019-papers/45/style-analyzer-fixing-code-style-inconsistencies-with-interpretable-unsupervised-alg},
year = {2019}
}
@article{Myers2018,
author = {Myers, Kenneth A. and Sivathamboo, Shobi and Perucca, Piero},
doi = {10.1111/epi.14587},
file = {::},
issn = {00139580},
journal = {Epilepsia},
keywords = {autonomic,epilepsy,heart rate variability,sudden unexpected death in epilepsy,sympathetic},
month = {dec},
number = {12},
pages = {2169--2178},
publisher = {John Wiley {\&} Sons, Ltd (10.1111)},
title = {{Heart rate variability measurement in epilepsy: How can we move from research to clinical practice?}},
url = {http://doi.wiley.com/10.1111/epi.14587},
volume = {59},
year = {2018}
}
@article{Saez2016,
abstract = {Canonical machine learning algorithms assume that the number of objects in the considered classes are roughly similar. However, in many real-life situations the distribution of examples is skewed since the examples of some of the classes appear much more frequently. This poses a difficulty to learning algorithms, as they will be biased towards the majority classes. In recent years many solutions have been proposed to tackle imbalanced classification, yet they mainly concentrate on binary scenarios. Multi-class imbalanced problems are far more difficult as the relationships between the classes are no longer straightforward. Additionally, one should analyze not only the imbalance ratio but also the characteristics of the objects within each class. In this paper we present a study on oversampling for multi-class imbalanced datasets that focuses on the analysis of the class characteristics. We detect subsets of specific examples in each class and fix the oversampling for each of them independently. Thus, we are able to use information about the class structure and boost the more difficult and important objects. We carry an extensive experimental analysis, which is backed-up with statistical analysis, in order to check when the preprocessing of some types of examples within a class may improve the indiscriminate preprocessing of all the examples in all the classes. The results obtained show that oversampling concrete types of examples may lead to a significant improvement over standard multi-class preprocessing that do not consider the importance of example types.},
annote = {Defines the following challenges for class imbalance:
- Safe examples
- Borderline examples
- Rare examples
- Outliers (sometimes Noisy)


One idea from this paper is to extend the work based on the types of false classifiers in the data.},
author = {S{\'{a}}ez, Jos{\'{e}} A. and Krawczyk, Bartosz and Wo{\'{z}}niak, Micha{\l}},
doi = {10.1016/j.patcog.2016.03.012},
file = {::},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Imbalanced classification,Machine learning,Minority class types,Multi-class imbalance,Oversampling},
pages = {164--178},
title = {{Analyzing the oversampling of different classes and types of examples in multi-class imbalanced datasets}},
volume = {57},
year = {2016}
}
@book{Bourque2004,
abstract = {The purpose of the Guide to the Software Engineering Body of Knowledge is to provide a validated classification of the bounds of the software engineering discipline and topical access that will support this discipline. The Body of Knowledge is subdivided into ten software engineering Knowledge Areas (KA) that differentiate among the various important concepts, allowing readers to find their way quickly to subjects of interest. Upon finding a subject, readers are referred to key papers or book chapters. Emphases on engineering practice lead the Guide toward a strong relationship with the normative literature. The normative literature is validated by consensus formed among practitioners and is concentrated in standards and related documents. The two major standards bodies for software engineering (IEEE Computer Society Software and Systems Engineering Standards Committee and ISO/IEC JTC1/SC7) are represented in the project. The Guide is oriented toward a variety of audiences, all over the world. It aims to serve public and private organizations in need of a consistent view of software engineering for defining education and training requirements, classifying jobs, developing performance evaluation policies or specifying software development tasks. It also addresses practicing, or managing, software engineers and the officials responsible for making public policy regarding licensing and professional guidelines. In addition, professional societies and educators defining the certification rules, accreditation policies for university curricula, and guidelines for professional practice will benefit from the SWEBOK Guide, as well as the students learning the software engineering profession and educators and trainers engaged in defining curricula and course content. It is hoped that readers will find this book useful in guiding them toward the knowledge and resources they need in their lifelong career development as software engineering professionals. The current Guide marks the end of the Ironman period by providing a Guide that has achieved consensus through broad review and trial application. The overall goal of the current revision is to improve the readability, consistency, and usability of the Guide. In several cases, the topical breakdown of a KA was rearranged to make it more usable. The reference list is updated so that it will be easier to obtain the references. Trial usage resulted in the recommendation that three KAs should be rewritten. Finally, some KAs were revised to remove material duplicating that of other KAs.},
author = {Bourque, P and Dupuis, R},
booktitle = {SWEBOK 2004 Guide to the Software Engineering Body of Knowledge},
doi = {10.1109/SESS.1999.767664},
file = {::},
isbn = {0769523307},
issn = {07407459},
number = {1},
pages = {204},
pmid = {13861254},
title = {{Guide to the Software Engineering Body of Knowledge 2004 Version}},
url = {http://www.computer.org/portal/web/swebok/html/copyright},
volume = {1},
year = {2004}
}
@article{Malloy2019,
abstract = {Python is one of the most popular and widely adopted programming languages in use today. In 2008 the Python developers introduced a new version of the language, Python 3.0, that was not backward compatible with Python 2, initiating a transitional phase for Python software developers. In this paper, we describe a study that investigates the degree to which Python software developers are making the transition from Python 2 to Python 3. We have developed a Python compliance analyser, PyComply, and have analysed a previously studied corpus of Python applications called Qualitas. We use PyComply to measure and quantify the degree to which Python 3 features are being used, as well as the rate and context of their adoption in the Qualitas corpus. Our results indicate that Python software developers are not exploiting the new features and advantages of Python 3, but rather are choosing to retain backward compatibility with Python 2. Moreover, Python developers are confining themselves to a language subset, governed by the diminishing intersection of Python 2, which is not under development, and Python 3, which is under development with new features being introduced as the language continues to evolve.},
author = {Malloy, Brian A. and Power, James F.},
doi = {10.1007/s10664-018-9637-2},
file = {::},
isbn = {1066401896},
issn = {15737616},
journal = {Empirical Software Engineering},
keywords = {Compliance,Programming language evolution,Python programming},
number = {2},
pages = {751--778},
publisher = {Empirical Software Engineering},
title = {{An empirical analysis of the transition from Python 2 to Python 3}},
volume = {24},
year = {2019}
}
@misc{Song2018,
abstract = {IEEE Context: Software defect prediction (SDP) is an important challenge in the field of software engineering, hence much research work has been conducted, most notably through the use of machine learning algorithms. However, class-imbalance typified by few defective components and many non-defective ones is a common occurrence causing difficulties for these methods. Imbalanced learning aims to deal with this problem and has recently been deployed by some researchers, unfortunately with inconsistent results.},
annote = {Application to software defects

Journal, 27 data sets, 7 classifiers, 7 types of input metrics and 17 imbalancedlearning methods 

Uses Weka as the programming framework

Structure:
- Intro
- Related work
- Method
- Measures
- Algorithm Evaluation
- Statistical Methods
- Software Metrics
- Data Sets
- Experimental Results and analysis
- RQs
- Threats to Validity


It's the effect size, stupid: What effect size is and why it is important,

Dominance statistics: Ordinal analyses to answer ordinal questions

Ordinal analysis of behavioral data

Social sciences and Psychology have a lot of stats based work.},
author = {Song, Qinbao and Guo, Yuchen and Shepperd, Martin},
booktitle = {IEEE Transactions on Software Engineering},
doi = {10.1109/TSE.2018.2836442},
file = {::},
issn = {00985589},
keywords = {Bagging,Boosting,Computer bugs,Machine learning algorithms,Measurement,Software,Software defect prediction,bug prediction,effect size,imbalance ratio,imbalanced learning},
title = {{A Comprehensive Investigation of the Role of Imbalanced Learning for Software Defect Prediction}},
year = {2018}
}
@article{Manski2019,
abstract = {A central objective of empirical research on treatment response is to inform treatment choice. Unfortunately, researchers commonly use concepts of statistical inference whose foundations are distant from the problem of treatment choice. It has been particularly common to use hypothesis tests to compare treatments. Wald's development of statistical decision theory provides a coherent frequentist framework for use of sample data on treatment response to make treatment decisions. A body of recent research applies statistical decision theory to characterize uniformly satisfactory treatment choices, in the sense of maximum loss relative to optimal decisions (also known as maximum regret). This article describes the basic ideas and findings, which provide an appealing practical alternative to use of hypothesis tests. For simplicity, the article focuses on medical treatment with evidence from classical randomized clinical trials. The ideas apply generally, encompassing use of observational data and treatment choice in nonmedical contexts.},
author = {Manski, Charles F.},
doi = {10.1080/00031305.2018.1513377},
file = {::},
issn = {15372731},
journal = {American Statistician},
keywords = {Analysis of treatment response,Medical decisions,Minimax regret,Randomized clinical trials},
number = {sup1},
pages = {296--304},
title = {{Treatment Choice With Trial Data: Statistical Decision Theory Should Supplant Hypothesis Testing}},
volume = {73},
year = {2019}
}
@article{Albert2012,
abstract = {We consider the problem of combining opinions from different ex- perts in an explicitly model-based way to construct a valid subjective prior in a Bayesian statistical approach. We propose a generic approach by considering a hierarchical model accounting for various sources of variation as well as account- ing for potential dependence between experts. We apply this approach to two problems. The first problem deals with a food risk assessment problem involving modelling dose-response for Listeria monocytogenes contamination of mice. Two hierarchical levels of variation are considered (between and within experts) with a complex mathematical situation due to the use of an indirect probit regression. The second concerns the time taken by PhD students to submit their thesis in a particular school. It illustrates a complex situation where three hierarchical levels of variation are modelled but with a simpler underlying probability distribution (log-Normal).},
author = {Albert, Isabelle and Donnet, Sophie and Guihenneuc-Jouyaux, Chantal and Low-Choy, Samantha and Mengersen, Kerrie and Rousseau, Judith},
doi = {10.1214/12-BA717},
file = {::},
issn = {19360975},
journal = {Bayesian Analysis},
keywords = {Bayesian statistics,Hierarchical model,Random effects,Risk assessment},
number = {3},
pages = {503--532},
title = {{Combining expert opinions in prior elicitation}},
volume = {7},
year = {2012}
}
@article{Das2018,
abstract = {Most of the traditional pattern classifiers assume their input data to be well-behaved in terms of similar underlying class distributions, balanced size of classes, the presence of a full set of observed features in all data instances, etc. Practical datasets, however, show up with various forms of irregularities that are, very often, sufficient to confuse a classifier, thus degrading its ability to learn from the data. In this article, we provide a bird's eye view of such data irregularities, beginning with a taxonomy and characterization of various distribution-based and feature-based irregularities. Subsequently, we discuss the notable and recent approaches that have been taken to make the existing stand-alone as well as ensemble classifiers robust against such irregularities. We also discuss the interrelation and co-occurrences of the data irregularities including class imbalance, small disjuncts, class skew, missing features, and absent (non-existing or undefined) features. Finally, we uncover a number of interesting future research avenues that are equally contextual with respect to the regular as well as deep machine learning paradigms.},
annote = {Contains a list of future research directions that are well worth looking over again at some point.

Defines: Missing features and Absent features

small disjuncts - sub clusters inside the main clusters

class distribution skew - difficult to visualise when there are more than 3 dimensions 


Solutions:
Data Level
- Undersampling
- Oversampling
- Hybrid

Algorithm Level
- Cost sensitive learning
- Boundary shifting methods
- Single class learning
- Active learning
- Kernel perturbation techniques
- Discriminative regression based supervised learning models},
author = {Das, Swagatam and Datta, Shounak and Chaudhuri, Bidyut B.},
doi = {10.1016/j.patcog.2018.03.008},
file = {::},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Absent features,Class imbalance,Class-distribution skew,Data irregularities,Missing features,Small disjuncts},
number = {June},
pages = {674--693},
title = {{Handling data irregularities in classification: Foundations, trends, and future challenges}},
volume = {81},
year = {2018}
}
@article{Olsen2019,
author = {Olsen, Megan and Raunak, Mohammad},
doi = {10.1109/TR.2018.2850315},
file = {::},
issn = {00189529},
journal = {IEEE Transactions on Reliability},
keywords = {Agent-based models (ABM),Discrete-event simulation (DES),Metamorphic testing (MT),Simulation validation},
number = {1},
pages = {91--108},
publisher = {IEEE},
title = {{Increasing validity of simulation models through metamorphic testing}},
volume = {68},
year = {2019}
}
@article{Wang2016,
abstract = {—Deep learning has become increasingly popular in both academic and industrial areas in the past years. Various domains including pattern recognition, computer vision, and natural language processing have witnessed the great power of deep networks. However, current studies on deep learning mainly focus on data sets with balanced class labels, while its performance on imbalanced data is not well examined. Imbalanced data sets exist widely in real world and they have been providing great challenges for classification tasks. In this paper, we focus on the problem of classification using deep network on imbalanced data sets. Specifically, a novel loss function called mean false error together with its improved version mean squared false error are proposed for the training of deep networks on imbalanced data sets. The proposed method can effectively capture classification errors from both majority class and minority class equally. Experiments and comparisons demonstrate the superiority of the proposed approach compared with conventional methods in classifying imbalanced data sets on deep neural networks.},
author = {Wang, Shoujin and Liu, Wei and Wu, Jia and Cao, Longbing and Meng, Qinxue and Kennedy, Paul J.},
doi = {10.1109/IJCNN.2016.7727770},
file = {::},
isbn = {9781509006199},
journal = {Proceedings of the International Joint Conference on Neural Networks},
keywords = {Data imbalance,Deep neural network,Loss function},
pages = {4368--4374},
title = {{Training deep neural networks on imbalanced data sets}},
volume = {2016-Octob},
year = {2016}
}
@article{Breck2019,
annote = {Training and serving data - production asset

Data Validation System (three components) - Data Analyzer, Data Validator (through schema), Model Unit Tester

Types of Data Validation - Single batch validation, inter batch validation, model testing

Single batch validation - Are there data errors within each new batch that is ingested by the pipeline ?
Any deviation from the expected characteristics, given expert domain knowledge - anomaly

Any disagreement during schema validation is flagged as an anomaly.
Data Validator - to avoid training on bad data
- Each anomaly corresponds to a validation of some property specified in the schema

Inter batch validation - There are certain anomalies that only manifest when two or more batches of data are considered together

Training-serving skew - skew between training and serving data , reasons - different code paths to generate training(offline) and serving(online) data

Three categories of skew - Feature skew (changes to training code not reflected on serving code), Distribution skew (during sampling), scoring/serving skew(only subset of scored examples are actually served)

Time saving - by catching important data anomalies early, by helping teams to diagnose model-quality problems caused by data errors

Anomalies are categorised
Changing data type of a feature (from string to int) is a serious anomaly

Feature presence - some features are expected to be present in all examples, others present only in a fraction

Feature domains - Many features assume values only from a limited domain

Feature value count - Features can be single valued/list},
author = {Breck, Eric and Polyzotis, Neoklis and Roy, Sudip and Whang, Steven Euijong and Zinkevich, Martin},
file = {::},
journal = {Sysml},
title = {{DATA VALIDATION FOR MACHINE LEARNING Eric}},
year = {2019}
}
@article{Gharehyazie2017,
abstract = {{\textcopyright} 2017 IEEE. Code reuse has well-known benefits on code quality, coding efficiency, and maintenance. Open Source Software (OSS) programmers gladly share their own code and they happily reuse others'. Social programming platforms like GitHub have normalized code foraging via their common platforms, enabling code search and reuse across different projects. Removing project borders may facilitate more efficient code foraging, and consequently faster programming. But looking for code across projects takes longer and, once found, may be more challenging to tailor to one's needs. Learning how much code reuse goes on across projects, and identifying emerging patterns in past cross-project search behavior may help future foraging efforts. To understand cross-project code reuse, here we present an in-depth study of cloning in GitHub. Using Deckard, a clone finding tool, we identified copies of code fragments across projects, and investigate their prevalence and characteristics using statistical and network science approaches, and with multiple case studies. By triangulating findings from different methods, we find that cross-project cloning is prevalent in GitHub, ranging from cloning few lines of code to whole project repositories. Some of the projects serve as popular sources of clones, and others seem to contain more clones than their fair share. Moreover, we find that ecosystem cloning follows an onion model: most clones come from the same project, then from projects in the same application domain, and finally from projects in different domains. Our results show directions for new tools that can facilitate code foraging and sharing within GitHub.},
author = {Gharehyazie, Mohammad and Ray, Baishakhi and Filkov, Vladimir},
doi = {10.1109/MSR.2017.15},
file = {::},
isbn = {9781538615447},
issn = {21601860},
journal = {IEEE International Working Conference on Mining Software Repositories},
keywords = {Code reuse,Cross-project clones,GitHub},
pages = {291--301},
title = {{Some from Here, Some from There: Cross-Project Code Reuse in GitHub}},
year = {2017}
}
@article{Kristiansen2012,
author = {Kristiansen, Simon and Stidsen, Thomas R},
file = {::},
journal = {Proceedings of the Ninth International Conference on the Practice and Theory of Automated Timetabling (PATAT 2012)},
keywords = {2000,90-08,90b35,90c10,90c59,adaptive large neighborhood,educational timetabling,elective course planning,high school planning,mathematics subject classi cation,metaheuristics,search,student sectioning},
number = {August},
pages = {29--31},
title = {{Adaptive large neighborhood search for student sectioning at Danish high schools}},
year = {2012}
}
@article{Ralph2019,
abstract = {Software engineering is increasingly concerned with theory because the foundational knowledge comprising theories provides a crucial counterpoint to the practical knowledge expressed through methods and techniques. Fortunately, much guidance is available for generating and evaluating theories for explaining why things happen (variance theories). Unfortunately, little guidance is available concerning theories for explaining how things happen (process theories), or theories for analyzing and understanding situations (taxonomies). This paper therefore attempts to clarify the nature and functions of process theories and taxonomies in software engineering research, and to synthesize methodological guidelines for their generation and evaluation. It further advances the key insight that most process theories are taxonomies with additional propositions, which helps inform their evaluation. The proposed methodological guidance has many benefits: it provides a concise summary of existing guidance from reference disciplines, it adapts techniques from reference disciplines to the software engineering context, and it promotes approaches that better facilitate scientific consensus.},
author = {Ralph, Paul},
doi = {10.1109/TSE.2018.2796554},
file = {::},
issn = {19393520},
journal = {IEEE Transactions on Software Engineering},
keywords = {Research methodology,action research,case study,experiment,framework,grounded theory,guidelines,model,process theory,questionnaire,taxonomy,theory for analysis,theory for understanding},
number = {7},
pages = {712--735},
publisher = {IEEE},
title = {{Toward Methodological Guidelines for Process Theories and Taxonomies in Software Engineering}},
volume = {45},
year = {2019}
}
@inproceedings{Gelman2018,
abstract = {Code search and comprehension have become more difficult in recent years due to the rapid expansion of available source code. Current tools lack a way to label arbitrary code at scale while maintaining up-to-date representations of new programming languages, libraries, and functionalities. Comprehensive labeling of source code enables users to search for documents of interest and obtain a high-level understanding of their contents. We use Stack Overflow code snippets and their tags to train a language-agnostic, deep convolutional neural network to automatically predict semantic labels for source code documents. On Stack Overflow code snippets, we demonstrate a mean area under ROC of 0.957 over a long-tailed list of 4,508 tags. We also manually validate the model outputs on a diverse set of unlabeled source code documents retrieved from Github, and we obtain a top-1 accuracy of 86.6{\%}. This strongly indicates that the model successfully transfers its knowledge from Stack Overflow snippets to arbitrary source code documents.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1906.01032},
author = {Gelman, Ben and Hoyle, Bryan and Moore, Jessica and Saxe, Joshua and Slater, David},
booktitle = {Proceedings of the 1st International Workshop on Machine Learning and Software Engineering in Symbiosis - MASES 2018},
doi = {10.1145/3243127.3243132},
eprint = {1906.01032},
file = {::},
isbn = {9781450359726},
keywords = {acm reference format,classification,crowdsourcing,deep learning,multilabel,natural language processing,semantic labeling,source code},
pages = {36--44},
publisher = {ACM Press},
title = {{A Language-Agnostic Model for Semantic Source Code Labeling}},
url = {http://arxiv.org/abs/1906.01032{\%}0Ahttp://dx.doi.org/10.1145/3243127.3243132},
year = {2018}
}
@article{Hong2019,
abstract = {This study employs an experiment to test subjects' perceptions of an artificial intelligence (AI) crime-predicting agent that produces clearly racist predictions. It used a 2 (human crime predictor/AI crime predictor) x 2 (high/low seriousness of crime) design to test the relationship between the level of autonomy and responsibility for the unjust results. The seriousness of crime was manipulated to examine the relationship between the perceived threat and trust in the authority's decisions. Participants (N = 334) responded to an online questionnaire after reading one of four scenarios with the same story depicting a crime predictor unjustly reporting a higher likelihood of subsequent crimes for a black defendant than for a white defendant for similar crimes. The results indicate that people think that an AI crime predictor has significantly less autonomy than a human crime predictor. However, both the identity of the crime predictor and the seriousness of the crime showed insignificant results on the level of responsibility assigned to the predictor. Also, a clear positive relationship between autonomy and responsibility was found in both human and AI crime predictor scenarios. The implications of the findings for applications and theory are discussed.},
author = {Hong, Joo Wha and Williams, Dmitri},
doi = {10.1016/j.chb.2019.06.012},
file = {::},
issn = {07475632},
journal = {Computers in Human Behavior},
keywords = {Artificial intelligence,Attribution theory,CASA,Human-AI Communication,Predictive policing,Racism},
number = {February},
pages = {79--84},
publisher = {Elsevier},
title = {{Racism, responsibility and autonomy in HCI: Testing perceptions of an AI agent}},
url = {https://doi.org/10.1016/j.chb.2019.06.012},
volume = {100},
year = {2019}
}
@inproceedings{SriramSrinivasan2018,
address = {San Jose},
author = {{Sriram Srinivasan}},
booktitle = {DataWorks Summit},
title = {{Applying Software engineering practices for the data science and machine learning lifecycle}},
url = {https://www.slideshare.net/Hadoop{\_}Summit/software-engineering-practices-for-the-data-science-and-machine-learning-lifecycle},
year = {2018}
}
@book{IEEEComputerSociety2013,
abstract = {A recommended practice for applying the Distributed Simulation Engineering and Execution Process (DSEEP) to the development and execution of distributed simulation environments that include more than one distributed simulation architecture is described. The distributed simulation architectures to which the recommended practice applies include Distributed Interactive Simulation (DIS), High Level Architecture (HLA), and Test and Training Enabling Architecture (TENA). The DSEEP Multi-Architecture Overlay (DMAO) identifies and describes multi-architecture issues and provides recommended actions for simulation environment developers faced with those issues. The DMAO also augments the DSEEP lists of inputs, recommended tasks, and outcomes with additional inputs, recommended tasks, and outcomes that apply to multi-architecture simulation environments. This document is an overlay to the DSEEP, which is a separate recommended practice.},
author = {{IEEE Computer Society}},
booktitle = {Ieee Standard 1730.1-2013},
doi = {10.1109/IEEESTD.2013.6654219},
file = {::},
isbn = {9780738164687},
number = {January},
title = {{IEEE Recommended Practice for Distributed Simulation Engineering and Execution Process Multi-Architecture Overlay (DMAO)}},
url = {http://ieeexplore.ieee.org/servlet/opac?punumber=6654217},
volume = {2013},
year = {2013}
}
@incollection{Dragicevic2016,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
author = {Dragicevic, Pierre},
booktitle = {Modern Statistical Methods for HCI},
doi = {10.1007/978-3-319-26633-6_13},
file = {::},
isbn = {9783319266336},
pages = {291--330},
publisher = {Springer},
title = {{Fair Statistical Communication in HCI}},
year = {2016}
}
@inproceedings{posnett2011simpler,
author = {Posnett, Daryl and Hindle, Abram and Devanbu, Premkumar},
booktitle = {Proceedings of the 8th working conference on mining software repositories},
pages = {73--82},
title = {{A simpler model of software readability}},
year = {2011}
}
@article{Cai2013,
abstract = {An application of dynamic Bayesian networks for quantitative risk assessment of human factors on offshore blowouts is presented. Human error is described using human factor barrier failure (HFBF), which consists of three categories of factors, including individual factor barrier failure (IFBF), organizational factor barrier failure (OFBF) and group factor barrier failure (GFBF). The structure of human factors is illustrated using pseudo-fault tree, which is defined by incorporating the intermediate options into fault tree in order to eliminate the binary restriction. A methodology of translating pseudo-fault tree into Bayesian networks and dynamic Bayesian networks taking repair into consideration is proposed and the propagation is performed. The results show that the human factor barrier failure probability only increases within the first two weeks and rapidly reaches a stable level when the repair is considered, whereas it increases continuously when the repair action is not considered. The results of mutual information show that the important degree sequences for the three categories of human factors on HFBF are: GFBF, OFBF and IFBF. In addition, each individual human factor contributes different to the HFBF, those which contribute much should given more attention in order to improve the human reliability and prevent the potential accident occurring. {\textcopyright} 2013 Elsevier Ltd.},
author = {Cai, Baoping and Liu, Yonghong and Zhang, Yunwei and Fan, Qian and Liu, Zengkai and Tian, Xiaojie},
doi = {10.1016/j.jlp.2013.01.001},
file = {::},
issn = {09504230},
journal = {Journal of Loss Prevention in the Process Industries},
keywords = {Dynamic Bayesian networks,Human factors,Offshore blowouts,Quantitative risk assessment},
number = {4},
pages = {639--649},
publisher = {Elsevier Ltd},
title = {{A dynamic Bayesian networks modeling of human factors on offshore blowouts}},
url = {http://dx.doi.org/10.1016/j.jlp.2013.01.001},
volume = {26},
year = {2013}
}
@article{Beelders2016,
abstract = {Syntax highlighting or syntax colouring, plays a vital role in programming development environments by colour-coding various code elements differently. The supposition is that this syntax highlighting assists programmers when reading and analysing code. However, academic text books are largely only available in black-and-white which could influence the comprehension of novice and beginner programmers. This study investigated whether student programmers experience more difficulty in reading and comprehending source code when it is presented without syntax highlighting. Number of fixations, fixation durations and regressions were all higher for black-and-white code than for colour code but not significantly so. Subjectively students indicated that the colour code snippets were easier to read and more aesthetically pleasing. Based on the analysis it could be concluded that students do not experience significantly more difficulty when reading code in black-and-white as printed in text books.},
author = {Beelders, T. R. and {Du Plessis}, Jean Pierre L.},
doi = {10.16910/jemr.9.1.1},
file = {::},
issn = {19958692},
journal = {Journal of Eye Movement Research},
keywords = {Code comprehension,Eye-tracking,Reading behaviour,Syntax highlighting},
number = {1},
pages = {2207--2219},
title = {{Syntax highlighting as an influencing factor when reading and comprehending source code}},
volume = {9},
year = {2016}
}
@article{Papamichail2020,
author = {Papamichail, Aggelos and Zarras, Apostolos V. and Vassiliadis, Panos},
doi = {10.1007/978-3-030-38919-2_35},
file = {::},
isbn = {9783030389185},
issn = {16113349},
keywords = {coding styles,naming conventions,sql programming},
pages = {429--440},
title = {{Do People Use Naming Conventions in SQL Programming?}},
year = {2020}
}
@article{Abdi2016,
abstract = {Class imbalance problem is quite pervasive in our nowadays human practice. This problem basically refers to the skewness in the data underlying distribution which, in turn, imposes many difficulties on typical machine learning algorithms. To deal with the emerging issues arising from multi-class skewed distributions, existing efforts are mainly divided into two categories: model-oriented solutions and data-oriented techniques. Focusing on the latter, this paper presents a new over-sampling technique which is inspired by Mahalanobis distance. The presented over-sampling technique, called MDO (Mahalanobis Distance-based Over-sampling technique), generates synthetic samples which have the same Mahalanobis distance from the considered class mean as other minority class examples. By preserving the covariance structure of the minority class instances and intelligently generating synthetic samples along the probability contours, new minority class instances are modelled better for learning algorithms. Moreover, MDO can reduce the risk of overlapping between different class regions which are considered as a serious challenge in multi-class problems. Our theoretical analyses and empirical observations across wide spectrum multi-class imbalanced benchmarks indicate that MDO is the method of choice by offering statistical superior MAUC and precision compared to the popular over-sampling techniques},
annote = {Journal: 20 multi-clas benchmark data sets 

Also uses Weka.

Not good on high dimensions because it takes a long time to run. They recommend looking at feature reduction techniques i.e. PCA},
author = {Abdi, Lida and Hashemi, Sattar},
doi = {10.1109/TKDE.2015.2458858},
file = {::},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Mahalanobis distance,Multi-class imbalance problems,over-sampling techniques},
number = {1},
pages = {238--251},
publisher = {IEEE},
title = {{To Combat Multi-Class Imbalanced Problems by Means of Over-Sampling Techniques}},
volume = {28},
year = {2016}
}
@inproceedings{Renzella2020,
abstract = {Introductory programming is challenging for many students, requiring them to engage with a deep approach to learning concepts in order to succeed. These challenges compound for online students who do not have direct face-to-face interactions with teaching staff. With the growing demand for online education, we need to examine approaches that assist in building supportive learning environments for these students. A growing body of work from other education disciplines indicates that audio feedback provides an opportunity for developing stronger relationships with students. Further studies recommend an integrated implementation of audio recording into the virtual learning environment. To evaluate audio feedback for use in programming education, we developed an integrated, cross-browser audio feedback feature into the open-source Doubt-fire learning management system. Doubtfire is used to support and scale a task-oriented teaching and learning system built upon the principles of constructive alignment and has been shown to help students engage with programming concepts in campus-only units. Our findings from experimental and observational activities indicate that programming tutors can use a blended approach of audio and text feedback via the learning management system to better support student learning. The richer, more nuanced feedback delivery communicates personality to students while retaining the benefits of written feedback for code-specific issues. CCS CONCEPTS • Applied computing → Learning management systems; Distance learning; E-learning; • Human-centered computing → Human computer interaction (HCI).},
address = {Seoul, Republic of Korea},
author = {Renzella, Jake and Cain, Andrew},
booktitle = {Proceedings of the 42nd International Conference on Software Engineering},
doi = {10.1145/3377814.3381712},
file = {::},
isbn = {9781450371247},
keywords = {Learning management system,audio feedback,forma-tive feedback,introductory programming,online students ACM Reference Format: Jake Renzell},
title = {{Enriching Programming Student Feedback with Audio Comments}},
year = {2020}
}
@article{Wang2018c,
abstract = {The training, maintenance, deployment, monitoring, organization and documentation of machine learning (ML) models – in short model management – is a critical task in virtually all production ML use
cases. Wrong model management decisions can lead to poor performance of a ML system and can result
in high maintenance cost. As both research on infrastructure as well as on algorithms is quickly evolving,
there is a lack of understanding of challenges and best practices for ML model management. Therefore,
this field is receiving increased attention in recent years, both from the data management as well as
from the ML community. In this paper, we discuss a selection of ML use cases, develop an overview
over conceptual, engineering, and data-processing related challenges arising in the management of the
corresponding ML models, and point out future research directions.},
annote = {ML Lifecycle is model development, training (training pipelines, trained models and live data), inference (prediction service and logic) and feedback to training, query and prediction from end user application

Model development stages are offline training data, data collection, cleaning and visualisation, feature engineering and model design and training and validation

Each stage (neural networks design, data managment, cluster management) demands different skills set.

Pervasive problems in ML are feature management, data provenance, pipeline reproducibility, low-latency serving, prediction monitoring
Facebook - FB Learner flow, Uber - Michelangelo, Google - TFX
Classical time series forecasting technique - ARIMA
Content moderation - offline training of models using manually labeled data
Automating model metadata tracking 
1. Managing the meta data - Who created the model at what time ? Which hyperparameters were used ? What feature transformations have been applied ?
2. Lineage - Which dataset was the model derived from ?
Which dataset was used for computing the evalution data ?

Model management challenges are conceptual challenges, data management challenges and engineering challenges

Conceptual challenges are ML model definition (To define the actual model to manage), model validation (To backtest the accuray of models, improvement might cause longer prediction times), decisions on model retraining, adversarial settings (understand the boundary conditions of the classifier)

Data management challenges are lack of declarative abstraction for the whole ML pipeline, querying model meta data

Engineering challenges are multi language code bases, heterogenous skill level of users, backward compatibility of trained models

Provenance - place of origin, prevasive - unwelcoming
ProvDB - a unified provenance, metadata management system, flexible and extensible ingestion mechanism, novel querying

Data Engineers, Data Scientists, Domain Experts

Evolution of Jupyter Notebook - targeting Data Scientists 
A holistic approach of conducting, auditing and continuously monitoring

ProvDB - developed under the umbrella of Datahub project, 'Schema later' approach
Caffe - a deep learning framework
Metadata - about accuracy and loss metrics for learned models
Cypher and Gremlin are query languages 
A version, identified by id is immutable in ProvDB
ProvDB two subsets - graph segmentation, graph summarization

Version -{\textgreater} artifact -{\textgreater} snapshot -{\textgreater} record
Artifacts - scripts, datasets, dervied results
Entities - Project artefacts (files, datasets, scripts)
Activities - System/user actions (train, git commit, cron jobs)
Agents - parties who are responsible for some activity (team member, system component)

Storing, querying and analyzing provenance graphs - versioned artifacts, evolving workflows, partial knowledge in collaboration


Raw Data -{\textgreater} Data Prep -{\textgreater} Training -{\textgreater} Deployment - cyclic steps of ML

ML Flow facilitates local execution and remote cluster deployment
ML Flow - Open source ML Platform, Works with any ML Library (Keras, Tensorflow, PyTorch), Programming Language, deploy tool

Three key components - MLflow Tracking (Experiment tracking), MLflow Projects(reproducible runs), MLflow models (model packaging)

MLflow tracking API supported in Azure Machine Learning
Leverage throughout all products, logging real time
Facebook(FBLearner), Uber(Michaelangelo), Google(Tensorflow)

ML application challenges - data versions, codes, tuning parameters

MLflow covers three key challenges - experimentation, reproducibility, model deployment
ML optimizes specific metric (eg - prediction accuracy)},
author = {Wang, Haixun and Gonzalez, Joseph and Li, Guoliang and Meliou, Alexandra},
file = {::},
number = {4},
pages = {5--13},
title = {{On Challenges in Machine Learning Model Management}},
url = {http://tab.computer.org/tcde/bull{\_}about.html.},
volume = {41},
year = {2018}
}
@article{Amodei2016,
annote = {AI is everywhere - medicine, science, transportation, privacy, security, fairness, economic, military
AI - robustness, risk sensitivity and safe exploration
AI Safety - supervised classification, reinforcement learning
Social impacts of AI and accidents in ML systems

Safety problems are where in the process things went wrong. 

Five broad categories of AI Safety research areas are avoiding side effects, avoiding reward hacking, scalable supervision, safe exploration and distributional shift. Having wrong objective function will cause negative side effects (Accomplishing some specific tasks), reward hacking(Designer admits some clever easy solution), scalable oversight(how to ensure safe behavior, even with limited access to the true objective function), safe exploration(negative/irrecoverable consequences that outweigh the long term value of exploration), robustness to distributional shift(how to avoid having ML systems make bad decisions)

A cleaning robot at office workspace is an illustrative example of AI Safety

Need for AI Safety - increasing promise of Reinforcement Learning (RL), trending more complex agents and environments and increasing autonomy in AI Systems

Avoiding negative side effects - many distruptive things, common sense constraints on the environment
Define an impact regularizer - formalize change to the environment, penalize state distance, choice of representation and distance metric
Learn a generalized impact regularizer
Penalize influence - not get into positions where there are side effects
Multi agent approaches - Inclusion of human agents in coperative inverse RL, reward autoencoder
Reward uncertainty - to avoid unanticipated side effects
Define a baseline policy around which changes are being considered

Avoiding reward hacking - Partially observed goals (Assumption on RL is that reward is directly experienced, but only partially observed), complicated systems, abstract rewards (hacking one dimensional space), Goodhart's Law(targeting highly correlated function to accomplish specific task), feedback loops(self-amplifying component), environmental embedding (human in the reward loop, giving the agent incentive)

Adversarial reward functions - exploit the problem with intension of high reward
Model lookahead - reward based on anticipated future states, not the current one
Adversarial blinding - blind a model to certain variables
Counterexample resistance - adversarial training
Trip wires - deliberate introduction of some plausible vulnerabilities 

Scalable oversight - semi-supervised RL, evaluation based on reward from all episodes, optimization based on limited reward samples

Safe exploration - destroy the agent or trap it in states it can't get out of it, cannot hard code all problems, reduce the need for domain specific engineering, optimise worst case performance, off policy estimation, inverse RL {\&} apprenticeship learning (Learning algorithm is provided with expert trajectories of near-optimal behavior)

Robustness to Distributional Change - recognize our own ignorance, trained on one distribution, deployed on different test distribution, limited by variance of the important estimate, covariate shift assumption (very strong and untestable), build a generative model for distribution(drawback - this is fragile), partially specified models with assumptions on some aspects of a distribution

Modeling distribution of errors of a model, assumption - errors are independent and gaussian distributed, a good example is speech systems},
archivePrefix = {arXiv},
arxivId = {arXiv:1606.06565v2},
author = {Amodei, Dario and Steinhardt, Jacob and Man, Dan and Christiano, Paul},
eprint = {arXiv:1606.06565v2},
file = {::},
pages = {1--29},
title = {{Concrete Problems in AI Safety}},
year = {2016}
}
@article{Wasserstein2019,
author = {Wasserstein, Ronald L. and Schirm, Allen L. and Lazar, Nicole A.},
doi = {10.1080/00031305.2019.1583913},
file = {::},
issn = {15372731},
journal = {American Statistician},
number = {sup1},
pages = {1--19},
title = {{Moving to a World Beyond “p {\textless} 0.05”}},
volume = {73},
year = {2019}
}
@article{Chandola2009,
abstract = {Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.},
author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
doi = {10.1145/1541880.1541882},
file = {::},
issn = {1557-7341},
journal = {ACM Computing Surveys},
keywords = {Anomaly detection,Outlier detection},
number = {3},
pages = {1--72},
title = {{Anomaly detection: A survey}},
volume = {41},
year = {2009}
}
@article{Liu2018,
abstract = {PhD thesis of l'Universit{\'{e}}Universit´Universit{\'{e}} Paris-Saclay Prepared at T ´ e{\'{i}} ecom ParisTech Doctoral school n • 580 Sciences et technologies de l'information et de la communication (STIC)},
author = {Liu, Wanyu "Abbie"},
file = {::},
journal = {Universit{\'{e}} Paris-Saclay},
title = {{Information theory as a unified tool for understanding and designing human-computer interaction}},
year = {2018}
}
@article{Raghuraman2019,
abstract = {The benefits of modeling the design to improve the quality and maintainability of software systems have long been advocated and recognized. Yet, the empirical evidence on this remains scarce. In this paper, we fill this gap by reporting on an empirical study of the relationship between UML modeling and software defect proneness in a large sample of open-source GitHub projects. Using statistical modeling, and controlling for confounding variables, we show that projects containing traces of UML models in their repositories experience, on average, a statistically minorly different number of software defects (as mined from their issue trackers) than projects without traces of UML models.},
author = {Raghuraman, Adithya and Ho-Quang, Truong and {V Chaudron Chalmers}, Michel R and Serebrenik, Alexander and Vasilescu, Bogdan},
file = {::},
journal = {16th International Conference on Mining Software Repositories},
keywords = {UML,open source software,software design,software quality},
title = {{Does UML Modeling Associate with Lower Defect Proneness?: A Preliminary Empirical Investigation}},
url = {https://pypi.org/project/langdetect/},
year = {2019}
}
@inproceedings{Cohen2018,
address = {New York, New York, USA},
author = {Cohen, Eldan and Consens, Mariano P.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories - MSR '18},
doi = {10.1145/3196398.3196436},
file = {::},
isbn = {9781450357166},
pages = {426--436},
publisher = {ACM Press},
title = {{Large-scale analysis of the co-commit patterns of the active developers in github's top repositories}},
url = {http://dl.acm.org/citation.cfm?doid=3196398.3196436},
year = {2018}
}
@article{Dulac-arnold,
archivePrefix = {arXiv},
arxivId = {arXiv:2003.11881v1},
author = {Dulac-arnold, Gabriel and Mar, L G and Li, Jerry},
eprint = {arXiv:2003.11881v1},
file = {::},
title = {{An empirical investigation of the challenges of real-world reinforcement learning}}
}
@article{Kiral-Kornek2018,
abstract = {Background: Seizure prediction can increase independence and allow preventative treatment for patients with epilepsy. We present a proof-of-concept for a seizure prediction system that is accurate, fully automated, patient-specific, and tunable to an individual's needs. Methods: Intracranial electroencephalography (iEEG) data of ten patients obtained from a seizure advisory system were analyzed as part of a pseudoprospective seizure prediction study. First, a deep learning classifier was trained to distinguish between preictal and interictal signals. Second, classifier performance was tested on held-out iEEG data from all patients and benchmarked against the performance of a random predictor. Third, the prediction system was tuned so sensitivity or time in warning could be prioritized by the patient. Finally, a demonstration of the feasibility of deployment of the prediction system onto an ultra-low power neuromorphic chip for autonomous operation on a wearable device is provided. Results: The prediction system achieved mean sensitivity of 69{\%} and mean time in warning of 27{\%}, significantly surpassing an equivalent random predictor for all patients by 42{\%}. Conclusion: This study demonstrates that deep learning in combination with neuromorphic hardware can provide the basis for a wearable, real-time, always-on, patient-specific seizure warning system with low power consumption and reliable long-term performance.},
author = {Kiral-Kornek, Isabell and Roy, Subhrajit and Nurse, Ewan and Mashford, Benjamin and Karoly, Philippa and Carroll, Thomas and Payne, Daniel and Saha, Susmita and Baldassano, Steven and O'Brien, Terence and Grayden, David and Cook, Mark and Freestone, Dean and Harrer, Stefan},
doi = {10.1016/j.ebiom.2017.11.032},
file = {::},
issn = {23523964},
journal = {EBioMedicine},
keywords = {Artificial intelligence,Deep neural networks,Epilepsy,Mobile medical devices,Precision medicine,Seizure prediction},
month = {jan},
pages = {103--111},
publisher = {Elsevier B.V.},
title = {{Epileptic Seizure Prediction Using Big Data and Deep Learning: Toward a Mobile System}},
volume = {27},
year = {2018}
}
@article{Nargesian2017,
abstract = {Feature engineering is the task of improving predictive modelling performance on a dataset by transforming its feature space. Existing approaches to automate this process rely on either transformed feature space exploration through evaluation-guided search, or explicit expansion of datasets with all transformed features followed by feature selection. Such approaches incur high computational costs in runtime and/or memory. We present a novel technique, called Learning Feature Engineering (LFE), for automating feature engineering in classification tasks. LFE is based on learning the effectiveness of applying a transformation (e.g., arithmetic or aggregate operators) on numerical features, from past feature engineering experiences. Given a new dataset, LFE recommends a set of useful transformations to be applied on features without relying on model evaluation or explicit feature expansion and selection. Using a collection of datasets, we train a set of neural networks, which aim at predicting the transformation that impacts classification performance positively. Our empirical results show that LFE outperforms other feature engineering approaches for an overwhelming majority (89{\%}) of the datasets from various sources while incurring a substantially lower computational cost.},
author = {Nargesian, Fatemeh and Samulowitz, Horst and Khurana, Udayan and Khalil, Elias B. and Turaga, Deepak},
doi = {10.24963/ijcai.2017/352},
file = {::},
isbn = {9780999241103},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {Classification,Feature Selection/Construction,Machine Learning},
number = {August},
pages = {2529--2535},
title = {{Learning feature engineering for classification}},
year = {2017}
}
@article{Miller1995,
abstract = {This database links English nouns, verbs, adjectives, and adverbs to sets of synonims that are in turn link through semantic relations that determine word definitions.},
author = {Miller, George A.},
doi = {10.1145/219717.219748},
file = {::},
isbn = {1558602720},
issn = {00010782},
journal = {Communications of the ACM},
number = {11},
pages = {39--41},
pmid = {17081734},
title = {{WordNet: a lexical database for English}},
url = {http://portal.acm.org/citation.cfm?doid=219717.219748},
volume = {38},
year = {1995}
}
@article{Wang2019,
abstract = {By bringing together code, text, and examples, Jupyter notebooks have become one of the most popular means to produce scientific results in a productive and reproducible way. As many of the notebook authors are experts in their scientific fields, but laymen with respect to software engineering, one may ask questions on the quality of notebooks and their code. In a preliminary study, we experimentally demonstrate that Jupyter notebooks are inundated with poor quality code, e.g., not respecting recommended coding practices, or containing unused variables and deprecated functions. Considering the education nature of Jupyter notebooks, these poor coding practices as well as the lacks of quality control might be propagated into the next generation of developers. Hence, we argue that there is a strong need to programmatically analyze Jupyter notebooks, calling on our community to pay more attention to the reliability of Jupyter notebooks.},
archivePrefix = {arXiv},
arxivId = {1906.05234},
author = {Wang, Jiawei and Li, Li and Zeller, Andreas},
eprint = {1906.05234},
file = {::},
number = {3},
title = {{Better Code, Better Sharing:On the Need of Analyzing Jupyter Notebooks}},
url = {http://arxiv.org/abs/1906.05234},
year = {2019}
}
@article{Vartak2018,
abstract = {Machine learning applications have become ubiquitous in a variety of domains. Powering each of these ML applications are one or more machine learning models that are used to make key decisions or compute key quantities. The life-cycle of an ML model starts with data processing, going on to feature engineering, model experimentation, deployment, and maintenance. We call the process of tracking a model across all phases of its life-cycle as model management. In this paper, we discuss the current need for model management and describe MODELDB, the first open-source model management system developed at MIT. We also discuss the changing landscape and growing challenges and opportunities in managing models.},
author = {Vartak, Manasi and Madden, Samuel},
file = {::},
journal = {Bulletin of the IEEE Computer Society Technical Committee on Data Engineering},
title = {{ModelDB : Opportunities and Challenges in Managing Machine Learning Models}},
url = {http://sites.computer.org/debull/A18dec/A18DEC-CD.pdf{\#}page=18},
year = {2018}
}
@article{zou2019does,
author = {Zou, Weiqin and Xuan, Jifeng and Xie, Xiaoyuan and Chen, Zhenyu and Xu, Baowen},
journal = {Empirical Software Engineering},
number = {6},
pages = {3871--3903},
publisher = {Springer},
title = {{How does code style inconsistency affect pull request integration? An exploratory study on 117 GitHub projects}},
volume = {24},
year = {2019}
}
@article{Regnesentral2017,
author = {Regnesentral, Norsk},
file = {::},
keywords = {Calibration,Forecast accuracy,Forecast evaluation,Probabilistic forecasting,Proper scoring rules,Reliability},
number = {October},
title = {{Verification : assessment of calibration and Note}},
year = {2017}
}
@article{Koenzen2020,
abstract = {Duplicating one's own code makes it faster to write software. This expediency is particularly valuable for users of computational notebooks. Duplication allows notebook users to quickly test hypotheses and iterate over data. In this paper, we explore how much, how and from where code duplication occurs in computational notebooks, and identify potential barriers to code reuse. Previous work in the area of computational notebooks describes developers' motivations for reuse and duplication but does not show how much reuse occurs or which barriers they face when reusing code. To address this gap, we first analyzed GitHub repositories for code duplicates contained in a repository's Jupyter notebooks, and then conducted an observational user study of code reuse, where participants solved specific tasks using notebooks. Our findings reveal that repositories in our sample have a mean self-duplication rate of 7.6{\%}. However, in our user study, few participants duplicated their own code, preferring to reuse code from online sources.},
annote = {Software engineering does not promote duplicating code. But, Jupyter notebook users take use of it as they do exploratory programming.

There's no mention that Jupyter notebook users are data scientists.

Researchers appreciate usage of modules, else unaware that where the code originates from.

Research focus on how much code is being reused and what barriers do they have.

The scope is restricted towards code cells only. (Similar to ours)

Trying to find relevant code snippets is a pain point for data scientist.},
archivePrefix = {arXiv},
arxivId = {2005.13709},
author = {Koenzen, Andreas and Ernst, Neil and Storey, Margaret-Anne},
eprint = {2005.13709},
file = {::},
isbn = {9781728169019},
title = {{Code Duplication and Reuse in Jupyter Notebooks}},
url = {http://arxiv.org/abs/2005.13709},
year = {2020}
}
@article{Hofmeister2019,
abstract = {Developers spend the majority of their time reading code, a process in which identifier names play a key role. Although many identifier naming styles exist, they often lack an empirical basis and it is not clear whether short or long identifier names facilitate comprehension. In this paper, we investigate the effect of different identifier naming styles (single letters, abbreviations, and words) on program comprehension. We conducted an experimental study with 72 professional C{\#} developers who had to locate defects in source code snippets. We used a within-subjects design, such that each developer worked with all three versions of identifier naming styles, and we measured the time it took them to find a defect. We found that word identifiers led to a 19{\%} increase in speed to find defects compared to meaningless single letters and abbreviations, but we did not find a difference between letters and abbreviations. The results of our study suggest that code is more difficult to comprehend when it contains only letters and abbreviations as identifier names. Words as identifier names facilitate program comprehension and may help to save costs and improve software quality.},
author = {Hofmeister, Johannes C. and Siegmund, Janet and Holt, Daniel V.},
doi = {10.1007/s10664-018-9621-x},
file = {::},
isbn = {1066401896},
issn = {15737616},
journal = {Empirical Software Engineering},
keywords = {Defect detection,Identifier names,Professional C{\#} developers,Program comprehension,Psychology,Software quality},
number = {1},
pages = {417--443},
publisher = {Empirical Software Engineering},
title = {{Shorter identifier names take longer to comprehend}},
volume = {24},
year = {2019}
}
@article{Weinman2011,
abstract = {This chapter describes a GPU-based implementation of a discriminative maximum entropy learning algorithm that can improve runtime on large datasets by a factor of over 200. A typical machine-learning algorithm creates a classification function that inductively generalizes from training examples-input features and associated classification labels-to previously unseen examples requiring labels. It is used on a variety of problems, including time series prediction for financial forecasting, machine translation, character and speech recognition, and even conservation biology. Although there are many techniques for performing such classifications, the aforementioned approaches all use one type of model: the maximum entropy classifier, also known as multinomial logistic regression. Optimizing the prediction accuracy of the learned function for complex problems can require massive amounts of training data. A learner is implemented that utilizes the parallelism of a GPU for the most common scenarios. It is likely that in the cases where matrix multiplication is not the bottleneck, performance can be improved even further by optimizing the max and sum reductions at the heart of the other kernels. Unrolling loops and/or initializing extraneous values for nonpower of two block sizes so that special cases can be eliminated should yield improved runtimes. The motivation for employing MaxEnt has been to improve character recognition in arbitrary images of natural scenes. This task is more complex than typical document-based character recognition because it involves a wide variety of fonts and uncontrolled viewing conditions. {\textcopyright} 2011 Copyright {\textcopyright} 2011 NVIDIA Corporation and Wen-mei W. Hwu Published by Elsevier Inc. All rights reserved..},
archivePrefix = {arXiv},
arxivId = {1603.04467v2},
author = {Weinman, Jerod J. and Lidaka, Augustus and Aggarwal, Shitanshu},
doi = {1603.04467},
eprint = {1603.04467v2},
file = {::},
isbn = {9780123849885},
issn = {01420615},
journal = {GPU Computing Gems Emerald Edition},
pages = {277--291},
title = {{TensorFlow: Large-scale machine learning}},
year = {2011}
}
@article{Hassan2017,
abstract = {{\textcopyright} 2017 IEEE. Despite the advancement in software build tools such as Maven and Gradle, human involvement is still often required in software building. To enable large-scale advanced program analysis and data mining of software artifacts, software engineering researchers need to have a large corpus of built software, so automatic software building becomes essential to improve research productivity. In this paper, we present a feasibility study on automatic software building. Particularly, we first put state-of-the-art build automation tools (Ant, Maven and Gradle) to the test by automatically executing their respective default build commands on top 200 Java projects from GitHub. Next, we focus on the 86 projects that failed this initial automated build attempt, manually examining and determining correct build sequences to build each of these projects. We present a detailed build failure taxonomy from these build results and show that at least 57{\%} build failures can be automatically resolved.},
author = {Hassan, Foyzul and Mostafa, Shaikh and Lam, Edmund S.L. and Wang, Xiaoyin},
doi = {10.1109/ESEM.2017.11},
file = {::},
isbn = {9781509040391},
issn = {19493789},
journal = {International Symposium on Empirical Software Engineering and Measurement},
pages = {38--47},
title = {{Automatic Building of Java Projects in Software Repositories: A Study on Feasibility and Challenges}},
volume = {2017-Novem},
year = {2017}
}
@article{Dhakal2018,
author = {Dhakal, Vivek and Feit, Anna Maria and Kristensson, Per Ola and Oulasvirta, Antti},
doi = {10.1145/3173574.3174220},
file = {::},
isbn = {9781450356206},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Text entry,large-scale study,modern typing behavior},
pages = {1--12},
title = {{Observations on Typing from 136 Million Keystrokes}},
year = {2018}
}
@article{NELSON1976,
author = {NELSON, T. M. and LADAN, C. J.},
doi = {10.1111/j.2044-8325.1976.tb00331.x},
issn = {03058107},
journal = {Journal of Occupational Psychology},
month = {jun},
number = {2},
pages = {65--74},
title = {{Patterns and correlates of fatigue among office workers}},
url = {http://doi.wiley.com/10.1111/j.2044-8325.1976.tb00331.x},
volume = {49},
year = {1976}
}
@article{Grant2006,
abstract = {A neglected aspect of inventory management is stock loss caused by breakage, theft, deterioration or obsolescence. Such loss requires financial write-offs that affect financial indicators of a firm's overall inventory management effectiveness. Stock loss or damage related to finished goods is easier to identify than obsolete or dead stock, and firms often focus on finished goods due to their high and identifiable value and a higher risk of becoming unusable and thus obsolete. However, factors that affect finished goods also affect raw materials and work-in-progress. A change in operating environment can introduce factors of stock obsolescence, including a firm's external environment of technological change and demand, or internal procedures such as poor forecasting. Firms need to evaluate whether their current stock levels and write-off policies are reasonable for all inventory classifications to reduce the amount of write-offs or to keep the amount at a low and manageable level, and if not investigate the factors that produce these write-offs. This paper discusses dry goods stock obsolescence and write-offs and the impact of demand forecasting on them at a leading UK whisky producer.},
author = {Grant, David B. and Karagianni, Chariklia and Li, Mei},
doi = {10.1080/13675560600859615},
file = {::},
issn = {1367-5567},
journal = {International Journal of Logistics Research and Applications},
title = {{Forecasting and stock obsolescence in whisky production}},
year = {2006}
}
@inproceedings{Polyzotis2017,
address = {New York, New York, USA},
annote = {Training data - Understanding, validating, cleaning, enriching

Core expertise of database community - analyzing, modeling, enriching, validating and debugging data

Training data -{\textgreater} Training -{\textgreater} Model -{\textgreater} Serving -{\textgreater} Serving Data (Serving to Training Data Transformations)

1. Understanding - Encode their data into features, identify explicit and implicit data dependencies

Salient features of data - The range and statistical distribution of feature values, correlations between features in training data, distributions of positive and negative examples across different slices

2. Validation - Validity affects quality of model, training{\_}serving skew, time travel of features
Two factors - Scale of data and validity checks need to be done with data

3. Cleaning - three tasks
3.1. Understanding where the error occurred
3.2. Understanding the impact of the error
3.3. Fixing the error

4. Enrichment - The augementation of training and serving data 

The common forms of enrichment are joining a new data structure and using same signals with different transformations},
author = {Polyzotis, Neoklis and Roy, Sudip and Whang, Steven Euijong and Zinkevich, Martin},
booktitle = {Proceedings of the 2017 ACM International Conference on Management of Data  - SIGMOD '17},
doi = {10.1145/3035918.3054782},
file = {::},
isbn = {9781450341974},
keywords = {data enrichment,data management,data understanding,data validation,machine learning,production},
pages = {1723--1726},
publisher = {ACM Press},
title = {{Data Management Challenges in Production Machine Learning}},
url = {http://dl.acm.org/citation.cfm?doid=3035918.3054782},
year = {2017}
}
@inproceedings{Manning2014,
address = {Stroudsburg, PA, USA},
author = {Manning, Christopher and Surdeanu, Mihai and Bauer, John and Finkel, Jenny and Bethard, Steven and McClosky, David},
booktitle = {Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
doi = {10.3115/v1/P14-5010},
file = {::},
pages = {55--60},
publisher = {Association for Computational Linguistics},
title = {{The Stanford CoreNLP Natural Language Processing Toolkit}},
url = {http://aclweb.org/anthology/P14-5010},
year = {2014}
}
@article{Gneiting2007,
abstract = {Scoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is proper if the forecaster maximizes the expected score for an observation drawn from the distribution F if he or she issues the probabilistic forecast F, rather than G ≠ F. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster to make careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand. This article reviews and develops the theory of proper scoring rules on general probability spaces, and proposes and discusses examples thereof. Proper scoring rules derive from convex functions and relate to information measures, entropy functions, and Bregman divergences. In the case of categorical variables, we prove a rigorous version of the Savage representation. Examples of scoring rules for probabilistic forecasts in the form of predictive densities include the logarithmic, spherical, pseudospherical, and quadratic scores. The continuous ranked probability score applies to probabilistic forecasts that take the form of predictive cumulative distribution functions. It generalizes the absolute error and forms a special case of a new and very general type of score, the energy score. Like many other scoring rules, the energy score admits a kernel representation in terms of negative definite functions, with links to inequalities of Hoeffding type, in both univariate and multivariate settings. Proper scoring rules for quantile and interval forecasts are also discussed. We relate proper scoring rules to Bayes factors and to cross-validation, and propose a novel form of cross-validation known as random-fold cross-validation. A case study on probabilistic weather forecasts in the North American Pacific Northwest illustrates the importance of propriety. We note optimum score approaches to point and quantile estimation, and propose the intuitively appealing interval score as a utility function in interval estimation that addresses width as well as coverage. {\textcopyright} 2007 American Statistical Association.},
author = {Gneiting, Tilmann and Raftery, Adrian E.},
doi = {10.1198/016214506000001437},
file = {::},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Bayes factor,Bregman divergence,Brier score,Coherent,Continuous ranked probability score,Cross-validation,Entropy,Kernel score,Loss function,Minimum contrast estimation,Negative definite function},
number = {477},
pages = {359--378},
title = {{Strictly proper scoring rules, prediction, and estimation}},
volume = {102},
year = {2007}
}
@article{Spinellis2011,
abstract = {The style of our code, encompassing formatting, the ordering of the program's elements, and the naming of our identifiers, is a key aspect of its maintainability. Expertly styled code is more expressive, making us more productive when reading or writing code, while avoiding distractions. To improve code style, acquaint yourself with the style guidelines of each language you use or software you edit and apply them religiously. Also, learn from other people's code; don't rely on formatting tools to do the job for you. {\textcopyright} 2011 IEEE.},
author = {Spinellis, Diomidis},
doi = {10.1109/MS.2011.31},
file = {::},
issn = {07407459},
journal = {IEEE Software},
keywords = {formatting guidelines,programming style},
number = {2},
pages = {103--104},
title = {{elytS edoC}},
volume = {28},
year = {2011}
}
@article{Sculley2014,
abstract = {Machine learning offers a fantastically powerful toolkit for building complex sys-tems quickly. This paper argues that it is dangerous to think of these quick wins as coming for free. Using the framework of technical debt, we note that it is re-markably easy to incur massive ongoing maintenance costs at the system level when applying machine learning. The goal of this paper is highlight several ma-chine learning specific risk factors and design patterns to be avoided or refactored where possible. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, changes in the external world, and a variety of system-level anti-patterns.},
author = {Sculley, D and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael},
file = {::},
journal = {NIPS 2014 Workshop on Software Engineering for Machine Learning (SE4ML)},
title = {{Machine Learning : The High-Interest Credit Card of Technical Debt}},
year = {2014}
}
@phdthesis{Barnett2017,
author = {Barnett, Scott},
file = {::},
school = {Swinburne University of Technology},
title = {{Extracting Technical Domain Knowledge to Improve Software Architecture}},
year = {2017}
}
@book{GhoshSohom2019,
author = {{Ghosh Sohom}, Author. and Gunning, Dwight},
publisher = {Packt Publishing},
title = {{Natural language processing fundamentals.}},
url = {http://ezproxy.deakin.edu.au/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=cat00097a{\&}AN=deakin.b4158080{\&}authtype=sso{\&}custid=deakin{\&}site=eds-live{\&}scope=site},
year = {2019}
}
@article{Sulir2017,
abstract = {Source code is a primary artifact where program-mers are looking when they try to comprehend a program. However, to improve program comprehension efficiency, tools often associate parts of source code with metadata collected from static and dynamic analysis, communication artifacts and many other sources. In this article, we present a systematic mapping study of approaches and tools labeling source code elements with metadata and presenting them to developers in various forms. We selected 25 from more than 2,000 articles and categorized them. A taxonomy with four dimensions – source, target, presentation and persistence – was formed. Based on the survey results, we also identified interesting future research challenges.},
author = {Sulir, Matus and Poruban, Jaroslav},
doi = {10.15439/2017F229},
file = {::},
isbn = {9788394625375},
journal = {Proceedings of the 2017 Federated Conference on Computer Science and Information Systems, FedCSIS 2017},
pages = {721--729},
title = {{Labeling source code with metadata: A survey and taxonomy}},
volume = {11},
year = {2017}
}
@inproceedings{Best2007a,
author = {Best, Christopher and Eidman, Craig and Crane, Peter and Kam, Clinton and Skinner, Michael and Hasenbosch, Sam and Burchat, Eleanore and Finch, Melanie and Shanahan, Christopher and Zamba, Mitch},
booktitle = {Twelfth Australian Aeronautical Conference},
file = {::},
number = {7104},
title = {{Exercise Pacific Link 2 : Distributed Training for Air Battle Managers}},
year = {2007}
}
@inproceedings{Yuan2017,
abstract = {{\textcopyright} 2017 ACM. With the advances in pervasive sensor technologies, physiological signals can be captured continuously to prevent the serious outcomes caused by epilepsy. Detection of epileptic seizure onset on collected multi-channel electroencephalogram (EEG) has attracted lots of attention recently. Deep learning is a promising method to analyze large-scale unlabeled data. In this paper, we propose a multi-view deep learning model to capture brain abnormality from multi-channel epileptic EEG signals for seizure detection. Specifically, we first generate EEG spectrograms using short-time Fourier transform (STFT) to represent the time-frequency information after signal segmentation. Second, we adopt stacked sparse denoising autoencoders (SSDA) to unsupervisedly learn multiple features by considering both intra and inter correlation of EEG channels, denoted as intra-channel and cross-channel features, respectively. Third, we add an SSDA-based channel selection procedure using proposed response rate to reduce the dimension of intra-channel feature. Finally, we concatenate the learned multi-features and apply a fully-connected SSDA model with softmax classifier to jointly learn the cross-patient seizure detector in a supervised fashion. To evaluate the performance of the proposed model, we carry out experiments on a real world benchmark EEG dataset and compare it with six baselines. Extensive experimental results demonstrate that the proposed learning model is able to extract latent features with meaningful interpretation, and hence is effective in detecting epileptic seizure.},
author = {Yuan, Ye and Jia, Kebin and Xun, Guangxu and Zhang, Aidong},
booktitle = {ACM-BCB 2017 - Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
doi = {10.1145/3107411.3107419},
file = {::},
isbn = {9781450347228},
keywords = {Deep learning,Electroencephalogram,Epileptic seizure,Feature extraction,Time-frequency analysis},
month = {aug},
pages = {213--222},
publisher = {Association for Computing Machinery, Inc},
title = {{A multi-view deep learning method for epileptic seizure Detection using short-time Fourier transform}},
year = {2017}
}
@incollection{Herrera2018,
annote = {Keel is the main dataset
4 broad solutions
3 major problems, only 2 can be dealt with},
author = {Herrera, Francisco and Garc{\'{i}}a, Salvador and Fern{\'{a}}ndez, Alberto and Krawczyk, Bartosz and Galar, Mikel and Prati, Ronaldo C.},
booktitle = {Learning from Imbalanced Data Sets},
doi = {10.1007/978-3-319-98074-4_2},
title = {{Foundations on Imbalanced Classification}},
year = {2018}
}
@article{Kuhne2006,
abstract = {Abstract With the recent trend to model driven engineering a common understanding of basic notions such as model and metamodel becomes a pivotal issue. Even though these notions have been in widespread use for quite a while, there is still little consensus about when exactly it is appropriate to use them. The aim of this article is to start establishing a consensus about generally acceptable terminology. Its main contributions are the distinction between two fundamentally different kinds of model roles, i.e. token model versus type model (The terms type and token have been introduced by C.S. Peirce, 18391914.), a formal notion of metaness, and the consideration of generalization as yet another basic relationship between models. In particular, the recognition of the fundamental difference between the above mentioned two kinds of model roles is crucial in order to enable communication among the model driven engineering community that is free of both unnoticed misunderstandings and unnecessary disagreement.},
author = {K{\"{u}}hne, Thomas},
doi = {10.1007/s10270-006-0017-9},
file = {::},
issn = {16191366},
journal = {Software and Systems Modeling},
keywords = {Metamodeling,Model driven engineering,Modeling,Token model,Type model},
number = {4},
pages = {369--385},
title = {{Matters of (meta-) modeling}},
volume = {5},
year = {2006}
}
@article{Kuhn2007,
abstract = {Many of the existing approaches in Software Comprehension focus on program structure or external documentation. However, by analyzing formal information the informal semantics contained in the vocabulary of source code are overlooked. To understand software as a whole, we need to enrich software analysis with the developer knowledge hidden in the code naming. This paper proposes the use of information retrieval to exploit linguistic information found in source code, such as identifier names and comments. We introduce Semantic Clustering, a technique based on Latent Semantic Indexing and clustering to group source artifacts that use similar vocabulary. We call these groups semantic clusters and we interpret them as linguistic topics that reveal the intention of the code. We compare the topics to each other, identify links between them, provide automatically retrieved labels, and use a visualization to illustrate how they are distributed over the system. Our approach is language independent as it works at the level of identifier names. To validate our approach we applied it on several case studies, two of which we present in this paper. Note: Some of the visualizations presented make heavy use of colors. Please obtain a color copy of the article for better understanding.},
author = {Kuhn, Adrian and Ducasse, St{\'{e}}phane and G{\^{i}}rba, Tudor},
doi = {10.1016/J.INFSOF.2006.10.017},
file = {::},
issn = {0950-5849},
journal = {Information and Software Technology},
month = {mar},
number = {3},
pages = {230--243},
publisher = {Elsevier},
title = {{Semantic clustering: Identifying topics in source code}},
url = {https://www.sciencedirect.com/science/article/pii/S0950584906001820},
volume = {49},
year = {2007}
}
@book{spolsky2008more,
author = {Spolsky, Avram Joel},
publisher = {Apress},
title = {{More Joel on software: further thoughts on diverse and occasionally related matters that will prove of interest to software developers, designers, and managers, and to those who, whether by good fortune or ill luck, work with them in some capacity}},
year = {2008}
}
@article{Sivathamboo2018a,
author = {Sivathamboo, Niveshan and Hitchcock, Alison and Graham, Janet and Sivathamboo, Shobi and Chen, Zhibin and O'Brien, Terence J. and Vajda, Frank J. E.},
doi = {10.1111/epi.14539},
file = {::},
issn = {00139580},
journal = {Epilepsia},
keywords = {antiepileptic drugs,anxiety,birth defects,congenital malformations,depression,seizure control},
month = {sep},
number = {9},
pages = {1696--1704},
publisher = {John Wiley {\&} Sons, Ltd (10.1111)},
title = {{The use of antidepressant drugs in pregnant women with epilepsy: A study from the Australian Pregnancy Register}},
url = {http://doi.wiley.com/10.1111/epi.14539},
volume = {59},
year = {2018}
}
@article{Khurana2018,
author = {Khurana, Udayan and Samulowitz, Horst and Turaga, Deepak},
file = {::},
journal = {ICML 2018 AutoML Workshop},
keywords = {automl,ensembles,feature engineering,reinforcement learning},
title = {{Ensembles with Automated Feature Engineering}},
year = {2018}
}
@article{Japkowicz1998,
annote = {Introduces concept complexity, data set size and degree of class imbalance.},
author = {Japkowicz, Nathalie and ju Stephen, Sha},
doi = {10.2165/00042310-199812070-00003},
file = {::},
issn = {11720360},
journal = {Drugs and Therapy Perspectives},
number = {7},
pages = {10},
title = {{The Class Imbalance Problem: A Systematic Study}},
volume = {12},
year = {1998}
}
@article{Mucci2016,
abstract = {Hypertension (HT) is a long-term medical condition characterized by persistently elevated blood pressure (BP) in the arterial vessels. Although HT initially is an asymptomatic condition, it chronically evolves into a major risk factor for cardiovascular, cerebrovascular, and renal diseases that, in turn, represent crucial causes of morbidity and mortality in industrialized countries. HT is a complex disorder that is estimated to affect more than a quarter of the world's adult population. It is classified on the basis of both its pathophysiology (primary and secondary HT) and on the resting BP values (elevated systolic, diastolic, and pulse pressure). It originates from a complicated interaction of genes and several environmental risk factors including aging, smoking, lack of exercise, overweight and obesity, elevated salt intake, stress, depression, and anxiety. Anxiety and depressive disorders are the most commonly diagnosed mental disorders, affecting millions of people each year and impairing every aspect of everyday life, both of them characterized by affective, cognitive, psychomotor, and neurovegetative symptoms. Moreover, work-related stress has been considered as an important risk factor for HT and cardiovascular diseases (CVDs). Although different authors have investigated and suggested possible relations between HT, stress, anxiety, and depression during the last decades, a full understanding of the underlying pathophysiological mechanisms has not been satisfactorily achieved, especially in young adults. The aim of this study was to investigate the impact of anxiety and workrelated stress in the development of HT amongst young health care profession students and the possible related consequences of early CVDs.},
author = {Mucci, Nicola and Giorgi, Gabriele and Ceratti, Stefano De Pasquale and Fiz-P{\'{e}}rez, Javier and Mucci, Federico and Arcangeli, Giulio},
doi = {10.3389/fpsyg.2016.01682},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Anxiety,Blood pressure,Health care professions,Health promotion,Occupational medicine,Students,Work-related stress,Workplace},
month = {oct},
pages = {1--10},
publisher = {Frontiers Media S.A.},
title = {{Anxiety, stress-related factors, and blood pressure in young adults}},
volume = {7},
year = {2016}
}
@inproceedings{Greff2017,
abstract = {—We present a toolchain for computational research consisting of Sacred and two supporting tools. Sacred is an open source Python framework which aims to provide basic infrastructure for running computational experiments independent of the methods and libraries used. Instead, it focuses on solving universal everyday problems, such as managing configurations, reproducing results, and bookkeeping. Moreover, it provides an extensible basis for other tools, two of which we present here: Labwatch helps with tuning hyperparameters, and Sacredboard provides a web-dashboard for organizing and analyzing runs and results.},
author = {Greff, Klaus and Klein, Aaron and Chovanec, Martin and Hutter, Frank and Schmidhuber, J{\"{u}}rgen},
booktitle = {Proceedings of the 16th Python in Science Conference},
doi = {10.25080/shinma-7f4c6e7-008},
file = {::},
pages = {49--56},
publisher = {SciPy},
title = {{The Sacred Infrastructure for Computational Research}},
url = {https://conference.scipy.org/proceedings/scipy2017/klaus{\_}greff.html},
year = {2017}
}
@article{Chen2016a,
abstract = {The sheer number of available technologies and the complex relationships among them make it challenging to choose the right technologies for software projects. Developers often turn to online resources (e.g., expert articles and community answers) to get a good understanding of the technology landscape. Such online resources are primarily opinion-based and are often out of date. Furthermore, information is often scattered in many online resources, which has to be aggregated to have a big picture of the technology landscape. In this paper, we exploit the fact that Stack Overflow users tag their questions with the main technologies that the questions revolve around, and develop association rule mining and community detection techniques to mine technology landscape from Stack Overflow question tags. The mined technology landscape is represented in a graphical Technology Associative Network (TAN). Our empirical study shows that the mined TAN captures a wide range of technologies, the complex relationships among the technologies, and the trend of the technologies in the developers' discussions on Stack Overflow. We develop a website (https://graphofknowledge.appspot.com/) for the community to access and evaluate the mined technology landscape. The website visit statistics by Google Analytics shows the developers' general interests in our technology landscape service. We also report a small-scale user study to evaluate the potential usefulness of our tool.},
author = {Chen, Chunyang and Xing, Zhenchang},
doi = {10.1145/2961111.2962588},
file = {::},
isbn = {9781450344272},
issn = {19493789},
journal = {International Symposium on Empirical Software Engineering and Measurement},
keywords = {Association Rule Mining,Community Detection,Technology Associative Network,Technology Landscape},
title = {{Mining Technology Landscape from Stack Overflow}},
volume = {08-09-Sept},
year = {2016}
}
@article{Woolston,
author = {Woolston, H B},
editor = {Bristol, L M},
issn = {15503283},
journal = {The American Journal of Theology},
number = {2},
pages = {311--313},
publisher = {University of Chicago Press},
title = {{Social Adaptation}},
url = {http://www.jstor.org/stable/3155443},
volume = {21}
}
@article{Coleman1994,
author = {Coleman, D. and Ash, D. and Lowther, B. and Oman, P.},
doi = {10.1109/2.303623},
issn = {0018-9162},
journal = {Computer},
month = {aug},
number = {8},
pages = {44--49},
title = {{Using metrics to evaluate software system maintainability}},
url = {http://ieeexplore.ieee.org/document/303623/},
volume = {27},
year = {1994}
}
@article{Reeves2015,
abstract = {{\textless}div class="page" title="Page 1"{\textgreater}{\textless}div class="layoutArea"{\textgreater}{\textless}div class="column"{\textgreater}{\textless}p{\textgreater}{\textless}span{\textgreater}The human-computer interaction (HCI) has had a long and troublesome relationship to the role of ‘science'. HCI's status as an academic object in terms of coherence and adequacy is often in question—leading to desires for establishing a true scientific discipline. In this paper I explore formative cognitive science influences on HCI, through the impact of early work on the design of input devices. The paper discusses a core idea that I argue has animated much HCI research since: the notion of scientific design spaces. In evaluating this concept, I disassemble the broader ‘picture of science' in HCI and its role in constructing a disciplinary order for the increasingly diverse and overlapping research communities that contribute in some way to what we call ‘HCI'. In concluding I explore notions of rigour and debates around how we might reassess HCI's disciplinarity.{\textless}/span{\textgreater}{\textless}/p{\textgreater}{\textless}/div{\textgreater}{\textless}/div{\textgreater}{\textless}/div{\textgreater}},
author = {Reeves, Stuart},
doi = {10.7146/aahcc.v1i1.21296},
file = {::},
journal = {Aarhus Series on Human Centered Computing},
number = {1},
pages = {12},
title = {{Human-computer interaction as science}},
volume = {1},
year = {2015}
}
@article{Kaptein2012,
abstract = {CHI researchers typically use a significance testing approach to statistical analysis when testing hypotheses during usability evaluations. However, the appropriateness of this approach is under increasing criticism, with statisticians, economists, and psychologists arguing against the use of routine interpretation of results using "canned" p values. Three problems with current practice - the fallacy of the transposed conditional, a neglect of power, and the reluctance to interpret the size of effects - can lead us to build weak theories based on vaguely specified hypothesis, resulting in empirical studies which produce results that are of limited practical or scientific use. Using publicly available data presented at CHI 2010 [19] as an example we address each of the three concerns and promote consideration of the magnitude and actual importance of effects, as opposed to statistical significance, as the new criteria for evaluating CHI research. Copyright 2012 ACM.},
author = {Kaptein, Maurits and Robertson, Judy},
doi = {10.1145/2207676.2208557},
file = {::},
isbn = {9781450310154},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Bayesian statistics,Research methods,Usability evaluation},
pages = {1105--1113},
title = {{Rethinking statistical analysis methods for CHI}},
year = {2012}
}
@book{gelman2013,
author = {Gelman, A. and Carlin, J.B. and Stern, H.S. and Dunson, D.B. and Vehtari, A. and Rubin, D.B.},
publisher = {Taylor $\backslash${\&} Francis},
title = {{Bayesian Data Analysis, Third Edition}},
year = {2013}
}
@article{Ernst2007,
abstract = {Daikon is an implementation of dynamic detection of likely invariants; that is, the Daikon invariant detector reports likely program invariants. An invariant is a property that holds at a certain point or points in a program; these are often used in assert statements, documentation, and formal specifications. Examples include being constant (x = a), non-zero (x ≠ 0), being in a range (a ≤ x ≤ b), linear relationships (y = a x + b), ordering (x ≤ y), functions from a library (x = fn (y)), containment (x ∈ y), sortedness (x is sorted), and many more. Users can extend Daikon to check for additional invariants. Dynamic invariant detection runs a program, observes the values that the program computes, and then reports properties that were true over the observed executions. Dynamic invariant detection is a machine learning technique that can be applied to arbitrary data. Daikon can detect invariants in C, C++, Java, and Perl programs, and in record-structured data sources; it is easy to extend Daikon to other applications. Invariants can be useful in program understanding and a host of other applications. Daikon's output has been used for generating test cases, predicting incompatibilities in component integration, automating theorem proving, repairing inconsistent data structures, and checking the validity of data streams, among other tasks. Daikon is freely available in source and binary form, along with extensive documentation, at http://pag.csail.mit.edu/daikon/. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
annote = {Forth industrial revolution - fast and widespread AI, shift towards more algorithmic society
Four concerns on AI - Lack of transparency, powerful predictions, cannot be directly explained, improve trust and transparency

Monetary value of AI - Increase in global investment in AI, AI market growth

FAT (Fairness, Accountability, Transparency) Academics

Definition of Data Science - A field that unifies statistics, data analytics, machine learning and their related methods in order to understand and anlayze actual phenomena with data

Reasons for XAI - Explain to justify, explain to control, explain to improve, explain to discover
XAI Application domains - Transportation, healthcare, legal, finance, military

The technical challenge of enabling XAI - Why the use of XAI is not systematic ?
Why is not everyone using XAI?

Four basic research areas - Data Science, AI/ML, Human Science, HCI
Six major academic databases - SCOPUS, IEEExplore, ACM Digital Library, Google Scholar, Citeseer Library, ScienceDirect

Scoop related methods - Understanding the entire model behavior/understanding a single prediction},
author = {Ernst, Michael D. and Perkins, Jeff H. and Guo, Philip J. and McCamant, Stephen and Pacheco, Carlos and Tschantz, Matthew S. and Xiao, Chen},
doi = {10.1016/j.scico.2007.01.015},
file = {::},
issn = {01676423},
journal = {Science of Computer Programming},
keywords = {Daikon,Dynamic analysis,Dynamic invariant detection,Inductive logic programming,Inference,Invariant,Likely invariant,Program understanding,Specification,Specification mining},
number = {1-3},
pages = {35--45},
title = {{The Daikon system for dynamic detection of likely invariants}},
volume = {69},
year = {2007}
}
@article{Brown1964,
author = {Brown, George W. and Lu, John Y. and Wolfson, Robert J.},
doi = {10.1287/mnsc.11.1.51},
file = {::},
issn = {0025-1909},
journal = {Management Science},
month = {sep},
number = {1},
pages = {51--63},
publisher = {INFORMS},
title = {{Dynamic Modeling of Inventories Subject to Obsolescence}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.11.1.51},
volume = {11},
year = {1964}
}
@misc{Meng2017,
abstract = {The success of an application programming interface (API) crucially depends on how well its documentation meets the information needs of software developers. Previous research suggests that these information needs have not been sufficiently understood. This article presents the results of a series of semistructured interviews and a follow-up questionnaire conducted to explore the learning goals and learning strategies of software developers, the information resources they turn to and the quality criteria they apply to API documentation. Our results show that developers initially try to form a global understanding regarding the overall purpose and main features of an API, but then adopt either a concepts-oriented or a code-oriented learning strategy that API documentation both needs to address. Our results also show that general quality criteria such as completeness and clarity are relevant to API documentation as well. Developing and maintaining API documentation therefore need to involve the expertise of communication professionals.},
author = {Meng, Michael and Steinhardt, Stephanie and Schubert, Andreas},
booktitle = {Journal of Technical Writing and Communication},
doi = {10.1177/0047281617721853},
isbn = {0047-2816, 1541-3780},
issn = {15413780},
keywords = {application programming interface documentation,audience analysis,information design,technical documentation,usability},
title = {{Application Programming Interface Documentation: What Do Software Developers Want?}},
year = {2017}
}
@misc{Vagia2016,
abstract = {In this paper we present a literature review of the evolution of the levels of autonomy from the end of the 1950s up until now. The motivation of this study was primarily to gather and to compare the literature that exists, on taxonomies on levels of automation. Technical developments within both computer hardware and software have made it possible to introduce autonomy into virtually all aspects of human-machine systems. The current study, is focusing on how different authors treat the problem of different levels of automation. The outcome of this study is to present the differences between the proposed levels of automation and the various taxonomies, giving the potential users a number of choices in order to decide which taxonomy satisfies their needs better. In addition, this paper surveys deals with the term adaptive automation, which seems to be a new trend in the literature on autonomy.},
author = {Vagia, Marialena and Transeth, Aksel A. and Fjerdingen, Sigurd A.},
booktitle = {Applied Ergonomics},
doi = {10.1016/j.apergo.2015.09.013},
file = {::},
issn = {18729126},
keywords = {Adaptive automation,Autonomy/automation,Levels of autonomy,Taxonomies},
pmid = {26467193},
title = {{A literature review on the levels of automation during the years. What are the different taxonomies that have been proposed?}},
year = {2016}
}
@article{Feyisetan2020,
abstract = {Privacy-preserving data analysis has become essential in Machine Learning (ML), where access to vast amounts of data can provide large gains the in accuracies of tuned models. A large proportion of user-contributed data comes from natural language e.g., text transcriptions from voice assistants. It is therefore important for curated natural language datasets to preserve the privacy of the users whose data is collected and for the models trained on sensitive data to only retain non-identifying (i.e., generalizable) information. The workshop aims to bring together researchers and practitioners from academia and industry to discuss the challenges and approaches to designing, building, verifying, and testing privacy-preserving systems in the context of Natural Language Processing (NLP).},
author = {Feyisetan, Oluwaseyi and Ghanavati, Sepideh and Thaine, Patricia},
doi = {10.1145/3336191.3371881},
file = {::},
isbn = {9781450368223},
journal = {WSDM 2020 - Proceedings of the 13th International Conference on Web Search and Data Mining},
keywords = {Cryptography,Differential privacy,Machine learning,Natural language processing,Privacy,Security,Text processing},
number = {4417749},
pages = {903--904},
title = {{Workshop on privacy in NLP (PrivaTENLP 2020)}},
year = {2020}
}
@article{Kangasraasio2017,
abstract = {An important problem for HCI researchers is to estimate the parameter values of a cognitive model from behavioral data. This is a difficult problem, because of the substantial complexity and variety in human behavioral strategies. We report an investigation into a new approach using approximate Bayesian computation (ABC) to condition model parameters to data and prior knowledge. As the case study we examine menu interaction, where we have click time data only to infer a cognitive model that implements a search behaviour with parameters such as fixation duration and recall probability. Our results demonstrate that ABC (i) improves estimates of model parameter values, (ii) enables meaningful comparisons between model variants, and (iii) supports fitting models to individual users. ABC provides ample opportunities for theoretical HCI research by allowing principled inference of model parameter values and their uncertainty. Copyright is held by the owner/author(s).},
archivePrefix = {arXiv},
arxivId = {1612.00653},
author = {Kangasr{\"{a}}{\"{a}}si{\"{o}}, Antti and Athukorala, Kumaripaba and Howes, Andrew and Corander, Jukka and Kaski, Samuel and Oulasvirta, Antti},
doi = {10.1145/3025453.3025576},
eprint = {1612.00653},
file = {::},
isbn = {9781450346559},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Approximate Bayesian computation,Cognitive models in HCI,Computational rationality,Inverse modeling},
pages = {1295--1306},
title = {{Inferring cognitive models from data using approximate Bayesian computation}},
volume = {2017-May},
year = {2017}
}
@article{Kaul2017,
abstract = {In recent years, the importance of feature engineering has been confirmed by the exceptional performance of deep learning techniques, that automate this task for some applications. For others, feature engineering requires substantial manual effort in designing and selecting features and is often tedious and non-scalable. We present AutoLearn, a regression-based feature learning algorithm. Being data-driven, it requires no domain knowledge and is hence generic. Such a representation is learnt by mining pairwise feature associations, identifying the linear or non-linear relationship between each pair, applying regression and selecting those relationships that are stable and improve the prediction performance. Our experimental evaluation on 18 UC Irvine and 7 Gene expression datasets, across different domains, provides evidence that the features learnt through our model can improve the overall prediction accuracy by 13.28{\%}, compared to original feature space and 5.87{\%} over other top performing models, across 8 different classifiers without using any domain knowledge.},
author = {Kaul, Ambika and Maheshwary, Saket and Pudi, Vikram},
doi = {10.1109/ICDM.2017.31},
file = {::},
isbn = {9781538638347},
issn = {15504786},
journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
keywords = {Classification,Feature Generation,Feature Selection},
pages = {217--226},
title = {{Autolearn - automated feature generation and selection}},
volume = {2017-Novem},
year = {2017}
}
@article{Avazpour2014,
abstract = {Recommendation systems support users and developers of various computer and software systems to overcome information overload, perform information discovery tasks, and approximate computation, among others. They have recently become popular and have attracted a wide variety of application scenarios ranging from business process modeling to source code manipulation. Due to this wide variety of application domains, different approaches and metrics have been adopted for their evaluation. In this chapter, we review a range of evaluation metrics and measures as well as some approaches used for evaluating recommendation systems. The metrics presented in this chapter are grouped under sixteen different dimensions, e.g., correctness, novelty, coverage. We review these metrics according to the dimensions to which they correspond. A brief overview of approaches to comprehensive evaluation using collections of recommendation system dimensions and associated metrics is presented. We also provide suggestions for key future research and practice directions.},
author = {Avazpour, Iman and Pitakrat, Teerat and Grunske, Lars and Grundy, John},
doi = {10.1007/978-3-642-45135-5_10},
file = {::},
isbn = {9783642451355},
journal = {Recommendation Systems in Software Engineering},
number = {c},
pages = {245--273},
title = {{Dimensions and metrics for evaluating recommendation systems}},
year = {2014}
}
@article{Easterbrook2008,
abstract = {Selecting a research method for empirical software engineering research is problematic because the benefits and challenges to using each method are not yet well catalogued. Therefore, this chapter describes a number of empirical methods available. It examines the goals of each and analyzes the types of questions each best addresses. Theoretical stances behind the methods, practical considerations in the application of the methods and data collection are also briefly reviewed. Taken together, this information provides a suitable basis for both understanding and selecting from the variety of methods applicable to empirical software engineering. {\textcopyright} 2008 Springer-Verlag London.},
annote = {Types of research methods - Controlled Experiments, Case Studies, Survey Research, Ethnographies, Action Research

Types of research questions - Existence, Description and Classification, Descriptive-Comparative

Types of philosophical stances - positivism, constructivism, critical theory, pragmatism},
author = {Easterbrook, Steve and Singer, Janice and Storey, Margaret Anne and Damian, Daniela},
doi = {10.1007/978-1-84800-044-5_11},
file = {::},
isbn = {9781848000438},
journal = {Guide to Advanced Empirical Software Engineering},
pages = {285--311},
title = {{Selecting empirical methods for software engineering research}},
year = {2008}
}
@inproceedings{Curumsing:2020semotion,
annote = {Unpublished},
archivePrefix = {arXiv},
arxivId = {2004.03120},
author = {Curumsing, Maheshwaree Kissoon and Cummaudo, Alex and Graetsch, Ulrike Maria and Barnett, Scott and Vasa, Rajesh},
eprint = {2004.03120},
keywords = {InReview},
mendeley-tags = {InReview},
title = {{Ranking Computer Vision Service Issues using Emotion}},
year = {2020}
}
@article{Japkowicz1998,
annote = {Introduces concept complexity, data set size and degree of class imbalance.},
author = {Japkowicz, Nathalie and ju Stephen, Sha},
doi = {10.2165/00042310-199812070-00003},
file = {::},
issn = {11720360},
journal = {Drugs and Therapy Perspectives},
number = {7},
pages = {10},
title = {{The Class Imbalance Problem: A Systematic Study}},
volume = {12},
year = {1998}
}
@article{Truong2018,
abstract = {Seizure prediction has attracted growing attention as one of the most challenging predictive data analysis efforts to improve the life of patients with drug-resistant epilepsy and tonic seizures. Many outstanding studies have reported great results in providing sensible indirect (warning systems) or direct (interactive neural stimulation) control over refractory seizures, some of which achieved high performance. However, to achieve high sensitivity and a low false prediction rate, many of these studies relied on handcraft feature extraction and/or tailored feature extraction, which is performed for each patient independently. This approach, however, is not generalizable, and requires significant modifications for each new patient within a new dataset. In this article, we apply convolutional neural networks to different intracranial and scalp electroencephalogram (EEG) datasets and propose a generalized retrospective and patient-specific seizure prediction method. We use the short-time Fourier transform on 30-s EEG windows to extract information in both the frequency domain and the time domain. The algorithm automatically generates optimized features for each patient to best classify preictal and interictal segments. The method can be applied to any other patient from any dataset without the need for manual feature extraction. The proposed approach achieves sensitivity of 81.4{\%}, 81.2{\%}, and 75{\%} and a false prediction rate of 0.06/h, 0.16/h, and 0.21/h on the Freiburg Hospital intracranial EEG dataset, the Boston Children's Hospital-MIT scalp EEG dataset, and the American Epilepsy Society Seizure Prediction Challenge dataset, respectively. Our prediction method is also statistically better than an unspecific random predictor for most of the patients in all three datasets.},
author = {Truong, Nhan Duy and Nguyen, Anh Duy and Kuhlmann, Levin and Bonyadi, Mohammad Reza and Yang, Jiawei and Ippolito, Samuel and Kavehei, Omid},
doi = {10.1016/j.neunet.2018.04.018},
file = {::},
issn = {18792782},
journal = {Neural Networks},
keywords = {Convolutional neural network,Intracranial EEG,Machine learning,Scalp EEG,Seizure prediction},
month = {sep},
pages = {104--111},
publisher = {Elsevier Ltd},
title = {{Convolutional neural networks for seizure prediction using intracranial and scalp electroencephalogram}},
volume = {105},
year = {2018}
}
@article{Kassiri2017,
author = {Kassiri, Hossein and Tonekaboni, Sana and Salam, M. Tariqus and Soltani, Nima and Abdelhalim, Karim and Velazquez, Jose Luis Perez and Genov, Roman},
doi = {10.1109/TBCAS.2017.2694638},
file = {::},
issn = {1932-4545},
journal = {IEEE Transactions on Biomedical Circuits and Systems},
month = {oct},
number = {5},
pages = {1026--1040},
title = {{Closed-Loop Neurostimulators: A Survey and A Seizure-Predicting Design Example for Intractable Epilepsy Treatment}},
url = {http://ieeexplore.ieee.org/document/7982670/},
volume = {11},
year = {2017}
}
@article{Tenenbaum2006,
abstract = {Human perception and memory are often explained as optimal statistical inferences that are informed by accurate prior probabilities. In contrast, cognitive judgments are usually viewed as following error-prone heuristics that are insensitive to priors.We examined the optimality of human cognition in a more realistic context than typical laboratory studies, asking people to make predictions about the duration or extent of everyday phenomena such as human life spans and the box-office take of movies. Our results suggest that everyday cognitive judgments follow the same optimal statistical principles as perception and memory, and reveal a close correspondence between people's implicit probabilistic models and the statistics of the world.},
author = {Tenenbaum, Joshua B and Griffiths, Thomas L},
file = {::},
journal = {Psychological Science},
number = {9},
pages = {767--773},
title = {{Optimal Predictions in Everyday Cognition}},
volume = {17},
year = {2006}
}
@article{Dudley2018,
author = {Dudley, John J and Kristensson, Per Ola and Kingdom, United},
file = {::},
journal = {ACM Trans. Interact. Intell. Syst.},
number = {2},
title = {{A Review of User Interface Design for Interactive Machine Learning.}},
volume = {8},
year = {2018}
}
@article{Shang2016,
annote = {Overview of imbalanced learning},
author = {Shang, Jennifer and Mingyun, Gu and Yijing, Li and Bing, Gong and Yuanyue, Huang and Haixiang, Guo},
doi = {10.1016/j.eswa.2016.12.035},
file = {::},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Rare events,Imbalanced data,Machine learning,Data},
number = {December},
pages = {220--239},
publisher = {Elsevier Ltd},
title = {{Learning from class-imbalanced data: Review of methods and applications}},
url = {http://dx.doi.org/10.1016/j.eswa.2016.12.035},
volume = {73},
year = {2016}
}
@article{Lecun2015,
abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
doi = {10.1038/nature14539},
file = {::},
issn = {14764687},
journal = {Nature},
number = {7553},
pages = {436--444},
pmid = {26017442},
title = {{Deep learning}},
volume = {521},
year = {2015}
}
@article{Wang2018,
abstract = {As an emerging research topic, online class imbalance learning often combines the challenges of both class imbalance and concept drift. It deals with data streams having very skewed class distributions, where concept drift may occur. It has recently received increased research attention; however, very little work addresses the combined problem where both class imbalance and concept drift coexist. As the first systematic study of handling concept drift in class-imbalanced data streams, this paper first provides a comprehensive review of current research progress in this field, including current research focuses and open challenges. Then, an in-depth experimental study is performed, with the goal of understanding how to best overcome concept drift in online learning with class imbalance. Based on the analysis, a general guideline is proposed for the development of an effective algorithm.},
archivePrefix = {arXiv},
arxivId = {arXiv:1703.06683v1},
author = {Wang, Shuo and Minku, Leandro L. and Yao, Xin},
doi = {10.1109/TNNLS.2017.2771290},
eprint = {arXiv:1703.06683v1},
file = {::},
isbn = {2017030317},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Class imbalance,concept drift,online learning,resampling},
number = {10},
pages = {4802--4821},
publisher = {IEEE},
title = {{A Systematic Study of Online Class Imbalance Learning with Concept Drift}},
volume = {29},
year = {2018}
}
@article{Martins2018,
abstract = {We provide a repository of 50,000 compilable Java projects. Each project in this dataset comes with references to all the dependencies required to compile it, the resulting bytecode, and the scripts with which the projects were built.

The dependencies and the build scripts provide a mechanism to re-create compilation of the projects, if needed (to instruct source code for bytecode analysis, for example). The bytecode is ready for testing, execution, and dynamic analysis tools.},
author = {Martins, Pedro and Achar, Rohan and Lopes, Cristina V.},
doi = {10.1145/3196398.3196450},
file = {::},
isbn = {9781450357166},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
keywords = {large scale compilation,runnable software repositories,software mining},
pages = {1--5},
title = {{50K-C: A dataset of compilable, and compiled, Java projects}},
year = {2018}
}
@inproceedings{Alexandru2018,
author = {Alexandru, Carol V. and Merchante, Jos{\'{e}} J. and Panichella, Sebastiano and Proksch, Sebastian and Gall, Harald C. and Robles, Gregorio},
booktitle = {2018 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
doi = {10.1145/3276954.3276960},
file = {::},
pages = {1--11},
publisher = {Association for Computing Machinery (ACM)},
title = {{On the usage of pythonic idioms}},
year = {2018}
}
@article{Agarwal2018,
abstract = {—With the passage of recent federal legislation many medical institutions are now responsible for reaching target hospital readmission rates. Chronic diseases account for many hospital readmissions and Chronic Obstructive Pulmonary Disease has been recently added to the list of diseases for which the United States government penalizes hospitals incurring excessive readmissions. Though there have been efforts to statistically predict those most in danger of readmission, few have focused primarily on unstructured clinical notes. We have proposed a framework which uses Natural Language Processing to analyze clinical notes and predict readmission. Many algorithms within the field of data mining and machine learning exist, so a framework for component selection is created to select the best components. Na{\"{i}}ve Bayes using Chi-Squared feature selection offers an AUC of 0.690 while maintaining fast computational times. Keywords—Natural language processing, Medical information systems, Decision support systems, Data mining, Feature Extraction},
author = {Agarwal, Ankur and Baechle, Christopher and Behara, Ravi and Zhu, Xingquan},
doi = {10.1109/JBHI.2017.2684121},
file = {::},
issn = {21682194},
journal = {IEEE Journal of Biomedical and Health Informatics},
keywords = {Data mining,decision support systems,feature extraction,medical information systems,natural language processing},
month = {mar},
number = {2},
pages = {588--596},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{A Natural Language Processing Framework for Assessing Hospital Readmissions for Patients with COPD}},
volume = {22},
year = {2018}
}
@article{Jedlitschka2005,
author = {Jedlitschka, Andreas and Tn, Alberta},
file = {::},
isbn = {0780395085},
journal = {Evaluation},
pages = {95--104},
title = {{Reporting Guidelines for Controlled Experiments in Software Engineering Dietmar Pfahl}},
year = {2005}
}
@book{fowler2018refactoring,
author = {Fowler, Martin},
publisher = {Addison-Wesley Professional},
title = {{Refactoring: improving the design of existing code}},
year = {2018}
}
@article{Chen2016,
abstract = {Third-party libraries are an integral part of many software projects. It often happens that developers need to find analogical libraries that can provide comparable features to the libraries they are already familiar with. Existing methods to find analogical libraries are limited by the community-curated list of libraries, blogs, or Q{\&}A posts, which often contain overwhelming or out-of-date information. In this paper, we present a new approach to recommend analogical libraries based on a knowledge base of analogical libraries mined from tags of millions of Stack Overflow questions. The novelty of our approach is to solve analogical-libraries questions by combining state-of-the-art word embedding technique and domain-specific relational and categorical knowledge mined from Stack Overflow. We implement our approach in a proof-of-concept web application (https://graphofknowledge.appspot.com/similartech). The evaluation results show that our approach can make accurate recommendation of analogical libraries (Precision@1=0.81 and Precision@5=0.67). Google Analytics of the website traffic provides initial evidence of the potential usefulness of our web application for software developers.},
author = {Chen, Chunyang and Gao, Sa and Xing, Zhenchang},
doi = {10.1109/saner.2016.21},
file = {::},
isbn = {9781509018550},
keywords = {-analogical libraries,categorical knowledge,graph,knowledge,relational knowledge,word embedding},
pages = {338--348},
publisher = {IEEE},
title = {{Mining Analogical Libraries in Q{\&}A Discussions -- Incorporating Relational and Categorical Knowledge into Word Embedding}},
year = {2016}
}
@book{Bishop2006,
author = {Bishop, Christopher M.},
publisher = {Springer Verlag},
title = {{Pattern Recognition and Machine Learning (Information Science and Statistics)}},
year = {2006}
}
@article{Vassallo2018a,
abstract = {Continuous Integration (CI) is a software engineering practice where developers constantly integrate their changes to a project through an automated build process. The goal of CI is to provide developers with prompt feedback on several quality dimensions after each change. Indeed, previous studies provided empirical evidence on a positive association between properly following CI principles and source code quality. A core principle behind CI is Continuous Code Quality (also known as CCQ, which includes automated testing and automated code inspection) may appear simple and effective, yet we know little about its practical adoption. In this paper, we propose a preliminary empirical investigation aimed at understanding how rigorously practitioners follow CCQ. Our study reveals a strong dichotomy between theory and practice: developers do not perform continuous inspection but rather control for quality only at the end of a sprint and most of the times only on the release branch. Preprint [https://doi.org/10.5281/zenodo.1341036]. Data and Materials [http://doi.org/10.5281/zenodo.1341015].},
author = {Vassallo, Carmine and Bacchelli, Alberto and Palomba, Fabio and Gall, Harald C.},
doi = {10.1145/3238147.3240729},
file = {::},
isbn = {9781450359375},
journal = {ASE 2018 - Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
keywords = {Code Quality,Continuous Integration,Empirical Studies},
pages = {790--795},
title = {{Continuous code quality: Are we (really) doing that?}},
year = {2018}
}
@article{Zhang2018b,
abstract = {Explainable recommendation attempts to develop models that generate not only high-quality recommendations but also intuitive explanations. The explanations may either be post-hoc or directly come from an explainable model. Explainable recommendation tries to address the problem of why: by providing explanations to users or system designers, it helps humans to understand why certain items are recommended by the algorithm, where the human can either be users or system designers. Explainable recommendation helps to improve the transparency, persuasiveness, effectiveness, trustworthiness, and satisfaction of recommendation systems. It also facilitates system designers for better system debugging. In recent years, a large number of explainable recommendation approaches -- especially model-based methods -- have been proposed and applied in real-world systems. In this survey, we provide a comprehensive review for the explainable recommendation research. We highlight the position of explainable recommendation in recommender system research by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation on three perspectives: 1) We provide a chronological research timeline of explainable recommendation, including user study approaches in the early years and more recent model-based approaches. 2) We provide a two-dimensional taxonomy to classify existing explainable recommendation research: one dimension is the information source of the explanations, and the other dimension is the algorithmic mechanism to generate explainable recommendations. 3) We summarize how explainable recommendation applies to different recommendation tasks, such as product, social, and POI recommendations. We also devote a section to discuss the future directions to promote the explainable recommendation research.},
archivePrefix = {arXiv},
arxivId = {1804.11192},
author = {Zhang, Yongfeng and Chen, Xu},
eprint = {1804.11192},
file = {::},
number = {Xx},
pages = {1--100},
title = {{Explainable Recommendation: A Survey and New Perspectives}},
url = {http://arxiv.org/abs/1804.11192},
volume = {XX},
year = {2018}
}
@article{Gneiting2007a,
abstract = {Probabilistic forecasts of continuous variables take the form of predictive densities or predictive cumulative distribution functions. We propose a diagnostic approach to the evaluation of predictive performance that is based on the paradigm of maximizing the sharpness of the predictive distributions subject to calibration. Calibration refers to the statistical consistency between the distributional forecasts and the observations and is a joint property of the predictions and the events that materialize. Sharpness refers to the concentration of the predictive distributions and is a property of the forecasts only. A simple theoretical framework allows us to distinguish between probabilistic calibration, exceedance calibration and marginal calibration. We propose and study tools for checking calibration and sharpness, among them the probability integral transform histogram, marginal calibration plots, the sharpness diagram and proper scoring rules. The diagnostic approach is illustrated by an assessment and ranking of probabilistic forecasts of wind speed at the Stateline wind energy centre in the US Pacific Northwest. In combination with cross-validation or in the time series context, our proposal provides very general, nonparametric alternatives to the use of information criteria for model diagnostics and model selection. {\textcopyright} 2007 Royal Statistical Society.},
author = {Gneiting, Tilmann and Balabdaoui, Fadoua and Raftery, Adrian E.},
doi = {10.1111/j.1467-9868.2007.00587.x},
file = {::},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Cross-validation,Density forecast,Ensemble prediction system,Ex post evaluation,Forecast verification,Model diagnostics,Posterior predictive assessment,Predictive distribution,Prequential principle,Probability integral transform,Proper scoring rule},
number = {2},
pages = {243--268},
title = {{Probabilistic forecasts, calibration and sharpness}},
volume = {69},
year = {2007}
}
@article{Boogerd2008,
abstract = {In spite of the widespread use of coding standards and tools enforcing their rules, there is little empirical evidence supporting the intuition that they prevent the introduction of faults in software. Not only can compliance with a set of rules having little impact on the number of faults be considered wasted effort, but it can actually result in an increase in faults, as any modification has a non-zero probability of introducing a fault or triggering a previously concealed one. Therefore, it is important to build a body of empirical knowledge, helping us understand which rules are worthwhile enforcing, and which ones should be ignored in the context of fault reduction. In this paper, we describe two approaches to quantify the relation between rule violations and actual faults, and present empirical data on this relation for the MISRA C 2004 standard on an industrial case study. {\textcopyright} 2008 IEEE.},
author = {Boogerd, Cathal and Moonen, Leon},
doi = {10.1109/ICSM.2008.4658076},
file = {::},
isbn = {9781424426140},
journal = {IEEE International Conference on Software Maintenance, ICSM},
pages = {277--286},
title = {{Assessing the value of coding standards: An empirical study}},
year = {2008}
}
@article{Vaicenavicius2019,
abstract = {Probabilistic classifiers output a probability distribution on target classes rather than just a class prediction. Besides providing a clear separation of prediction and decision making, the main advantage of probabilistic models is their ability to represent uncertainty about predictions. In safety-critical applications, it is pivotal for a model to possess an adequate sense of uncertainty, which for probabilistic classifiers translates into outputting probability distributions that are consistent with the empirical frequencies observed from realized outcomes. A classifier with such a property is called calibrated. In this work, we develop a general theoretical calibration evaluation framework grounded in probability theory, and point out subtleties present in model calibration evaluation that lead to refined interpretations of existing evaluation techniques. Lastly, we propose new ways to quantify and visualize miscalibration in probabilistic classification, including novel multidimensional reliability diagrams.},
archivePrefix = {arXiv},
arxivId = {1902.06977},
author = {Vaicenavicius, Juozas and Widmann, David and Andersson, Carl and Lindsten, Fredrik and Roll, Jacob and Sch{\"{o}}n, Thomas B.},
eprint = {1902.06977},
file = {::},
title = {{Evaluating model calibration in classification}},
url = {http://arxiv.org/abs/1902.06977},
volume = {89},
year = {2019}
}
@article{Fowler2002_refactoring,
abstract = {Almost every expert in Object-Oriented Development stresses the importance of iterative development. As you proceed with the iterative development, you need to add function to the existing code base. If you are really lucky that code base is structured just right to support the new function while still preserving its design integrity. Of course most of the time we are not lucky, the code does not quite fit what we want to do. You could just add the function on top of the code base. But soon this leads to applying patch upon patch making your system more complex than it needs to be. This complexity leads to bugs, and cripples your productivity.},
author = {Fowler, Martin},
doi = {10.1007/3-540-45672-4_31},
file = {::},
isbn = {3540440240},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
title = {{Refactoring: Improving the design of existing code}},
volume = {2418},
year = {2002}
}
@article{Zaharia2018,
abstract = {Machine learning development creates multiple new challenges that are not present in a traditional software development lifecycle. These include keeping track of the myriad inputs to an ML application (e.g., data versions, code and tuning parameters), reproducing results, and production deployment. In this paper, we summarize these challenges from our experience with Databricks customers, and describe MLflow, an open source platform we recently launched to streamline the machine learning lifecycle. MLflow covers three key challenges: experimentation, reproducibility, and model deployment, using generic APIs that work with any ML library, algorithm and programming language. The project has a rapidly growing open source community, with over 50 contributors since its launch in June 2018.},
author = {Zaharia, Matei and Chen, Andrew and Davidson, Aaron and Ghodsi, Ali and Hong, Sue Ann and Konwinski, Andy and Murching, Siddharth and Nykodym, Tomas and Ogilvie, Paul and Parkhe, Mani and Xie, Fen and Zumar, Corey},
journal = {Bulletin of the IEEE Computer Society Technical Committee on Data Engineering},
pages = {39--45},
title = {{Accelerating the Machine Learning Lifecycle with MLflow}},
url = {https://people.eecs.berkeley.edu/{~}alig/papers/mlflow.pdf},
year = {2018}
}
@article{Angela2014,
author = {Angela, J Yu},
file = {::},
journal = {The Oxford Handbook of Attention},
title = {{Bayesian Models of Attention}},
year = {2014}
}
@article{Kovalenko2020,
archivePrefix = {arXiv},
arxivId = {2002.03997},
author = {Kovalenko, Vladimir and Bogomolov, Egor and Bryksin, Timofey and Bacchelli, Alberto},
eprint = {2002.03997},
file = {::},
keywords = {Interpretability,Point-wise explanations,Ranking},
title = {{Building Implicit Vector Representations of Individual Coding Style}},
year = {2020}
}
@article{Syntetos2009,
abstract = {Forecasting and planning for inventory management has received considerable attention from the Operational Research (OR) community over the last 50 years because of its implications for decision making, both at the strategic level of an organization and at the operational level. Many influential contributions have been made in this area, reflecting different perspectives that have evolved in divergent strands of the literature, namely: system dynamics, control theory and forecasting theory (both statistical and judgemental). Although this pluralism is healthy in terms of knowledge advancement, it also signifies the fragmentation of the OR discipline and the lack of cross-fertilization of ideas to develop more comprehensive approaches towards the resolution of the same issues. In this paper, the relevant literature is reviewed and synthesized to promote some convergence between these different approaches to inventory forecasting and planning. The review concludes with an inter-disciplinary agenda for further research.},
author = {Syntetos, A. A. and Boylan, J. E. and Disney, S. M.},
doi = {10.1057/jors.2008.173},
file = {::},
issn = {01605682},
journal = {Journal of the Operational Research Society},
keywords = {Control theory,Forecasting,Inventory management,System dynamics},
number = {SUPPL. 1},
title = {{Forecasting for inventory planning: A 50-year review}},
volume = {60},
year = {2009}
}
@book{preece_book,
author = {Preece, J and Rogers, Y and Sharp, H},
publisher = {Wiley},
title = {{Interaction Design: Beyond Human Computer Interaction}},
year = {2015}
}
@article{Phelan2019,
abstract = {Bayesian statistical analysis has gained attention in recent years, including in HCI. The Bayesian approach has several advantages over traditional statistics, including producing results with more intuitive interpretations. Despite growing interest, few papers in CHI use Bayesian analysis. Existing tools to learn Bayesian statistics require significant time investment, making it difficult to casually explore Bayesian methods. Here, we present a tool that lowers the barrier to exploration: a set of R code templates that guide Bayesian novices through their first analysis. The templates are tailored to CHI, supporting analyses found to be most common in recent CHI papers. In a user study, we found that the templates were easy to understand and use. However, we found that participants without a statistical background were not confident in their use. Together our contributions provide a concise analysis tool and empirical results for understanding and addressing barriers to using Bayesian analysis in HCI.},
author = {Phelan, Chanda and Hullman, Jessica and Kay, Matthew and Resnick, Paul},
doi = {10.1145/3290605.3300709},
file = {::},
isbn = {9781450359702},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Bayesian statistics,Code templates,Evaluation,Hypothesis testing,Statistics,Tutorials},
pages = {1--12},
title = {{Some prior(s) experience necessary templates for getting started with Bayesian analysis}},
year = {2019}
}
@article{Isaak2018,
abstract = {With the revelation that Facebook handed over personally identifiable information of more than 87 million users to Cambridge Analytica, it is now imperative that comprehensive privacy policy laws be developed. Technologists, researchers, and innovators should meaningfully contribute to the development of these policies.},
author = {Isaak, Jim and Hanna, Mina J.},
doi = {10.1109/MC.2018.3191268},
file = {::},
issn = {15580814},
journal = {Computer},
keywords = {Cambridge Analytica,Facebook,Internet/Web technologies,PII,The Policy Corner,cybercrime,data privacy,data security,online security,personally identifiable information,privacy,privacy protection,security,social media,user data privacy},
number = {8},
pages = {56--59},
publisher = {IEEE},
title = {{User Data Privacy: Facebook, Cambridge Analytica, and Privacy Protection}},
volume = {51},
year = {2018}
}
@inproceedings{Best2014,
address = {Sydney, Australia},
author = {Best, Christopher and Jia, Dawei and Simpkin, Graeme},
booktitle = {NATO STO MSG 111 Multi-Workshop, Sydney, Australia},
file = {::},
title = {{Air Force Synthetic Training Effectiveness Research in the Australian Context}},
url = {https://www.sto.nato.int/publications/STO Meeting Proceedings/STO-MP-MSG-111/MP-MSG-111-16.pdf},
year = {2014}
}
@article{Shannon1948,
author = {Shannon, C. E.},
doi = {10.1002/j.1538-7305.1948.tb00917.x},
file = {::},
issn = {15387305},
journal = {Bell System Technical Journal},
number = {4},
pages = {623--656},
title = {{A Mathematical Theory of Communication}},
volume = {27},
year = {1948}
}
@article{Katz2017,
abstract = {—Feature generation is one of the challenging aspects of machine learning. We present ExploreKit, a framework for automated feature generation. ExploreKit generates a large set of candidate features by combining information in the original features, with the aim of maximizing predictive performance according to user-selected criteria. To overcome the exponential growth of the feature space, ExploreKit uses a novel ma-chine learning-based feature selection approach to predict the usefulness of new candidate features. This approach enables efficient identification of the new features and produces superior results compared to existing feature selection solutions. We demonstrate the effectiveness and robustness of our approach by conducting an extensive evaluation on 25 datasets and 3 different classification algorithms. We show that ExploreKit can achieve classification-error reduction of 20{\%} overall. Our code is available at https://github.com/giladkatz/ExploreKit.},
author = {Katz, Gilad and Shin, Eui Chul Richard and Song, Dawn},
doi = {10.1109/ICDM.2016.176},
file = {::},
isbn = {9781509054725},
issn = {15504786},
journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
pages = {979--984},
publisher = {IEEE},
title = {{ExploreKit: Automatic feature generation and selection}},
year = {2017}
}
@article{Pearl2019,
abstract = {THE DRAMATIC SUCCESS In machine learning has led to an explosion of artificial intelligence (AI) applications and increasing expectations for autonomous systems that exhibit human-level intelligence. These expectations have, however, met with fundamental obstacles that cut across many application areas. One such obstacle is adaptability, or robustness. Machine learning researchers have noted current systems lack the ability to recognize or react to new circumstances they have not been specifically programmed or trained for.},
author = {Pearl, Judea},
doi = {10.1145/3241036},
file = {::},
issn = {15577317},
journal = {Communications of the ACM},
number = {3},
pages = {54--60},
title = {{The seven tools of causal inference, with reflections on machine learning}},
volume = {62},
year = {2019}
}
@article{VanJaarsveld2011,
abstract = {In this paper obsolescence of service parts is analyzed in a practical environment. Based on the analysis, we propose a method that can be used to estimate the risk of obsolescence of service parts, which is subsequently used to enhance inventory control for those parts. The method distinguishes groups of service parts. For these groups, the risk of obsolescence is estimated using the behavior of similar groups of service parts in the past. The method uses demand data as main information source, and can therefore be applied without the use of an expert's opinion. We will give numerical values for the risk of obsolescence obtained with the method, and the effects of these values on inventory control will be examined. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
annote = {Assumptions:
- high price
- long life-cycle
- consist of many parts

i.e. automobiles, aircrafts, etc.},
author = {{Van Jaarsveld}, Willem and Dekker, Rommert},
doi = {10.1016/j.ijpe.2010.06.014},
file = {::},
issn = {09255273},
journal = {International Journal of Production Economics},
keywords = {Case study,Inventory control,Obsolescence,Spare parts,Sudden death},
number = {1},
pages = {423--431},
title = {{Estimating obsolescence risk from demand data to enhance inventory control - A case study}},
volume = {133},
year = {2011}
}
@inproceedings{Shamim2016,
abstract = {{\textcopyright} 2016 IEEE. Epileptic seizures are recurring brief episodes of abnormal excessive or synchronous neuronal activity in the brain, and are often accompanied by changes in various autonomic functions like heart rate (HR). A better approach for detecting epileptic seizures is by using electrocardiogram (ECG) signals because ECG acquisition is relatively easier as compared to EEG. In this paper a new technique is proposed for detection of seizures in epileptic patients using the electrocardiogram (ECG) signal. Feature sets for analysis of HRV (heart rate variability) comprises of parameters from multiple domains. For temporal analysis activity, mobility and complexity features are identified and for spectral analysis mean of absolute deviation of Fast Fourier Transform coefficients and spectral entropy are identified for seizure detection. These features are classified by using two different approaches i.e. by setting threshold and by using linear support vector machine where average latency by threshold approach was found to be better than linear SVM. The performance parameters for the proposed technique using threshold approach for classification are accuracy (94.2{\%}), sensitivity (84.1{\%}) and specificity (94.5{\%}) which shows that the proposed algorithm detects epileptic seizures efficiently. Comparison of performance of this model was done with those proposed earlier using ECG signal and this model was found to be better.},
author = {Shamim, Gulezar and Khan, Yusuf Uzzaman and Sarfraz, Mohammad and Farooq, Omar},
booktitle = {2016 International Conference on Signal Processing and Communication, ICSC 2016},
doi = {10.1109/ICSPCom.2016.7980585},
isbn = {9781509026845},
keywords = {Classification,Feature extraction,Heart rate variability,Performance evaluation,Seizure},
pages = {250--254},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Epileptic seizure detection using heart rate variability}},
year = {2016}
}
@article{Hong2016,
abstract = {We propose thresholding as an approach to deal with class imbalance. We define the concept of thresholding as a process of determining a decision boundary in the presence of a tunable parameter. The threshold is the maximum value of this tunable parameter where the conditions of a certain decision are satisfied. We show that thresholding is applicable not only for linear classifiers but also for non-linear classifiers. We show that this is the implicit assumption for many approaches to deal with class imbalance in linear classifiers. We then extend this paradigm beyond linear classification and show how non-linear classification can be dealt with under this umbrella framework of thresholding. The proposed method can be used for outlier detection in many real-life scenarios like in manufacturing. In advanced manufacturing units, where the manufacturing process has matured over time, the number of instances (or parts) of the product that need to be rejected (based on a strict regime of quality tests) becomes relatively rare and are defined as outliers. How to detect these rare parts or outliers beforehand? How to detect combination of conditions leading to these outliers? These are the questions motivating our research. This paper focuses on prediction of outliers and conditions leading to outliers using classification. We address the problem of outlier detection using classification. The classes are good parts (those passing the quality tests) and bad parts (those failing the quality tests and can be considered as outliers). The rarity of outliers transforms this problem into a class-imbalanced classification problem.},
annote = {Provides a good introduction for working on a paper that is part of an industry case study with experiments.},
archivePrefix = {arXiv},
arxivId = {1607.02705},
author = {Hong, Charmgil and Ghosh, Rumi and Srinivasan, Soundar},
doi = {10.475/123},
eprint = {1607.02705},
file = {::},
isbn = {1234567245},
keywords = {class imbalance,classification,decision trees,scrap detection},
title = {{Dealing with Class Imbalance using Thresholding}},
url = {http://arxiv.org/abs/1607.02705},
volume = {1},
year = {2016}
}
@article{Hong2016a,
abstract = {We propose thresholding as an approach to deal with class imbalance. We define the concept of thresholding as a process of determining a decision boundary in the presence of a tunable parameter. The threshold is the maximum value of this tunable parameter where the conditions of a certain decision are satisfied. We show that thresholding is applicable not only for linear classifiers but also for non-linear classifiers. We show that this is the implicit assumption for many approaches to deal with class imbalance in linear classifiers. We then extend this paradigm beyond linear classification and show how non-linear classification can be dealt with under this umbrella framework of thresholding. The proposed method can be used for outlier detection in many real-life scenarios like in manufacturing. In advanced manufacturing units, where the manufacturing process has matured over time, the number of instances (or parts) of the product that need to be rejected (based on a strict regime of quality tests) becomes relatively rare and are defined as outliers. How to detect these rare parts or outliers beforehand? How to detect combination of conditions leading to these outliers? These are the questions motivating our research. This paper focuses on prediction of outliers and conditions leading to outliers using classification. We address the problem of outlier detection using classification. The classes are good parts (those passing the quality tests) and bad parts (those failing the quality tests and can be considered as outliers). The rarity of outliers transforms this problem into a class-imbalanced classification problem.},
archivePrefix = {arXiv},
arxivId = {1607.02705},
author = {Hong, Charmgil and Ghosh, Rumi and Srinivasan, Soundar},
doi = {10.475/123},
eprint = {1607.02705},
file = {::},
isbn = {1234567245},
keywords = {class imbalance,classification,decision trees,scrap detection},
title = {{Dealing with Class Imbalance using Thresholding}},
url = {http://arxiv.org/abs/1607.02705},
volume = {1},
year = {2016}
}
@article{Alshangiti2019,
abstract = {As smart and automated applications pervade our lives, an increasing number of software developers are required to incorporate machine learning (ML) techniques into application development. However, acquiring the ML skill set can be nontrivial for software developers owing to both the breadth and depth of the ML domain. Aims: We seek to understand the challenges developers face in the process of ML application development and offer insights to simplify the process. Despite its importance, there has been little research on this topic. A few existing studies on development challenges with ML are outdated, small scale, or they do no involve a representative set of developers. Method: We conduct an empirical study of ML-related developer posts on Stack Overflow. We perform in-depth quantitative and qualitative analyses focusing on a series of research questions related to the challenges of developing ML applications and the directions to address them. Results: Our findings include: (1) ML questions suffer from a much higher percentage of unanswered questions on Stack Overflow than other domains; (2) there is a lack of ML experts in the Stack Overflow QA community; (3) the data preprocessing and model deployment phases are where most of the challenges lay; and (4) addressing most of these challenges require more ML implementation knowledge than ML conceptual knowledge. Conclusions: Our findings suggest that most challenges are under the data preparation and model deployment phases, i.e., early and late stages. Also, the implementation aspect of ML shows much higher difficulty level among developers than the conceptual aspect.},
annote = {An empirical study on ML related SO posts 
Following are the problems in ML related Stack Overflow posts
A higher percentage of questions suffer from no accepted answer and no response compared to other domains in SO; ML questions take ten times longer to be answered than the typical SO question on average and there is a lack of ML experts in SO community},
author = {Alshangiti, Moayad and Sapkota, Hitesh and Murukannaiah, Pradeep K. and Liu, Xumin and Yu, Qi},
doi = {10.1109/ESEM.2019.8870187},
file = {::},
isbn = {9781728129686},
issn = {19493789},
journal = {International Symposium on Empirical Software Engineering and Measurement},
keywords = {Data Mining,Machine Learning,Software Development,Stack Overflow},
title = {{Why is Developing Machine Learning Applications Challenging? A Study on Stack Overflow Posts}},
volume = {2019-Septe},
year = {2019}
}
@article{tan2018introduction,
author = {Tan, Pang-Ning and Steinbach, Michael and Karpatne, Anuj and Kumar, Vipin},
publisher = {Pearson},
title = {{Introduction to Data Mining}},
year = {2018}
}
@article{Osman2019,
author = {Osman, Ahmed Hamza and Alzahrani, Ahmad A.},
doi = {10.1109/ACCESS.2018.2886608},
file = {::},
issn = {21693536},
journal = {IEEE Access},
keywords = {Epilepsy disease,RBF,SOM,classification,neural network},
pages = {4741--4747},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{New Approach for Automated Epileptic Disease Diagnosis Using an Integrated Self-Organization Map and Radial Basis Function Neural Network Algorithm}},
volume = {7},
year = {2019}
}
@article{Bafatakis2019,
abstract = {Software developers all over the world use Stack Overflow (SO) to interact and exchange code snippets. Research also uses SO to harvest code snippets for use with recommenda- tion systems. However, previous work has shown that code on SO may have quality issues, such as security or license problems. We analyse Python code on SO to determine its coding style compliance. From 1,962,535 code snippets tagged with ‘python', we extracted 407,097 snippets of at least 6 statements of Python code. Surprisingly, 93.87{\%} of the extracted snippets contain style violations, with an average of 0.7 violations per statement and a huge number of snippets with a considerably higher ratio. Researchers and developers should, therefore, be aware that code snippets on SO may not representative of good coding style. Furthermore, while user reputation seems to be unrelated to coding style compliance, for posts with vote scores in the range between -10 and 20, we found a strong correlation (r = −0.87, p {\textless} 10−7) between the vote score a post received and the average number of violations per statement for snippets in such posts.},
author = {Bafatakis, Nikolaos and Boecker, Niels and Boon, Wenjie and Salazar, Martin Cabello and Krinke, Jens and Oznacar, Gazi and White, Robert},
doi = {10.1109/MSR.2019.00042},
file = {::},
journal = {In Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {210--214},
title = {{Python Coding Style Compliance on Stack Overflow}},
year = {2019}
}
@inproceedings{Barnett2015b,
abstract = {Modern IDEs provide limited support for developers when starting a new data-driven mobile app. App developers are currently required to write copious amounts of boilerplate code, scripts, organise complex directories, and author actual functionality. Although this scenario is ripe for automation, current tools are yet to address it adequately. In this paper we present RAPPT, a tool that generates the scaffolding of a mobile app based on a high level description specified in a Domain Specific Language (DSL). We demonstrate the feasibility of our approach by an example case study and feedback from a professional development team. Demo at: https://www.youtube.com/watch?v=ffquVgBYpLM.},
author = {Barnett, Scott and Vasa, Rajesh and Grundy, John},
booktitle = {2015 IEEE/ACM 37th IEEE International Conference on Software Engineering},
doi = {10.1109/ICSE.2015.216},
isbn = {978-1-4799-1934-5},
month = {may},
pages = {657--660},
publisher = {IEEE},
title = {{Bootstrapping Mobile App Development}},
url = {http://ieeexplore.ieee.org/document/7203036/},
year = {2015}
}
@inproceedings{Ma2018,
abstract = {With the increasing popularity of open-source software development, there is a tremendous growth of software artifacts that provide insight into how people build software. Researchers are always looking for large-scale and representative software artifacts to produce systematic and unbiased validation of novel and existing techniques. For example, in the domain of software requirements traceability, researchers often use software applications with multiple types of artifacts, such as requirements, system elements, verifications, or tasks to develop and evaluate their traceability analysis techniques. However, the manual identification of rich software artifacts is very labor-intensive. In this work, we first conduct a large-scale study to identify which types of software artifacts are produced by a wide variety of open-source projects at different levels of granularity. Then we propose an automated approach based on Machine Learning techniques to identify various types of software artifacts. Through a set of experiments, we report and compare the performance of these algorithms when applied to software artifacts. {\textcopyright} 2018 ACM.},
author = {Ma, Yuzhan and Fakhoury, Sarah and Christensen, Michael and Arnaoudova, Venera and Zogaan, Waleed and Mirakhorli, Mehdi},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1145/3196398.3196446},
file = {::},
isbn = {9781450357166},
issn = {02705257},
keywords = {machine learning,open-source software,software artifacts},
month = {may},
pages = {414--425},
publisher = {IEEE Computer Society},
title = {{Automatic classification of software artifacts in open-source applications}},
year = {2018}
}
@article{Abdul,
abstract = {Advances in artificial intelligence, sensors and big data management have far-reaching societal impacts. As these systems augment our everyday lives, it becomes increasingly important for people to understand them and remain in control. We investigate how HCI researchers can help to develop accountable systems by performing a literature analysis of 289 core papers on explanations and explainable systems, as well as 12,412 citing papers. Using topic modeling, co-occurrence and network analysis, we mapped the research space from diverse domains, such as algorithmic accountability , interpretable machine learning, context-awareness, cognitive psychology, and software learnability. We reveal fading and burgeoning trends in explainable systems, and identify domains that are closely connected or mostly isolated. The time is ripe for the HCI community to ensure that the powerful new autonomous systems have intelligible interfaces built-in. From our results, we propose several implications and directions for future research towards this goal.},
author = {Abdul, Ashraf and Vermeulen, Jo and Wang, Danding and Lim, Brian Y and Kankanhalli, Mohan},
doi = {10.1145/3173574.3174156},
file = {::},
isbn = {9781450356206},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Explainable artificial intelligence,Intelligibility,explanations,interpretable machine learning.},
title = {{Trends and Trajectories for Explainable, Accountable and Intelligible Systems: An HCI Research Agenda}},
url = {https://doi.org/10.1145/3173574.3174156},
year = {2018}
}
@inproceedings{DeLucia2012,
abstract = {Information Retrieval (IR) techniques have been used for various software engineering tasks, including the labeling of software artifacts by extracting "keywords" from them. Such techniques include Vector Space Models, Latent Semantic Indexing, Latent Dirichlet Allocation, as well as customized heuristics extracting words from specific source code elements. This paper investigates how source code artifact labeling performed by IR techniques would overlap (and differ) from labeling performed by humans. This has been done by asking a group of subjects to label 20 classes from two Java software systems, JHotDraw and eXVantage. Results indicate that, in most cases, automatic labeling would be more similar to human-based labeling if using simpler techniques - e.g., using words from class and method names - that better reflect how humans behave. Instead, clustering-based approaches (LSI and LDA) are much more worthwhile to be used on source code artifacts having a high verbosity, as well as for artifacts requiring more effort to be manually labeled. {\textcopyright} 2012 IEEE.},
author = {{De Lucia}, Andrea and {Di Penta}, Massimiliano and Oliveto, Rocco and Panichella, Annibale and Panichella, Sebastiano},
booktitle = {IEEE International Conference on Program Comprehension},
doi = {10.1109/ICPC.2012.6240488},
file = {::},
isbn = {9781467312165},
keywords = {Empirical Studies,Information Retrieval,Latent Dirichlet Allocation,Topic Extraction},
pages = {193--202},
publisher = {IEEE},
title = {{Using IR methods for labeling source code artifacts: Is it worthwhile?}},
year = {2012}
}
@article{Dobslaw,
archivePrefix = {arXiv},
arxivId = {arXiv:2001.06652v1},
author = {Dobslaw, Felix and Gomes, Francisco and Neto, De Oliveira and Feldt, Robert},
eprint = {arXiv:2001.06652v1},
file = {::},
pages = {1--8},
title = {{Boundary Value Exploration for Software Analysis}}
}
@misc{Pylint,
author = {Pylint},
title = {{Pylint - code analysis for Python | www.pylint.org}},
url = {https://www.pylint.org/},
urldate = {2019-12-02}
}
@article{Ghani2019,
abstract = {Big data analytics has recently emerged as an important research area due to the popularity of the Internet and the advent of the Web 2.0 technologies. Moreover, the proliferation and adoption of social media applications have provided extensive opportunities and challenges for researchers and practitioners. The massive amount of data generated by users using social media platforms is the result of the integration of their background details and daily activities. This enormous volume of generated data known as “big data” has been intensively researched recently. A review of the recent works is presented to obtain a broad perspective of the social media big data analytics research topic. We classify the literature based on important aspects. This study also compares possible big data analytics techniques and their quality attributes. Moreover, we provide a discussion on the applications of social media big data analytics by highlighting the state-of-the-art techniques, methods, and the quality attributes of various studies. Open research challenges in big data analytics are described as well.},
author = {Ghani, Norjihan Abdul and Hamid, Suraya and {Targio Hashem}, Ibrahim Abaker and Ahmed, Ejaz},
doi = {10.1016/j.chb.2018.08.039},
file = {::},
issn = {07475632},
journal = {Computers in Human Behavior},
number = {August 2018},
pages = {417--428},
title = {{Social media big data analytics: A survey}},
volume = {101},
year = {2019}
}
@article{Liao,
author = {Liao, Q Vera and Muller, Michael},
file = {::},
journal = {Proceedings of the 24th International Conference on Intelligent User Interfaces},
keywords = {a specialized,agents,artificial intelligence,extensive training nor mastering,human in,human-ai collaboration,machine learning,so that model development,the loop,will no longer require},
title = {{Human-AI Collaboration : Towards Socially-Guided Machine Learning}},
year = {2019}
}
@inproceedings{Cummaudo:2019icsme,
abstract = {Recent advances in artificial intelligence (AI) and machine learning (ML), such as computer vision, are now available as intelligent services and their accessibility and simplicity is compelling. Multiple vendors now offer this technology as cloud services and developers want to leverage these advances to provide value to end-users. However, there is no firm investigation into the maintenance and evolution risks arising from use of these intelligent services; in particular, their behavioural consistency and transparency of their functionality. We evaluated the responses of three different intelligent services (specifically computer vision) over 11 months using 3 different data sets, verifying responses against the respective documentation and assessing evolution risk. We found that there are: (1) inconsistencies in how these services behave; (2) evolution risk in the responses; and (3) a lack of clear communication that documents these risks and inconsistencies. We propose a set of recommendations to both developers and intelligent service providers to inform risk and assist maintainability.},
address = {Cleveland, OH, USA},
author = {Cummaudo, Alex and Vasa, Rajesh and Grundy, John and Abdelrazek, Mohamed and Cain, Andrew},
booktitle = {Proceedings of the 35th IEEE International Conference on Software Maintenance and Evolution},
doi = {10.1109/ICSME.2019.00051},
isbn = {978-1-72-813094-1},
month = {dec},
pages = {333--342},
publisher = {IEEE},
title = {{Losing Confidence in Quality: Unspoken Evolution of Computer Vision Services}},
year = {2019}
}
@article{Harper2019,
abstract = {This article examines some of the mystique surrounding AI, including the interrelated notions of explainability and complexity, and argues that these notions suggest that designing human-centered AI is difficult. It explains how, once these are put aside, an HCI perspective can help define interaction between AI and users that can enhance rather than substitute one important aspect of human life: creativity. Key to developing such creative interactions are abstractions and grammars of action and other notions; the article explores the history of these in HCI and how they are to be used in the contemporary interaction and design space, in relation to AI. The article is programmatic rather than empirical though its argument uses real-world examples.},
author = {Harper, Richard H.R.},
doi = {10.1080/10447318.2019.1631527},
file = {::},
issn = {15327590},
journal = {International Journal of Human-Computer Interaction},
title = {{The Role of HCI in the Age of AI}},
volume = {7318},
year = {2019}
}
@article{Smit,
abstract = {Maintainability is a desirable property of software, and a variety of metrics have been proposed for measuring it, all based on different notions of complexity. Although these metrics are useful, complexity is only one factor influencing maintainability. Practical experience in software development has led to a set of best practices and coding conventions that are believed to make source code easier to read, understand and maintain. Based on a survey of software engineers, we identify the relative importance of 71 coding conventions to maintainability. We propose a metric that offers a different perspective on maintenance, namely a "convention adherence" metric based on the number and severity of violations of these coding conventions. We examine the code repositories of four open-source Java projects to measure their adherence to coding conventions over the life of the project, based on both their self-identified conventions and those of the convention-adherence metric. Through our analysis, we discovered several interesting phenomena, including pre-release effort to bring new code in line with desirable conventions, effective usage of automated code convention checkers as part of the build process to improve adherence, variations in adherence over the software lifecycle, and a class of conventions consistently ignored in open source projects.},
author = {Smit, Michael and Gergel, Barry and Hoover, HJ and Stroulia, Eleni},
file = {::},
journal = {Cs.Ualberta.Ca},
pages = {1--10},
title = {{Maintainability and Source Code Conventions: An Analysis of Open Source Projects}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Maintainability+and+Source+Code+Conventions+:+An+Analysis+of+Open+Source+Projects{\#}0}
}
@inproceedings{Gousios2013,
abstract = {During the last few years, GitHub has emerged as a popular project hosting, mirroring and collaboration platform. GitHub provides an extensive REST API, which enables researchers to retrieve high-quality, interconnected data. The GHTorent project has been collecting data for all public projects available on Github for more than a year. In this paper, we present the dataset details and construction process and outline the challenges and research opportunities emerging from it. {\textcopyright} 2013 IEEE.},
author = {Gousios, Georgios},
booktitle = {2013 10th Working Conference on Mining Software Repositories (MSR)},
doi = {10.1109/MSR.2013.6624034},
file = {::},
isbn = {978-1-4673-2936-1},
issn = {21601852},
keywords = {Dataset,GitHub,Repository},
month = {may},
pages = {233--236},
publisher = {IEEE},
title = {{The GHTorent dataset and tool suite}},
url = {http://ieeexplore.ieee.org/document/6624034/},
year = {2013}
}
@article{Rivera-Villicana2019,
abstract = {In this paper we present an early Apprenticeship Learning approach to mimic the behaviour of different players in a short adaption of the interactive fiction Anchorhead. Our motivation is the need to understand and simulate player behaviour to create systems to aid the design and person-alisation of Interactive Narratives (INs). INs are partially observable for the players and their goals are dynamic as a result. We used Receding Horizon IRL (RHIRL) to learn players' goals in the form of reward functions, and derive policies to imitate their behaviour. Our preliminary results suggest that RHIRL is able to learn action sequences to complete a game, and provided insights towards generating behaviour more similar to specific players.},
archivePrefix = {arXiv},
arxivId = {1909.07268},
author = {Rivera-Villicana, Jessica and Zambetta, Fabio and Harland, James and Berry, Marsha},
doi = {10.1145/3341215.3356314},
eprint = {1909.07268},
file = {::},
isbn = {9781450368711},
journal = {CHI PLAY 2019 - Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play},
keywords = {Anchorhead,Apprenticeship Learning,Interactive Narratives,Inverse Reinforcement Learning,Player Modelling},
pages = {645--652},
title = {{Exploring apprenticeship learning for player modelling in interactive narratives}},
year = {2019}
}
@article{Li2018,
abstract = {Entropy measures that assess signals' complexity have drawn increasing attention recently in biomedical field, as they have shown the ability of capturing unique features that are intrinsic and physiologically meaningful. In this study, we applied entropy analysis to electroencephalogram (EEG) data to examine its performance in epilepsy detection based on short-term EEG, aiming at establishing a short-term analysis protocol with optimal seizure detection performance. Two classification problems were considered, i.e., 1) classifying interictal and ictal EEGs (epileptic group) from normal EEGs; and 2) classifying ictal from interictal EEGs. For each problem, we explored two protocols to analyze the entropy of EEG: i) using a single analytical window with different window lengths, and ii) using an average of multiple windows for each window length. Two entropy methods—fuzzy entropy (FuzzyEn) and distribution entropy (DistEn)–were used that have valid outputs for any given data lengths. We performed feature selection and trained classifiers based on a cross-validation process. The results show that performance of FuzzyEn and DistEn may complement each other and the best performance can be achieved by combining: 1) FuzzyEn of one 5-s window and the averaged DistEn of five 1-s windows for classifying normal from epileptic group (accuracy: 0.93, sensitivity: 0.91, specificity: 0.96); and 2) the averaged FuzzyEn of five 1-s windows and DistEn of one 5-s window for classifying ictal from interictal EEGs (accuracy: 0.91, sensitivity: 0.93, specificity: 0.90). Further studies are warranted to examine whether this proposed short-term analysis procedure can help track the epileptic activities in real time and provide prompt feedback for clinical practices.},
author = {Li, Peng and Karmakar, Chandan and Yearwood, John and Venkatesh, Svetha and Palaniswami, Marimuthu and Liu, Changchun},
doi = {10.1371/journal.pone.0193691},
editor = {Bazhenov, Maxim},
file = {::},
issn = {1932-6203},
journal = {PLOS ONE},
month = {mar},
number = {3},
pages = {e0193691},
publisher = {Public Library of Science},
title = {{Detection of epileptic seizure based on entropy analysis of short-term EEG}},
url = {https://dx.plos.org/10.1371/journal.pone.0193691},
volume = {13},
year = {2018}
}
@article{Zhang2019,
abstract = {Deep neural networks (DNN) have achieved remarkable results in sentiment classification. Some ensemble methods of DNN models and traditional feature-based models are proposed recently. However, to the best of our knowledge, most of the works use traditional ensemble combination techniques, e.g. voting and stacking, which are designed for weak base classifiers. So far many base classifiers, e.g. DNN, have been able to achieve good results in sentiment classification tasks, so there should be a new ensemble combination technique designed for strong base classifiers. To address this issue, we proposed a cost-sensitive combination technique using sequential three-way decisions (3WD), which is named S3WC. In S3WC, base classifiers are arranged in a linear arrangement, and a gate mechanism is constructed in each step to divide the objects into three groups, i.e., positive region, negative region and boundary region, which respectively correspond to acceptance, rejection and deferment in sequential 3WD. Each object is grouped by minimizing its total cost consisting of misclassification cost and time cost. The objects in boundary region require more information to decrease the misclassification cost, so they are reclassified by the subsequent base classifiers in order to obtain more information, while the time cost increases. In the experiment, we apply S3WC to DNN models and traditional feature-based models on five benchmark datasets, and compare its performance with traditional ensemble combination techniques. The experimental results show that S3WC outperforms any of its base classifiers in terms of classification accuracy, and the total cost of S3WC is lower than that of the existing ensemble combination techniques (e.g. majority-voting, weighted-voting, meta-learning).},
annote = {- Contains 5 text binary classification datasets. 
- 6 baseline models 

Majority voting
Weighted voting
Meta-learning},
author = {Zhang, Yuebing and Miao, Duoqian and Wang, Jiaqi and Zhang, Zhifei},
doi = {10.1016/j.ijar.2018.10.019},
file = {::},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {Ensemble learning,Sentiment classification,Three-way decisions},
pages = {85--97},
publisher = {Elsevier Inc.},
title = {{A cost-sensitive three-way combination technique for ensemble learning in sentiment classification}},
url = {https://doi.org/10.1016/j.ijar.2018.10.019},
volume = {105},
year = {2019}
}
@article{Rasmussen2019,
abstract = {Purpose: Blue-collar workers spend much leisure time sedentary, which is associated with numerous health impairments. The extensive sedentary leisure time among blue-collar workers could be caused by fatigue from physically demanding work, like stationary standing. Occupational stationary standing is prevalent in many blue-collar jobs and has been shown to induce fatigue. The objective of this study was to investigate the association between occupational standing and sedentary leisure time over several workdays among blue-collar workers. Methods: This study used data from 925 workers from Danish workplaces within cleaning, transportation, manufacturing, construction, road maintenance, garbage disposal, and health service. Eligible workers wore accelerometers for 2–5 consecutive workdays. A linear regression was used to investigate the association between percent of work time spent standing and leisure time spent sedentary. A multilevel growth model was used to assess the association between standing during work and sedentary leisure time over consecutive workdays. Results: We found no association between percent of work hours spent standing and percent of leisure time spent sedentary (coef. = 0.01, p = 0.84). The results showed an increase in the workers' sedentary leisure time over a week (coef. = 0.70, p {\textless} 0.01). However, this increase was not associated with consecutive workdays exposed to occupational standing (coef. = 0.02, p = 0.42). Conclusion: In this study, we found no support of a positive association between occupational standing and sedentary leisure time. This lack of association could be attributable to a low variation in sedentary leisure time or the chosen definition and measurement of occupational standing.},
author = {Rasmussen, Charlotte Lund and Nabe-Nielsen, Kirsten and J{\o}rgensen, Marie Birk and Holtermann, Andreas},
doi = {10.1007/s00420-018-1378-4},
file = {::},
issn = {14321246},
journal = {International Archives of Occupational and Environmental Health},
keywords = {Accelerometer,Cleaning,Manufacturing,Physical activity,Physical work demand,Transportation},
month = {may},
number = {4},
pages = {481--490},
publisher = {Springer Verlag},
title = {{The association between occupational standing and sedentary leisure time over consecutive workdays among blue-collar workers in manual jobs}},
volume = {92},
year = {2019}
}
@article{McCabe1976a,
author = {McCabe, T.J.},
doi = {10.1109/TSE.1976.233837},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
month = {dec},
number = {4},
pages = {308--320},
title = {{A Complexity Measure}},
url = {http://ieeexplore.ieee.org/document/1702388/},
volume = {SE-2},
year = {1976}
}
@article{Usman2017,
abstract = {Context: Software Engineering (SE) is an evolving discipline with new subareas being continuously developed and added. To structure and better understand the SE body of knowledge, taxonomies have been proposed in all SE knowledge areas. Objective: The objective of this paper is to characterize the state-of-the-art research on SE taxonomies. Method: A systematic mapping study was conducted, based on 270 primary studies. Results: An increasing number of SE taxonomies have been published since 2000 in a broad range of venues, including the top SE journals and conferences. The majority of taxonomies can be grouped into the following SWEBOK knowledge areas: construction (19.55{\%}), design (19.55{\%}), requirements (15.50{\%}) and maintenance (11.81{\%}). Illustration (45.76{\%}) is the most frequently used approach for taxonomy validation. Hierarchy (53.14{\%}) and faceted analysis (39.48{\%}) are the most frequently used classification structures. Most taxonomies rely on qualitative procedures to classify subject matter instances, but in most cases (86.53{\%}) these procedures are not described in sufficient detail. The majority of the taxonomies (97{\%}) target unique subject matters and many taxonomy-papers are cited frequently. Most SE taxonomies are designed in an ad-hoc way. To address this issue, we have revised an existing method for developing taxonomies in a more systematic way. Conclusion: There is a strong interest in taxonomies in SE, but few taxonomies are extended or revised. Taxonomy design decisions regarding the used classification structures, procedures and descriptive bases are usually not well described and motivated.},
author = {Usman, Muhammad and Britto, Ricardo and B{\"{o}}rstler, J{\"{u}}rgen and Mendes, Emilia},
doi = {10.1016/j.infsof.2017.01.006},
file = {::},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Classification,Software engineering,Systematic mapping study,Taxonomy},
pages = {43--59},
publisher = {Elsevier B.V.},
title = {{Taxonomies in software engineering: A Systematic mapping study and a revised taxonomy development method}},
url = {http://dx.doi.org/10.1016/j.infsof.2017.01.006},
volume = {85},
year = {2017}
}
@misc{Kadhim2019b,
abstract = {{\textless}h3 class="a-plus-plus"{\textgreater}Abstract{\textless}/h3{\textgreater}
                  {\textless}p class="a-plus-plus"{\textgreater}Supervised machine learning studies are gaining more significant recently because of the availability of the increasing number of the electronic documents from different resources. Text classification can be defined that the task was automatically categorized a group documents into one or more predefined classes according to their subjects. Thereby, the major objective of text classification is to enable users for extracting information from textual resource and deals with process such as retrieval, classification, and machine learning techniques together in order to classify different pattern. In text classification technique, term weighting methods design suitable weights to the specific terms to enhance the text classification performance. This paper surveys of text classification, process of different term weighing methods and comparison between different classification techniques.{\textless}/p{\textgreater}},
annote = {K-NN with TFIDF was shown to perform well on a variety of text classification problems

Text classification:
Insufficient number of samples of testing text documents, Features for the dataset, Differences in techniques, Incompatibility between the techniques and the problems, Class ambiguity.},
author = {Kadhim, Ammar Ismael},
booktitle = {Artificial Intelligence Review},
doi = {10.1007/s10462-018-09677-1},
issn = {15737462},
keywords = {Classification techniques,Supervised machine learning,Term weighting,Text classification},
title = {{Survey on supervised machine learning techniques for automatic text classification}},
year = {2019}
}
@article{Chen2018a,
abstract = {In the era of big data, recommender system (RS) has become an effective information filtering tool that alleviates information overload for Web users. Collaborative filtering (CF), as one of the most successful recommendation techniques, has been widely studied by various research institutions and industries and has been applied in practice. CF makes recommendations for the current active user using lots of users' historical rating information without analyzing the content of the information resource. However, in recent years, data sparsity and high dimensionality brought by big data have negatively affected the efficiency of the traditional CF-based recommendation approaches. In CF, the context information, such as time information and trust relationships among the friends, is introduced into RS to construct a training model to further improve the recommendation accuracy and user's satisfaction, and therefore, a variety of hybrid CF-based recommendation algorithms have emerged. In this paper, we mainly review and summarize the traditional CF-based approaches and techniques used in RS and study some recent hybrid CF-based recommendation approaches and techniques, including the latest hybrid memory-based and model-based CF recommendation algorithms. Finally, we discuss the potential impact that may improve the RS and future direction. In this paper, we aim at introducing the recent hybrid CF-based recommendation techniques fusing social networks to solve data sparsity and high dimensionality and provide a novel point of view to improve the performance of RS, thereby presenting a useful resource in the state-of-the-art research result for future researchers.},
author = {Chen, Rui and Hua, Qingyi and Chang, Yan Shuo and Wang, Bo and Zhang, Lei and Kong, Xiangjie},
doi = {10.1109/ACCESS.2018.2877208},
file = {::},
issn = {21693536},
journal = {IEEE Access},
keywords = {Collaborative filtering,Matrix factorization,Recommender systems,Singular value decomposition,Social networks,Trust-aware collaborative filtering},
pages = {64301--64320},
publisher = {IEEE},
title = {{A survey of collaborative filtering-based recommender systems: from traditional methods to hybrid methods based on social networks}},
volume = {6},
year = {2018}
}
@article{Briggs2012,
abstract = {A model's purpose is to inform medical decisions and health care resource allocation. Modelers employ quantitative methods to structure the clinical, epidemiological, and economic evidence base and gain qualitative insight to assist decision makers in making better decisions. From a policy perspective, the value of a model-based analysis lies not simply in its ability to generate a precise point estimate for a specific outcome but also in the systematic examination and responsible reporting of uncertainty surrounding this outcome and the ultimate decision being addressed. Different concepts relating to uncertainty in decision modeling are explored. Stochastic (first-order) uncertainty is distinguished from both parameter (second-order) uncertainty and from heterogeneity, with structural uncertainty relating to the model itself forming another level of uncertainty to consider. The article argues that the estimation of point estimates and uncertainty in parameters is part of a single process and explores the link between parameter uncertainty through to decision uncertainty and the relationship to value of information analysis. The article also makes extensive recommendations around the reporting of uncertainty, in terms of both deterministic sensitivity analysis techniques and probabilistic methods. Expected value of perfect information is argued to be the most appropriate presentational technique, alongside cost-effectiveness acceptability curves, for representing decision uncertainty from probabilistic analysis. {\textcopyright} 2012 International Society for Pharmacoeconomics and Outcomes Research (ISPOR).},
author = {Briggs, Andrew H. and Weinstein, Milton C. and Fenwick, Elisabeth A.L. and Karnon, Jonathan and Sculpher, Mark J. and Paltiel, A. David},
doi = {10.1177/0272989X12458348},
file = {::},
issn = {0272989X},
journal = {Medical Decision Making},
keywords = {guidelines,heterogeneity,sensitivity analysis,uncertainty analysi (ADP) s,value of information},
number = {5},
pages = {722--732},
publisher = {Elsevier Inc.},
title = {{Model parameter estimation and uncertainty analysis: A report of the ISPOR-SMDM modeling good research practices task force working group-6}},
url = {http://dx.doi.org/10.1016/j.jval.2012.04.014},
volume = {32},
year = {2012}
}
@inproceedings{Renzella2020a,
abstract = {With the global increase in demand for online tertiary education, teachers are facing unique challenges in scaling assessment activities and meaningful student engagement. One such aspect is contract cheating behaviours exhibited in the modern online environment posing a threat to the academic integrity of tertiary education. These obstacles amplify when applied to traditionally difficult domains like introductory programming education. Prior research on contract cheating identification proposes that while challenging, techniques such as developing strong teacher-student relationships, and real-time discussions may lead to instances of identifying contract cheating behaviours. The proposition, then, is to scale real-time, student-teacher discussions with large, online co-horts-similar to those discussions which traditionally took place in the classroom. This poster paper presents Intelligent Discussion Comments (IDCs): A scalable, teacher-asynchronous system which engages students in real-time discussions to extract authentic student understanding. Artificial intelligence services such as voice identification and transcription enrich the discussion process, supporting the teaching team in their decision-making process. CCS CONCEPTS • Applied computing → Learning management systems; Distance learning; E-learning; • Human-centered computing → Human computer interaction (HCI).},
address = {Seoul, Republic of Korea},
author = {Renzella, Jake and Cain, Andrew and Schneider, Jean-Guy},
booktitle = {Proceedings of the 42nd International Conference on Software Engineering},
doi = {10.1145/3377812.3390795},
file = {::},
isbn = {9781450371223},
keywords = {Learning management system,computing assessment,computing education,contract cheating detection,human computer interaction,online education,programming education},
title = {{An Intelligent Tool for Combatting Contract Cheating Behaviour by Facilitating Scalable Student-Tutor Discussions}},
year = {2020}
}
@book{Grandjean1987,
author = {Grandjean, E. (Etienne)},
isbn = {9780850663501},
pages = {227},
publisher = {Taylor {\&} Francis},
title = {{Ergonomics in computerized offices}},
year = {1987}
}
@article{Zhao2018,
author = {Zhao, Xiuhe and Lhatoo, Samden D.},
doi = {10.1007/s11910-018-0849-z},
file = {::},
issn = {1528-4042},
journal = {Current Neurology and Neuroscience Reports},
month = {jul},
number = {7},
pages = {40},
publisher = {Springer US},
title = {{Seizure detection: do current devices work? And when can they be useful?}},
url = {http://link.springer.com/10.1007/s11910-018-0849-z},
volume = {18},
year = {2018}
}
@article{MinlongLin2013,
annote = {Journal: 20 datasets},
author = {{Minlong Lin} and {Ke Tang} and {Xin Yao}},
doi = {10.1109/tnnls.2012.2228231},
file = {::},
issn = {2162-237X},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
number = {4},
pages = {647--660},
publisher = {IEEE},
title = {{Dynamic Sampling Approach to Training Neural Networks for Multiclass Imbalance Classification}},
volume = {24},
year = {2013}
}
@inproceedings{Poncin2011,
author = {Poncin, Wouter and Serebrenik, Alexander and van den Brand, Mark},
booktitle = {2011 15th European Conference on Software Maintenance and Reengineering},
doi = {10.1109/CSMR.2011.5},
file = {::},
isbn = {978-1-61284-259-2},
month = {mar},
pages = {5--14},
publisher = {IEEE},
title = {{Process Mining Software Repositories}},
url = {http://ieeexplore.ieee.org/document/5741254/},
year = {2011}
}
@article{Khomh2018,
annote = {AI is not intended to achieve 100{\%} accuracy as humans aren't 100{\%} accurate in their tasks. This creates the question what is the correct measure.

Also mentions the idea of putting AI into context. 

Sociological studyies are needed to determine how AI changes human behaviour.},
author = {Khomh, Foutse and Adams, Bram and Cheng, Jinghui and Fokaefs, Marios and Antoniol, Giuliano},
doi = {10.1109/MS.2018.3571224},
file = {::},
issn = {0740-7459},
journal = {IEEE Software},
number = {5},
pages = {81--84},
publisher = {IEEE},
title = {{Software Engineering for Machine-Learning Applications: The Road Ahead}},
url = {https://ieeexplore.ieee.org/document/8474484/},
volume = {35},
year = {2018}
}
@article{Beniczky2018,
abstract = {OBJECTIVE To determine the accuracy of automated detection of generalized tonic-clonic seizures (GTCS) using a wearable surface EMG device. METHODS We prospectively tested the technical performance and diagnostic accuracy of real-time seizure detection using a wearable surface EMG device. The seizure detection algorithm and the cutoff values were prespecified. A total of 71 patients, referred to long-term video-EEG monitoring, on suspicion of GTCS, were recruited in 3 centers. Seizure detection was real-time and fully automated. The reference standard was the evaluation of video-EEG recordings by trained experts, who were blinded to data from the device. Reading the seizure logs from the device was done blinded to all other data. RESULTS The mean recording time per patient was 53.18 hours. Total recording time was 3735.5 hours, and device deficiency time was 193 hours (4.9{\%} of the total time the device was turned on). No adverse events occurred. The sensitivity of the wearable device was 93.8{\%} (30 out of 32 GTCS were detected). Median seizure detection latency was 9 seconds (range -4 to 48 seconds). False alarm rate was 0.67/d. CONCLUSIONS The performance of the wearable EMG device fulfilled the requirements of patients: it detected GTCS with a sensitivity exceeding 90{\%} and detection latency within 30 seconds. CLASSIFICATION OF EVIDENCE This study provides Class II evidence that for people with a history of GTCS, a wearable EMG device accurately detects GTCS (sensitivity 93.8{\%}, false alarm rate 0.67/d).},
author = {Beniczky, S{\'{a}}ndor and Conradsen, Isa and Henning, Oliver and Fabricius, Martin and Wolf, Peter},
doi = {10.1212/WNL.0000000000004893},
file = {::},
issn = {1526-632X},
journal = {Neurology},
month = {jan},
number = {5},
pages = {e428--e434},
pmid = {29305441},
publisher = {American Academy of Neurology},
title = {{Automated real-time detection of tonic-clonic seizures using a wearable EMG device.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/29305441 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5791791},
volume = {90},
year = {2018}
}
@article{DeHaan2006,
abstract = {This paper describes a case study for constructing the yearly schedule of a secondary school in the Netherlands. This construction is divided in three steps. In the first step we create cluster schemes containing the optional subjects. A cluster scheme consists of cluster lines, and a cluster line contains classes which will be taught simultaneously. Part of the problem is that the students are not yet assigned to the classes. Once the cluster schemes are fixed, it remains to schedule the lessons to time slots and rooms. We first schedule the lessons to day-parts, and once this is completed we schedule the lessons to time slots within the day-parts. Thanks to consistency checks in the day-part phase, going from day-parts to time slots is possible. Finally, in the third step, we improve the previously found schedule by a tabu search using ejection chains. Compared to hand-made schedules, the results are very promising. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
author = {{De Haan}, Peter and Landman, Ronald and Post, Gerhard and Ruizenaar, Henri},
doi = {10.1007/978-3-540-77345-0_17},
file = {::},
isbn = {3540773444},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {267--279},
title = {{A case study for timetabling in a dutch secondary school}},
volume = {3867 LNCS},
year = {2006}
}
@article{Tanjung2020,
author = {Tanjung, Handrizal and Ahmad, Noraziah and Abdalla, Ahmed and Alla},
month = {mar},
title = {{SPREAD SPECTRUM PROCESS USING DIRECT SEQUENCE SPREAD SPECTRUM (DSSS) AND FREQUENCY HOPPING SPREAD SPECTRUM (FHSS)}},
year = {2020}
}
@inproceedings{smit2011code,
abstract = {Maintainability is a desired property of software, and a variety of metrics have been proposed for measuring it, focusing on different notions of complexity and code readability. Many practices have been proposed to improve maintainability through code refactorings: improving the cohesion, simplification of interfaces, renamings to improve understandability. Code conventions are a body of advice on lexical and syntactic aspects of code, aiming to standardize low-level code design under the assumption that such a systematic approach will make code easier to read, understand, and maintain. We present the first stage in our examination of code-convention adherence practices as a proxy measurement for maintainability. Based on a preliminary survey of software engineers, we identify a set of coding conventions that most relate to maintainability. Then we devise a {\&}{\#}x201C;convention adherence{\&}{\#}x201D; metric, based on the number and severity of violations of a defined coding convention. Finally, we analyze several open-source projects according to this metric to better understand how consistent different teams are with respect to adopting and conforming to code conventions.},
author = {Smit, Michael and Gergel, Barry and Hoover, H. James and Stroulia, Eleni},
booktitle = {2011 27th IEEE International Conference on Software Maintenance (ICSM)},
doi = {10.1109/ICSM.2011.6080819},
file = {::},
isbn = {9781457706646},
organization = {IEEE},
pages = {504--507},
title = {{Code convention adherence in evolving software}},
year = {2011}
}
@article{Braiek2018a,
abstract = {Nowadays, we are witnessing a wide adoption of Machine learning (ML) models in many safety-critical systems, thanks to recent breakthroughs in deep learning and reinforcement learning. Many people are now interacting with systems based on ML every day, e.g., voice recognition systems used by virtual personal assistants like Amazon Alexa or Google Home. As the field of ML continues to grow, we are likely to witness transformative advances in a wide range of areas, from finance, energy, to health and transportation. Given this growing importance of ML-based systems in our daily life, it is becoming utterly important to ensure their reliability. Recently, software researchers have started adapting concepts from the software testing domain (e.g., code coverage, mutation testing, or property-based testing) to help ML engineers detect and correct faults in ML programs. This paper reviews current existing testing practices for ML programs. First, we identify and explain challenges that should be addressed when testing ML programs. Next, we report existing solutions found in the literature for testing ML programs. Finally, we identify gaps in the literature related to the testing of ML programs and make recommendations of future research directions for the scientific community. We hope that this comprehensive review of software testing practices will help ML engineers identify the right approach to improve the reliability of their ML-based systems. We also hope that the research community will act on our proposed research directions to advance the state of the art of testing for ML programs.},
archivePrefix = {arXiv},
arxivId = {1812.02257},
author = {Braiek, Houssem Ben and Khomh, Foutse},
eprint = {1812.02257},
keywords = {data cleaning,feature engineering testing,implementation testing,machine learning,model testing},
title = {{On Testing Machine Learning Programs}},
url = {http://arxiv.org/abs/1812.02257},
year = {2018}
}
@article{Easton1995,
author = {Easton, Peter D and Harris, Trevor S},
file = {::},
journal = {Journal of Accounting Research},
number = {1},
pages = {19--36},
title = {{Earnings as an explanatory variable for returns University of Chicago Stable}},
volume = {29},
year = {1995}
}
@article{Andrzejak2001,
author = {Andrzejak, Ralph G. and Lehnertz, Klaus and Mormann, Florian and Rieke, Christoph and David, Peter and Elger, Christian E.},
doi = {10.1103/PhysRevE.64.061907},
issn = {1063-651X},
journal = {Physical Review E},
month = {nov},
number = {6},
pages = {061907},
publisher = {American Physical Society},
title = {{Indications of nonlinear deterministic and finite-dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state}},
url = {https://link.aps.org/doi/10.1103/PhysRevE.64.061907},
volume = {64},
year = {2001}
}
@article{Itti2009,
abstract = {We propose a formal Bayesian definition of surprise to capture subjective aspects of sensory information. Surprise measures how data affects an observer, in terms of differences between posterior and prior beliefs about the world. Only data observations which substantially affect the observer's beliefs yield surprise, irrespectively of how rare or informative in Shannon's sense these observations are. We test the framework by quantifying the extent to which humans may orient attention and gaze towards surprising events or items while watching television. To this end, we implement a simple computational model where a low-level, sensory form of surprise is computed by simple simulated early visual neurons. Bayesian surprise is a strong attractor of human attention, with 72{\%} of all gaze shifts directed towards locations more surprising than the average, a figure rising to 84{\%} when focusing the analysis onto regions simultaneously selected by all observers. The proposed theory of surprise is applicable across different spatio-temporal scales, modalities, and levels of abstraction. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Itti, Laurent and Baldi, Pierre},
doi = {10.1016/j.visres.2008.09.007},
file = {::},
issn = {00426989},
journal = {Vision Research},
keywords = {Attention,Bayes theorem,Eye movements,Free viewing,Information theory,Natural vision,Novelty,Saliency,Surprise},
number = {10},
pages = {1295--1306},
pmid = {18834898},
publisher = {Elsevier Ltd},
title = {{Bayesian surprise attracts human attention}},
url = {http://dx.doi.org/10.1016/j.visres.2008.09.007},
volume = {49},
year = {2009}
}
@article{Schelter2017,
abstract = {We present a lightweight system to extract, store and manage metadata and prove-nance information of common artifacts in machine learning (ML) experiments: datasets, models, predictions, evaluations and training runs. Our system accelerates users in their ML workflow, and provides a basis for comparability and repeata-bility of ML experiments. We achieve this by tracking the lineage of produced artifacts and automatically extracting metadata such as hyperparameters of models, schemas of datasets or layouts of deep neural networks. Our system provides a general declarative representation of said ML artifacts, is integrated with popular frameworks such as MXNet, SparkML and scikit-learn, and meets the demands of various production use cases at Amazon.},
author = {Schelter, Sebastian and B{\"{o}}se, Joos-Hendrik and Kirschnick, Johannes and Klein, Thoralf and Seufert, Stephan},
file = {::},
journal = {Machine Learning Systems Workshop at NIPS },
title = {{Automatically Tracking Metadata and Provenance of Machine Learning Experiments}},
url = {http://learningsys.org/nips17/assets/papers/paper{\_}13.pdf},
year = {2017}
}
@article{hofmeister2019shorter,
author = {Hofmeister, Johannes C and Siegmund, Janet and Holt, Daniel V},
journal = {Empirical Software Engineering},
number = {1},
pages = {417--443},
publisher = {Springer},
title = {{Shorter identifier names take longer to comprehend}},
volume = {24},
year = {2019}
}
@article{Gomez-Uribe2015,
abstract = {This article discusses the various algorithms that make up the Netflix recommender system, and describes its business purpose. We also describe the role of search and related algorithms, which for us turns into a recommendations problem as well. We explain the motivations behind and review the approach that we use to improve the recommendation algorithms, combining A/B testing focused on improving member retention andmedium term engagement, as well as offline experimentation using historical member engagement data. We discuss some of the issues in designing and interpreting A/B tests. Finally, we describe some current areas of focused innovation, which include making our recommender system global and language aware.},
author = {Gomez-Uribe, Carlos A. and Hunt, Neil},
doi = {10.1145/2843948},
file = {::},
issn = {21586578},
journal = {ACM Transactions on Management Information Systems},
number = {4},
title = {{The netflix recommender system: Algorithms, business value, and innovation}},
volume = {6},
year = {2015}
}
@article{Barnett2019a,
abstract = {Interest in mobile application development has significantly increased. The need for rapid, iterative development coupled with the diversity of platforms, technologies and frameworks impacts on the productivity of developers. In this paper we propose a new approach and tool support, Rapid APPlication Tool (RAPPT), that enables rapid development of mobile applications. It employs Domain Specific Visual Languages and Modeling techniques to help developers define the characteristics of their applications using high level visual notations. Our approach also provides multiple views of the application to help developers have a better understanding of the different aspects of their application. Our user evaluation of RAPPT demonstrates positive feedback ranging from expert to novice developers.},
author = {Barnett, Scott and Avazpour, Iman and Vasa, Rajesh and Grundy, John},
doi = {10.1016/j.cola.2019.02.001},
issn = {25901184},
journal = {Journal of Computer Languages},
month = {apr},
pages = {88--96},
title = {{Supporting multi-view development for mobile applications}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1045926X15300458},
volume = {51},
year = {2019}
}
@inproceedings{242525,
author = {Oman, P and Hagemeister, J},
booktitle = {Proceedings Conference on Software Maintenance 1992},
doi = {10.1109/ICSM.1992.242525},
issn = {null},
keywords = {software maintenance;software metrics;software met},
month = {nov},
pages = {337--344},
title = {{Metrics for assessing a software system's maintainability}},
year = {1992}
}
@article{Adadi2018,
abstract = {At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.},
annote = {Forth industrial revolution - fast {\&} widespread AI
Shift towards more algorithmic society

AI - Lack of transparency, powerful predictions, cannot be directly explained, improve trust and transparency

Monetary value of AI - Increase in global investment on AI (12 billion USD in 2017 to 52.2 trillion USD in 2021)
AI Market growth (480 billion USD in 2017 to 2.59 trillion USD in 2021)

Reasons for XAI - Explain to justify, explain to control, explain to improve, explain to discover

XAI Application domains - transportation, healthcare, legal, finance, military

The technical challenge question in enabling XAI - Why the use of XAI is not systematic ?
Why is not everyone using XAI?

Four basic research areas - Data science, AI/ML, Human science, Human Computer Interface (HCI)

Six major academic databases - SCOPUS, IEEExplore, ACM Digital Library, Google Scholar, Citeseer Library, ScienceDirect

More complex the model, it is more dificult to interpret.
Scoop related methods - understanding the entire model behavior/understanding a single prediction, broadly categorised into global interpretability and local interpretability methods

Model related methods - visualisation (surrogate models, Partial Dependence Plot (PDP), Individual Conditional Expectation (ICE)), knowledge extraction, influence methods, example based explanation

Surrogate models - a simple model used to explain complex models
Knowledge extraction - rule extraction (pedogogical, decompositional, ecelectic), model distillation
Influence methods - sensitivity analysis, layer wise relevance propagation, feature importance},
author = {Adadi, Amina and Berrada, Mohammed},
doi = {10.1109/ACCESS.2018.2870052},
file = {::},
issn = {21693536},
journal = {IEEE Access},
keywords = {Explainable artificial intelligence,black-box models,interpretable machine learning},
pages = {52138--52160},
publisher = {IEEE},
title = {{Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)}},
volume = {6},
year = {2018}
}
@incollection{Castle2018,
abstract = {We explore strategies for optimizing selectivity, specificity, and sensitivity in broadband {\{}CARS{\}} by precalculating pulse shapes using an evolutionary algorithm. We show the possibility of selective excitation of a single constituent in a test case of a mixture of five resonant compounds. The obtainable contrast ratio for a test case of {\{}PMMA{\}} in a mixture of five resonant compounds is predicted to be 2000:1, and is related the uniqueness of the complex vibrational response of the compound of interest compared to that of the surrounding molecules. Furthermore we investigate how the effects of homodyne mixing in the focal volume affect the obtainable contrast ratio and how noise affects the optimization. We also show preliminary results of experimental optimization of the {\{}CARS{\}} signal from {\{}PMMA{\}} microspheres, resulting in high contrast imaging, free of non-resonant background signal.},
author = {Aichernig, Bernhard K. and Mostowski, Wojciech and Mousavi, Mohammad Reza and Tappler, Martin and Taromirad, Masoumeh},
doi = {10.1007/978-3-319-96562-8_3},
file = {::},
isbn = {978-3-319-96561-1},
number = {July},
pages = {74--100},
title = {{Model Learning and Model-Based Testing}},
url = {http://link.springer.com/10.1007/978-3-319-96562-8 http://link.springer.com/10.1007/978-3-319-96562-8{\_}3},
volume = {11026},
year = {2018}
}
@article{Casalnuovo2015,
abstract = {{\textcopyright} 2015 IEEE. Asserts have long been a strongly recommended (if non-functional) adjunct to programs. They certainly don't add any user-evident feature value; and it can take quite some skill and effort to devise and add useful asserts. However, they are believed to add considerable value to the developer. Certainly, they can help with automated verification; but even in the absence of that, claimed advantages include improved understandability, maintainability, easier fault localization and diagnosis, all eventually leading to better software quality. We focus on this latter claim, and use a large dataset of asserts in C and C++ programs to explore the connection between asserts and defect occurrence. Our data suggests a connection: functions with asserts do have significantly fewer defects. This indicates that asserts do play an important role in software quality; we therefore explored further the factors that play a role in assertion placement: specifically, process factors (such as developer experience and ownership) and product factors, particularly interprocedural factors, exploring how the placement of assertions in functions are influenced by local and global network properties of the callgraph. Finally, we also conduct a differential analysis of assertion use across different application domains.},
author = {Casalnuovo, Casey and Devanbu, Prem and Oliveira, Abilio and Filkov, Vladimir and Ray, Baishakhi},
doi = {10.1109/ICSE.2015.88},
file = {::},
isbn = {9781479919345},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
pages = {755--766},
title = {{Assert use in GitHub projects}},
volume = {1},
year = {2015}
}
@article{Cook2013,
abstract = {Background: Seizure prediction would be clinically useful in patients with epilepsy and could improve safety, increase independence, and allow acute treatment. We did a multicentre clinical feasibility study to assess the safety and efficacy of a long-term implanted seizure advisory system designed to predict seizure likelihood and quantify seizures in adults with drug-resistant focal seizures. Methods: We enrolled patients at three centres in Melbourne, Australia, between March 24, 2010, and June 21, 2011. Eligible patients had between two and 12 disabling partial-onset seizures per month, a lateralised epileptogenic zone, and no history of psychogenic seizures. After devices were surgically implanted, patients entered a data collection phase, during which an algorithm for identification of periods of high, moderate, and low seizure likelihood was established. If the algorithm met performance criteria (ie, sensitivity of high-likelihood warnings greater than 65{\%} and performance better than expected through chance prediction of randomly occurring events), patients then entered an advisory phase and received information about seizure likelihood. The primary endpoint was the number of device-related adverse events at 4 months after implantation. Our secondary endpoints were algorithm performance at the end of the data collection phase, clinical effectiveness (measures of anxiety, depression, seizure severity, and quality of life) 4 months after iniation of the advisory phase, and longer-term adverse events. This trial is registered with ClinicalTrials.gov, number NCT01043406. Findings: We implanted 15 patients with the advisory system. 11 device-related adverse events were noted within four months of implantation, two of which were serious (device migration, seroma); an additional two serious adverse events occurred during the first year after implantation (device-related infection, device site reaction), but were resolved without further complication. The device met enabling criteria in 11 patients upon completion of the data collection phase, with high likelihood performance estimate sensitivities ranging from 65{\%} to 100{\%}. Three patients' algorithms did not meet performance criteria and one patient required device removal because of an adverse event before sufficient training data were acquired. We detected no significant changes in clinical effectiveness measures between baseline and 4 months after implantation. Interpretation: This study showed that intracranial electroencephalographic monitoring is feasible in ambulatory patients with drug-resistant epilepsy. If these findings are replicated in larger, longer studies, accurate definition of preictal electrical activity might improve understanding of seizure generation and eventually lead to new management strategies. Funding: NeuroVista. {\textcopyright} 2013 Elsevier Ltd.},
author = {Cook, Mark J. and O'Brien, Terence J. and Berkovic, Samuel F. and Murphy, Michael and Morokoff, Andrew and Fabinyi, Gavin and D'Souza, Wendyl and Yerra, Raju and Archer, John and Litewka, Lucas and Hosking, Sean and Lightfoot, Paul and Ruedebusch, Vanessa and Sheffield, W. Douglas and Snyder, David and Leyde, Kent and Himes, David},
doi = {10.1016/S1474-4422(13)70075-9},
issn = {14744422},
journal = {The Lancet Neurology},
month = {jun},
number = {6},
pages = {563--571},
publisher = {Elsevier},
title = {{Prediction of seizure likelihood with a long-term, implanted seizure advisory system in patients with drug-resistant epilepsy: A first-in-man study}},
volume = {12},
year = {2013}
}
@inproceedings{Pimentel2019,
abstract = {Jupyter Notebooks have been widely adopted by many different communities, both in science and industry. They support the creation of literate programming documents that combine code, text, and execution results with visualizations and all sorts of rich media. The self-documenting aspects and the ability to reproduce results have been touted as significant benefits of notebooks. At the same time, there has been growing criticism that the way notebooks are being used leads to unexpected behavior, encourage poor coding practices, and that their results can be hard to reproduce. To understand good and bad practices used in the development of real notebooks, we studied 1.4 million notebooks from GitHub. We present a detailed analysis of their characteristics that impact reproducibility. We also propose a set of best practices that can improve the rate of reproducibility and discuss open challenges that require further research and development.},
author = {Pimentel, Jo{\~{a}}o Felipe and Murta, Leonardo and Braganholo, Vanessa and Freire, Juliana},
booktitle = {2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)},
doi = {10.1109/MSR.2019.00077},
file = {::},
isbn = {978-1-7281-3412-3},
issn = {21601860},
keywords = {Github,Jupyter notebook,Reproducibility},
month = {may},
pages = {507--517},
publisher = {IEEE},
title = {{A Large-Scale Study About Quality and Reproducibility of Jupyter Notebooks}},
url = {https://ieeexplore.ieee.org/document/8816763/},
year = {2019}
}
@article{Logeswaran2019,
abstract = {We present the zero-shot entity linking task, where mentions must be linked to unseen entities without in-domain labeled data. The goal is to enable robust transfer to highly specialized domains, and so no metadata or alias tables are assumed. In this setting, entities are only identified by text descriptions, and models must rely strictly on language understanding to resolve the new entities. First, we show that strong reading comprehension models pre-trained on large unlabeled data can be used to generalize to unseen entities. Second, we propose a simple and effective adaptive pre-training strategy, which we term domain-adaptive pre-training (DAP), to address the domain shift problem associated with linking unseen entities in a new domain. We present experiments on a new dataset that we construct for this task and show that DAP improves over strong pre-training baselines, including BERT. The data and code are available at https://github.com/lajanugen/zeshel.},
archivePrefix = {arXiv},
arxivId = {1906.07348},
author = {Logeswaran, Lajanugen and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina and Devlin, Jacob and Lee, Honglak},
eprint = {1906.07348},
file = {::},
title = {{Zero-Shot Entity Linking by Reading Entity Descriptions}},
url = {http://arxiv.org/abs/1906.07348},
year = {2019}
}
@article{Meseguer2010,
abstract = {This paper proposes a fault diagnosis method using a timed discrete-event approach based on interval observers that improves the integration of fault detection and isolation tasks. The interface between fault detection and fault isolation considers the activation degree and the occurrence time instant of the diagnostic signals using a combination of several theoretical fault signature matrices that store the knowledge of the relationship between diagnostic signals and faults. The fault isolation module is implemented using a timed discrete-event approach that recognizes the occurrence of a fault by identifying a unique sequence of observable events (fault signals). The states and transitions that characterize such a system can directly be inferred from the relation between fault signals and faults. The proposed fault diagnosis approach has been motivated by the problem of detecting and isolating faults of the Barcelona's urban sewer system limnimeters (level meter sensors). The results obtained in this case study illustrate the benefits of using the proposed approach in comparison with the standard fault detection and isolation approach. {\textcopyright} 2010 IEEE.},
author = {Meseguer, Jordi and Puig, Vicen and Escobet, Teresa},
doi = {10.1109/TSMCA.2010.2052036},
file = {::},
issn = {10834427},
journal = {IEEE Transactions on Systems, Man, and Cybernetics Part A:Systems and Humans},
keywords = {Discrete-event systems (DESs),fault detection,fault diagnosis,intervals,observers,robustness},
number = {5},
pages = {900--916},
title = {{Fault diagnosis using a timed discrete-event approach based on interval observers: Application to sewer networks}},
volume = {40},
year = {2010}
}
@article{Zhang2018,
author = {Zhang, Yan Ping and Wu, Zeng Bao and Zhao, Shu and Yan, Yuan Ting and Chen, Jie and Du, Xiu Quan},
doi = {10.1016/j.ijar.2018.12.011},
file = {::},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
pages = {1--16},
publisher = {Elsevier Inc.},
title = {{A three-way decision ensemble method for imbalanced data oversampling}},
url = {https://doi.org/10.1016/j.ijar.2018.12.011},
volume = {107},
year = {2018}
}
@incollection{Herrera2018,
annote = {Keel is the main dataset
4 broad solutions
3 major problems, only 2 can be dealt with},
author = {Herrera, Francisco and Garc{\'{i}}a, Salvador and Fern{\'{a}}ndez, Alberto and Krawczyk, Bartosz and Galar, Mikel and Prati, Ronaldo C.},
booktitle = {Learning from Imbalanced Data Sets},
doi = {10.1007/978-3-319-98074-4_2},
title = {{Foundations on Imbalanced Classification}},
year = {2018}
}
@article{Ashmore2019,
abstract = {Machine learning has evolved into an enabling technology for a wide range of highly successful applications. The potential for this success to continue and accelerate has placed machine learning (ML) at the top of research, economic and political agendas. Such unprecedented interest is fuelled by a vision of ML applicability extending to healthcare, transportation, defence and other domains of great societal importance. Achieving this vision requires the use of ML in safety-critical applications that demand levels of assurance beyond those needed for current ML applications. Our paper provides a comprehensive survey of the state-of-the-art in the assurance of ML, i.e. in the generation of evidence that ML is sufficiently safe for its intended use. The survey covers the methods capable of providing such evidence at different stages of the machine learning lifecycle, i.e. of the complex, iterative process that starts with the collection of the data used to train an ML component for a system, and ends with the deployment of that component within the system. The paper begins with a systematic presentation of the ML lifecycle and its stages. We then define assurance desiderata for each stage, review existing methods that contribute to achieving these desiderata, and identify open challenges that require further research.},
annote = {Desiderata - something that is needed/wanted

vision - ML is everywhere, it is determined by the level of assurance provided for ML
ML errors in smart cameras can be deleted, the selection of odd word in translation system can be ignored. But ML errors in medical diagnosis/self driving cars are unacceptable.

Understand the complex, iterative process of ML and use ML.
4 stages of ML Lifecycle - Data Management, Model Learning, Model Verification, Model Deployment
ML Learning - supervised, unsupervised, reinforcement
Convolutional NN is used in classification of road signs in self driving cars

ML represents the automated extraction of models/patterns from data.
Data Management - collection, augmentation, preprocessing and analysis of data
Augmentation - add further data samples
Model selection depends on problem type, volume {\&} structure of training data and personal experience.
Hyperparameter selection can cause overfitting, underfitting and model complexity.
Loss function is a measure of training errors.

Feature extraction can be subcategorised as numerical (blood sugar level in a healthcare system), ordinal (position in a queue in a traffic management system), categorical (an element(bus, car, truck) from the set in a self driving car)

MAPE control system - Monitor Analyze Plan Execute Control System
Learning - Deep learning, reinforcement learning, transfer learning, ensemble learning
Data Management - collection (source), preprocessing (one to one mapping), augmentation (one to many mapping)

Desiderata - relevant, complete, balanced, accurate
Relevant - the intersection between the dataset {\&} the desired behavior in intended operational domain
Complete - the way samples are distributed across input domain and subspaces of it.
Input domain space, operational domain space, failure domain space, adversarial domain space
Balanced - the distribution of features 
Accurate - how measurement issues can affect the way that samples reflect the intended operational domain

Challenges in relevancy - detection of hidden backdoors, demonstrating that synthetic data is appropriate, detecting {\&} correcting for data leakage

To consider whether a data set is complete, we can plot marginal distribution of each feature, ratio of sampling density between densely sampled {\&} sparsely sampled

Challenges in completeness - understanding completeness across operational domain, finding verifiable ways of achieving augmentation, demonstrating completeness across adversarial domain, labeling discrepancies introduced by human

Model categories are classification, regression, clustering and reinforcement.
Objective function reflects the requirements for the model.
Hyper parameter selection strategies - initialisation with values offered by ML frameworks, manual configuration based on recommendations from literature/experience, trial and error
NN model, used for facial recognition can be reused for operator fatigue.

Prediction errors have three components such as irreducible error, bias error and variance error.

Model specific parameters restrict the users the choice of model.},
archivePrefix = {arXiv},
arxivId = {1905.04223},
author = {Ashmore, Rob and Calinescu, Radu and Paterson, Colin},
eprint = {1905.04223},
file = {::},
title = {{Assuring the Machine Learning Lifecycle: Desiderata, Methods, and Challenges}},
url = {http://arxiv.org/abs/1905.04223},
year = {2019}
}
@inproceedings{Rybicki2019,
abstract = {The goal of Data Science projects is to extract knowledge and insights from collected data. The focus is put on the novelty and usability of the obtained insights. However, the impact of a project can be seriously reduced if the results are not communicated well. In this paper, we describe a means of managing and describing the outcomes of the Data Science projects in such a way that they optimally convey the insights gained. We focus on the main artifact of 854the non-verbal communication, namely project structure. In particular, we surveyed three sources of information on how to structure projects: common management methodologies, community best practices, and data sharing platforms. The survey resulted in a list of recommendations on how to build the project artifacts to make them clear, intuitive, and logical. We also provide hints on tools that can be helpful for managing such structures in an efficient manner. The paper is intended to motivate and support an informed decision on how to structure a Data Science project to facilitate better communication of the outcomes.},
author = {Rybicki, Jedrzej},
booktitle = {Proceedings of 39th International Conference on Information Systems Architecture and Technology -- ISAT 2018},
doi = {10.1007/978-3-319-99993-7_31},
file = {::},
isbn = {978-3-319-99993-7},
keywords = {Data science,Management methodologies,Project management,Tools},
pages = {348--357},
publisher = {Springer International Publishing},
title = {{Best Practices in Structuring Data Science Projects}},
year = {2019}
}
@article{Charles2017,
abstract = {We establish novel generalization bounds for learning algorithms that converge to global minima. We do so by deriving black-box stability results that only depend on the convergence of a learning algorithm and the geometry around the minimizers of the loss function. The results are shown for nonconvex loss functions satisfying the Polyak-{\{}$\backslash$L{\}}ojasiewicz (PL) and the quadratic growth (QG) conditions. We further show that these conditions arise for some neural networks with linear activations. We use our black-box results to establish the stability of optimization algorithms such as stochastic gradient descent (SGD), gradient descent (GD), randomized coordinate descent (RCD), and the stochastic variance reduced gradient method (SVRG), in both the PL and the strongly convex setting. Our results match or improve state-of-the-art generalization bounds and can easily be extended to similar optimization algorithms. Finally, we show that although our results imply comparable stability for SGD and GD in the PL setting, there exist simple neural networks with multiple local minima where SGD is stable but GD is not.},
archivePrefix = {arXiv},
arxivId = {1710.08402},
author = {Charles, Zachary and Papailiopoulos, Dimitris},
eprint = {1710.08402},
file = {::},
issn = {1938-7228},
title = {{Stability and Generalization of Learning Algorithms that Converge to Global Optima}},
year = {2017}
}
@article{He2004,
abstract = {The study was carried out to examine whether acupuncture treatment can reduce chronic pain in the neck and shoulders and related headache, and also to examine whether possible effects are long-lasting. Therefore, 24 female office workers (47±9 years old, mean±SD) who had had neck and shoulder pain for 12±9 years were randomly assigned to a test group (TG) or a control group (CG). Acupuncture was applied 10 times during 3-4 weeks either at presumed anti-pain acupoints (TG) or at placebo-points (CG). A physician measured the pain threshold (PPT) in the neck and shoulder regions with algometry before the first treatment, and after the last one and six months after the treatments. Questionnaires on muscle pain and headache were answered at the same occasions and again 3 years after the last treatment. The intensity and frequency of pain fell more for TG than for CG (Pb≤0.04) during the treatment period. Three years after the treatments TG still reported less pain than before the treatments (Pw{\textless}0.001), contrary to what CG did (Pb{\textless}0.04). The degree of headache fell during the treatment period for both groups, but more for TG than for CG (Pb=0.02). Three years after the treatments the effect still lasted for TG (P w{\textless}0.001) while the degree of headache for CG was back to the pre-treatment level (Pb{\textless}0.001). PPT of some muscles rose during the treatments for TG and remained higher 6 months after the treatments (P w{\textless}0.05), which contrasts the situation for CG. Adequate acupuncture treatment may reduce chronic pain in the neck and shoulders and related headache. The effect lasted for 3 years. {\textcopyright} 2004 International Association for the Study of Pain. Published by Elsevier B.V. All rights reserved.},
author = {He, Dong and Veiersted, Kaj Bo and H{\o}stmark, Arne T. and Medb{\o}, Jon Ingulf},
doi = {10.1016/j.pain.2004.01.018},
issn = {03043959},
journal = {Pain},
keywords = {Acupuncture,Algometry,Chronic pain,Neck,Placebo or sham acupuncture,Shoulder},
month = {jun},
number = {3},
pages = {299--307},
title = {{Effect of acupuncture treatment on chronic neck and shoulder pain in sedentary female workers: A 6-month and 3-year follow-up study}},
volume = {109},
year = {2004}
}
@article{virtanen2020scipy,
author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and Others},
journal = {Nature methods},
number = {3},
pages = {261--272},
publisher = {Nature Publishing Group},
title = {{SciPy 1.0: fundamental algorithms for scientific computing in Python}},
volume = {17},
year = {2020}
}
@article{Alexandru2019,
abstract = {Researchers often analyze several revisions of a software project to obtain historical data about its evolution. For example, they statically analyze the source code and monitor the evolution of certain metrics over multiple revisions. The time and resource requirements for running these analyses often make it necessary to limit the number of analyzed revisions, e.g., by only selecting major revisions or by using a coarse-grained sampling strategy, which could remove significant details of the evolution. Most existing analysis techniques are not designed for the analysis of multi-revision artifacts and they treat each revision individually. However, the actual difference between two subsequent revisions is typically very small. Thus, tools tailored for the analysis of multiple revisions should only analyze these differences, thereby preventing re-computation and storage of redundant data, improving scalability and enabling the study of a larger number of revisions. In this work, we propose the Lean Language-Independent Software Analyzer (LISA), a generic framework for representing and analyzing multi-revisioned software artifacts. It employs a redundancy-free, multi-revision representation for artifacts and avoids re-computation by only analyzing changed artifact fragments across thousands of revisions. The evaluation of our approach consists of measuring the effect of each individual technique incorporated, an in-depth study of LISA resource requirements and a large-scale analysis over 7 million program revisions of 4,000 software projects written in four languages. We show that the time and space requirements for multi-revision analyses can be reduced by multiple orders of magnitude, when compared to traditional, sequential approaches.},
author = {Alexandru, Carol V and Panichella, Sebastiano and Proksch, Sebastian and Gall, Harald C},
doi = {10.1007/s10664-018-9630-9},
file = {::},
issn = {1573-7616},
journal = {Empirical Software Engineering},
month = {feb},
number = {1},
pages = {332--380},
title = {{Redundancy-free analysis of multi-revision software artifacts}},
url = {https://doi.org/10.1007/s10664-018-9630-9},
volume = {24},
year = {2019}
}
@incollection{Jarczyk2014,
annote = {Very important paper for methodology.
Use the in paper annotations to get the idea.},
author = {Jarczyk, Oskar and Gruszka, B{\l}a{\.{z}}ej and Jaroszewicz, Szymon and Bukowski, Leszek and Wierzbicki, Adam},
booktitle = {International Conference on Social Informatics},
doi = {10.1007/978-3-319-13734-6_6},
file = {::},
pages = {80--94},
title = {{GitHub Projects. Quality Analysis of Open-Source Software}},
url = {http://link.springer.com/10.1007/978-3-319-13734-6{\_}6},
year = {2014}
}
@article{Fernandes2019,
annote = {Introduces an ensemble approach that is adaptive

Use mAUC and G-mean

Journal, 20 datasets

References for G-mean and MAUC, a multiclass version of the AUC

Back up all decisions from other papers, don't make up anything at all!!!},
author = {Fernandes, Everlandio and {De Carvalho}, Andre Carlos Ponce de Leon Ferreira and Yao, Xin},
doi = {10.1109/TKDE.2019.2898861},
file = {::},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
number = {8},
pages = {1--1},
title = {{Ensemble of Classifiers based on MultiObjective Genetic Sampling for Imbalanced Data}},
url = {https://ieeexplore.ieee.org/document/8640265/},
volume = {14},
year = {2019}
}
@article{Chavaillaz2016,
abstract = {Little is known about the long-term effects of system reliability when operators do not use a system during an extended lay-off period. To examine threats to skill maintenance, 28 participants operated twice a simulation of a complex process control system for 2.5 h, with an 8-month retention interval between sessions. Operators were provided with an adaptable support system, which operated at one of the following reliability levels: 60{\%}, 80{\%} or 100{\%}. Results showed that performance, workload, and trust remained stable at the second testing session, but operators lost self-confidence in their system management abilities. Finally, the effects of system reliability observed at the first testing session were largely found again at the second session. The findings overall suggest that adaptable automation may be a promising means to support operators in maintaining their performance at the second testing session.},
author = {Chavaillaz, Alain and Wastell, David and Sauer, J??rgen},
doi = {10.1016/j.apergo.2015.10.006},
file = {::},
issn = {18729126},
journal = {Applied Ergonomics},
keywords = {Adaptable automation,Lay-off period,Skill retention,System reliability,Trust},
pmid = {26603139},
title = {{Effects of extended lay-off periods on performance and operator trust under adaptable automation}},
year = {2016}
}
@article{Stamatatos2008,
annote = {The main idea in this paper was to combine all the documents for each of the classes. Many short sentences were then sampled from the minoroity classes where as less longer sentences were sampled form the majority classes. This resulted in inverting the class imbalance problem slightly but showed better results than down sampling all classes and undersampling the majority.},
author = {Stamatatos},
file = {::},
keywords = {author identification,class imbalance,text categorization},
number = {2},
pages = {790--799},
title = {{Using text sampling to handle the class imbalance problem}},
volume = {44},
year = {2008}
}
@article{Schelter2018,
abstract = {Modern companies and institutions rely on data to guide every single business process and decision. Missing or incorrect information seriously compromises any decision process downstream. Therefore, a crucial, but tedious task for everyone involved in data processing is to verify the quality of their data. We present a system for automating the verification of data quality at scale, which meets the requirements of production use cases. Our system provides a declarative API, which combines common quality constraints with user-defined validation code, and thereby enables 'unit tests' for data. We efficiently execute the resulting constraint validation workload by translating it to aggregation queries on Apache Spark. Our platform supports the incremental validation of data quality on growing datasets, and leverages machine learning, e.g., for enhancing constraint suggestions, for estimating the 'predictability' of a column, and for detecting anomalies in historic data quality time series. We discuss our design decisions, describe the resulting system architecture, and present an experimental evaluation on various datasets.},
annote = {Need for increased automation of data validation

Declarativity - Users to spend time on thinking, how their data should look like, Not to worry too much about how to implement the actual quality checks 

High flexibility on data validation

Data validation systems have to acknowledge - as data is being continuously produced

Scalability - Data validation systems should continuously scale to large datasets

Data quality dimensions - extension of the data (data values), intension of the data (the schema)

Completeness - The degree to which an entity includes data required to describe a real world object

Consistency - The degree to which a set of semantic rules are violated, Two types - Intra Relation Constraints (Tshirt size - S, M and L) and Inter Relation Constraints (Customer Id)

Accuracy - The correctness of data, Two types - syntactic and semantic 
Syntactic - Representation of a value with a corresponding definition domain
Semantic - Compares a value with its real world representation 

Unit tests for Data - Declarative definition of data quality constraints

Predictability

Data is seldomly static. Computing metrics for the growing dataset from all snapshots, result in incremental computations. For each feature column, summary statistics (minimum, maximum, mean, standard deviation, approximate quartiles) is computed.

Learning semantics of column and table names
Anomaly Detection - operates on historic time series of data, quality metrics (the ratio of missing values for different versions of a dataset)

Checks and constraints on dataframes
Metrics - size of the dataset, completeness of six columns, compliance for the three satisfies constraints

States Management
Logistic Regression -{\textgreater} SGD Classifier and hashing vectorizer
Experimental evaluation on 50 GB in parquet format, data sources are reddit.com and twitter},
author = {Schelter, Sebastian and Lange, Dustin and Schmidt, Philipp and Celikel, Meltem and Biessmann, Felix and Grafberger, Andreas},
doi = {10.14778/3229863.3229867},
file = {::},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
number = {12},
pages = {1781--1794},
title = {{Automating large-scale data quality verification}},
volume = {11},
year = {2018}
}
@article{Sadowski2015,
annote = {Developers in Google compose 12 search queries on average for a weekday, how about data scientists' frequency of composing search queries ?

Code search covers the spectrum from searching for code reuse to searching for concept localization

Code search studies - Observing programmers directly, analyzing search logs in controlled settings using pre-defined tasks or surveying developers about their search practices

A browser extension plugin and plugin was installed in all computers, the logs are collected whenever developers use internally built search tool},
author = {Sadowski, Caitlin and Stolee, Kathryn T and Elbaum, Sebastian},
file = {::},
journal = {Proceedings of the 2015 10th Joint Meeting on Foundationsof Software Engineering},
keywords = {17,28,3,31,code search,code search appears to,developer tools,have ce-,mented its role in,software development,throughout this evolution,user evaluation},
pages = {191--201},
title = {{How Developers Search for Code: A Case Study}},
year = {2015}
}
@inproceedings{Allamanis2014,
abstract = {Every programmer has a characteristic style, ranging from preferences about identifier naming to preferences about object relationships and design patterns. Coding conventions define a consistent syntactic style, fostering readability and hence maintainability. When collaborating, programmers strive to obey a project's coding conventions. However, one third of reviews of changes contain feedback about coding conventions, indicating that programmers do not always follow them and that project members care deeply about adherence. Unfortunately, programmers are often unaware of coding conventions because inferring them requires a global view, one that aggregates the many local decisions programmers make and identifies emergent consensus on style. We present NATURALIZE, a framework that learns the style of a codebase, and suggests revisions to improve stylistic consistency. NATURALIZE builds on recent work in applying statistical natural language processing to source code. We apply NATURALIZE to suggest natural identifier names and formatting conventions. We present four tools focused on ensuring natural code during development and release management, including code review. NATURALIZE achieves 94{\%} accuracy in its top suggestions for identifier names. We used NATURALIZE to generate 18 patches for 5 open source projects: 14 were accepted.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1402.4182},
author = {Allamanis, Miltiadis and Barr, Earl T. and Bird, Christian and Sutton, Charles},
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering - FSE 2014},
doi = {10.1145/2635868.2635883},
eprint = {1402.4182},
file = {::},
isbn = {9781450330565},
keywords = {Coding conventions,Naturalness of software},
pages = {281--293},
publisher = {ACM Press},
title = {{Learning natural coding conventions}},
url = {http://dl.acm.org/citation.cfm?doid=2635868.2635883},
year = {2014}
}
@inproceedings{Khalajzadeh2020a,
author = {Khalajzadeh, Hourieh and Simmons, Andrew J. and Abdelrazek, Mohamed and Grundy, John and Hosking, John and He, Qiang},
booktitle = {Evaluation of Novel Approaches to Software Engineering (ENASE)},
file = {::},
keywords = {big data analytics,big data modeling,big data toolkits,domain specific visual languages,end-user},
title = {{Visual Languages for Supporting Big Data Analytics Development}},
year = {2020}
}
@inproceedings{zhu2014patterns,
author = {Zhu, Jiaxin and Zhou, Minghui and Mockus, Audris},
booktitle = {Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
file = {::},
organization = {ACM},
pages = {30},
title = {{Patterns of folder use and project popularity: A case study of GitHub repositories}},
year = {2014}
}
@inproceedings{Cummaudo:2019esem,
abstract = {Background: Good API documentation facilitates the development process, improving productivity and quality. While the topic of API documentation quality has been of interest for the last two decades, there have been few studies to map the specific constructs needed to create a good document. In effect, we still need a structured taxonomy that captures such knowledge systematically.Aims: This study reports emerging results of a systematic mapping study. We capture key conclusions from previous studies that assess API documentation quality, and synthesise the results into a single framework.Method: By conducting a systematic review of 21 key works, we have developed a five dimensional taxonomy based on 34 categorised weighted recommendations.Results: All studies utilise field study techniques to arrive at their recommendations, with seven studies employing some form of interview and questionnaire, and four conducting documentation analysis. The taxonomy we synthesise reinforces that usage description details (code snippets, tutorials, and reference documents) are generally highly weighted as helpful in API documentation, in addition to design rationale and presentation.Conclusions: We propose extensions to this study aligned to developer utility for each of the taxonomy's categories.},
address = {Porto de Galinhas, Recife, Brazil},
author = {Cummaudo, Alex and Vasa, Rajesh and Grundy, John},
booktitle = {Proceedings of the 13th International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2019.8870148},
isbn = {978-1-72-812968-6},
issn = {1949-3789},
keywords = {API,DevX,documentation,systematic mapping study,taxonomy},
month = {oct},
pages = {1--6},
publisher = {IEEE},
title = {{What should I document? A preliminary systematic mapping study into API documentation knowledge}},
year = {2019}
}
@inproceedings{Dormuth2019,
abstract = {Many software analysis methods have come to rely on machine learning approaches. Code segmentation - the process of decomposing source code into meaningful blocks - can augment these methods by featurizing code, reducing noise, and limiting the problem space. Traditionally, code segmentation has been done using syntactic cues; current approaches do not intentionally capture logical content. We develop a novel deep learning approach to generate logical code segments regardless of the language or syntactic correctness of the code. Due to the lack of logically segmented source code, we introduce a unique data set construction technique to approximate ground truth for logically segmented code. Logical code segmentation can improve tasks such as automatically commenting code, detecting software vulnerabilities, repairing bugs, labeling code functionality, and synthesizing new code.},
archivePrefix = {arXiv},
arxivId = {1907.08615},
author = {Dormuth, Jacob and Gelman, Ben and Moore, Jessica and Slater, David},
booktitle = {Proceedings of the 31st International Conference on Software Engineering and Knowledge Engineering},
doi = {10.18293/SEKE2019-026},
eprint = {1907.08615},
file = {::},
title = {{Logical Segmentation of Source Code}},
url = {http://arxiv.org/abs/1907.08615{\%}0Ahttp://dx.doi.org/10.18293/SEKE2019-026},
year = {2019}
}
@inproceedings{Braiek2018,
author = {Braiek, Houssem Ben and Khomh, Foutse and Adams, Bram},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories - MSR '18},
doi = {10.1145/3196398.3196445},
editor = {Zaidman, Andy and Kamei, Yasutaka and Hill, Emily},
file = {::},
isbn = {9781450357166},
pages = {353--363},
publisher = {ACM Press},
title = {{The open-closed principle of modern machine learning frameworks}},
url = {http://dl.acm.org/citation.cfm?doid=3196398.3196445},
year = {2018}
}
@article{Palmer2009,
abstract = {In this paper we describe Ginger, a new language with first class support for literate programming. Literate programming is a philosophy that argues computer programs should be written as literature with human readability and understanding of paramount importance. While the intent of literate programming is to make understanding computer programs simpler, most literate programming systems are quite complex and consist of three different languages corresponding to 1) an implementation language, 2) a documentation language, and 3) a literate programming glue language. In Knuth's original implementation these were Pascal, TeX, and WEB respectively. Antithetical to the goals that literate programming espouses, this three language paradigm creates a truly challenging environment for new programmers. In this paper we reimagine literate programming as a core programming language feature and describe a novel system for literate programming based on G-expression transformations. We show that Ginger code can be used to naturally represent code, prose, and literate connections, which in turn unifies, simplifies and significantly extends the literate programming experience. Copyright {\textcopyright} 2009 ACM.},
author = {Palmer, James Dean and Hillenbrand, Eddie},
doi = {10.1145/1639950.1640072},
file = {::},
isbn = {9781605587660},
journal = {Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA},
keywords = {Ginger,Literate programming,Program comprehension},
pages = {1007--1014},
title = {{Reimagining literate programming}},
year = {2009}
}
@article{Ghahramani2015,
abstract = {How can a machine learn from experience? Probabilistic modelling provides a framework for understanding what learning is, and has therefore emerged as one of the principal theoretical and practical approaches for designing machines that learn from data acquired through experience. The probabilistic framework, which describes how to represent and manipulate uncertainty about models and predictions, has a central role in scientific data analysis, machine learning, robotics, cognitive science and artificial intelligence. This Review provides an introduction to this framework, and discusses some of the state-of-the-art advances in the field, namely, probabilistic programming, Bayesian optimization, data compression and automatic model discovery.},
author = {Ghahramani, Zoubin},
doi = {10.1038/nature14541},
file = {::},
issn = {14764687},
journal = {Nature},
number = {7553},
pages = {452--459},
title = {{Probabilistic machine learning and artificial intelligence}},
volume = {521},
year = {2015}
}
@article{Nundhapana2018,
abstract = {Understandability is a software characteristic that helps ease software maintenance and evolution. When modifying or reusing software that is written by someone else, software developers often have difficulties in trying to understand what the existing software does and how. Such an issue is commonly found in software-developing organizations. This paper discusses an approach taken by an IT organization in Thailand which attempts to enforce coding standards within its iOS development team in order to promote software understandability and maintainability. Among coding standards, naming conventions are important but are most often violated. This paper presents the development of a naming convention checking framework that consists of tools to automatically detect naming convention violations in Objective C programs. The framework facilitates iOS developers in modifying the programs so that they adhere to the naming conventions. An experiment showed that the developers' understanding in the programs that had been modified, as suggested by the naming convention checking framework, did improve at a statistical significance level of 0.05. This approach can enhance program understandability and can be applied to other software-developing organizations.},
author = {Nundhapana, Ruchuta and Senivongse, Twittie},
file = {::},
isbn = {9789881404817},
issn = {20780958},
journal = {Lecture Notes in Engineering and Computer Science},
keywords = {Maintainability,Naming convention,Objective C,Understandability},
pages = {314--319},
title = {{Enhancing understandability of objective C programs using naming convention checking framework}},
volume = {2237},
year = {2018}
}
@article{Yang2016,
abstract = {Enriched by natural language texts, Stack Overflow code snippets are an invaluable code-centric knowledge base of small units of source code. Besides being useful for software developers, these annotated snippets can potentially serve as the basis for automated tools that provide working code solutions to specific natural language queries. With the goal of developing automated tools with the Stack Overflow snippets and surrounding text, this paper investigates the following questions: (1) How usable are the Stack Overflow code snippets? and (2) When using text search engines for matching on the natural language questions and answers around the snippets, what percentage of the top results contain usable code snippets? A total of 3M code snippets are analyzed across four languages: C{\#}, Java, JavaScript, and Python. Python and JavaScript proved to be the languages for which the most code snippets are usable. Conversely, Java and C{\#} proved to be the languages with the lowest usability rate. Further qualitative analysis on usable Python snippets shows the characteristics of the answers that solve the original question. Finally, we use Google search to investigate the alignment of usability and the natural language annotations around code snippets, and explore how to make snippets in Stack Overflow an adequate base for future automatic program generation.},
archivePrefix = {arXiv},
arxivId = {1605.04464},
author = {Yang, Di and Hussain, Aftab and Lopes, Cristina Videira},
doi = {10.1145/2901739.2901767},
eprint = {1605.04464},
file = {::},
isbn = {9781450341868},
journal = {Proceedings - 13th Working Conference on Mining Software Repositories, MSR 2016},
keywords = {Automatic program generation,Code mining},
pages = {391--401},
title = {{From query to usable code: An analysis of Stack Overflow code snippets}},
year = {2016}
}
@article{Amershi2019,
abstract = {Advances in artifcial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of guidelines for human-AI interaction design.},
author = {Amershi, Saleema and Weld, Dan and Vorvoreanu, Mihaela and Fourney, Adam and Nushi, Besmira and Collisson, Penny and Suh, Jina and Iqbal, Shamsi and Bennett, Paul N. and Inkpen, Kori and Teevan, Jaime and Kikin-Gil, Ruth and Horvitz, Eric},
doi = {10.1145/3290605.3300233},
file = {::},
isbn = {9781450359702},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {AI-infused systems,Design guidelines,Human-AI interaction},
pages = {1--13},
title = {{Guidelines for human-AI interaction}},
year = {2019}
}
@incollection{Krawczyk2018,
author = {Krawczyk, Bartosz and Prati, Ronaldo C. and Herrera, Francisco and Garc{\'{i}}a, Salvador and Galar, Mikel and Fern{\'{a}}ndez, Alberto},
booktitle = {Learning from Imbalanced Data Sets},
doi = {10.1007/978-3-319-98074-4_8},
title = {{Imbalanced Classification with Multiple Classes}},
year = {2018}
}
@article{Blei2014,
abstract = {We survey latent variable models for solving data-analysis problems. A latent variable model is a probabilistic model that encodes hidden patterns in the data. We uncover these patterns from their conditional distribution and use them to summarize data and form predictions. Latent variable models are important in many fields, including computational biology, natural language processing, and social network analysis. Our perspective is that models are developed iteratively: We build a model, use it to analyze data, assess how it succeeds and fails, revise it, and repeat. We describe how new research has transformed these essential activities. First, we describe probabilistic graphical models, a language for formulating latent variable models. Second, we describe mean field variational inference, a generic algorithm for approximating conditional distributions. Third, we describe how to use our analyses to solve problems: exploring the data, forming predictions, and pointing us in the direction of improved models.},
author = {Blei, David M.},
doi = {10.1146/annurev-statistics-022513-115657},
file = {::},
journal = {Ssrn},
number = {2014},
title = {{Build, Compute, Critique, Repeat: Data Analysis with Latent Variable Models}},
year = {2014}
}
@article{Chikkerur2010,
abstract = {In the theoretical framework of this paper, attention is part of the inference process that solves the visual recognition problem of what is where. The theory proposes a computational role for attention and leads to a model that predicts some of its main properties at the level of psychophysics and physiology. In our approach, the main goal of the visual system is to infer the identity and the position of objects in visual scenes: spatial attention emerges as a strategy to reduce the uncertainty in shape information while feature-based attention reduces the uncertainty in spatial information. Featural and spatial attention represent two distinct modes of a computational process solving the problem of recognizing and localizing objects, especially in difficult recognition tasks such as in cluttered natural scenes. We describe a specific computational model and relate it to the known functional anatomy of attention. We show that several well-known attentional phenomena - including bottom-up pop-out effects, multiplicative modulation of neuronal tuning curves and shift in contrast responses - all emerge naturally as predictions of the model. We also show that the Bayesian model predicts well human eye fixations (considered as a proxy for shifts of attention) in natural scenes. {\textcopyright} 2010 Elsevier Ltd.},
author = {Chikkerur, Sharat and Serre, Thomas and Tan, Cheston and Poggio, Tomaso},
doi = {10.1016/j.visres.2010.05.013},
file = {::},
issn = {00426989},
journal = {Vision Research},
keywords = {Attention,Bayesian inference,Computational model,Object recognition},
number = {22},
pages = {2233--2247},
publisher = {Elsevier Ltd},
title = {{What and where: A Bayesian inference theory of attention}},
url = {http://dx.doi.org/10.1016/j.visres.2010.05.013},
volume = {50},
year = {2010}
}
@article{KevinRange2012,
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Loren, Cobb and Ashok, Krishnamurty and Jan, Mandel and Johnathan, Beezley},
doi = {10.1038/jid.2014.371},
eprint = {NIHMS150003},
file = {::},
isbn = {6176321972},
issn = {15378276},
journal = {Bone},
keywords = {epiblast,gfp fusion,histone h2b-,icm,lineage specification,live imaging,mouse blastocyst,pdgfr $\alpha$,primitive endoderm},
number = {1},
pages = {1--7},
pmid = {1000000221},
title = {{Bayesian Tracking of Emerging Epidemics Using Ensemble Optimal Statistical Interpolation}},
volume = {23},
year = {2012}
}
@book{yeung_book,
editor = {Yeung, K. and Lodge, M.},
publisher = {Oxford University Press},
title = {{Algorithmic Regulation}},
year = {2019}
}
@article{GeorgeW.Brown2016,
author = {{George W . Brown}, John Y . Lu and Robert J . Wolfson},
file = {::},
number = {1},
pages = {51--63},
title = {{Dynamic Modelling of Inventories Subject to Obsolescence Author ( s ): George W . Brown , John Y . Lu and Robert J . Wolfson Published by : INFORMS Stable URL : http://www.jstor.org/stable/2627992}},
volume = {11},
year = {2016}
}
@inproceedings{shoeb2010application,
abstract = {We present and evaluate a machine learning approach to constructing patient-specific classifiers that detect the onset of an epileptic seizure through analysis of the scalp EEG, a non-invasive measure of the brain's electrical activity. This problem is challenging because the brain's electrical activity is composed of numerous classes with overlapping characteristics. The key steps involved in realizing a high performance algorithm included shaping the problem into an appropriate machine learning framework, and identifying the features critical to separating seizure from other types of brain activity. When trained on 2 or more seizures per patient and tested on 916 hours of continuous EEG from 24 patients, our algorithm detected 96{\%} of 173 test seizures with a median detection delay of 3 seconds and a median false detection rate of 2 false detections per 24 hour period. We also provide information about how to download the CHB-MIT database, which contains the data used in this study.},
author = {Shoeb, Ali and Guttag, John},
booktitle = {ICML 2010 - Proceedings, 27th International Conference on Machine Learning},
file = {::},
isbn = {9781605589077},
pages = {975--982},
title = {{Application of machine learning to epileptic seizure detection}},
year = {2010}
}
@inproceedings{Haiduc2010a,
abstract = {During maintenance developers cannot read the entire code of large systems. They need a way to get a quick understanding of source code entities (such as, classes, methods, packages, etc.), so they can efficiently identify and then focus on the ones related to their task at hand. Sometimes reading just a method header or a class name does not tell enough about its purpose and meaning, while reading the entire implementation takes too long. We study a solution which mitigates the two approaches, i.e., short and accurate textual descriptions that illustrate the software entities without having to read the details of the implementation. We create such descriptions using techniques from automatic text summarization. The paper presents a study that investigates the suitability of various such techniques for generating source code summaries. The results indicate that a combination of text summarization techniques is most appropriate for source code summarization and that developers generally agree with the summaries produced.},
author = {Haiduc, Sonia and Aponte, Jairo and Moreno, Laura and Marcus, Andrian},
booktitle = {Proceedings - Working Conference on Reverse Engineering, WCRE},
doi = {10.1109/WCRE.2010.13},
file = {::},
isbn = {9780769541235},
issn = {10951350},
keywords = {Program comprehension,Text summarization},
pages = {35--44},
title = {{On the use of automated text summarization techniques for summarizing source code}},
year = {2010}
}
@article{Stamatatos2008,
annote = {The main idea in this paper was to combine all the documents for each of the classes. Many short sentences were then sampled from the minoroity classes where as less longer sentences were sampled form the majority classes. This resulted in inverting the class imbalance problem slightly but showed better results than down sampling all classes and undersampling the majority.},
author = {Stamatatos},
file = {::},
keywords = {author identification,class imbalance,text categorization},
number = {2},
pages = {790--799},
title = {{Using text sampling to handle the class imbalance problem}},
volume = {44},
year = {2008}
}
@article{Alshomrani2015,
abstract = {In a general scenario of classification, one of the main drawbacks for the achievement of accurate models is the presence of high overlapping among the concepts to be learnt. This drawback becomes more severe when we are addressing problems with an imbalanced class distribution. In such cases, the minority class usually represents the most important target of the classification. The failure to correctly identify the minority class instances is often related to those boundary areas in which they are outnumbered by the majority class examples. Throughout the learning stage of the most common rule learning methodologies, the process is often biased to obtain rules that cover the largest areas of the problem. The reason for this behavior is that these types of algorithms aim to maximize the confidence, measured as a ratio of positive and negative covered examples. Rules that identify small areas, in which minority class examples are poorly represented and overlap with majority class examples, will be discarded in favor of more general rules whose consequent will be unequivocally associated with the majority class. Among all types of rule systems, linguistic Fuzzy Rule Based Systems have shown good behavior in the context of classification with imbalanced datasets. Accordingly, we propose a feature weighting approach which aims at analyzing the significance of the problem's variables by weighting the membership degree within the inference process. This is done by applying a different degree of significance to the variables that represent the dataset, enabling to smooth the problem boundaries. These parameters are learnt by means of an optimization process in the framework of evolutionary fuzzy systems. Experimental results using a large number of benchmark problems with different degrees of imbalance and overlapping, show the goodness of our proposal.},
author = {Alshomrani, Saleh and Bawakid, Abdullah and Shim, Seong O. and Fern{\'{a}}ndez, Alberto and Herrera, Francisco},
doi = {10.1016/j.knosys.2014.09.002},
file = {::},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Evolutionary fuzzy systems,Feature weighting,Fuzzy rule based classification systems,Imbalanced datasets,Overlapping},
pages = {1--17},
publisher = {Elsevier B.V.},
title = {{A proposal for evolutionary fuzzy systems using feature weighting: Dealing with overlapping in imbalanced datasets}},
url = {http://dx.doi.org/10.1016/j.knosys.2014.09.002},
volume = {73},
year = {2015}
}
@article{Wang2015,
abstract = {Online class imbalance learning is a new learning problem that combines the challenges of both online learning and class imbalance learning. It deals with data streams having very skewed class distributions. This type of problems commonly exists in real-world applications, such as fault diagnosis of real-time control monitoring systems and intrusion detection in computer networks. In our earlier work, we defined class imbalance online, and proposed two learning algorithms OOB and UOB that build an ensemble model overcoming class imbalance in real time through resampling and time-decayed metrics. In this paper, we further improve the resampling strategy inside OOB and UOB, and look into their performance in both static and dynamic data streams. We give the first comprehensive analysis of class imbalance in data streams, in terms of data distributions, imbalance rates and changes in class imbalance status. We find that UOB is better at recognizing minority-class examples in static data streams, and OOB is more robust against dynamic changes in class imbalance status. The data distribution is a major factor affecting their performance. Based on the insight gained, we then propose two new ensemble methods that maintain both OOB and UOB with adaptive weights for final predictions, called WEOB1 and WEOB2. They are shown to possess the strength of OOB and UOB with good accuracy and robustness.},
author = {Wang, Shuo and Minku, Leandro L. and Yao, Xin},
doi = {10.1109/TKDE.2014.2345380},
file = {::},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Bagging,Class imbalance,ensemble learning,online learning,resampling},
number = {5},
pages = {1356--1368},
publisher = {IEEE},
title = {{Resampling-based ensemble methods for online class imbalance learning}},
volume = {27},
year = {2015}
}
@inproceedings{leff2001web,
author = {Leff, Avraham and Rayfield, James T},
booktitle = {Proceedings fifth ieee international enterprise distributed object computing conference},
organization = {IEEE},
pages = {118--127},
title = {{Web-application development using the model/view/controller design pattern}},
year = {2001}
}
@article{Massa2015,
abstract = {Cognitive problems following stroke are typically analysed using either short but relatively uninformative general tests or through detailed but time consuming tests of domain specific deficits (e.g., in language, memory, praxis). Here we present an analysis of neuropsychological deficits detected using a screen designed to fall between other screens by being 'broad' (testing multiple cognitive abilities) but 'shallow' (sampling the abilities briefly, to be time efficient) - the BCoS. Assessment using the Birmingham Cognitive Screen (BCoS) enables the relations between 'domain specific' and 'domain general' cognitive deficits to be evaluated as the test generates an overall cognitive profile for individual patients. We analysed data from 287 patients tested at a sub-acute stage of stroke ({\textless}3 months). Graphical modelling techniques were used to investigate the associative structure and conditional independence between deficits within and across the domains sampled by BCoS (attention and executive functions, language, memory, praxis and number processing). The patterns of deficit within each domain conformed to existing cognitive models. However, these within-domain patterns underwent substantial change when the whole dataset was modelled, indicating that domain-specific deficits can only be understood in relation to linked changes in domain-general processes. The data point to the importance of using over-arching cognitive screens, measuring domain-general as well as domain-specific processes, in order to account for neuropsychological deficits after stroke. The paper also highlights the utility of using graphical modelling to understand the relations between cognitive components in complex datasets.},
author = {Massa, M. Sofia and Wang, Naxian and Bickerton, Wa Ling and Demeyere, Nele and Riddoch, M. Jane and Humphreys, Glyn W.},
doi = {10.1016/j.cortex.2015.06.006},
file = {::},
issn = {19738102},
journal = {Cortex},
keywords = {Assessment,Cognitive impairment,Statistical analysis},
pages = {190--204},
publisher = {Elsevier Srl.},
title = {{On the importance of cognitive profiling: Agraphical modelling analysis of domain-specific and domain-general deficits after stroke}},
volume = {71},
year = {2015}
}
@inproceedings{Simpkin2013,
abstract = {Synthetic training exercises, not unlike live exercises, require extensive planning, preparation and management in order to provide trainees with effective training experiences. These activities are performed by training facilitators, commonly known as the White Force. For many exercises, White Force personnel far outnumber the training audience, and the limited availability of White Force personnel places an upper- limit on exercise size, scope and fidelity. This paper examines the White Force activities in previous Australian synthetic training exercises, and builds the case for further development of White Force technologies and techniques. It is the premise of this work that developments leveraging White Force personnel will directly improve the cost effectiveness of synthetic training.},
address = {Vibe Hotel, North Sydney, Australia},
author = {Simpkin, Graeme and Ross, Peter and Macpherson, Bradley},
booktitle = {NATO Modelling {\&} Simulation Group (NMSG) Multi-Workshop},
doi = {10.14339/STO-MP-MSG-111},
file = {::},
title = {{On the Need for White Force Multipliers}},
url = {http://ftp.rta.nato.int/public/PubFullText/RTO/MP/STO-MP-MSG-111/MP-MSG-111-20.pdf https://www.sto.nato.int/publications/STO Meeting Proceedings/Forms/Meeting Proceedings Document Set/docsethomepage.aspx?ID=40677{\&}FolderCTID=0x0120D5200078F9E87043356C409A0},
year = {2013}
}
@article{Zhu2017,
abstract = {Multiclass imbalance data learning has attracted increasing interests from the research community. Unfortunately, existing oversampling solutions, when facing this more challenging problem as compared to two-class imbalance case, have shown their respective deficiencies such as causing serious over generalization or not actively improving the class imbalance in data space. We propose a k-nearest neighbors (k-NN)-based synthetic minority oversampling algorithm, termed SMOM, to handle multiclass imbalance problems. Different from previous k-NN-based oversampling algorithms, where for any original minority instance the synthetic instances are randomly generated in the directions of its k-nearest neighbors, SMOM assigns a selection weight to each neighbor direction. The neighbor directions that can produce serious over generalization will be given small selection weights. This way, SMOM forms a mechanism of avoiding over generalization as the safer neighbor directions are more likely to be selected to yield the synthetic instances. Owing to this, SMOM can aggressively explore the regions of minority classes by configuring a high value for parameter k, but do not result in severe over generalization. Extensive experiments using 27 real-world data sets demonstrate the effectiveness of our algorithm.},
author = {Zhu, Tuanfei and Lin, Yaping and Liu, Yonghe},
doi = {10.1016/j.patcog.2017.07.024},
file = {::},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Multiclass imbalance problems,Neighbor directions,Over generalization,Synthetic minority oversampling},
pages = {327--340},
publisher = {Elsevier Ltd},
title = {{Synthetic minority oversampling technique for multiclass imbalance problems}},
volume = {72},
year = {2017}
}
@article{Tian2017,
abstract = {Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads. However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases. In this paper, we design, implement and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explores different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge.},
archivePrefix = {arXiv},
arxivId = {1708.08559},
author = {Tian, Yuchi and Pei, Kexin and Jana, Suman and Ray, Baishakhi},
eprint = {1708.08559},
file = {::},
isbn = {9781450356381},
keywords = {acm reference format,au-,deep learning,deep neural networks,neuron coverage,self-driving cars,testing,tonomous vehicle},
title = {{DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous Cars}},
url = {http://arxiv.org/abs/1708.08559},
year = {2017}
}
@article{Yu2017,
abstract = {The attention mechanisms in deep neural networks are inspired by human's attention that sequentially focuses on the most relevant parts of the information over time to generate prediction output. The attention parameters in those models are implicitly trained in an end-to-end manner, yet there have been few trials to explicitly incorporate human gaze tracking to supervise the attention models. In this paper, we investigate whether attention models can benefit from explicit human gaze labels, especially for the task of video captioning. We collect a new dataset called VAS, consisting of movie clips, and corresponding multiple descriptive sentences along with human gaze tracking data. We propose a video captioning model named Gaze Encoding Attention Network (GEAN) that can leverage gaze tracking information to provide the spatial and temporal attention for sentence generation. Through evaluation of language similarity metrics and human assessment via Amazon mechanical Turk, we demonstrate that spatial attentions guided by human gaze data indeed improve the performance of multiple captioning methods. Moreover, we show that the proposed approach achieves the state-of-the-art performance for both gaze prediction and video captioning not only in our VAS dataset but also in standard datasets (e.g. LSMDC [24] and Hollywood2 [18]).},
archivePrefix = {arXiv},
arxivId = {1707.06029},
author = {Yu, Youngjae and Choi, Jongwook and Kim, Yeonhwa and Yoo, Kyung and Lee, Sang Hun and Kim, Gunhee},
doi = {10.1109/CVPR.2017.648},
eprint = {1707.06029},
file = {::},
isbn = {9781538604571},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
pages = {6119--6127},
title = {{Supervising neural attention models for video captioning by human gaze data}},
volume = {2017-Janua},
year = {2017}
}
@book{Pasquini1999,
abstract = {Cyber attacks are the core of any security assessment of ICT-based systems. One of the more promising research fields in this$\backslash$n context is related to the representation of the attack patterns. Several are the models proposed to represent them; these$\backslash$n models usually provide a generic representation of attacks. Conversely, the experience shows that attack profiles are strongly$\backslash$n dependent upon several “boundary conditions”. This paper defends that from the security assessment perspective, it is necessary$\backslash$n to integrate the knowledge contained in the attack patterns with “boundary” knowledge related to vulnerability of the target$\backslash$n system and to the potential threats. In this paper, after a characterization of this “boundary knowledge”, we propose an n-dimensional$\backslash$n view of the attack tree approach, integrating information on threats and vulnerabilities. Moreover, we show how to use this$\backslash$n view to derive knowledge about the security exposure of a target system.$\backslash$n $\backslash$n Keywords: Security assessment, Attack Pattern.},
author = {Pasquini, Alberto},
doi = {10.1007/3-540-48249-0},
file = {::},
isbn = {978-3-540-66488-8},
keywords = {Artificial intelligence,Dependability,Safety engin,artificial intelligence,data quality,dependability,empirical modelling,model validation,safety engineering},
pages = {431--438},
publisher = {Springer International Publishing},
title = {{Computer Safety, Reliability and Security}},
url = {http://link.springer.com/10.1007/3-540-48249-0},
volume = {1698},
year = {1999}
}
@inproceedings{Yuan2018,
abstract = {Epileptic seizure detection using multi-channel scalp electroencephalogram (EEG) signals has gained increasing attention in clinical therapy. Recently, researchers attempt to employ deep learning techniques with channel selection to determine critical channels. However, existing models with such hard selection procedure do not take dynamic constraints into account, since the irrelevant channels vary significantly across different situations. To address these issues, we propose ChannelAtt, an end-to-end multi-view deep learning model with channel-aware attention mechanism, to express multi-channel EEG signals in a high-level space with interpretable meanings. ChannelAtt jointly learns both multi-view representation and its contribution scores. We propose two attention mechanisms to learn the attentional representations of multi-channel EEG signals in time-frequency domain. Experimental results show that the proposed ChannelAtt model outperforms the baselines in detecting epileptic seizures. Analytical results of a case study demonstrate that the learned attentional representations are meaningful.},
author = {Yuan, Ye and Xun, Guangxu and Ma, Fenglong and Suo, Qiuling and Xue, Hongfei and Jia, Kebin and Zhang, Aidong},
booktitle = {2018 IEEE EMBS International Conference on Biomedical and Health Informatics, BHI 2018},
doi = {10.1109/BHI.2018.8333405},
file = {::},
isbn = {9781538624050},
month = {apr},
pages = {206--209},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{A novel channel-aware attention framework for multi-channel EEG seizure detection via multi-view deep learning}},
volume = {2018-Janua},
year = {2018}
}
@article{Kay2016,
abstract = {A core tradition of HCI lies in the experimental evaluation of the effects of techniques and interfaces to determine if they are useful for achieving their purpose. However, our individual analyses tend to stand alone, and study results rarely accrue in more precise estimates via meta-analysis: in a literature search, we found only 56 meta-analyses in HCI in the ACM Digital Library, 3 of which were published at CHI (often called the top HCI venue). Yet meta-analysis is the gold standard for demonstrating robust quantitative knowledge. We treat this as a user-centered design problem: the failure to accrue quantitative knowledge is not the users' (i.e. researchers') failure, but a failure to consider those users' needs when designing statistical practice. Using simulation, we compare hypothetical publication worlds following existing frequentist against Bayesian practice. We show that Bayesian analysis yields more precise effects with each new study, facilitating knowledge accrual without traditional meta-analyses. Bayesian practices also allow more principled conclusions from small-n studies of novel techniques. These advantages make Bayesian practices a likely better fit for the culture and incentives of the field. Instead of admonishing ourselves to spend resources on larger studies, we propose using tools that more appropriately analyze small studies and encourage knowledge accrual from one study to the next. We also believe Bayesian methods can be adopted from the bottom up without the need for new incentives for replication or meta-analysis. These techniques offer the potential for a more user-(i.e. researcher-) centered approach to statistical analysis in HCI.},
author = {Kay, Matthew and Nelson, Gregory L. and Hekler, Eric B.},
doi = {10.1145/2858036.2858465},
file = {::},
isbn = {9781450333627},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Bayesian statistics,Effect size,Estimation,Meta-analysis,Replication,Small studies},
pages = {4521--4532},
title = {{Researcher-centered design of statistics: Why Bayesian statistics better fit the culture and incentives of HCI}},
year = {2016}
}
@article{He2012,
abstract = {We develop a production-inventory model for deteriorating items with demand disruption. This differs from the conventional inventory model which is affected only by either deterioration or disruption. In real-life production-inventory systems, deterioration of products and demand disruption are inevitable. The objective of this paper is to address these issues and to be able to derive the optimal production run time and replenishment policy for spot market purchases. We divide the problem into different scenarios according to disruption's time and magnitude. In each scenario the optimal production and inventory plans are provided so that the manufacturer can satisfy the new demand and decrease the loss. Then a numerical example is used to illustrate the model. We develop a production-inventory model for deteriorating items with demand disruption. This differs from the conventional inventory model which is affected only by either deterioration or disruption. In real-life production-inventory systems, deterioration of products and demand disruption are inevitable. The objective of this paper is to address these issues and to be able to derive the optimal production run time and replenishment policy for spot market purchases. We divide the problem into different scenarios according to disruption's time and magnitude. In each scenario the optimal production and inventory plans are provided so that the manufacturer can satisfy the new demand and decrease the loss. Then a numerical example is used to illustrate the model.},
author = {He, Yong and Wang, Shouyang},
doi = {10.1080/00207543.2011.615351},
issn = {00207543},
journal = {International Journal of Production Research},
keywords = {deteriorating items,disruption management,inventory,production},
title = {{Analysis of production-inventory system for deteriorating items with demand disruption}},
year = {2012}
}
@inproceedings{Cummaudo:2020icse,
address = {Seoul, Republic of Korea},
annote = {In Press},
author = {Cummaudo, Alex and Vasa, Rajesh and Barnett, Scott and Grundy, John and Abdelrazek, Mohamed},
booktitle = {Proceedings of the 42nd International Conference on Software Engineering},
keywords = {InPress},
mendeley-tags = {InPress},
month = {oct},
publisher = {IEEE},
title = {{Interpreting Cloud Computer Vision Pain-Points: A Mining Study of Stack Overflow}},
year = {2020}
}
@article{Esfahani2013,
abstract = {The ever-growing complexity of software systems coupled with their stringent availability requirements are challenging the manual management of software after its deployment. This has motivated the development of self-adaptive software systems. Self-adaptation endows a software system with the ability to satisfy certain objectives by automatically modifying its behavior at runtime. While many promising approaches for the construction of self-adaptive software systems have been developed, the majority of them ignore the uncertainty underlying the adaptation. This has been one of the key inhibitors to widespread adoption of self-adaption techniques in risk-averse real-world applications. Uncertainty in this setting is a vaguely understood term. In this paper, we characterize the sources of uncertainty in self-adaptive software system, and demonstrate its impact on the system's ability to satisfy its objectives. We then provide an alternative notion of optimality that explicitly incorporates the uncertainty underlying the knowledge (models) used for decision making. We discuss the state-of-the-art for dealing with uncertainty in this setting, and conclude with a set of challenges, which provide a road map for future research.},
author = {Esfahani, Naeem and Malek, Sam},
doi = {10.1007/978-3-642-35813-5_9},
file = {::},
isbn = {9783642358128},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Self-Adaptive Software Systems,Uncertainty},
pages = {214--238},
title = {{Uncertainty in self-adaptive software systems}},
volume = {7475 LNCS},
year = {2013}
}
@article{Wilming2017,
abstract = {We present a dataset of free-viewing eye-movement recordings that contains more than 2.7 million fixation locations from 949 observers on more than 1000 images from different categories. This dataset aggregates and harmonizes data from 23 different studies conducted at the Institute of Cognitive Science at Osnabr{\"{u}}ck University and the University Medical Center in Hamburg-Eppendorf. Trained personnel recorded all studies under standard conditions with homogeneous equipment and parameter settings. All studies allowed for free eye-movements, and differed in the age range of participants (∼7-80 years), stimulus sizes, stimulus modifications (phase scrambled, spatial filtering, mirrored), and stimuli categories (natural and urban scenes, web sites, fractal, pink-noise, and ambiguous artistic figures). The size and variability of viewing behavior within this dataset presents a strong opportunity for evaluating and comparing computational models of overt attention, and furthermore, for thoroughly quantifying strategies of viewing behavior. This also makes the dataset a good starting point for investigating whether viewing strategies change in patient groups.},
author = {Wilming, Niklas and Onat, Selim and Ossand{\'{o}}n, Jos{\'{e}} P. and A{\c{c}}ik, Alper and Kietzmann, Tim C. and Kaspar, Kai and Gameiro, Ricardo R. and Vormberg, Alexandra and K{\"{o}}nig, Peter},
doi = {10.1038/sdata.2016.126},
file = {::},
issn = {20524463},
journal = {Scientific Data},
pages = {1--11},
title = {{An extensive dataset of eye movements during viewing of complex images}},
volume = {4},
year = {2017}
}
@misc{Radon2018,
author = {Radon},
title = {{Radon 2.4.0 documentation}},
url = {https://radon.readthedocs.io/en/latest/},
urldate = {2019-12-16},
year = {2018}
}
@article{Bourbonnais1996,
abstract = {[Objectives In line with Karasek's job strain model, the objective of the study was to determine whether workers submitted to high job strain, a combination of high psychological demand and low decision latitude, develop more psychological distress than workers not submitted to high job strain. A second objective was to determine whether social support at work modifies the association between job strain and psychological distress. Methods The design was cross-sectional and included white-collar workers in the Qu{\'{e}}bec city area. A selfadministered 26-item questionnaire (the Job Content Questionnaire) measured psychological demand, decision latitude, and social support at work. Psychological distress was measured by the Psychiatric Symptom Index, a 14-item self-administered instrument. Results Among the 2889 participants, the prevalence of psychological distress was 27.8{\%}. High job strain was present in 20.5{\%} of the subjects. The crude odds ratio (OR) of high job strain with psychological distress was 3.52 [95{\%} confidence interval (95{\%} CI) 2.54— 4.88]. The OR adjusted for age, gender, employment status, occupation, social support at work, nonwork social support, cynicism, hostility, domestic load, and stressful life events during the last 12 months was still significant (OR 2.45, 95{\%} CI 1.66— 3.62). Conclusions Our results support the association between job strain and psychological distress. Social support at work, although significantly associated with psychological distress, did not modify the association between job strain and psychological distress.]},
author = {Bourbonnais, Ren{\'{e}}e and Brisson, Chantal and Moisan, Jocelyne and V{\'{e}}zina, Michel},
issn = {03553140, 1795990X},
journal = {Scandinavian Journal of Work, Environment {\&} Health},
month = {feb},
number = {2},
pages = {139--145},
publisher = {Scandinavian Journal of Work, Environment {\&} Health},
title = {{Job strain and psychological distress in white-collar workers}},
url = {http://www.jstor.org/stable/40966522},
volume = {22},
year = {1996}
}
@article{Voulodimos2018,
abstract = {Over the last years deep learning methods have been shown to outperform previous state-of-the-art machine learning techniques in several fields, with computer vision being one of the most prominent cases. This review paper provides a brief overview of some of the most significant deep learning schemes used in computer vision problems, that is, Convolutional Neural Networks, Deep Boltzmann Machines and Deep Belief Networks, and Stacked Denoising Autoencoders. A brief account of their history, structure, advantages, and limitations is given, followed by a description of their applications in various computer vision tasks, such as object detection, face recognition, action and activity recognition, and human pose estimation. Finally, a brief overview is given of future directions in designing deep learning schemes for computer vision problems and the challenges involved therein.},
author = {Voulodimos, Athanasios and Doulamis, Nikolaos and Doulamis, Anastasios and Protopapadakis, Eftychios},
doi = {10.1155/2018/7068349},
file = {::},
issn = {16875273},
journal = {Computational Intelligence and Neuroscience},
title = {{Deep Learning for Computer Vision: A Brief Review}},
volume = {2018},
year = {2018}
}
@article{Best2007b,
author = {Best, Christopher and Hasenbosch, Sam and Skinner, Michael and Crane, Peter and Burchat, Eleanore and Gehr, Sara Elizabeth and Kam, Clinton and Shanahan, Christopher and Zamba, Mitch},
file = {::},
number = {March},
pages = {1--17},
title = {{Coalition Distributed Mission Training : Exercise Pacific Link 2 AIAC12 – Twelfth Australian International Aerospace Congress}},
url = {https://search.informit.com.au/documentSummary;dn=556840067074338;res=IELENG},
year = {2007}
}
@article{Praseeratasang2019,
abstract = {This article aims to resolve a particular production planning and workforce assignment problem. Many production lines may have different production capacities while producing the same product. Each production line is composed of three production stages, and each stage requires different periods of times and numbers of workers. Moreover, the workers will have different skill levels which can affect the number of workers required for production line. The number of workers required in each farm also depends on the amount of pigs that it is producing. Production planning must fulfill all the demands and can only make use of the workers available. A production plan aims to generate maximal profit for the company. A mathematical model has been developed to solve the proposed problem, when the size of problem increases, the model is unable to resolve large issues within a reasonable timeframe. A metaheuristic method called adaptive large-scale neighborhood search (ALNS) has been developed to solve the case study. Eight destroy and four repair operators (including ant colony optimization based destroy and repair methods) have been presented. Moreover, three formulas which are used to make decisions for acceptance of the newly generated solution have been proposed. The present study tested 16 data sets, including the case study. From the computational results of the small size of test instances, ALNS should be able to find optimal solutions for all the random data sets in much less computational time compared to commercial optimization software. For medium and larger test instance sizes, the findings of the heuristics were 0.48{\%} to 0.92{\%} away from the upper bound and generated within 480-620 h, in comparison to the 1 h required for the proposed method. The Ant Colony Optimization-based destroy and repair method found solutions that were 0.98 to 1.03{\%} better than the original ALNS.},
author = {Praseeratasang, Nat and Pitakaso, Rapeepan and Sethanan, Kanchana and Kaewman, Sasitorn and Golinska-Dawson, Paulina},
doi = {10.3390/joitmc5020026},
file = {::},
issn = {21998531},
journal = {Journal of Open Innovation: Technology, Market, and Complexity},
keywords = {Adaptive large neighborhood search,Ant colony optimization,Assignment problems,Scheduling problems},
number = {2},
title = {{Adaptive large neighborhood search for a production planning problem arising in pig farming}},
volume = {5},
year = {2019}
}
@inproceedings{Oman,
author = {Oman, P. and Hagemeister, J.},
booktitle = {Proceedings Conference on Software Maintenance 1992},
doi = {10.1109/ICSM.1992.242525},
isbn = {0-8186-2980-0},
pages = {337--344},
publisher = {IEEE Comput. Soc. Press},
title = {{Metrics for assessing a software system's maintainability}},
url = {http://ieeexplore.ieee.org/document/242525/}
}
@inproceedings{Petersen2013,
abstract = {Background - Validity threats should be considered and consistently reported to judge the value of an empirical software engineering research study. The relevance of specific threats for a particular research study depends on the worldview or philosophical worldview of the researchers of the study. Problem/Gap - In software engineering, different categorizations exist, which leads to inconsistent reporting and consideration of threats. Contribution - In this paper, we relate different worldviews to software engineering research methods, identify generic categories for validity threats, and provide a categorization of validity threats with respect to their relevance for different world views. Thereafter, we provide a checklist aiding researchers in identifying relevant threats. Method - Different threat categorizations and threats have been identified in literature, and are reflected on in relation to software engineering research. Results - Software engineering is dominated by the pragmatist worldviews, and therefore use multiple methods in research. Maxwell's categorization of validity threats has been chosen as very suitable for reporting validity threats in software engineering research. Conclusion - We recommend to follow a checklist approach, and reporting first the philosophical worldview of the researcher when doing the research, the research methods and all threats relevant, including open, reduced, and mitigated threats.},
annote = {Petersen and Gencel (2013) provided a reflection of validity threat categorizations for software engineering and proposed to discuss four types of validity threats: 1) descriptive validity (ability to describe what we observe objectively and truthfully), 2) theoretical validity (concerns controllability and whether the measures used capture what they intend to capture), 3) generalizability (the degree of generalizability internally (within groups, communities, or a company) and externally (across groups, communities, and companies)), and 4) interpretive validity (whether the conclusions/inferences are reasonably drawn from the data objectively).},
author = {Petersen, Kai and Gencel, Cigdem},
booktitle = {Proceedings - Joint Conference of the 23rd International Workshop on Software Measurement and the 8th International Conference on Software Process and Product Measurement, IWSM-MENSURA 2013},
doi = {10.1109/IWSM-Mensura.2013.22},
file = {::},
isbn = {9780769550787},
title = {{Worldviews, research methods, and their relationship to validity in empirical software engineering research}},
year = {2013}
}
@inproceedings{Barnett2015d,
abstract = {This paper demonstrates a multi-view framework for Rapid APPlication Tool (RAPPT). RAPPT enables rapid development of mobile applications. It employs a multilevel approach to mobile application development: a Domain Specific Visual Language to define the high level structure of mobile apps, a Domain Specific Textual Language to define behavioural concepts, and concrete source code for fine grained improvements.},
author = {Barnett, Scott and Avazpour, Iman and Vasa, Rajesh and Grundy, John},
booktitle = {2015 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},
doi = {10.1109/VLHCC.2015.7357239},
isbn = {978-1-4673-7457-6},
month = {oct},
pages = {305--306},
publisher = {IEEE},
title = {{A multi-view framework for generating mobile apps}},
url = {http://ieeexplore.ieee.org/document/7357239/},
year = {2015}
}
@article{Metamodeling2003,
abstract = { Metamodeling is an essential foundation for MDD, but there's little consensus on the precise form it should take and role it should play. The authors analyze the underlying motivation for MDD and then derive a concrete set of requirements that a supporting infrastructure should satisfy. They discuss why the traditional "language definition" interpretation of metamodeling isn't a sufficient foundation and explain how it can be extended to unlock MDD's full potential.},
author = {Atkinson, Colin and K{\"{u}}hne, Thomas},
doi = {10.1109/MS.2003.1231149},
file = {::},
isbn = {0740-7459},
issn = {07407459},
journal = {IEEE Software},
keywords = {domain meta concepts,language definition,ling,metamode-,model driven development requirements},
number = {5},
pages = {36--41},
title = {{Model-driven development: A metamodeling foundation}},
volume = {20},
year = {2003}
}
@article{Usman2017,
abstract = {Epileptic seizures occur due to disorder in brain functionality which can affect patient's health. Prediction of epileptic seizures before the beginning of the onset is quite useful for preventing the seizure by medication. Machine learning techniques and computational methods are used for predicting epileptic seizures from Electroencephalograms (EEG) signals. However, preprocessing of EEG signals for noise removal and features extraction are two major issues that have an adverse effect on both anticipation time and true positive prediction rate. Therefore, we propose a model that provides reliable methods of both preprocessing and feature extraction. Our model predicts epileptic seizures' sufficient time before the onset of seizure starts and provides a better true positive rate. We have applied empirical mode decomposition (EMD) for preprocessing and have extracted time and frequency domain features for training a prediction model. The proposed model detects the start of the preictal state, which is the state that starts few minutes before the onset of the seizure, with a higher true positive rate compared to traditional methods, 92.23{\%}, and maximum anticipation time of 33 minutes and average prediction time of 23.6 minutes on scalp EEG CHB-MIT dataset of 22 subjects.},
author = {Usman, Syed Muhammad and Usman, Muhammad and Fong, Simon},
doi = {10.1155/2017/9074759},
file = {::},
issn = {17486718},
journal = {Computational and Mathematical Methods in Medicine},
publisher = {Hindawi Limited},
title = {{Epileptic Seizures Prediction Using Machine Learning Methods}},
volume = {2017},
year = {2017}
}
@article{Sivathamboo2018,
author = {Sivathamboo, Shobi and Perucca, Piero and Velakoulis, Dennis and Jones, Nigel C and Goldin, Jeremy and Kwan, Patrick and O'Brien, Terence J},
doi = {10.1093/sleep/zsy015},
file = {::},
issn = {0161-8105},
journal = {Sleep},
keywords = {epilepsy,mortality,seizures,sleep,sleep apnea syndromes,sudden unexplained death in epilepsy},
month = {apr},
number = {4},
publisher = {Narnia},
title = {{Sleep-disordered breathing in epilepsy: epidemiology, mechanisms, and treatment}},
url = {https://academic.oup.com/sleep/article/doi/10.1093/sleep/zsy015/4830560},
volume = {41},
year = {2018}
}
@article{Song2018b,
abstract = {Thesis: M. Eng., Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, 2018.},
author = {Song, Hyunjoon},
file = {::},
keywords = {Electrical Engineering and Computer Science.,Thesis},
number = {2017},
title = {{AutoFE : efficient and robust automated feature engineering}},
url = {https://dspace.mit.edu/handle/1721.1/119919},
year = {2018}
}
@article{Mirza2019,
abstract = {Information gathering comprises actions whose (sensory) consequences resolve uncertainty (i.e., are salient). In other words, actions that solicit salient information cause the greatest shift in beliefs (i.e., information gain) about the causes of our sensations. However, not all information is relevant to the task at hand: this is especially the case in complex, naturalistic scenes. This paper introduces a formal model of selective attention based on active inference and contextual epistemic foraging. We consider a visual search task with a special emphasis on goal-directed and task-relevant exploration. In this scheme, attention modulates the expected fidelity (precision) of the mapping between observations and hidden states in a state-dependent or context-sensitive manner. This ensures task-irrelevant observations have little expected information gain, and so the agent – driven to reduce expected surprise (i.e., uncertainty) – does not actively seek them out. Instead, it selectively samples task-relevant observations, which inform (task-relevant) hidden states. We further show, through simulations, that the atypical exploratory behaviours in conditions such as autism and anxiety may be due to a failure to appropriately modulate sensory precision in a context-specific way.},
author = {Mirza, M. Berk and Adams, Rick A. and Friston, Karl and Parr, Thomas},
doi = {10.1038/s41598-019-50138-8},
file = {::},
issn = {20452322},
journal = {Scientific Reports},
number = {1},
pages = {1--22},
title = {{Introducing a Bayesian model of selective attention based on active inference}},
volume = {9},
year = {2019}
}
@inproceedings{Vartak2016,
abstract = {{\textcopyright} 2016 Copyright held by the owner/author(s). Building a machine learning model is an iterative process. A data scientist will build many tens to hundreds of models before arriving at one that meets some acceptance criteria (e.g. AUC cutoff, accuracy threshold). However, the current style of model building is ad-hoc and there is no practical way for a data scientist to manage models that are built over time. As a result, the data scientist must attempt to "remember" previously constructed models and insights obtained from them. This task is challenging for more than a handful of models and can hamper the process of sensemaking. Without a means to manage models, there is no easy way for a data scientist to answer questions such as "Which models were built using an incorrect feature?", "Which model performed best on American customers?" or "How did the two top models compare?" In this paper, we describe our ongoing work on ModelDB, a novel end-to-end system for the management of machine learning models. ModelDB clients automatically track machine learning models in their native environments (e.g. scikit-learn, spark.ml), the ModelDB backend introduces a common layer of abstractions to represent models and pipelines, and the ModelDB frontend allows visual exploration and analyses of models via a web-based interface.},
author = {Vartak, Manasi and Subramanyam, Harihar and Lee, Wei En and Viswanathan, Srinidhi and Husnoo, Saadiyah and Madden, Samuel and Zaharia, Matei},
booktitle = {HILDA 2016 - Proceedings of the Workshop on Human-In-the-Loop Data Analytics},
doi = {10.1145/2939502.2939516},
isbn = {9781450342070},
title = {{ModelDB: A system for machine learning model management}},
url = {https://dl.acm.org/citation.cfm?id=2939516},
year = {2016}
}
@article{Yet2013a,
abstract = {Warfarin therapy is known as a complex process because of the variation in the patients' response. Failure to deal with such variation may lead to death as a result of thrombosis or bleeding. The possible sources of variation such as concomitant illnesses and drug interactions have to be investigated by the clinician in order to deal with the variation. This paper describes a decision support system (DSS) using Bayesian networks for assisting clinicians to make better decisions in Warfarin therapy management. The DSS is developed in collaboration with a Swedish hospital group that manages Warfarin therapy for more than 3000 patients. The proposed model can assist the clinician in making dose-adjustment and follow-up interval decisions, investigating variation causes, and evaluating bleeding and thrombosis risks related to therapy. The model is built upon previous findings from medical literature, the knowledge of domain experts, and large dataset of patients. {\textcopyright} 2012 Elsevier B.V.},
annote = {Use sensitvity analysis on the outputs},
author = {Yet, Barbaros and Bastani, Kaveh and Raharjo, Hendry and Lifvergren, Svante and Marsh, William and Bergman, Bo},
doi = {10.1016/j.dss.2012.10.007},
issn = {01679236},
journal = {Decision Support Systems},
keywords = {Anticoagulant therapy,Bayesian networks,Decision support systems,Warfarin therapy},
title = {{Decision support system for Warfarin therapy management using Bayesian networks}},
year = {2013}
}
@article{Lee2015,
abstract = {Adherence to coding conventions during the code production stage of software development is essential. Benefits include enabling programmers to quickly understand the context of shared code, communicate with one another in a consistent manner, and easily maintain the source code at low costs. In reality, however, programmers tend to doubt or ignore the degree to which the quality of their code is affected by adherence to these guidelines. This paper addresses research questions such as "Do violations of coding conventions affect the readability of the produced code?", "What kinds of coding violations reduce code readability?", and "How much do variable factors such as developer experience, project size, team size, and project maturity influence coding violations?" To respond to these research questions, we explored 210 open-source Java projects with 117 coding conventions from the Sun standard checklist. We believe our findings and the analysis approach used in the paper will encourage programmers and QA managers to develop their own customized and effective coding style guidelines.},
author = {Lee, Taek and Lee, Jung Been and In, Hoh Peter},
doi = {10.1587/transinf.2014EDP7327},
file = {::},
issn = {17451361},
journal = {IEICE Transactions on Information and Systems},
keywords = {Code readability,Coding conventions,Coding style standard,Empirical study,Software quality},
number = {7},
pages = {1286--1296},
title = {{Effect analysis of coding convention violations on readability of post-delivered code}},
volume = {E98D},
year = {2015}
}
@article{VandeVel2016,
abstract = {Purpose Detection of, and alarming for epileptic seizures is increasingly demanded and researched. Our previous review article provided an overview of non-invasive, non-EEG (electro-encephalography) body signals that can be measured, along with corresponding methods, state of the art research, and commercially available systems. Three years later, many more studies and devices have emerged. Moreover, the boom of smart phones and tablets created a new market for seizure detection applications. Method We performed a thorough literature review and had contact with manufacturers of commercially available devices. Results This review article gives an updated overview of body signals and methods for seizure detection, international research and (commercially) available systems and applications. Reported results of non-EEG based detection devices vary between 2.2{\%} and 100{\%} sensitivity and between 0 and 3.23 false detections per hour compared to the gold standard video-EEG, for seizures ranging from generalized to convulsive or non-convulsive focal seizures with or without loss of consciousness. It is particularly interesting to include monitoring of autonomic dysfunction, as this may be an important pathophysiological mechanism of SUDEP (sudden unexpected death in epilepsy), and of movement, as many seizures have a motor component. Conclusion Comparison of research results is difficult as studies focus on different seizure types, timing (night versus day) and patients (adult versus pediatric patients). Nevertheless, we are convinced that the most effective seizure detection systems are multimodal, combining for example detection methods for movement and heart rate, and that devices should especially take into account the user's seizure types and personal preferences.},
author = {{Van de Vel}, Anouk and Cuppens, Kris and Bonroy, Bert and Milosevic, Milica and Jansen, Katrien and {Van Huffel}, Sabine and Vanrumste, Bart and Cras, Patrick and Lagae, Lieven and Ceulemans, Berten},
doi = {10.1016/j.seizure.2016.07.012},
file = {::},
issn = {15322688},
journal = {Seizure},
keywords = {Alarm system,Epilepsy,Non-EEG based seizure detection,SUDEP,Sudden unexpected death},
pages = {141--153},
publisher = {BEA Trading Ltd},
title = {{Non-EEG seizure detection systems and potential SUDEP prevention: State of the art: Review and update}},
url = {http://dx.doi.org/10.1016/j.seizure.2016.07.012},
volume = {41},
year = {2016}
}
@article{Huang2017,
abstract = {The problem of probabilistic modeling and inference, at a high-level, can be viewed as constructing a (model, query, inference) tuple, where an inference algorithm implements a query on a model. Notably, the derivation of inference al-gorithms can be a difficult and error-prone task. Hence, re-searchers have explored how ideas from probabilistic pro-gramming can be applied. In the context of constructing these tuples, probabilistic programming can be seen as tak-ing a language-based approach to probabilistic modeling and inference. For instance, by using (1) appropriate languages for expressing models and queries and (2) devising infer-ence techniques that operate on encodings of models (and queries) as program expressions, the task of inference can be automated. In this paper, we describe a compiler that transforms a probabilistic model written in a restricted modeling language and a query for posterior samples given observed data into a Markov Chain Monte Carlo (MCMC) inference algorithm that implements the query. The compiler uses a sequence of intermediate languages (ILs) that guide it in gradually and successively refining a declarative specification of a proba-bilistic model and the query into an executable MCMC in-ference algorithm. The compilation strategy produces com-posable MCMC algorithms for execution on a CPU or GPU.},
author = {Huang, Daniel and Tristan, Jean-Baptiste and Morrisett, Greg},
doi = {10.1145/3140587.3062375},
file = {::},
isbn = {9781450349888},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {all or part of,classroom use is granted,copies are not made,guages,intermediate lan-,markov-chain monte carlo kernels,or,or distributed,or hard copies of,permission to make digital,probabilistic programming,this work for personal,without fee provided that},
number = {6},
pages = {111--125},
title = {{Compiling Markov chain Monte Carlo algorithms for probabilistic modeling}},
volume = {52},
year = {2017}
}
@techreport{Kalliamvakou2007,
abstract = {With over 10 million git repositories, GitHub is becoming one of the most important source of software artifacts on the Internet. Researchers are starting to mine the information stored in GitHub's event logs, trying to understand how its users employ the site to collaborate on software. However, so far there have been no studies describing the quality and properties of the data available from GitHub. We document the results of an empirical study aimed at understanding the characteristics of the repositories in GitHub and how users take advantage of GitHub's main features-namely commits, pull requests, and issues. Our results indicate that, while GitHub is a rich source of data on software development, mining GitHub for research purposes should take various potential perils into consideration. We show, for example, that the majority of the projects are personal and inactive; that GitHub is also being used for free storage and as a Web hosting service; and that almost 40{\%} of all pull requests do not appear as merged, even though they were. We provide a set of recommendations for software engineering researchers on how to approach the data in GitHub.},
author = {Kalliamvakou, Eirini and Gousios, Georgios and tudelftnl {Kelly Blincoe} and Singer, Leif and German, Daniel M and Damian, Daniela},
file = {::},
keywords = {D28 [Software Engineering]: Management-Software co,GitHub,code reviews,git},
title = {{The Promises and Perils of Mining GitHub}},
url = {https://github.com/rails/rails.},
year = {2007}
}
@article{Khalajzadeh2020,
author = {Khalajzadeh, Hourieh and Simmons, Andrew J. and Abdelrazek, Mohamed and Grundy, John and Hosking, John and He, Qiang},
doi = {10.1016/j.cola.2020.100964},
file = {::},
issn = {2590-1184},
journal = {Journal of Computer Languages},
keywords = {big data analytics,big data modeling,big data toolkits,domain-specific visual languages,end-user tools,multidisciplinary teams},
publisher = {Elsevier Ltd},
title = {{An End-to-End Model-based Approach to Support Big Data Analytics Development}},
url = {https://doi.org/10.1016/j.cola.2020.100964},
year = {2020}
}
@inproceedings{Dutta2018a,
abstract = {Probabilistic programming systems (PP systems) allow developers to model stochastic phenomena and perform efficient inference on the models. The number and adoption of probabilistic programming systems is growing significantly. However, there is no prior study of bugs in these systems and no methodology for systematically testing PP systems. Yet, testing PP systems is highly non-trivial, especially when they perform approximate inference. In this paper, we characterize 118 previously reported bugs in three open-source PP systems-Edward, Pyro and Stan-and propose ProbFuzz, an extensible system for testing PP systems. Prob-Fuzz allows a developer to specify templates of probabilistic models, from which it generates concrete probabilistic programs and data for testing. ProbFuzz uses language-specific translators to generate these concrete programs, which use the APIs of each PP system. ProbFuzz finds potential bugs by checking the output from running the generated programs against several oracles, including an accuracy checker. Using ProbFuzz, we found 67 previously unknown bugs in recent versions of these PP systems. Developers already accepted 51 bug fixes that we submitted to the three PP systems, and their underlying systems, PyTorch and TensorFlow. CCS CONCEPTS • Software and its engineering → Software testing;},
author = {Dutta, Saikat and Legunsen, Owolabi and Huang, Zixin and Misailovic, Sasa},
doi = {10.1145/3236024.3236057},
title = {{Testing probabilistic programming systems}},
year = {2018}
}
@article{Nelesen2008,
abstract = {Background: Although characteristics such as heart rate (HR) and blood pressure (BP) are commonly reported in studies of the relationship between fatigue and cardiac functioning, few reports examine how cardiac function parameters such as cardiac output (CO) and stroke volume (SV) relate to fatigue. This study examined the relationship between self-reported fatigue and hemodynamic functioning at rest and in response to a public speaking stressor in healthy individuals. Methods: A total of 142 individuals participated in this study. Subjects were placed in low-, moderate-, or high-fatigue groups based on their Profile of Moods State fatigue scale. Heart rate, SV, and CO were determined using impedance cardiography at rest and during a speaking stressor. Stroke volume and CO values were converted to stroke index (SI) and cardiac index (CI) by adjusting for body surface area. Data were analyzed with hierarchical regression analysis and a 3 (group) x 3 (stress period) mixed model analysis of variance. Results: At rest, fatigue was not associated with BP or HR but was significantly associated with decreased CI (P{\textless}.001; 95{\%} confidence interval, -0.046 to -0.014) and stroke index (SI) (P=.002; 95{\%} confidence interval -0.664 to -0.151), even after controlling for demographic variables and depressive symptoms. Heart rate and BP increased, as expected, from baseline to preparation to speaking stressor (F1,124=118.6 and F 1,122=46.450, respectively) (P{\textless}.001 for both). More interestingly, there were effects on SI and CI of fatigue (P{\textless}.03 for both) and stress (P{\textless}.03 for both); high-fatigue individuals had lower SI and CI levels than moderate- and low-fatigue individuals both at rest and in response to the stressor. Conclusion: This study demonstrates that fatigue complaints may have hemodynamic correlates even in ostensibly healthy individuals. {\textcopyright}2008 American Medical Association. All rights reserved.},
author = {Nelesen, Richard and Dar, Yasmin and Thomas, Kamala and Dimsdale, Joel E.},
doi = {10.1001/archinte.168.9.943},
file = {::},
issn = {00039926},
journal = {Archives of Internal Medicine},
month = {may},
number = {9},
pages = {943--949},
title = {{The relationship between fatigue and cardiac functioning}},
volume = {168},
year = {2008}
}
@article{Stephanidis2019,
abstract = {This article aims to investigate the Grand Challenges which arise in the current and emerging landscape of rapid technological evolution towards more intelligent interactive technologies, coupled with increased and widened societal needs, as well as individual and collective expectations that HCI, as a discipline, is called upon to address. A perspective oriented to humane and social values is adopted, formulating the challenges in terms of the impact of emerging intelligent interactive technologies on human life both at the individual and societal levels. Seven Grand Challenges are identified and presented in this article: Human-Technology Symbiosis; Human-Environment Interactions; Ethics, Privacy and Security; Well-being, Health and Eudaimonia; Accessibility and Universal Access; Learning and Creativity; and Social Organization and Democracy. Although not exhaustive, they summarize the views and research priorities of an international interdisciplinary group of experts, reflecting different scientific perspectives, methodological approaches and application domains. Each identified Grand Challenge is analyzed in terms of: concept and problem definition; main research issues involved and state of the art; and associated emerging requirements. BACKGROUND This article presents the results of the collective effort of a group of 32 experts involved in the community of the Human Computer Interaction International (HCII) Conference series. The group's collaboration started in early 2018 with the collection of opinions from all group members, each asked to independently list and describe five HCI grand challenges. During a one-day meeting held on the 20th July 2018 in the context of the HCI International 2018 Conference in Las Vegas, USA, the identified topics were debated and challenges were formulated in terms of the impact of emerging intelligent interactive technologies on human life both at the individual and societal levels. Further analysis and consolidation led to a set of seven Grand Challenges presented herein. This activity was organized and supported by the HCII Conference series.},
author = {Stephanidis, Constantine and Salvendy, Gavriel and Antona, Margherita and Chen, Jessie Y.C. and Dong, Jianming and Duffy, Vincent G. and Fang, Xiaowen and Fidopiastis, Cali and Fragomeni, Gino and Fu, Limin Paul and Guo, Yinni and Harris, Don and Ioannou, Andri and Jeong, Kyeong ah (Kate) and Konomi, Shin'ichi and Kr{\"{o}}mker, Heidi and Kurosu, Masaaki and Lewis, James R. and Marcus, Aaron and Meiselwitz, Gabriele and Moallem, Abbas and Mori, Hirohiko and {Fui-Hoon Nah}, Fiona and Ntoa, Stavroula and Rau, Pei Luen Patrick and Schmorrow, Dylan and Siau, Keng and Streitz, Norbert and Wang, Wentao and Yamamoto, Sakae and Zaphiris, Panayiotis and Zhou, Jia},
doi = {10.1080/10447318.2019.1619259},
file = {::},
issn = {15327590},
journal = {International Journal of Human-Computer Interaction},
title = {{Seven HCI Grand Challenges}},
volume = {7318},
year = {2019}
}
@article{Yusop2020,
abstract = {Usability is one of the software qualities attributes that is subjective and often considered as a less critical defect to be fixed. One of the reasons was due to the vague defect descriptions that could not convince developers about the validity of usability issues. Producing a comprehensive usability defect description can be a challenging task, especially in reporting relevant and important information. Prior research in improving defect report comprehension has often focused on defects in general or studied various aspects of software quality improvement such as triaging defect reports, metrics and predictions, automatic defect detection and fixing. In this paper, we studied 2241 usability and non-usability defects from three open-source projects-Mozilla Thunderbird, Firefox for Android, and Eclipse Platform. We examined the presence of eight defect attributes-steps to reproduce, impact, software context, expected output, actual output, assume cause, solution proposal, and supplementary information, and used various statistical tests to answer the research questions. In general, we found that usability defects are resolved slower than non-usability defects, even for non-usability defect reports that have less information. In terms of defect report content, usability defects often contain output details and software context while non-usability defects are preferably explained using supplementary information, such as stack traces and error logs. Our research findings extend the body of knowledge of software defect reporting, especially in understanding the characteristics of usability defects. The promising results also may be valuable to improve software development practitioners' practice.},
author = {Yusop, Nor Shahida Mohamad and Grundy, John and Schneider, Jean Guy and Vasa, Rajesh},
doi = {10.18517/ijaseit.10.1.10225},
file = {::},
issn = {24606952},
journal = {International Journal on Advanced Science, Engineering and Information Technology},
keywords = {Defect report,Open-source,Software defect repository,Software repository mining,Usability defects},
number = {1},
pages = {98--105},
title = {{How usability defects defer from non-usability defects?: A case study on open source projects}},
volume = {10},
year = {2020}
}
@article{McLean2019,
abstract = {Artificial Intelligent (AI) In-home Voice Assistants have seen unprecedented growth. However, we have little understanding on the factors motivating individuals to use such devices. Given the unique characteristics of the technology, in the main hands free, controlled by voice, and the presentation of a voice user interface, the current technology adoption models are not comprehensive enough to explain the adoption of this new technology. Focusing on voice interactions, this research combines the theoretical foundations of U{\&}GT with technology theories to gain a clearer understanding on the motivations for adopting and using in-home voice assistants. This research presents a conceptual model on the use of voice controlled technology and an empirical validation of the model through the use of Structural Equation Modelling with a sample of 724 in-home voice assistant users. The findings illustrate that individuals are motivated by the (1) utilitarian benefits, (2) symbolic benefits and (3) social benefits provided by voice assistants, the results found that hedonic benefits only motivate the use of in-home voice assistants in smaller households. Additionally, the research establishes a moderating role of perceived privacy risks in dampening and negatively influencing the use of in-home voice assistants.},
author = {McLean, Graeme and Osei-Frimpong, Kofi},
doi = {10.1016/j.chb.2019.05.009},
file = {::},
issn = {07475632},
journal = {Computers in Human Behavior},
keywords = {Artificial intelligence,Machine learning,Social presence,Technology adoption,Uses and gratification theory,Voice assistants},
number = {January},
pages = {28--37},
title = {{Hey Alexa {\ldots} examine the variables influencing the use of artificial intelligent in-home voice assistants}},
volume = {99},
year = {2019}
}
@inproceedings{Biswas2019,
author = {Biswas, Sumon and Islam, Md Johirul and Huang, Yijia and Rajan, Hridesh},
booktitle = {2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)},
doi = {10.1109/MSR.2019.00086},
editor = {Storey, Margaret-Anne D and Adams, Bram and Haiduc, Sonia},
file = {::},
isbn = {978-1-7281-3412-3},
month = {may},
pages = {577--581},
publisher = {IEEE},
title = {{Boa Meets Python: A Boa Dataset of Data Science Software in Python Language}},
url = {https://ieeexplore.ieee.org/document/8816757/},
year = {2019}
}
@article{Kristiansen2016,
abstract = {The Elective Course Student Sectioning (ECSS) problem is a yearly recurrent planning problem at the Danish high schools. The problem is of assigning students to elective classes given their requests such that as many requests are fulfilled and the violations of the soft constraints are minimized. This paper presents an Adaptive Large Neighborhood Search heuristic for the ESCC. The algorithm is applied to 80 real-life instances from Danish high schools and compared with solutions found by using the state-of-the-art MIP solver Gurobi. The algorithm has been implemented in the commercial product Lectio, and is thereby available for approximately 200 high schools in Denmark.},
author = {Kristiansen, Simon and Stidsen, Thomas R.},
doi = {10.1007/s10479-014-1593-7},
file = {::},
issn = {15729338},
journal = {Annals of Operations Research},
keywords = {Adaptive large neighborhood search,Education timetabling,Elective course planning,High school timetabling,Integer programming,Student sectioning},
number = {1},
pages = {99--117},
publisher = {Springer US},
title = {{Elective course student sectioning at Danish high schools}},
url = {http://dx.doi.org/10.1007/s10479-014-1593-7},
volume = {239},
year = {2016}
}
@misc{Python.org2019,
author = {Python.org},
title = {{PEP 8 -- Style Guide for Python Code | Python.org}},
url = {https://www.python.org/dev/peps/pep-0008/},
urldate = {2019-12-02},
year = {2019}
}
@article{DosSantos2018,
abstract = {Several conventions and standards aim to improve maintainability of software code. However, low levels of code readability perceived by developers still represent a barrier to their daily work. In this paper, we describe a survey that assessed the impact of a set of Java coding practices on the readability perceived by software developers. While some practices promoted an enhancement of readability, others did not show statistically significant effects. Interestingly, one of the practices worsened the readability. Our results may help to identify coding conventions with a positive impact on readability and, thus, guide the creation of coding standards.},
author = {{Dos Santos}, Rodrigo Magalhes and Gerosa, Marco Aur{\'{e}}lio},
doi = {10.1145/3196321.3196342},
file = {::},
isbn = {9781450357142},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
keywords = {code comprehension,code readability,coding best practices,programming style,software developers' opinions survey},
pages = {277--285},
title = {{Impacts of coding practices on readability}},
year = {2018}
}
@article{Barrenechea2011,
annote = {Only focuses on ensembles for the binary classification problem.},
archivePrefix = {arXiv},
arxivId = {1503.08895},
author = {Barrenechea, E. and Herrera, F. and Fernandez, A. and Galar, M. and Bustince, H.},
doi = {10.1109/tsmcc.2011.2161285},
eprint = {1503.08895},
isbn = {1094-6977},
issn = {1094-6977},
journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
pmid = {9377276},
title = {{A Review on Ensembles for the Class Imbalance Problem: Bagging-, Boosting-, and Hybrid-Based Approaches}},
year = {2011}
}
@article{Al-msiebeen2018,
abstract = {Most of open-source software systems become available on the internet today. Thus, we need automatic methods to label software code. Software code can be labeled with a set of keywords. These keywords in this paper referred as software labels. The goal of this paper is to provide a quick view of the software code vocabulary. This paper proposes an automatic approach to document the object-oriented software by labeling its code. The approach exploits all software identifiers to label software code. The paper presents the results of study conducted on the ArgoUML and drawing shapes case studies. Results showed that all code labels were correctly identiﬁed.},
archivePrefix = {arXiv},
arxivId = {1803.00048},
author = {Al-msie'been, Ra'Fat (Mutah University)},
eprint = {1803.00048},
file = {::},
journal = {Sci.Int.(Lahore)},
keywords = {code label,reverse engineering,software comprehension,software engineering,software visualization},
number = {1},
pages = {45--48},
title = {{Automatic Labelling of the Object-Oriented Source Code}},
volume = {30},
year = {2018}
}
@inproceedings{manning-etal-2014-stanford,
address = {Baltimore, Maryland},
author = {Manning, Christopher and Surdeanu, Mihai and Bauer, John and Finkel, Jenny and Bethard, Steven and McClosky, David},
booktitle = {Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
doi = {10.3115/v1/P14-5010},
month = {jun},
pages = {55--60},
publisher = {Association for Computational Linguistics},
title = {{The Stanford Core NLP Natural Language Processing Toolkit}},
url = {https://www.aclweb.org/anthology/P14-5010},
year = {2014}
}
@article{SandJensen2015,
abstract = {In this position paper we discuss optimization in the HCI domain based on our experiences with Bayesian methods for modeling and optimization of audio systems, including challenges related to evaluating, designing, and optimizing such interfaces. We outline and demonstrate how a combined Bayesian modeling and optimization approach provides a flexible framework for integrating various user and content attributes, while also supporting model-based optimization of HCI systems. Finally, we discuss current and future research direction and applications, such as inferring user needs and optimizing interfaces for computer assisted teaching.},
author = {{Sand Jensen}, Bj{\o}rn and {Brehm Nielsen}, Jens and Larsen, Jan},
file = {::},
journal = {Workshop on Principles, Techniques and Perspectives on Optimization and HCI. CHI 2015.},
keywords = {Author Keywords Bayes,Gaussian process priors,HCI)],Miscellaneous,Optimization},
pages = {1--4},
title = {{Perspectives on Bayesian Optimization for HCI}},
year = {2015}
}
@inproceedings{10.1145/3373017.3373055,
address = {New York, NY, USA},
author = {Liu, Yu and Sivathamboo, Shobi and Goodin, Peter and Bonnington, Paul and Kwan, Patrick and Kuhlmann, Levin and O'Brien, Terence and Perucca, Piero and Ge, Zongyuan},
booktitle = {Proceedings of the Australasian Computer Science Week Multiconference},
doi = {10.1145/3373017.3373055},
file = {::},
isbn = {9781450376976},
keywords = {CNN,Epilepsy,Multi-Biosignal,Multimodal learning,Seizure detection},
publisher = {Association for Computing Machinery},
series = {ACSW '20},
title = {{Epileptic Seizure Detection Using Convolutional Neural Network: A Multi-Biosignal Study}},
url = {https://doi.org/10.1145/3373017.3373055},
year = {2020}
}
@article{Le2019,
abstract = {Software Engineering researchers are increasingly using Natural Language Processing (NLP) techniques to automate Software Vulnerabilities (SVs) assessment using the descriptions in public repositories. However, the existing NLP-based approaches suffer from concept drift. This problem is caused by a lack of proper treatment of new (out-of-vocabulary) terms for the evaluation of unseen SVs over time. To perform automated SVs assessment with concept drift using SVs' descriptions, we propose a systematic approach that combines both character and word features. The proposed approach is used to predict seven Vulnerability Characteristics (VCs). The optimal model of each VC is selected using our customized time-based cross-validation method from a list of eight NLP representations and six well-known Machine Learning models. We have used the proposed approach to conduct large-scale experiments on more than 100,000 SVs in the National Vulnerability Database (NVD). The results show that our approach can effectively tackle the concept drift issue of the SVs' descriptions reported from 2000 to 2018 in NVD even without retraining the model. In addition, our approach performs competitively compared to the existing word-only method. We also investigate how to build compact concept-drift-aware models with much fewer features and give some recommendations on the choice of classifiers and NLP representations for SVs assessment.},
author = {Le, Triet Huynh Minh and Sabir, Bushra and Babar, Muhammad Ali},
doi = {10.1109/MSR.2019.00063},
file = {::},
isbn = {9781728134123},
issn = {21601860},
journal = {IEEE International Working Conference on Mining Software Repositories},
keywords = {Machine learning,Mining software repositories,Multi-class classification,Natural language processing,Software vulnerability},
pages = {371--382},
title = {{Automated software vulnerability assessment with concept drift}},
volume = {2019-May},
year = {2019}
}
@article{He2004a,
abstract = {The study was carried out to examine whether acupuncture treatment can reduce chronic pain in the neck and shoulders and related headache, and also to examine whether possible effects are long-lasting. Therefore, 24 female office workers (47±9 years old, mean±SD) who had had neck and shoulder pain for 12±9 years were randomly assigned to a test group (TG) or a control group (CG). Acupuncture was applied 10 times during 3-4 weeks either at presumed anti-pain acupoints (TG) or at placebo-points (CG). A physician measured the pain threshold (PPT) in the neck and shoulder regions with algometry before the first treatment, and after the last one and six months after the treatments. Questionnaires on muscle pain and headache were answered at the same occasions and again 3 years after the last treatment. The intensity and frequency of pain fell more for TG than for CG (Pb≤0.04) during the treatment period. Three years after the treatments TG still reported less pain than before the treatments (Pw{\textless}0.001), contrary to what CG did (Pb{\textless}0.04). The degree of headache fell during the treatment period for both groups, but more for TG than for CG (Pb=0.02). Three years after the treatments the effect still lasted for TG (P w{\textless}0.001) while the degree of headache for CG was back to the pre-treatment level (Pb{\textless}0.001). PPT of some muscles rose during the treatments for TG and remained higher 6 months after the treatments (P w{\textless}0.05), which contrasts the situation for CG. Adequate acupuncture treatment may reduce chronic pain in the neck and shoulders and related headache. The effect lasted for 3 years. {\textcopyright} 2004 International Association for the Study of Pain. Published by Elsevier B.V. All rights reserved.},
author = {He, Dong and Veiersted, Kaj Bo and H{\o}stmark, Arne T. and Medb{\o}, Jon Ingulf},
doi = {10.1016/j.pain.2004.01.018},
issn = {03043959},
journal = {Pain},
keywords = {Acupuncture,Algometry,Chronic pain,Neck,Placebo or sham acupuncture,Shoulder},
month = {jun},
number = {3},
pages = {299--307},
title = {{Effect of acupuncture treatment on chronic neck and shoulder pain in sedentary female workers: A 6-month and 3-year follow-up study}},
volume = {109},
year = {2004}
}
@article{SUN2009,
abstract = {Classification of data with imbalanced class distribution has encountered a significant drawback of the performance attainable by most standard classifier learning algorithms which assume a relatively balanced class distribution and equal misclassification costs. This paper provides a review of the classification of imbalanced data regarding: the application domains; the nature of the problem; the learning difficulties with standard classifier learning algorithms; the learning objectives and evaluation measures; the reported research solutions; and the class imbalance problem in the presence of multiple classes.},
annote = {Overview of the classificaiton of imbalanced data, the emphasis is on binary classificaiton problems.},
author = {SUN, YANMIN and WONG, ANDREW K. C. and KAMEL, MOHAMED S.},
doi = {10.1142/s0218001409007326},
isbn = {0218-0014},
issn = {0218-0014},
journal = {International Journal of Pattern Recognition and Artificial Intelligence},
title = {{CLASSIFICATION OF IMBALANCED DATA: A REVIEW}},
year = {2009}
}
@inproceedings{Barnett2015c,
abstract = {Quality attributes are essential in software architecture and they are determined by identifying the concerns of the stakeholders of a system. The concerns of constructing mobile applications (apps) are quite specific due to the characteristics of mobile devices. These concerns have not been adequately addressed in industry standards and practices. In this paper, we present a mobile app development conceptual model comprising six key concepts that impact quality. Using two case studies, we show that these interrelated concepts influence the architectural decisions of mobile apps and their tradeoffs need to be well considered. As such, we suggest that these concepts should be first class entities when designing mobile app architecture to ensure that the quality attributes are satisfied.},
author = {Barnett, Scott and Vasa, Rajesh and Tang, Antony},
booktitle = {2015 12th Working IEEE/IFIP Conference on Software Architecture},
doi = {10.1109/WICSA.2015.28},
isbn = {978-1-4799-1922-2},
month = {may},
pages = {105--114},
publisher = {IEEE},
title = {{A Conceptual Model for Architecting Mobile Applications}},
url = {http://ieeexplore.ieee.org/document/7158509/},
year = {2015}
}
@inproceedings{shoeb2010application,
author = {Shoeb, Ali H and Guttag, John V},
booktitle = {Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
file = {::},
pages = {975--982},
title = {{Application of machine learning to epileptic seizure detection}},
year = {2010}
}
@article{Li2017,
abstract = {User-centered design (UCD) is an approach for creating human-machine interfaces that are usable and support the human operator's tasks. UCD can be challenging because designers can fail to account for human-machine interactions that occur due to the concurrency between the human and the other system elements. Formal methods are tools that enable analysts to consider all of the possible system interactions using a combination of formal modeling, specification, and proof-based verification. However, creating formal interface design models can be extremely difficult. This work describes a method that supports UCD by automatically generating formal designs of human-machine interface behavior from task-analytic models. The resulting interface design will always support the behavior captured in the task model. This paper describes the method and demonstrates its capabilities with three case studies: a light switch, a vending machine, and a patient-controlled analgesia pump. The produced designs are validated with formal verifications to prove that they support their associated tasks. Results and future research are discussed.},
author = {Li, Meng and Wei, Jiajun and Zheng, Xi and Bolton, Matthew L.},
doi = {10.1109/THMS.2017.2700630},
file = {::},
issn = {21682291},
journal = {IEEE Transactions on Human-Machine Systems},
keywords = {Formal methods,human-automation interaction,machine learning,task analysis,user-centered design (UCD)},
number = {6},
pages = {822--833},
title = {{A Formal Machine-Learning Approach to Generating Human-Machine Interfaces from Task Models}},
volume = {47},
year = {2017}
}
@article{Hong2016b,
abstract = {We propose thresholding as an approach to deal with class imbalance. We define the concept of thresholding as a process of determining a decision boundary in the presence of a tunable parameter. The threshold is the maximum value of this tunable parameter where the conditions of a certain decision are satisfied. We show that thresholding is applicable not only for linear classifiers but also for non-linear classifiers. We show that this is the implicit assumption for many approaches to deal with class imbalance in linear classifiers. We then extend this paradigm beyond linear classification and show how non-linear classification can be dealt with under this umbrella framework of thresholding. The proposed method can be used for outlier detection in many real-life scenarios like in manufacturing. In advanced manufacturing units, where the manufacturing process has matured over time, the number of instances (or parts) of the product that need to be rejected (based on a strict regime of quality tests) becomes relatively rare and are defined as outliers. How to detect these rare parts or outliers beforehand? How to detect combination of conditions leading to these outliers? These are the questions motivating our research. This paper focuses on prediction of outliers and conditions leading to outliers using classification. We address the problem of outlier detection using classification. The classes are good parts (those passing the quality tests) and bad parts (those failing the quality tests and can be considered as outliers). The rarity of outliers transforms this problem into a class-imbalanced classification problem.},
archivePrefix = {arXiv},
arxivId = {1607.02705},
author = {Hong, Charmgil and Ghosh, Rumi and Srinivasan, Soundar},
doi = {10.475/123},
eprint = {1607.02705},
file = {::},
isbn = {1234567245},
keywords = {class imbalance,classification,decision trees,scrap detection},
title = {{Dealing with Class Imbalance using Thresholding}},
url = {http://arxiv.org/abs/1607.02705},
volume = {1},
year = {2016}
}
@article{Fernandez2013,
author = {Fern{\'{a}}ndez, Alberto and Palade, Vasile and Herrera, Francisco and L{\'{o}}pez, Victoria and Garc{\'{i}}a, Salvador},
doi = {10.1016/j.ins.2013.07.007},
file = {::},
issn = {00200255},
journal = {Information Sciences},
keywords = {Cost-sensitive learning,Dataset shift,Imbalanced dataset,Noisy data,Sampling,Small disjuncts},
pages = {113--141},
publisher = {Elsevier Inc.},
title = {{An insight into classification with imbalanced data: Empirical results and current trends on using data intrinsic characteristics}},
url = {http://dx.doi.org/10.1016/j.ins.2013.07.007},
volume = {250},
year = {2013}
}
@article{Karoly2017,
abstract = {{\textcopyright} The Author (2017). Published by Oxford University Press on behalf of the Guarantors of Brain. All rights reserved. For Permissions, please email: journals.permissions@oup.com. It is now established that epilepsy is characterized by periodic dynamics that increase seizure likelihood at certain times of day, and which are highly patient-specific. However, these dynamics are not typically incorporated into seizure prediction algorithms due to the difficulty of estimating patient-specific rhythms from relatively short-term or unreliable data sources. This work outlines a novel framework to develop and assess seizure forecasts, and demonstrates that the predictive power of forecasting models is improved by circadian information. The analyses used long-term, continuous electrocorticography from nine subjects, recorded for an average of 320 days each. We used a large amount of out-of-sample data (a total of 900 days for algorithm training, and 2879 days for testing), enabling the most extensive post hoc investigation into seizure forecasting. We compared the results of an electrocorticography-based logistic regression model, a circadian probability, and a combined electrocorticography and circadian model. For all subjects, clinically relevant seizure prediction results were significant, and the addition of circadian information (combined model) maximized performance across a range of outcome measures. These results represent a proof-of-concept for implementing a circadian forecasting framework, and provide insight into new approaches for improving seizure prediction algorithms. The circadian framework adds very little computational complexity to existing prediction algorithms, and can be implemented using current-generation implant devices, or even non-invasively via surface electrodes using a wearable application. The ability to improve seizure prediction algorithms through straightforward, patient-specific modifications provides promise for increased quality of life and improved safety for patients with epilepsy.},
author = {Karoly, Philippa J. and Ung, Hoameng and Grayden, David B. and Kuhlmann, Levin and Leyde, Kent and Cook, Mark J. and Freestone, Dean R.},
doi = {10.1093/brain/awx173},
file = {::},
issn = {14602156},
journal = {Brain},
keywords = {circadian rhythms,epilepsy,forecasting,seizure prediction},
month = {aug},
number = {8},
pages = {2169--2182},
publisher = {Oxford University Press},
title = {{The circadian profile of epilepsy improves seizure forecasting}},
volume = {140},
year = {2017}
}
@article{Selic2012,
abstract = {Model-based engineering (MBE) has been touted as a new and substantively different approach to software development, characterized by higher levels of abstraction and automation compared to traditional methods. Despite the availability of published verifiable evidence that it can significantly boost both developer productivity and product quality in industrial projects, adoption of this approach has been surprisingly slow. In this article, we review the causes behind this, both technical and non-technical, and outline what needs to happen for MBE to become a reliable mainstream approach to software development.},
author = {Selic, Bran},
doi = {10.1007/s10270-012-0261-0},
file = {::},
issn = {16191366},
journal = {Software and Systems Modeling},
keywords = {Model-based engineering},
number = {4},
pages = {513--526},
title = {{What will it take? A view on adoption of model-based methods in practice}},
volume = {11},
year = {2012}
}
@article{Ahmad2018,
abstract = {Purpose: Software developers extensively use stack overflow (SO) for knowledge sharing on software development. Thus, software engineering researchers have started mining the structured/unstructured data present in certain software repositories including the Q{\&}A software developer community SO, with the aim to improve software development. The purpose of this paper is show that how academics/practitioners can get benefit from the valuable user-generated content shared on various online social networks, specifically from Q{\&}A community SO for software development. Design/methodology/approach: A comprehensive literature review was conducted and 166 research papers on SO were categorized about software development from the inception of SO till June 2016. Findings: Most of the studies revolve around a limited number of software development tasks; approximately 70 percent of the papers used millions of posts data, applied basic machine learning methods, and conducted investigations semi-automatically and quantitative studies. Thus, future research should focus on the overcoming existing identified challenges and gaps. Practical implications: The work on SO is classified into two main categories; “SO design and usage” and “SO content applications.” These categories not only give insights to Q{\&}A forum providers about the shortcomings in design and usage of such forums but also provide ways to overcome them in future. It also enables software developers to exploit such forums for the identified under-utilized tasks of software development. Originality/value: The study is the first of its kind to explore the work on SO about software development and makes an original contribution by presenting a comprehensive review, design/usage shortcomings of Q{\&}A sites, and future research challenges.},
author = {Ahmad, Arshad and Feng, Chong and Ge, Shi and Yousif, Abdallah},
doi = {10.1108/DTA-07-2017-0054},
file = {::},
issn = {25149288},
journal = {Data Technologies and Applications},
keywords = {Information retrieval,Mining,Software development,Software repositories,Stack overflow,Text mining},
number = {2},
pages = {190--247},
title = {{A survey on mining stack overflow: question and answering (Q{\&}A) community}},
volume = {52},
year = {2018}
}
@article{AlbertoFernandez2018,
abstract = {The Synthetic Minority Oversampling Technique (SMOTE) preprocessing algorithm is considered "de facto" standard in the framework of learning from imbalanced data. This is due to its simplicity in the design of the procedure, as well as its robustness when applied to different type of problems. Since its publication in 2002, SMOTE has proven successful in a variety of applications from several different domains. SMOTE has also inspired several approaches to counter the issue of class imbalance, and has also significantly contributed to new supervised learning paradigms, including multilabel classification, incremental learning, semi-supervised learning, multi-instance learning, among others. It is standard benchmark for learning from imbalanced data. It is also featured in a number of different software packages - from open source to commercial. In this paper, marking the fifteen year anniversary of SMOTE, we reflect on the SMOTE journey, discuss the current state of affairs with SMOTE, its applications, and also identify the next set of challenges to extend SMOTE for Big Data problems.},
author = {{Alberto Fernandez} and {Salvador Garcia} and {Francisco Herrera} and {Nitesh V. Chawla}},
doi = {10.1613/jair.1.11192},
file = {::},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
pages = {863--905},
title = {{SMOTE for Learning from Imbalanced Data: Progress and Challenges, Marking the 15-year Anniversary}},
url = {https://www.jair.org/index.php/jair/article/view/11192},
volume = {61},
year = {2018}
}
@article{Zhang2016,
abstract = {Uncertainty is intrinsic in most technical systems, including Cyber-Physical Systems (CPS). Therefore, handling uncertainty in a graceful manner during the real operation of CPS is critical. Since designing, developing, and testing modern and highly sophisticated CPS is an expanding field, a step to-wards dealing with uncertainty is to identify, define, and classify uncertainties at various levels of CPS. This will help develop a systematic and comprehen-sive understanding of uncertainty. To that end, we propose a conceptual model for uncertainty specifically designed for CPS. Since the study of uncertainty in CPS development and testing is still irrelatively unexplored, this conceptual model was derived in a large part by reviewing existing work on uncertainty in other fields, including philosophy, physics, statistics, and healthcare. The con-ceptual model is mapped to the three logical levels of CPS: Application, Infra-structure, and Integration. It is captured using UML class diagrams, including relevant OCL constraints. To validate the conceptual model, we identified, clas-sified, and specified uncertainties in two distinct industrial case studies.},
author = {Zhang, Man and Selic, Bran and Ali, Shaukat and Yue, Tao and Okariz, Oscar and Norgren, Roland},
doi = {10.1007/978-3-319-42061-5_16},
file = {::},
isbn = {9783319420608},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Conceptual model,Cyber-physical systems,Uncertainty},
pages = {247--264},
title = {{Understanding uncertainty in cyber-physical systems: A conceptual model}},
volume = {9764},
year = {2016}
}
@article{VanEmden2002_codesmell,
abstract = {Software inspection is a known technique for improving software quality. It involves carefully examining the code, the design, and the documentation of software and checking these for aspects that are known to be potentially problematic based on past experience. Code smells are a metaphor to describe patterns that are generally associated with bad design and bad programming practices. Originally, code smells are used to find the places in software that could benefit from refactoring. In this paper we investigate how the quality of code can be automatically assessed by checking for the presence of code smells and how this approach can contribute to automatic code inspection. We present an approach for the automatic detection and visualization of code smells and discuss how this approach can be used in the design of a software inspection tool. We illustrate the feasibility of our approach with the development of jCOSMO, a prototype code smell browser that detects and visualizes code smells in Java source code. Finally, we show how this tool was applied in a case study.},
author = {{Van Emden}, Eva and Moonen, Leon},
doi = {10.1109/WCRE.2002.1173068},
file = {::},
isbn = {0769517994},
issn = {10951350},
journal = {Proceedings - Working Conference on Reverse Engineering, WCRE},
keywords = {Java,Software inspection,code smells,quality assurance,refactoring},
pages = {97--106},
publisher = {IEEE},
title = {{Java quality assurance by detecting code smells}},
volume = {2002-Janua},
year = {2002}
}
@article{Aichernig2018,
abstract = {We present a survey of the recent research efforts in integrating model learning with model-based testing. We distinguished two strands of work in this domain, namely test-based learning (also called test-based modeling) and learning-based testing. We classify the results in terms of their underlying models, their test purpose and techniques, and their target domains.},
author = {Aichernig, Bernhard K. and Mostowski, Wojciech and Mousavi, Mohammad Reza and Tappler, Martin and Taromirad, Masoumeh},
doi = {10.1007/978-3-319-96562-8_3},
file = {::},
isbn = {9783319965611},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {74--100},
title = {{Model learning and model-based testing}},
volume = {11026 LNCS},
year = {2018}
}
@article{Python.org2019a,
author = {Python.org},
file = {::},
pages = {1--28},
title = {{PEP 8 -- Style Guide for Python Code | Python.org}},
url = {https://www.python.org/dev/peps/pep-0008/},
year = {2019}
}
@article{Camilli2017,
abstract = {{\textcopyright} Springer International Publishing AG 2017. With the purpose of delivering more robust systems, this paper revisits the problem of Inverse Uncertainty Quantification that is related to the discrepancy between the measured data at runtime (while the system executes) and the formal specification (i.e., a mathematical model) of the system under consideration, and the value calibration of unknown parameters in the model. We foster an approach to quantify and mitigate system uncertainty during the development cycle by combining Bayesian reasoning and online Model-based testing.},
author = {Camilli, Matteo and Gargantini, Angelo and Scandurra, Patrizia and Bellettini, Carlo},
doi = {10.1007/978-3-319-66197-1_24},
file = {::},
isbn = {9783319661964},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {375--381},
title = {{Towards inverse uncertainty quantification in software development}},
volume = {10469 LNCS},
year = {2017}
}
@article{Bao2011,
abstract = {Computer-aided diagnosis of neural diseases from EEG signals (or other physiological signals that can be treated as time series, e.g., MEG) is an emerging field that has gained much attention in past years. Extracting features is a key component in the analysis of EEG signals. In our previous works, we have implemented many EEG feature extraction functions in the Python programming language. As Python is gaining more ground in scientific computing, an open source Python module for extracting EEG features has the potential to save much time for computational neuroscientists. In this paper, we introduce PyEEG, an open source Python module for EEG feature extraction.},
author = {Bao, Forrest Sheng and Liu, Xin and Zhang, Christina},
doi = {10.1155/2011/406391},
file = {::},
issn = {1687-5273},
journal = {Computational intelligence and neuroscience},
pages = {406391},
pmid = {21512582},
publisher = {Hindawi Limited},
title = {{PyEEG: an open source Python module for EEG/MEG feature extraction.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21512582 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3070217},
volume = {2011},
year = {2011}
}
@article{Spinellis2011,
abstract = {The style of our code, encompassing formatting, the ordering of the program's elements, and the naming of our identifiers, is a key aspect of its maintainability. Expertly styled code is more expressive, making us more productive when reading or writing code, while avoiding distractions. To improve code style, acquaint yourself with the style guidelines of each language you use or software you edit and apply them religiously. Also, learn from other people's code; don't rely on formatting tools to do the job for you. {\textcopyright} 2011 IEEE.},
author = {Spinellis, Diomidis},
doi = {10.1109/MS.2011.31},
file = {::},
issn = {07407459},
journal = {IEEE Software},
keywords = {formatting guidelines,programming style},
number = {2},
pages = {103--104},
title = {{elytS edoC}},
volume = {28},
year = {2011}
}
@phdthesis{Simmons2019,
author = {Simmons, Andrew J.},
file = {::},
isbn = {9781450354905},
school = {Deakin University},
title = {{Computational Pipelines for Spatio-Temporal Analysis of Team Invasion Games}},
year = {2019}
}
@article{Dacrema2019,
abstract = {Deep learning techniques have become the method of choice for researchers working on algorithmic aspects of recommender systems. With the strongly increased interest in machine learning in general, it has, as a result, become difcult to keep track of what represents the state-of-the-art at the moment, e.g., for top-n recommendation tasks. At the same time, several recent publications point out problems in today's research practice in applied machine learning, e.g., in terms of the reproducibility of the results or the choice of the baselines when proposing new models. In this work, we report the results of a systematic analysis of algorithmic proposals for top-n recommendation tasks. Specifcally, we considered 18 algorithms that were presented at top-level research conferences in the last years. Only 7 of them could be reproduced with reasonable efort. For these methods, it however turned out that 6 of them can often be outperformed with comparably simple heuristic methods, e.g., based on nearest-neighbor or graph-based techniques. The remaining one clearly outperformed the baselines but did not consistently outperform a well-tuned non-neural linear ranking method. Overall, our work sheds light on a number of potential problems in today's machine learning scholarship and calls for improved scientifc practices in this area.},
author = {Dacrema, Maurizio Ferrari and Cremonesi, Paolo and Jannach, Dietmar},
doi = {10.1145/3298689.3347058},
file = {::},
isbn = {9781450362436},
journal = {RecSys 2019 - 13th ACM Conference on Recommender Systems},
keywords = {Deep Learning,Evaluation,Recommender Systems,Reproducibility},
pages = {101--109},
title = {{Are we really making much progress? A worrying analysis of recent neural recommendation approaches}},
year = {2019}
}
@inproceedings{Omari2019,
abstract = {The Python programming language has been picking up traction in Industry for the past few years in virtually all application domains. Python is known for its high calibre and passionate community of developers. Empirical research on Python systems has potential to promote a healthy environment, where claims and beliefs held by the community are supported by data. To facilitate such research, a corpus of 132 open source python projects have been identified, basic information, quality as well as complexity metrics has been collected and organized into CSV files. Collectively, the list consists of 36, 635 python modules, 59, 532 classes, 253, 954 methods and 84, 892 functions. Projects in the selected list span various application domains including Web/APIs, Scientific Computing, Security and more.},
author = {Omari, Safwan and Martinez, Gina},
booktitle = {Proceedings of the Future Technologies Conference (FTC) 2019},
doi = {10.1007/978-3-030-32523-7_49},
editor = {Arai, Kohei and Bhatia, Rahul and Kapoor, Supriya},
file = {::},
isbn = {978-3-030-32523-7},
pages = {661--669},
publisher = {Springer International Publishing},
title = {{Enabling Empirical Research: A Corpus of Large-Scale Python Systems}},
year = {2020}
}
@article{wilson2014best,
author = {Wilson, Greg and Aruliah, Dhavide A and Brown, C Titus and Hong, Neil P Chue and Davis, Matt and Guy, Richard T and Haddock, Steven H D and Huff, Kathryn D and Mitchell, Ian M and Plumbley, Mark D and Others},
journal = {PLoS biology},
number = {1},
publisher = {Public Library of Science},
title = {{Best practices for scientific computing}},
volume = {12},
year = {2014}
}
@article{Marculescu2019,
abstract = {In the context of robustness testing, the boundary between the valid and invalid regions of the input space can be an interesting source of erroneous inputs. Knowing where a specific software under test (SUT) has a boundary is essential for validation in relation to requirements. However, finding where a SUT actually implements the boundary is a non-trivial problem that has not gotten much attention. This paper proposes a method of finding the boundary between the valid and invalid regions of the input space. The proposed method consists of two steps. First, test data generators, directed by a search algorithm to maximise distance to known, valid test cases, generate valid test cases that are closer to the boundary. Second, these valid test cases undergo mutations to try to push them over the boundary and into the invalid part of the input space. This results in a pair of test sets, one consisting of test cases on the valid side of the boundary and a matched set on the outer side, with only a small distance between the two sets. The method is evaluated on a number of examples from the standard library of a modern programming language. We propose a method of determining the boundary between valid and invalid regions of the input space and apply it on a SUT that has a non-contiguous valid region of the input space. From the small distance between the developed pairs of test sets, and the fact that one test set contains valid test cases and the other invalid test cases, we conclude that the pair of test sets described the boundary between the valid and invalid regions of that input space. Differences of behaviour can be observed between different distances and sets of mutation operators, but all show that the method is able to identify the boundary between the valid and invalid regions of the input space. This is an important step towards more automated robustness testing.},
annote = {Defining boundaries for input space varies at different stages of software development and these boundaries are rich sources of software errors.

Finding boundaries will help to identify test cases which are near to the borderline of valid and invalid regions. This facilitates robustness and continual operation of the software, irrespective of correctness.

The research was conducted in two stages, namely generating automated data and mutating the valid test cases using property switching search.

GodelTest framework is utilized to develop an automated test data generator and it is assumed that the generator is fault free. The fitness function is calculated between the current candidate and the highest candidate of among already identified candidates and the fitness function needs to be maximized. 

In the second step, closed paired sets of test cases on either side of the boundary are selected and are swapped. Each candidate is started with the desired property, which is validity, and is mutated until the desired property is changed.},
archivePrefix = {arXiv},
arxivId = {arXiv:1810.06720v1},
author = {Marculescu, Bogdan and Feldt, Robert},
doi = {10.1109/APSEC.2018.00031},
eprint = {arXiv:1810.06720v1},
file = {::},
isbn = {9781728119700},
issn = {15301362},
journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
keywords = {search based software testing,software testing},
pages = {169--178},
title = {{Finding a Boundary between Valid and Invalid Regions of the Input Space}},
volume = {2018-Decem},
year = {2019}
}
@book{martin2009clean,
author = {Martin, Robert C},
publisher = {Pearson Education},
title = {{Clean code: a handbook of agile software craftsmanship}},
year = {2009}
}
@book{Russell_Norvig,
author = {Russell, Stuart and Norvig, Peter},
edition = {3rd},
publisher = {Prentice Hall Press},
title = {{Artificial Intelligence: A Modern Approach}},
year = {2009}
}
@article{Kanter2009,
abstract = {OBJECTIVE: To estimate whether an organized, consistent program of dietary and lifestyle counseling prevents excessive weight gain in pregnancy. METHODS: This randomized controlled trial assigned women to receive either an organized, consistent program of intensive dietary and lifestyle counseling or routine prenatal care. The primary study outcome was the proportion of patients whose gestational weight gain was within the Institute of Medicine (IOM) guidelines. Secondary outcomes included mode of delivery, rate of operative vaginal delivery, neonatal weight, and the incidence of preeclampsia, gestational diabetes mellitus (GDM), vaginal/perineal lacerations, and shoulder dystocia. RESULTS: A total of 100 women were randomized to the study (lifestyle counseling 57, routine prenatal care 43). Baseline demographic characteristics were similar between the study groups. The lifestyle counseling group gained significantly less weight than did the routine prenatal care group (28.7±12.5 lb compared with 35.6±15.5 lb, P=.01). The routine prenatal care group had significantly more cesarean deliveries due to “failure to progress” (routine prenatal care 58.3{\%} compared with lifestyle counseling 25.0{\%}, P=.02). Across groups, patients who were not adherent to the IOM guidelines had significantly heavier neonates (adherent 3,203.2±427.2 g compared with not adherent 3,517.4±572.4 g, P{\textless}.01). Nulliparous women gained significantly more weight than did parous women (36.5±14.5 lb compared with 27.7±12.7 lb, P{\textless}.01). The most predictive factor of IOM adherence was having a normal prepregnancy body mass index. No statistically significant differences were noted between the groups in adherence to IOM guidelines, rate of cesarean delivery, preeclampsia, GDM, operative vaginal delivery, or vaginal lacerations. CONCLUSION: An organized, consistent program of dietary and lifestyle counseling did reduce weight gain in pregnancy.},
author = {Kanter, James Max},
doi = {978-1-4673-8273-1},
file = {::},
isbn = {0029-7844},
issn = {00297844},
journal = {Obstetrics and Gynecology},
number = {2 PART 1},
pages = {305--312},
pmid = {19155899},
title = {{Deep Feature Synthesis: Towards Automating Data Science Endeavors James}},
volume = {113},
year = {2009}
}
@article{Barnett2019,
abstract = {In this viewpoint we describe the architecture of, and design rationale for, a new software platform designed to support the conduct of digital phenotyping research studies. These studies seek to collect passive and active sensor signals from participants' smartphones for the purposes of modelling and predicting health outcomes, with a specific focus on mental health. We also highlight features of the current research landscape that recommend the coordinated development of such platforms, including the significant technical and resource costs of development, and we identify specific considerations relevant to the design of platforms for digital phenotyping. In addition, we describe trade-offs relating to data quality and completeness versus the experience for patients and public users who consent to their devices being used to collect data. We summarize distinctive features of the resulting platform, InSTIL (Intelligent Sensing to Inform and Learn), which includes universal (ie, cross-platform) support for both iOS and Android devices and privacy-preserving mechanisms which, by default, collect only anonymized participant data. We conclude with a discussion of recommendations for future work arising from learning during the development of the platform. The development of the InSTIL platform is a key step towards our research vision of a population-scale, international, digital phenotyping bank. With suitable adoption, the platform will aggregate signals from large numbers of participants and large numbers of research studies to support modelling and machine learning analyses focused on the prediction of mental illness onset and disease trajectories.},
author = {Barnett, Scott and Huckvale, Kit and Christensen, Helen and Venkatesh, Svetha and Mouzakis, Kon and Vasa, Rajesh},
doi = {10.2196/16399},
issn = {1438-8871},
journal = {Journal of Medical Internet Research},
month = {nov},
number = {11},
pages = {e16399},
title = {{Intelligent Sensing to Inform and Learn (InSTIL): A Scalable and Governance-Aware Platform for Universal, Smartphone-Based Digital Phenotyping for Research and Clinical Applications}},
url = {https://www.jmir.org/2019/11/e16399},
volume = {21},
year = {2019}
}
@book{allbee2018hands,
author = {Allbee, Brian},
publisher = {Packt Publishing Ltd},
title = {{Hands-On Software Engineering with Python: Move beyond basic programming and construct reliable and efficient software with complex code}},
year = {2018}
}
@article{Covington2016,
abstract = {YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous userfacing impact.},
author = {Covington, Paul and Adams, Jay and Sargin, Emre},
doi = {10.1145/2959100.2959190},
file = {::},
isbn = {9781450340359},
journal = {RecSys 2016 - Proceedings of the 10th ACM Conference on Recommender Systems},
keywords = {Deep learning,Recommender system,Scalability},
pages = {191--198},
title = {{Deep neural networks for youtube recommendations}},
year = {2016}
}
@article{Wang2018d,
abstract = {As an emerging research topic, online class imbalance learning often combines the challenges of both class imbalance and concept drift. It deals with data streams having very skewed class distributions, where concept drift may occur. It has recently received increased research attention; however, very little work addresses the combined problem where both class imbalance and concept drift coexist. As the first systematic study of handling concept drift in class-imbalanced data streams, this paper first provides a comprehensive review of current research progress in this field, including current research focuses and open challenges. Then, an in-depth experimental study is performed, with the goal of understanding how to best overcome concept drift in online learning with class imbalance. Based on the analysis, a general guideline is proposed for the development of an effective algorithm.},
annote = {Precision is a measure of exactness - the proportion of positive class examples that are classified correctly to the examples predicted as positive by the classifier

Concept drift is mainly categorized into two groups - active vs passive approaches, depending on whether an explicit drift mechanism is employed or not.},
archivePrefix = {arXiv},
arxivId = {arXiv:1703.06683v1},
author = {Wang, Shuo and Minku, Leandro L. and Yao, Xin},
doi = {10.1109/TNNLS.2017.2771290},
eprint = {arXiv:1703.06683v1},
file = {::},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Class imbalance,concept drift,online learning,resampling},
number = {10},
pages = {4802--4821},
title = {{A Systematic Study of Online Class Imbalance Learning with Concept Drift}},
volume = {29},
year = {2018}
}
@article{Chen2018,
abstract = {This paper investigates how supply chain management (SCM) efficiency affects the value investors attach to the change in a company's inventory holdings. Based on a large number of U.S. firms from 1971 to 2013, we find that, on average, one dollar of inventory change is valued at {\$}0.507 in the stock market. Decomposition into normal and abnormal inventory changes reveals that the market value of one dollar of abnormal inventory change is 43{\%} smaller than that of normal inventory change, where a normal change moves the inventory balance to an estimated optimal level, and an abnormal change refers to the gap between actual inventory change and the estimated optimal change. We also investigate inventory turnover and gross margin and find economically and statistically significant relations between these proxies for efficient SCM and the value the market attaches to inventory changes. Finally, we find that the market attaches a higher value to inventory changes of firms with better growth prospects, higher sales predictability, and tighter financial constraints.},
author = {Chen, Jeff Zeyun and Jung, Boochun and Park, Duri and Shane, Philip B.},
doi = {10.2139/ssrn.3193750},
file = {::},
journal = {SSRN Electronic Journal},
keywords = {abnormal inventory,and comments from roger,boochun jung,corresponding author,debreceny,hawaii at manoa and,holdings,kaist-korea university joint seminar,market value of inventory,participants at university of,supply chain management,we appreciate helpful suggestions,workshop},
pages = {1--44},
title = {{The Market Value of Inventory}},
year = {2018}
}
@book{jackson2007natural,
author = {Jackson, P and Moulinier, I},
isbn = {9789027292445},
publisher = {John Benjamins Publishing Company},
series = {Natural Language Processing},
title = {{Natural Language Processing for Online Applications: Text retrieval, extraction and categorization. Second revised edition}},
url = {https://books.google.com.au/books?id=aZN05pMJTLAC},
year = {2007}
}
@article{N.2017,
abstract = {Electroencephalogram (EEG) is the recording of the electrical activity of the brain which can be used to identify different disease conditions. In the case of a partial epilepsy, some portions of the brain is affected and the EEG measured from that portions are called as Focal EEG and the EEG measured from other regions is termed as Non Focal EEG. The identification of Focal EEG assists the doctors in finding the epileptogenic focus and thereby go for surgical removal of those portions of the brain for those who are having drug resistant epilepsy. In this work, we have proposed a classification methodology to classify Focal and Non Focal EEG. We used the Bern Barcelona database and used entropies such as Approximate entropy (ApEn), Sample entropy (SampEn) and Reyni's entropy as features. These features were fed into six different classifiers such as Na{\"{i}}ve Bayes (NBC), Radial Basis function (RBF), Support Vector Machines (SVM), KNN classifier, Non-Nested Generalized Exemplars classifier (NNge) and Best First Decision Tree (BFDT) classifier. It was found that NNge classifier gave the highest accuracy of 98{\%}, sensitivity of 100{\%} and specificity of 96{\%}, which is the highest comparing to other methods in the literature. In addition to the above, the maximum computation time of our features is 0.054 seconds which opens the window for real time processing. Thus our method can be written as a handy software tool towards assisting the physician.},
author = {N., Arunkumar and K., Ramkumar and V., Venkatraman and Abdulhay, Enas and {Lawrence Fernandes}, Steven and Kadry, Seifedine and Segal, Sophia},
doi = {10.1016/j.patrec.2017.05.007},
file = {::},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Classification,EEG signal,Entropy,Epilepsy},
month = {jul},
pages = {112--117},
publisher = {Elsevier B.V.},
title = {{Classification of focal and non focal EEG using entropies}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0167865517301472},
volume = {94},
year = {2017}
}
@inproceedings{Sculley2015,
abstract = {Machine learning offers a fantastically powerful toolkit for building useful complex prediction systems quickly. This paper argues it is dangerous to think of these quick wins as coming for free. Using the software engineering framework of technical debt, we find it is common to incur massive ongoing maintenance costs in real-world ML systems. We explore several ML-specific risk factors to account for in system design. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, configuration issues, changes in the external world, and a variety of system-level anti-patterns.},
author = {Sculley, D and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Crespo, Jean-Fran{\c{c}}ois and Dennison, Dan},
booktitle = {Advances in Neural Information Processing Systems},
file = {::},
pages = {2503--2511},
title = {{Hidden Technical Debt in Machine Learning Systems}},
url = {http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf},
year = {2015}
}
@article{Haiduc2010,
abstract = {One of the main challenges faced by today's developers is keeping up with the staggering amount of source code that needs to be read and understood. In order to help developers with this problem and reduce the costs associated with it, one solution is to use simple textual descriptions of source code entities that developers can grasp easily, while capturing the code semantics precisely. We propose an approach to automatically determine such descriptions, based on automated text summarization technology.},
author = {Haiduc, Sonia and Aponte, Jairo and Marcus, Andrian},
doi = {10.1145/1810295.1810335},
file = {::},
isbn = {9781605587196},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
keywords = {program comprehension,summary,text summarization},
pages = {223--226},
title = {{Supporting program comprehension with source code summarization}},
volume = {2},
year = {2010}
}
@article{Coupe2000,
abstract = { When building a Bayesian belief network, usually a large number of probabilities have to be assessed by experts in the domain of application. Experience shows that experts are often reluctant to assess all probabilities required, feeling that they are unable to give assessments with a high level of accuracy. We argue that the elicitation of probabilities from experts can be supported to a large extent by iteratively performing sensitivity analyses of the belief network in the making, starting with rough, initial assessments. Since it gives insight into which probabilities require a high level of accuracy and which do not, performing a sensitivity analysis allows for focusing further elicitation efforts. We propose an elicitation procedure in which, alternately, sensitivity analyses are performed and probability assessments refined, until satisfactory behaviour of the belief network is obtained, until the costs of further elicitation outweigh the benefits of higher accuracy or until higher accuracy can no longer be attained due to lack of knowledge. },
author = {Coup{\'{e}}, Veerle M.H. and {Van Der Gaag}, Linda C. and Habbema, J. Dik F.},
doi = {10.1017/S0269888900003027},
file = {::},
issn = {02698889},
journal = {Knowledge Engineering Review},
number = {3},
pages = {215--232},
title = {{Sensitivity analysis: an aid for belief-network quantification}},
volume = {15},
year = {2000}
}
@book{sivia2006,
author = {{Sivia, D. and Skilling}, J.},
publisher = {Oxford University Press},
title = {{Data Analysis: A Bayesian Tutorial}},
year = {2006}
}
@article{Boogerd2008,
abstract = {In spite of the widespread use of coding standards and tools enforcing their rules, there is little empirical evidence supporting the intuition that they prevent the introduction of faults in software. Not only can compliance with a set of rules having little impact on the number of faults be considered wasted effort, but it can actually result in an increase in faults, as any modification has a non-zero probability of introducing a fault or triggering a previously concealed one. Therefore, it is important to build a body of empirical knowledge, helping us understand which rules are worthwhile enforcing, and which ones should be ignored in the context of fault reduction. In this paper, we describe two approaches to quantify the relation between rule violations and actual faults, and present empirical data on this relation for the MISRA C 2004 standard on an industrial case study. {\textcopyright} 2008 IEEE.},
author = {Boogerd, Cathal and Moonen, Leon},
doi = {10.1109/ICSM.2008.4658076},
file = {::},
isbn = {9781424426140},
journal = {IEEE International Conference on Software Maintenance, ICSM},
pages = {277--286},
title = {{Assessing the value of coding standards: An empirical study}},
year = {2008}
}
