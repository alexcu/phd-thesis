Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@inproceedings{Kurakin:2016vw,
abstract = {Most existing machine learning classifiers are highly vulnerable to adversarial examples. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake. Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model. Up to now, all previous work has assumed a threat model in which the adversary can feed data directly into the machine learning classifier. This is not always the case for systems operating in the physical world, for example those which are using signals from cameras and other sensors as input. This paper shows that even in such physical world scenarios, machine learning systems are vulnerable to adversarial examples. We demonstrate this by feeding adversarial images obtained from a cell-phone camera to an ImageNet Inception classifier and measuring the classification accuracy of the system. We find that a large fraction of adversarial examples are classified incorrectly even when perceived through the camera.},
address = {Palais des Congr{\`{e}}s Neptune, Toulon, France},
archivePrefix = {arXiv},
arxivId = {1607.02533},
author = {Kurakin, Alexey and Goodfellow, Ian J and Bengio, Samy},
booktitle = {Proceedings of the 5th International Conference on Learning Representations},
eprint = {1607.02533},
month = {apr},
title = {{Adversarial examples in the physical world}},
year = {2017}
}
@inproceedings{Ko:2004td,
abstract = {As programming skills increase in demand and utility, the learnability of end-user programming systems is of utmost importance. However, research on learning barriers in programming systems has primarily focused on languages, overlooking potential barriers in the environment and accompanying libraries. To address this, a study of beginning programmers learning Visual Basic. MET was performed. This identified six types of barriers: design, selection, coordination, use, understanding, and information. These barriers inspire a new metaphor of computation, which provides a more learner-centric view of programming system design. {\textcopyright}2004 IEEE.},
address = {Rome, Italy},
author = {Ko, Andrew J and Myers, Brad A and Aung, Htet Htet},
booktitle = {Proceedings of the 2004 IEEE Symposium on Visual Languages and Human Centric Computing},
doi = {10.1109/vlhcc.2004.47},
isbn = {0-78-038696-5},
month = {sep},
pages = {199--206},
publisher = {IEEE},
title = {{Six learning barriers in end-user programming systems}},
year = {2004}
}
@inproceedings{sculley2011detecting,
address = {San Diego, CA, USA},
author = {Sculley, D and Otey, Matthew Eric and Pohl, Michael and Spitznagel, Bridget and Hainsworth, John and Zhou, Yunkai},
booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/2020408.2020455},
month = {aug},
organization = {ACM},
pages = {274--282},
publisher = {ACM},
title = {{Detecting adversarial advertisements in the wild}},
year = {2011}
}
@book{Dey:2003ty,
abstract = {This book comprehensively covers all major topics of Vygotskian educa- tional theory and its classroom applications. Particular attention is paid to the Vygotskian idea of child development as a consequence rather than premise of learning experiences. Such a reversal allows for new interpretations of the relationships between cognitive development and education at different junc- tions of the human life span. It also opens new perspectives on atypical de- velopment, learning disabilities, and assessment of children's learning poten- tial. Classroomapplications ofVygotskian theory, teacher preparation, and the changing role of a teacher in a sociocultural classroom are discussed in addi- tion to the issues of learning activities and peer interaction. Relevant research findings fromthe United States,Western Europe, and Russia are considered to- gether to clarify the possible new applications of Vygotskian ideas in different disciplinary areas. The sociocultural orientation of Vygotskian theory helps to reveal learning patterns that become obscured in more traditional research.},
address = {New York, NY},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Dey, I},
doi = {10.4324/9780203879276},
eprint = {arXiv:1011.1669v3},
howpublished = {$\backslash$url{\{}http://books.google.com/books?id=bttwENORfhgC{\{}$\backslash${\&}{\}}pgis=1{\{}$\backslash${\%}{\}}5Cnhttp://books.google.co.uk/books?id=uOw6PQAACAAJ{\{}$\backslash${\&}{\}}dq=Educational+Psychology:+Cognition+an{\}}d+Learning,+Individual+Differences+and+Motivation{\&}hl=en{\&}ei=bbZlTKeCCMKSjAem2Y3pCw{\&}sa=X{\&}oi=book{\_}result{\&}ct=result{\&}},
isbn = {6-31-231726-9},
issn = {1367-6539},
pmid = {2539002},
publisher = {Routledge},
title = {{Qualitative Data Analysis: A User-Friendly Guide for Social Scientists}},
year = {1993}
}
@article{Zupan:2000tp,
author = {Zupan, Blaz and Dem{\v{s}}Ar, Janez and Kattan, Michael W and Beck, J Robert and Bratko, Ivan},
journal = {Artificial intelligence in medicine},
number = {1},
pages = {59--75},
title = {{Machine learning for survival analysis: a case study on recurrence of prostate cancer}},
volume = {20},
year = {2000}
}
@article{Thrun:1996wh,
abstract = {This paper investigates learning in a lifelong context. Lifelong learning addresses situations in which a learner faces a whole stream of learning tasks. Such scenarios provide the opportunity to transfer knowledge across multiple learning tasks, in order to generalize more accurately from less training data. In this paper, several different approaches to lifelong learning are described, and applied in an object recognition domain. It is shown that across the board, lifelong learning approaches generalize consistently more accurately from less training data, by their ability to transfer knowledge across learning tasks.},
address = {Denver, CO, USA},
author = {Thrun, Sebastian},
issn = {1049-5258},
journal = {Proceedings of the 8th International Conference on Neural Information Processing Systems},
month = {nov},
pages = {7},
publisher = {MIT Press},
title = {{Is Learning The n-th Thing Any Easier Than Learning The First?}},
year = {1996}
}
@inproceedings{Bajaj:2014wg,
abstract = {Modern web applications consist of a significant amount of clientside code, written in JavaScript, HTML, and CSS. In this paper, we present a study of common challenges and misconceptions among web developers, by mining related questions asked on Stack Overflow. We use unsupervised learning to categorize the mined questions and define a ranking algorithm to rank all the Stack Overflow questions based on their importance. We analyze the top 50 questions qualitatively. The results indicate that (1) the overall share of web development related discussions is increasing among developers, (2) browser related discussions are prevalent; however, this share is decreasing with time, (3) form validation and other DOM related discussions have been discussed consistently over time, (4) web related discussions are becoming more prevalent in mobile development, and (5) developers face implementation issues with new HTML5 features such as Canvas. We examine the implications of the results on the development, research, and standardization communities. Copyright is held by the author/owner(s). Publication rights licensed to ACM.},
address = {Hyderabad, India},
author = {Bajaj, Kartik and Pattabiraman, Karthik and Mesbah, Ali},
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
doi = {10.1145/2597073.2597083},
isbn = {978-1-45-032863-0},
keywords = {Stack Overflow,Text mining,Topic modeling,Web developers},
month = {may},
pages = {112--121},
publisher = {ACM},
title = {{Mining questions asked by web developers}},
year = {2014}
}
@article{Wieringa:2006vd,
abstract = {This paper was triggered by concerns about the methodological soundness of many RE papers. We present a conceptual framework that distinguishes design papers from research papers, and show that in this framework, what is called a research paper in RE is often a design paper. We then present and motivate two lists of evaluation criteria, one for research papers and one for design papers. We apply both of these lists to two samples drawn from the set of all submissions to the RE'3 conference. Analysis of these two samples shows that most submissions of the RE'3 conference are design papers, not research papers, and that most design papers present a solution to a problem but neither validate this solution nor investigate the problems that can be solved by this solution. We conclude with a discussion of the soundness of our results and of the possible impact on RE research and practice. {\textcopyright}Springer-Verlag London Limited 2006.},
author = {Wieringa, Roel J and Heerkens, J M G},
doi = {10.1007/s00766-006-0037-6},
issn = {0947-3602},
journal = {Requirements Engineering},
number = {4},
pages = {295--307},
title = {{The methodological soundness of requirements engineering papers: A conceptual framework and two case studies}},
volume = {11},
year = {2006}
}
@article{Chillarege:1992tm,
abstract = {This paper describes orthogonal defect classification (ODC), a concept that enables in-process feedback to developers by extracting signatures on the development process from defects. The ideas are evolved from an earlier finding that demonstrates the use of semantic information from defects to extract cause-effect relationships in the development process. This finding is leveraged to develop a systematic framework for building measurement and analysis methods. This paper • defines ODC and discusses the necessary and sufficient conditions required to provide feedback to a developer; • illustrates the use of the defect type distribution to measure the progress of a product through a process; • illustrates the use of the defect trigger distribution to evaluate the effectiveness and eventually the completeness of verification processes such as inspection or testing; • provides sample results from pilot projects using ODC; •opens the doors to a wide variety of analysis techniques for providing effective and fast feedback based on the concepts of ODC. {\textcopyright}1992 IEEE},
author = {Chillarege, Ram and Bhandari, Inderpal S and Chaar, Jarir K and Halliday, Michael J and Ray, Bonnie K and Moebus, Diane S},
doi = {10.1109/32.177364},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
number = {11},
pages = {943--956},
title = {{Orthogonal Defect Classification—A Concept for In-Process Measurements}},
volume = {18},
year = {1992}
}
@book{Hastie:2001wp,
author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome H},
edition = {2nd},
month = {jan},
publisher = {Springer},
series = {Data Mining, Inference, and Prediction},
title = {{The Elements of Statistical Learning}},
year = {2001}
}
@article{Juristo:2012bp,
abstract = {Experimentation has played a major role in scientific advancement. Replication is one of the essentials of the experimental methods. In replications, experiments are repeated aiming to check their results. Successful replication increases the validity and reliability of the outcomes observed in an experiment. There is debate about the best way of running replications of Software Engineering (SE) experiments. Some of the questions that have cropped up in this debate are, "Should replicators reuse the baseline experiment materials? Which is the adequate sort of communication among experimenters and replicators if any? What elements of the experimental structure can be changed and still be considered a replication instead of a new experiment?". A deeper understanding of the concept of replication should help to clarify these issues as well as increase and improve replications in SE experimental practices. In this chapter, we study the concept of replication in order to gain insight. The chapter starts with an introduction to the importance of replication and the state of replication in ESE. Then we discuss replication from both the statistical and scientific viewpoint. Based on a review of the diverse types of replication used in other scientific disciplines, we identify the different types of replication that are feasible to be run in our discipline. Finally, we present the different purposes that replication can serve in Experimental Software Engineering (ESE). {\textcopyright}2012 Springer-Verlag Berlin Heidelberg.},
address = {Elba Island, Italy},
author = {Juristo, Natalia and G{\'{o}}mez, Omar S},
doi = {10.1007/978-3-642-25231-0_2},
isbn = {978-3-64-225230-3},
issn = {0302-9743},
journal = {Lecture Notes in Computer Science},
keywords = {Empirical Software Engineering,Experimental Replicaction,Experimental Software Engineering,Types of Replication},
pages = {60--88},
publisher = {Springer},
title = {{Replication of software engineering experiments}},
volume = {7007 LNCS},
year = {2011}
}
@inproceedings{Cheng:2001vw,
abstract = {This paper investigates the methods for learning predictive classifiers based on Bayesian belief networks (BN)-primarily unrestricted Bayesian networks and Bayesian multi-nets. We present our algorithms for learning these classifiers, and discuss how these methods address the overfitting problem and provide a natural method for feature subset selection. Using a set of standard classification problems, we empirically evaluate the performance of various BN-based classifiers. The results show that the proposed BN and Bayes multinet classifiers are competitive with (or superior to) the best known classifiers, based on both BN and other formalisms; and that the computational time for learning and using these classifiers is relatively small. These results argue that BN-based classifiers deserve more attention in the data mining community.},
address = {Ottawa, ON, Canada},
author = {Cheng, Jie and Greiner, Russell},
booktitle = {Proceedings of the 14th Biennial Conference of the Canadian Society for Computational Studies of Intelligence},
doi = {10.1007/3-540-45153-6_14},
isbn = {3-54-042144-0},
issn = {1611-3349},
month = {jun},
pages = {141--151},
publisher = {Springer},
title = {{Learning bayesian belief network classifiers: Algorithms and system}},
volume = {2056},
year = {2001}
}
@techreport{McCall:1977uy,
abstract = {An hierarchical definition of factors affecting software quality was compiled after an extensive literature search. The definition covers the complete range of software development and is broken down into non-oriented and software-oriented characteristics. For the lowest level of the software-oriented factors, metrics were developed that would be independent of the programming language. These measurable criteria were collected and validated using actual Air Force data bases. A handbook was generated that will be useful to Air Force acquisition managers for specifying the overall quality of a software system.},
address = {Griffiss Air Force Base, NY, USA},
author = {McCall, Jim a. and Richards, Paul K and Walters, Gene F},
booktitle = {Technical Report: Rome Air Development Center, Air Force Systems Command},
institution = {General Electric Company},
month = {nov},
number = {RADC-TR-77-369},
pages = {689--1699},
title = {{Factors in Software Quality: Concept and Definitions of Software Quality}},
volume = {1},
year = {1977}
}
@inproceedings{Allamanis:2013is,
abstract = {Questions from Stack Overflow provide a unique opportunity to gain insight into what programming concepts are the most confusing. We present a topic modeling analysis that combines question concepts, types, and code. Using topic modeling, we are able to associate programming concepts and identifiers (like the String class) with particular types of questions, such as, "how to perform encoding". {\textcopyright}2013 IEEE.},
address = {San Francisco, CA, USA},
author = {Allamanis, Miltiadis and Sutton, Charles},
booktitle = {Proceedings of the 10th IEEE International Working Conference on Mining Software Repositories},
doi = {10.1109/MSR.2013.6624004},
isbn = {978-1-46-732936-1},
issn = {2160-1852},
month = {may},
pages = {53--56},
publisher = {IEEE},
title = {{Why, when, and what: Analyzing stack overflow questions by topic, type, and code}},
year = {2013}
}
@article{Bunge:1963jm,
abstract = {A mathematical theory is proposed and exemplified, which covers an extended class of black boxes. Every kind of stimulus and response is pictured by a channel connecting the box with its environment. The input-output relation is given by a postulate schema according to which the response is, in general, a nonlinear functional of the input. Several examples are worked out: the perfectly transmitting box, the damping box, and the amplifying box. The theory is shown to be (a) an extension of the S-matrix theory and the accompanying channel picture as developed in microphysics; (b) abstract and applicable to any problem involving the transactions of a system (physical, biological, social, etc.) with its milieu; (c) superficial, because unconcerned with either the structure of the box or the nature of the stimuli and responses. The motive for building the theory was to show the capabilities and limitations of the phenomenological approach.},
author = {Bunge, Mario},
doi = {10.1086/287954},
issn = {0031-8248},
journal = {Philosophy of Science},
month = {oct},
number = {4},
pages = {346--358},
title = {{A General Black Box Theory}},
volume = {30},
year = {1963}
}
@article{mcleod2011factors,
abstract = {Determining the factors that have an influence on software systems development and deployment project outcomes has been the focus of extensive and ongoing research for more than 30 years. We provide here a survey of the research literature that has addressed this topic in the period 1996-2006, with a particular focus on empirical analyses. On the basis of this survey we present a new classification framework that represents an abstracted and synthesized view of the types of factors that have been asserted as influencing project outcomes. {\textcopyright}2011 ACM.},
author = {McLeod, Laurie and MacDonell, Stephen G},
doi = {10.1145/1978802.1978803},
issn = {0360-0300},
journal = {ACM Computing Surveys},
keywords = {Development processes,Institutional context,People and action,Project content,Project outcomes},
number = {4},
pages = {24},
publisher = {ACM},
title = {{Factors that affect software systems development project outcomes: A survey of research}},
volume = {43},
year = {2011}
}
@article{Gamer:tj,
author = {Gamer, M and Lemon, J and Fellows, I and Singh, P},
journal = {R package version 0.83},
title = {{Irr: various coefficients of interrater reliability}},
year = {2010}
}
@article{Pazzani:2001tw,
abstract = {Objectives: The aim was to evaluate the potential for monotonicity constraints to bias machine learning systems to learn rules that were both accurate and meaningful. Methods: Two data sets, taken from problems as diverse as screening for dementia and assessing the risk of mental retardation, were collected and a rule learning system, with and without monotonicity constraints, was run on each. The rules were shown to experts, who were asked how willing they would be to use such rules in practice. The accuracy of the rules was also evaluated. Results: Rules learned with monotonicity constraints were at least as accurate as rules learned without such constraints. Experts were, on average, more willing to use the rules learned with the monotonicity constraints. Conclusions: The analysis of medical databases has the potential of improving patient outcomes and/or lowering the cost of health care delivery. Various techniques, from statistics, pattern recognition, machine learning, and neural networks, have been proposed to "mine" this data by uncovering patterns that may be used to guide decision making. This study suggests cognitive factors make learned models coherent and, therefore, credible to experts. One factor that influences the acceptance of learned models is consistency with existing medical knowledge.},
author = {Pazzani, M J and Mani, S and Shankle, W R},
doi = {10.1055/s-0038-1634196},
issn = {0026-1270},
journal = {Methods of Information in Medicine},
keywords = {Alzheimer Disease,Artificial Intelligence,Mental Retardation},
number = {5},
pages = {380--385},
pmid = {11776735},
title = {{Acceptance of rules generated by machine learning among medical experts}},
volume = {40},
year = {2001}
}
@inproceedings{breck2016s,
abstract = {Using machine learning in real-world production systems is complicated by a host of issues not found in small toy examples or even large offline research experiments. Testing and monitoring are key considerations for assessing the production-readiness of an ML system. But how much testing and monitoring is enough? We present an ML Test Score rubric based on a set of actionable tests to help quantify these issues.},
address = {Barcelona, Spain},
author = {Breck, Eric and Cai, Shanqing and Nielsen, Eric and Salib, Michael and Sculley, D},
booktitle = {Proceedings of the 30th Annual Conference on Neural Information Processing Systems},
month = {dec},
number = {NIPS},
publisher = {Curran Associates Inc.},
title = {{What's your ML Test Score? A rubric for ML production systems}},
year = {2016}
}
@article{Haenssle:2018bz,
abstract = {Background: Deep learning convolutional neural networks (CNN) May facilitate melanoma detection, but data comparing a CNN's diagnostic performance to larger groups of dermatologists are lacking. Methods: Google's Inception v4 CNN architecture was trained and validated using dermoscopic images and corresponding diagnoses. In a comparative cross-sectional reader study a 100-image test-set was used (level-I: dermoscopy only; level-II: dermoscopy plus clinical information and images). Main outcome measures were sensitivity, specificity and area under the curve (AUC) of receiver operating characteristics (ROC) for diagnostic classification (dichotomous) of lesions by the CNN versus an international group of 58 dermatologists during level-I or -II of the reader study. Secondary end points included the dermatologists' diagnostic performance in their management decisions and differences in the diagnostic performance of dermatologists during level-I and -II of the reader study. Additionally, the CNN's performance was compared with the top-five algorithms of the 2016 International Symposium on Biomedical Imaging (ISBI) challenge. Results: In level-I dermatologists achieved a mean (6standard deviation) sensitivity and specificity for lesion classification of 86.6{\%} (69.3{\%}) and 71.3{\%} (611.2{\%}), respectively. More clinical information (level-II) improved the sensitivity to 88.9{\%} (69.6{\%}, P ¼ 0.19) and specificity to 75.7{\%} (611.7{\%}, P {\textless}0.05). The CNN ROC curve revealed a higher specificity of 82.5{\%} when compared with dermatologists in level-I (71.3{\%}, P {\textless}0.01) and level-II (75.7{\%}, P {\textless}0.01) at their sensitivities of 86.6{\%} and 88.9{\%}, respectively. The CNN ROC AUC was greater than the mean ROC area of dermatologists (0.86 versus 0.79, P {\textless}0.01). The CNN scored results close to the top three algorithms of the ISBI 2016 challenge. Conclusions: For the first time we compared a CNN's diagnostic performance with a large international group of 58 dermatologists, including 30 experts. Most dermatologists were outperformed by the CNN. Irrespective of any physicians' experience, they May benefit from assistance by a CNN's image classification.},
author = {Haenssle, H A and Fink, C and Schneiderbauer, R and Toberer, F and Buhl, T and Blum, A and Kalloo, A and {Ben Hadj Hassen}, A and Thomas, L and Enk, A and Uhlmann, L and Alt, Christina and Arenbergerova, Monika and Bakos, Renato and Baltzer, Anne and Bertlich, Ines and Blum, Andreas and Bokor-Billmann, Therezia and Bowling, Jonathan and Braghiroli, Naira and Braun, Ralph and Buder-Bakhaya, Kristina and Buhl, Timo and Cabo, Horacio and Cabrijan, Leo and Cevic, Naciye and Classen, Anna and Deltgen, David and Fink, Christine and Georgieva, Ivelina and Hakim-Meibodi, Lara Elena and Hanner, Susanne and Hartmann, Franziska and Hartmann, Julia and Haus, Georg and Hoxha, Elti and Karls, Raimonds and Koga, Hiroshi and Kreusch, Ju¨rgen and Lallas, Aimilios and Majenka, Pawel and Marghoob, Ash and Massone, Cesare and Mekokishvili, Lali and Mestel, Dominik and Meyer, Volker and Neuberger, Anna and Nielsen, Kari and Oliviero, Margaret and Pampena, Riccardo and Paoli, John and Pawlik, Erika and Rao, Barbar and Rendon, Adriana and Russo, Teresa and Sadek, Ahmed and Samhaber, Kinga and Schneiderbauer, Roland and Schweizer, Anissa and Toberer, Ferdinand and Trennheuser, Lukas and Vlahova, Lyobomira and Wald, Alexander and Winkler, Julia and Wo¨lbing, Priscila and Zalaudek, Iris},
doi = {10.1093/annonc/mdy166},
issn = {1569-8041},
journal = {Annals of Oncology},
keywords = {Automated melanoma detection,Computer algorithm,Deep learning convolutional neural network,Dermoscopy,Melanocytic nevi,Melanoma},
month = {may},
number = {8},
pages = {1836--1842},
title = {{Man against Machine: Diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists}},
volume = {29},
year = {2018}
}
@article{Uddin:2019cz,
abstract = {With the proliferation of online developer forums, developers share their opinions about the APIs they use. The plethora of such information can present challenges to the developers to get quick but informed insights about the APIs. To understand the potential benefits of such API reviews, we conducted a case study of opinions in Stack Overflow using a benchmark dataset of 4522 sentences. We observed that opinions about diverse API aspects (e.g., usability) are prevalent and offer insights that can shape developers{\&}{\#}x0027; perception and decisions related to software development. Motivated by the finding, we built a suite of techniques to automatically mine and categorize opinions about APIs from forum posts. First, we detect opinionated sentences in the forum posts. Second, we associate the opinionated sentences to the API mentions. Third, we detect API aspects (e.g., performance, usability) in the reviews. We developed and deployed a tool called Opiner, supporting the above techniques. Opiner is available online as a search engine, where developers can search for APIs by their names to see all the aggregated opinions about the APIs that are automatically mined and summarized from developer forums.},
author = {Uddin, Gias and Khomh, Foutse},
doi = {10.1109/TSE.2019.2900245},
issn = {1939-3520},
journal = {IEEE Transactions on Software Engineering},
keywords = {API,API Aspect,API Review Mining,Benchmark testing,Categorization,Data mining,InPress,Java,Opinion,Review,Search engines,Tools,Usability},
mendeley-tags = {InPress},
month = {feb},
number = {99},
title = {{Automatic Mining of Opinions Expressed About APIs in Stack Overflow}},
year = {2019}
}
@phdthesis{Kim:2015vo,
author = {Kim, Been},
school = {Massachusetts Institute of Technology},
title = {{Interactive and Interpretable Machine Learning Models for Human Machine Collaboration}},
year = {2015}
}
@article{Maalej2013,
abstract = {Reading reference documentation is an important part of programming with application programming interfaces (APIs). Reference documentation complements the API by providing information not obvious from the API syntax. To improve the quality of reference documentation and the efficiency with which the relevant information it contains can be accessed, we must first understand its content. We report on a study of the nature and organization of knowledge contained in the reference documentation of the hundreds of APIs provided as a part of two major technology platforms: Java SDK 6 and.NET 4.0. Our study involved the development of a taxonomy of knowledge types based on grounded methods and independent empirical validation. Seventeen trained coders used the taxonomy to rate a total of 5,574 randomly sampled documentation units to assess the knowledge they contain. Our results provide a comprehensive perspective on the patterns of knowledge in API documentation: observations about the types of knowledge it contains and how this knowledge is distributed throughout the documentation. The taxonomy and patterns of knowledge we present in this paper can be used to help practitioners evaluate the content of their API documentation, better organize their documentation, and limit the amount of low-value content. They also provide a vocabulary that can help structure and facilitate discussions about the content of APIs. {\textcopyright}1976-2012 IEEE.},
author = {Maalej, Walid and Robillard, Martin P},
doi = {10.1109/TSE.2013.12},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {.NET,API documentation,Java,content analysis,data mining,empirical study,grounded method,pattern mining,software documentation},
title = {{Patterns of knowledge in API reference documentation}},
year = {2013}
}
@inproceedings{tu2000evolution,
abstract = {Most studies of software evolution have been performed on systems developed within a single company using traditional management techniques. With the widespread availability of several large software systems that have been developed using an 'open source' development approach, we now have a chance to examine these systems in detail, and see if their evolutionary narratives are significantly different from commercially developed systems. This paper summarizes our preliminary investigations into the evolution of the best known open source system: the Linux operating system kernel. Because Linux is large (over two million lines of code in the most recent version) and because its development model is not as tightly planned and managed as most industrial software processes, we had expected to find that Linux was growing more slowly as it got bigger and more complex. Instead, we have found that Linux has been growing at a super-linear rate for several years. In this paper, we explore the evolution of the Linux kernel both at the system level and within the major subsystems, and we discuss why we think Linux continues to exhibit such strong growth.},
address = {San Jose, CA, USA},
author = {Godfrey, Michael W and Tu, Qiang},
booktitle = {Conference on Software Maintenance},
doi = {10.1109/icsm.2000.883030},
month = {aug},
organization = {IEEE},
pages = {131--142},
title = {{Evolution in open source software: a case study}},
year = {2000}
}
@misc{Mandel:2008ww,
annote = {Accessed: 28 August 2018},
author = {Mandel, Lawrence},
month = {may},
title = {{Describe REST Web services with WSDL 2.0}},
url = {https://ibm.co/313RoNV},
year = {2008}
}
@article{Subramanian:1992ue,
author = {Subramanian, Girish H and Nosek, John and Raghunathan, Sankaran P and Kanitkar, Santosh S},
doi = {10.1145/129617.129621},
issn = {1557-7317},
journal = {Communications of the ACM},
keywords = {computer games,decision aids effectiveness,effectiveness of structured tools,human aspects of computing,human factors of experimentation},
number = {1},
pages = {89--94},
title = {{A comparison of the decision table and tree}},
volume = {35},
year = {1992}
}
@article{Davison:2004wo,
abstract = {Despite the growing prominence of canonical action research (CAR) in the information systems discipline, a paucity of methodological guidance continues to hamper those conducting and evaluating such studies. This article elicits a set of five principles and associated criteria to help assure both the rigor and the relevance of CAR in information systems. The first principle relates to the development of an agreement that facilitates collaboration between the action researcher and the client. The second principle is based upon a cyclical process model for action research that consists of five stages: diagnosis, planning, intervention, evaluation and reflection. Additional principles highlight the critical roles of theory, change through action, and the specification of learning in terms of implications for both research and practice. The five principles are illustrated through the analysis of one recently published CAR study.},
author = {Davison, Robert M and Martinsons, Maris G and Kock, Ned},
doi = {10.1111/j.1365-2575.2004.00162.x},
issn = {1350-1917},
journal = {Information Systems Journal},
keywords = {Canonical action research,Interpretivism,Meta-analysis,Organizational change,Organizational learning,Research frameworks},
number = {1},
pages = {65--86},
title = {{Principles of canonical action research}},
volume = {14},
year = {2004}
}
@article{Gebru:2018wh,
abstract = {Currently there is no standard way to identify how a dataset was created, and what characteristics, motivations, and potential skews it represents. To begin to address this issue, we propose the concept of a datasheet for datasets, a short document to accompany public datasets, commercial APIs, and pretrained models. The goal of this proposal is to enable better communication between dataset creators and users, and help the AI community move toward greater transparency and accountability. By analogy, in computer hardware, it has become industry standard to accompany everything from the simplest components (e.g., resistors), to the most complex microprocessor chips, with datasheets detailing standard operating characteristics, test results, recommended usage, and other information. We outline some of the questions a datasheet for datasets should answer. These questions focus on when, where, and how the training data was gathered, its recommended use cases, and, in the case of human-centric datasets, information regarding the subjects' demographics and consent as applicable. We develop prototypes of datasheets for two well-known datasets: Labeled Faces in The Wild and the Pang {\$}\backslashbackslashbackslash{\{}\backslash{\{}{\}}\backslashbackslash{\{}\backslash{\$}{\}}{\{}$\backslash${\}}{\}}{\&} Lee Polarity Dataset.},
archivePrefix = {arXiv},
arxivId = {1803.09010},
author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Daume{\'{e}}, Hal and Crawford, Kate},
eprint = {1803.09010},
howpublished = {$\backslash$url{\{}http://arxiv.org/abs/1803.09010{\}}},
journal = {arXiv preprint arXiv:1803.09010},
pages = {1--17},
title = {{Datasheets for Datasets}},
year = {2018}
}
@webpage{Draper:vb,
abstract = {"." Retrieved},
address = {Glasgow, Scotland, UK},
author = {Draper, Stephen W},
booktitle = {University of Glasgow},
howpublished = {$\backslash$url{\{}http://bit.ly/2uO2Kth{\}}},
pages = {4},
publisher = {University of Glasgow},
title = {{The Hawthorne, Pygmalion, Placebo and other effects of expectation: some notes}},
year = {2006}
}
@article{Oreskes:1994gn,
abstract = {Verification and validation of numerical models of natural systems is impossible. This is because natural systems are never closed and because model results are always non-unique. Models can be confirmed by the demonstration of agreement between observation and prediction, but confirmation is inherently partial. Complete confirmation is logically precluded by the fallacy of affirming the consequent and by incomplete access to natural phenomena. Models can only be evaluated in relative terms, and their predictive value is always open to question. The primary value of models is heuristic.},
author = {Oreskes, Naomi and Shrader-Frechette, Kristin and Belitz, Kenneth},
doi = {10.1126/science.263.5147.641},
issn = {0036-8075},
journal = {Science},
number = {5147},
pages = {641--646},
title = {{Verification, validation, and confirmation of numerical models in the earth sciences}},
volume = {263},
year = {1994}
}
@article{Aalst:2015gv,
abstract = {As more and more companies are embracing Big data, it has become apparent that the ultimate challenge is to relate massive amounts of event data to processes that are highly dynamic. To unleash the value of event data, events need to be tightly connected to the control and management of operational processes. However, the primary focus of Big data technologies is currently on storage, processing, and rather simple analytical tasks. Big data initiatives rarely focus on the improvement of end-to-end processes. To address this mismatch, we advocate a better integration of data science, data technology and process science. Data science approaches tend to be process agonistic whereas process science approaches tend to be model-driven without considering the 'evidence' hidden in the data. Process mining aims to bridge this gap. This editorial discusses the interplay between data science and process science and relates process mining to Big data technologies, service orientation, and cloud computing.},
author = {{Van Der Aalst}, Wil and Damiani, Ernesto},
doi = {10.1109/TSC.2015.2493732},
issn = {1939-1374},
journal = {IEEE Transactions on Services Computing},
keywords = {Big Data,Cloud Computing,Data Science,Process Mining,Process Science,Service Orientation},
month = {nov},
number = {6},
pages = {810--819},
title = {{Processes Meet Big Data: Connecting Data Science with Process Science}},
volume = {8},
year = {2015}
}
@article{Augasta:2012wx,
abstract = {Artificial neural networks often achieve high classification accuracy rates, but they are considered as black boxes due to their lack of explanation capability. This paper proposes the new rule extraction algorithm RxREN to overcome this drawback. In pedagogical approach the proposed algorithm extracts the rules from trained neural networks for datasets with mixed mode attributes. The algorithm relies on reverse engineering technique to prune the insignificant input neurons and to discover the technological principles of each significant input neuron of neural network in classification. The novelty of this algorithm lies in the simplicity of the extracted rules and conditions in rule are involving both discrete and continuous mode of attributes. Experimentation using six different real datasets namely iris, wbc, hepatitis, pid, ionosphere and creditg show that the proposed algorithm is quite efficient in extracting smallest set of rules with high classification accuracy than those generated by other neural network rule extraction methods. {\textcopyright}Springer Science+Business Media, LLC. 2011.},
author = {{Gethsiyal Augasta}, M and Kathirvalavakumar, T},
doi = {10.1007/s11063-011-9207-8},
issn = {1370-4621},
journal = {Neural Processing Letters},
keywords = {Classification,Neural networks,Pedagogical,Pruning,Reverse engineering,Rule extraction},
number = {2},
pages = {131--150},
title = {{Reverse engineering the neural networks for rule extraction in classification problems}},
volume = {35},
year = {2012}
}
@book{Meltzoff:1998wg,
abstract = {Could the research you read be fundamentally flawed? Could crucial effects in methodology slip by you undetected? To become an informed, interactive consumer of research, you may need an attitude adjustment: from acceptance to inquiry, from reverence to skepticism. Critical Thinking About Research: Psychology and Related Fields equips you with those tools needed to identify errors in others' research and to reduce them to a minimum in your own work. (PsycINFO Database Record (c) 2019 APA, all rights reserved) (Source: publicity materials)},
author = {Meltzoff, Julian and Cooper, Harris},
doi = {10.1037/0000052-000},
edition = {2nd},
publisher = {American psychological association},
title = {{Critical thinking about research: Psychology and related fields}},
year = {2018}
}
@inproceedings{Barnett:2015ec,
abstract = {Quality attributes are essential in software architecture and they are determined by identifying the concerns of the stakeholders of a system. The concerns of constructing mobile applications (apps) are quite specific due to the characteristics of mobile devices. These concerns have not been adequately addressed in industry standards and practices. In this paper, we present a mobile app development conceptual model comprising six key concepts that impact quality. Using two case studies, we show that these interrelated concepts influence the architectural decisions of mobile apps and their tradeoffs need to be well considered. As such, we suggest that these concepts should be first class entities when designing mobile app architecture to ensure that the quality attributes are satisfied.},
address = {Montreal, QC, Canada},
author = {Barnett, Scott and Vasa, Rajesh and Tang, Antony},
booktitle = {Proceedings of the 12th Working IEEE/IFIP Conference on Software Architecture},
doi = {10.1109/WICSA.2015.28},
isbn = {978-1-47-991922-2},
keywords = {Mobile Software Architecture,Quality Model},
month = {may},
pages = {105--114},
publisher = {IEEE},
title = {{A Conceptual Model for Architecting Mobile Applications}},
year = {2015}
}
@inproceedings{Pezzementi:2018tq,
abstract = {We introduce a method to evaluate the robustness of perception systems to the wide variety of conditions that a deployed system will encounter. Using person detection as a sample safety-critical application, we evaluate the robustness of several state-of-the-art perception systems to a variety of common image perturbations and degradations. We introduce two novel image perturbations that use 'contextual information' (in the form of stereo image data) to perform more physically-realistic simulation of haze and defocus effects. For both standard and contextual mutations, we show cases where performance drops catastrophically in response to barely-perceptible changes. We also show how robustness to contextual mutators can be predicted without the associated contextual information in some cases.},
address = {Philadelphia, PA, USA},
author = {Pezzementi, Zachary and Tabor, Trenton and Yim, Samuel and Chang, Jonathan K and Drozd, Bill and Guttendorf, David and Wagner, Michael and Koopman, Philip},
booktitle = {Proceedings of the 15th IEEE International Symposium on Safety, Security, and Rescue Robotics},
doi = {10.1109/SSRR.2018.8468619},
isbn = {978-1-53-865572-6},
month = {aug},
pages = {1--8},
publisher = {IEEE},
title = {{Putting Image Manipulations in Context: Robustness Testing for Safe Perception}},
year = {2018}
}
@book{Quinlan:1993vi,
address = {San Francisco, CA, USA},
author = {Quinlan, J Ross},
isbn = {978-1-55-860238-0},
publisher = {Morgan Kauffmann},
title = {{C4.5: Programs for machine learning}},
year = {1993}
}
@article{DBLP:journals/corr/abs-1907-04135,
abstract = {A key challenge in developing and deploying Machine Learning (ML) systems is understanding their performance across a wide range of inputs. To address this challenge, we created the What-If Tool, an open-source application that allows practitioners to probe, visualize, and analyze ML systems, with minimal coding. The What-If Tool lets practitioners test performance in hypothetical situations, analyze the importance of different data features, and visualize model behavior across multiple models and subsets of input data. It also lets practitioners measure systems according to multiple ML fairness metrics. We describe the design of the tool, and report on real-life usage at different organizations.},
archivePrefix = {arXiv},
arxivId = {1907.04135},
author = {Wexler, James and Pushkarna, Mahima and Bolukbasi, Tolga and Wattenberg, Martin and Viegas, Fernanda and Wilson, Jimbo},
doi = {10.1109/tvcg.2019.2934619},
eprint = {1907.04135},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
pages = {1},
title = {{The What-If Tool: Interactive Probing of Machine Learning Models}},
volume = {abs/1907.04135},
year = {2019}
}
@inproceedings{Quinlan:1999ue,
address = {Bled, Slovenia},
author = {Quinlan, J R},
booktitle = {Proceedings of the 9th International Workshop on Inductive Logic Programming},
doi = {10.1007/3-540-48751-4_3},
isbn = {3-54-066109-3},
issn = {1611-3349},
month = {jun},
pages = {15--18},
publisher = {Springer},
title = {{Some elements of machine learning}},
volume = {1634},
year = {1999}
}
@webpage{McGowen:2019vt,
author = {McGowen, Bret},
howpublished = {$\backslash$url{\{}http://bit.ly/3aUQpo2{\}}},
month = {jan},
title = {{Machine learning with Google APIs}},
year = {2019}
}
@phdthesis{Barnett:2018Kx,
address = {Hawthorn, Australia},
author = {Barnett, Scott},
school = {Swinburne University of Technology},
title = {{Extracting technical domain knowledge to improve software architecture}},
year = {2018}
}
@article{Glass:2002wa,
abstract = {This article is a background report describing a comprehensive study of research in the three computing disciplines Computer Science, Software Engineering, and Information Systems. Findings relate to research topics, approaches, methods, reference disciplines, and levels of analysis. The article informally describes the process used and the research products produced. {\textcopyright}2008 Elsevier B.V. All rights reserved.},
author = {Glass, Robert L and Vessey, Iris and Ramesh, V},
doi = {10.1016/j.infsof.2008.09.015},
issn = {0950-5849},
journal = {Information and Software Technology},
keywords = {Computing research,Literature search,Research taxonomy},
number = {1},
pages = {68--70},
title = {{RESRES: The story behind the paper "Research in software engineering: An analysis of the literature"}},
volume = {51},
year = {2009}
}
@book{Krippendorff:2018tda,
author = {Krippendorff, Klaus},
isbn = {978-1-50-639566-1},
publisher = {SAGE},
series = {An Introduction to Its Methodology},
title = {{Content Analysis}},
year = {1980}
}
@book{Litwin:1995wt,
abstract = {This Second Edition Has Been Thoroughly Revised And Updated And Efforts Have Been Made To Enhance The Usefulness Of The Book. In This Edition A New Chapter The Computer : Its Role In Research Have Been Added Keeping In View Of The Fact That Computers By Now Become A Indispensable Part Of Research Equipment. The Other Salient Feature Of This Revised Edition, Subject Contents Have Been Developed And Restructured At Several Places. New Problems Have Also Been Added In Various Chapters.Adoption Of Appropriate Methodology Is An Essential Characteristic Of Quality Research Studies Irrespective Of The Discipline With Which They Are Related. The Present Book Provides The Basic Tenets Of Methodological Research So That Researchers May Become Familiar With The Art Of Using Research Methods And Techniques.The Book Contains Introductory Explanations Of Several Quantitative Methods Enjoying Wide Use In Social Sciences. It Covers A Fairly Wide Range, Related To Research Methodology. The Presentations Are Uniformly Economical And Cogent. Illustrations Given Are Meaningful And Relevant. The Book Can Be Taken As A Well-Organised Guide For Researchers Whose Methodological Background Is Not Extensive.The Book Is Primarily Intended To Serve As A Textbook For Social Science Students Of All Indian Universities. It Will Also Serve As A Text For The Students Of M.Phil, Management, And Students Of Various Institutes. It Will Serve All Practitioners Doing Research Of One Form Or Other In A General Way.},
author = {Litwin, Mark},
doi = {10.4135/9781483348957},
publisher = {SAGE},
title = {{How to Measure Survey Reliability and Validity}},
volume = {7},
year = {1995}
}
@article{Niemeyer2008240,
author = {Niemeyer, Horst F and Niemeyer, Alice C},
issn = {0165-4896},
journal = {Mathematical Social Sciences},
keywords = { Sainte-Lagu{\"{e}} method,Alabama Paradox,Apportionment method,D'Hondt method,Hare/Hamilton method},
number = {2},
pages = {240--253},
title = {{Apportionment methods}},
volume = {56},
year = {2008}
}
@article{Karwath:2002tv,
abstract = {Background: The inference of homology between proteins is a key problem in molecular biology The current best approaches only identify ∼50{\%} of homologies (with a false positive rate set at 1/1000). Results: We present Homology Induction (HI), a new approach to inferring homology. HI uses machine learning to bootstrap from standard sequence similarity search methods. First a standard method is run, then HI learns rules which are true for sequences of high similarity to the target (assumed homologues) and not true for general sequences, these rules are then used to discriminate sequences in the twilight zone. To learn the rules HI describes the sequences in a novel way based on a bioinformatic knowledge base, and the machine learning method of inductive logic programming. To evaluate HI we used the PDB40D benchmark which lists sequences of known homology but low sequence similarity. We compared the HI methodoly with PSI-BLAST alone and found HI performed significantly better. In addition, Receiver Operating Characteristic (ROC) curve analysis showed that these improvements were robust for all reasonable error costs. The predictive homology rules learnt by HI by can be interpreted biologically to provide insight into conserved features of homologous protein families. Conclusions: HI is a new technique for the detection of remote protein homolgy - a central bioinformatic problem. HI with PSI-BLAST is shown to outperform PSI-BLAST for all error costs. It is expect that similar improvements would be obtained using HI with any sequence similarity method. {\textcopyright}2002 Karwath and King; licensee BioMed Central Ltd.},
author = {Karwath, Andreas and King, Ross D},
doi = {10.1186/1471-2105-3-11},
issn = {1471-2105},
journal = {BMC Bioinformatics},
number = {1},
pages = {11},
title = {{Homology induction: The use of machine learning to improve sequence similarity searches}},
volume = {3},
year = {2002}
}
@article{Brereton:2007by,
abstract = {A consequence of the growing number of empirical studies in software engineering is the need to adopt systematic approaches to assessing and aggregating research outcomes in order to provide a balanced and objective summary of research evidence for a particular topic. The paper reports experiences with applying one such approach, the practice of systematic literature review, to the published studies relevant to topics within the software engineering domain. The systematic literature review process is summarised, a number of reviews being undertaken by the authors and others are described and some lessons about the applicability of this practice to software engineering are extracted. The basic systematic literature review process seems appropriate to software engineering and the preparation and validation of a review protocol in advance of a review activity is especially valuable. The paper highlights areas where some adaptation of the process to accommodate the domain-specific characteristics of software engineering is needed as well as areas where improvements to current software engineering infrastructure and practices would enhance its applicability. In particular, infrastructure support provided by software engineering indexing databases is inadequate. Also, the quality of abstracts is poor; it is usually not possible to judge the relevance of a study from a review of the abstract alone. {\textcopyright}2006 Elsevier Inc. All rights reserved.},
author = {Brereton, Pearl and Kitchenham, Barbara A and Budgen, David and Turner, Mark and Khalil, Mohamed},
doi = {10.1016/j.jss.2006.07.009},
issn = {0164-1212},
journal = {Journal of Systems and Software},
keywords = {Empirical software engineering,Systematic literature review},
month = {apr},
number = {4},
pages = {571--583},
title = {{Lessons from applying the systematic literature review process within the software engineering domain}},
volume = {80},
year = {2007}
}
@article{Biggs:2014ur,
abstract = {Incluye bibliograf{\'{i}}a e {\'{i}}ndice},
author = {Biggs, J and Collis, K},
doi = {10.1177/089202068700100412},
isbn = {0-12-097551-1},
issn = {0892-0206},
journal = {Management in Education},
number = {4},
pages = {20},
title = {{Evaluating the Quality of Learning: The SOLO Taxonomy (Structure of the Observed Learning Outcome)}},
volume = {1},
year = {1987}
}
@inproceedings{Kitchenham:2004vj,
address = {Edinburgh, UK},
author = {Kitchenham, Barbara A and Dyb{\aa}, Tore and Jorgensen, Magne},
booktitle = {Proceedings of the 26th International Conference on Software Engineering},
isbn = {978-0-76-952163-3},
month = {may},
pages = {273--281},
publisher = {IEEE},
title = {{Evidence-Based Software Engineering}},
year = {2004}
}
@incollection{Jick:1979el,
abstract = {This article describes and discusses issues related to research design and data analysis in the mixing of qualitative and quantitative methods. It is increasingly desirable to use multiple methods in research, but questions arise as to how best to design and analyze the data generated by mixed methods projects. I offer a conceptualization for such design, discuss issues of sampling, and describe a strategy for processing qualitative data in ways that allow for more sophisticated and dynamic integration with quantita- tive data. Finally, drawing on data from previous research, I describe tools and strategies for this dynamic data integration and illustrate how effective strategy and use of tools allow for more efficient and sophisticated analysis, interpretation, and presentation.},
author = {Mayring, Philipp},
booktitle = {Mixed Methodology in Psychological Research},
chapter = {6},
doi = {10.1163/9789087903503_007},
pages = {27--36},
publisher = {Brill},
title = {{Mixing Qualitative and Quantitative Methods}},
year = {2007}
}
@book{Yin:2017tf,
address = {Los Angeles, CA, USA},
author = {Yin, Robert K},
edition = {6th},
isbn = {978-1-50-633616-9},
publisher = {SAGE publications},
title = {{Case study research and applications: Design and methods}},
year = {2017}
}
@article{Rosenfeld:2018ut,
archivePrefix = {arXiv},
arxivId = {1808.03305},
author = {Rosenfeld, Amir and Zemel, Richard and Tsotsos, John K},
eprint = {1808.03305},
journal = {arXiv preprint arXiv:1808.03305},
title = {{The elephant in the room}},
year = {2018}
}
@article{Craven:1995wg,
abstract = {A significant limitation of neural networks is that the representations they learn are usually incomprehensible to humans. We present a novel algorithm, Trepan, for extracting comprehensible, symbolic representations from trained neural networks. Our algorithm uses queries to induce a decision tree that approximates the concept represented by a given network. Our experiments demonstrate that Trepan is able to produce decision trees that maintain a high level of fidelity to their respective...},
address = {Denver, CO, USA},
author = {Craven, Mark W and Shavlik, Jude W},
isbn = {978-0-26-220107-0},
journal = {Proceedings of the 8th International Conference on Neural Information Processing Systems},
month = {dec},
pages = {24--30},
publisher = {MIT Press},
title = {{Extracting tree-structured representations of trained neural networks}},
volume = {8},
year = {1996}
}
@inproceedings{Patel:2008:ISM:1357054.1357160,
abstract = {As statistical machine learning algorithms and techniques continue to mature, many researchers and developers see statistical machine learning not only as a topic of expert study, but also as a tool for software development. Extensive prior work has studied software development, but little prior work has studied software developers applying statistical machine learning. This paper presents interviews of eleven researchers experienced in applying statistical machine learning algorithms and techniques to human-computer interaction problems, as well as a study of ten participants working during a five-hour study to apply statistical machine learning algorithms and techniques to a realistic problem. We distil] three related categories of difficulties that arise in applying statistical machine learning as a tool for software development: (1) difficulty pursuing statistical machine learning as an iterative and exploratory process, (2) difficulty understanding relationships between data and the behavior of statistical machine learning algorithms, and (3) difficulty evaluating the performance of statistical machine learning algorithms and techniques in the context of applications. This paper provides important new insight into these difficulties and the need for development tools that better support the application of statistical machine learning. Copyright 2008 ACM.},
address = {Florence, Italy},
author = {Patel, Kayur and Fogarty, James and Landay, James A and Harrison, Beverly},
booktitle = {Proceedings of the 26th SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/1357054.1357160},
isbn = {978-1-60-558011-1},
keywords = {Software development,Statistical machine learning},
month = {apr},
pages = {667--676},
publisher = {ACM},
series = {CHI '08},
title = {{Investigating statistical machine learning as a tool for software development}},
year = {2008}
}
@inproceedings{Arpteg2018,
abstract = {Surprisingly promising results have been achieved by deep learning (DL) systems in recent years. Many of these achievements have been reached in academic settings, or by large technology companies with highly skilled research groups and advanced supporting infrastructure. For companies without large research groups or advanced infrastructure, building high-quality production-ready systems with DL components has proven challenging. There is a clear lack of well-functioning tools and best practices for building DL systems. It is the goal of this research to identify what the main challenges are, by applying an interpretive research approach in close collaboration with companies of varying size and type. A set of seven projects have been selected to describe the potential with this new technology and to identify associated main challenges. A set of 12 main challenges has been identified and categorized into the three areas of development, production, and organizational challenges. Furthermore, a mapping between the challenges and the projects is defined, together with selected motivating descriptions of how and why the challenges apply to specific projects. Compared to other areas such as software engineering or database technologies, it is clear that DL is still rather immature and in need of further work to facilitate development of high-quality systems. The challenges identified in this paper can be used to guide future research by the software engineering and DL communities. Together, we could enable a large number of companies to start taking advantage of the high potential of the DL technology.},
address = {Prague, Czech Republic},
archivePrefix = {arXiv},
arxivId = {1810.12034},
author = {Arpteg, Anders and Brinne, Bj{\"{o}}rn and Crnkovic-Friis, Luka and Bosch, Jan},
booktitle = {Proceedings of the 44th Euromicro Conference on Software Engineering and Advanced Applications},
doi = {10.1109/SEAA.2018.00018},
eprint = {1810.12034},
howpublished = {$\backslash$url{\{}https://ieeexplore.ieee.org/document/8498185/{\}}},
isbn = {978-1-53-867382-9},
keywords = {Artificial intelligence,Deep learning,Machine learning,Software engineering challenges},
month = {aug},
pages = {50--59},
publisher = {IEEE},
title = {{Software engineering challenges of deep learning}},
year = {2018}
}
@misc{Cigital:2003tl,
author = {Cigital},
howpublished = {$\backslash$url{\{}http://goo.gl/OQlyNi{\}}},
title = {{Case Study: Finding defects earlier yields enormous savings}},
year = {2003}
}
@inproceedings{Ribeiro:2015dz,
abstract = {The demand for knowledge extraction has been increasing. With the growing amount of data being generated by global data sources (e.g., social media and mobile apps) and the popularization of context-specific data (e.g., the Internet of Things), companies and researchers need to connect all these data and extract valuable information. Machine learning has been gaining much attention in data mining, leveraging the birth of new solutions. This paper proposes an architecture to create a flexible and scalable machine learning as a service. An open source solution was implemented and presented. As a case study, a forecast of electricity demand was generated using real-world sensor and weather data by running different algorithms at the same time.},
address = {Miami, FL, USA},
author = {Ribeiro, Mauro and Grolinger, Katarina and Capretz, Miriam A M},
booktitle = {Proceedings of the 14th International Conference on Machine Learning and Applications},
doi = {10.1109/ICMLA.2015.152},
isbn = {978-1-50-900287-0},
keywords = {Machine learning as a service,Platform as a service,Prediction,Regression,Service component architecture,Service oriented architecture,Supervised learning},
month = {dec},
pages = {896--902},
publisher = {IEEE},
title = {{MLaaS: Machine learning as a service}},
year = {2015}
}
@article{AlQutaish:2010vua,
abstract = {The quality of the software is critical and essential in different types of organizations. In some types of software, poor quality of the software product in sensitive systems (such as: real-time systems, control systems, etc.) may lead to loss of human life, permanent injury, mission failure, or financial loss. In software engineering literature, there are a number of quality models in which they contain a number of quality characteristics (or factors, as called in some models). These quality characteristics could be used to reflect the quality of the software product from the view of that characteristic. Selecting which one of the quality models to use is a real challenge. In this paper, we will discuss the contents of the following quality models: McCall's quality model, Boehm's quality model, Dromey's quality model, FURPS quality model and ISO 9126 quality model. In addition, we will focus on a comparison between these quality models, and find the key differences between them. [Journal},
author = {Al-Qutaish, Rafa E},
journal = {Journal of American Science},
keywords = {Boehm's Quality Model,Dromey's Quality Model,FURPS Quality Model,ISO 9126,McCall's Quality Model,Quality Engineering,Quality Models,Software Quality},
number = {3},
pages = {166--175},
title = {{Quality Models in Software Engineering Literature: An Analytical and Comparative Study}},
volume = {6},
year = {2010}
}
@inproceedings{Parekh:2017hx,
address = {Halifax, NS, Canada},
author = {Parekh, Rajesh},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/3097983.3105815},
month = {aug},
pages = {27},
publisher = {ACM},
title = {{Designing AI at Scale to Power Everyday Life}},
year = {2017}
}
@article{Myers:2011bt,
abstract = {All software today is written using application programming interfaces (APIs). We performed a user study of the online documentation of a large and complex API for Enterprise Service-Oriented Architecture (eSOA), which identified many issues and recommendations for making API documentation easier to use. eSOA is an appropriate testbed because the target users include high-level business experts who do not have significant programming expertise and thus can be classified as “end-user developers.” Our study showed that the participants' background influenced how they navigated the documentation. Lack of familiarity with business terminology was a barrier for developers without business application experience. Both groups avoided areas of the documentation that had an inconsistent visual design. A new design for the documentation that supports flexible navigation strategies seems to be required to support the wide range of users for eSOA. This paper summarizes our study and provides recommendations for future documentation for APIs.},
author = {Myers, Brad A and Jeong, Sae Young and Xie, Yingyu and Beaton, Jack and Stylos, Jeff and Ehret, Ralf and Karstens, Jan and Efeoglu, Arkin and Busse, Daniela K},
doi = {10.4018/joeuc.2010101903},
issn = {1546-2234},
journal = {Journal of Organizational and End User Computing},
keywords = {Api design,Business solution architects,Documentation,Natural programming,Service-oriented architecture,Usability,Web services},
month = {jan},
number = {1},
pages = {23--51},
publisher = {IGI Global},
title = {{Studying the Documentation of an API for Enterprise Service-Oriented Architecture}},
volume = {22},
year = {2010}
}
@article{Barzilay:2013cn,
abstract = {The open source community, as well as numerous technical blogs and community web sites, put online vast quantities of free source code, ranging from snippets to full-blown products. This code embodies the software development community's domain knowledge, and mirrors the structure of the Internet: it is distributed rather than hierarchical; it is chaotic, incomplete, and inconsistent. StackOverflow.com is a Question and Answer (Q{\&}A) website which uses social media to facilitate knowledge exchange between programmers by mitigating the pitfalls involved in using code from the Internet. Its design nurtures a community of developers, and enables crowd sourced software engineering activities ranging from documentation to providing useful, high quality code snippets to be used in production. In this chapter we review Stack Overflow from three perspectives: (1) its design and its social media characteristics, (2) the role it plays in the software documentation landscape, and (3) the use of Stack Overflow in the context of the example centric programming paradigm.},
author = {Barzilay, Ohad and Treude, Christoph and Zagalsky, Alexey},
doi = {10.1007/978-1-4614-6596-6_15},
isbn = {978-1-46-146596-6},
journal = {Finding Source Code on the Web for Remix and Reuse},
number = {4},
pages = {289--308},
title = {{Facilitating crowd sourced software engineering via stack overflow}},
volume = {9781461465966},
year = {2014}
}
@article{Lethbridge:2005jv,
abstract = {Software engineering is an intensively people-oriented activity, yet too little is known about how designers, maintainers, requirements analysts and all other types of software engineers perform their work. In order to improve software engineering tools and practice, it is therefore essential to conduct field studies, i.e. to study real practitioners as they solve real problems. To do so effectively, however, requires an understanding of the techniques most suited to each type of field study task. In this paper, we provide a taxonomy of techniques, focusing on those for data collection. The taxonomy is organized according to the degree of human intervention each requires. For each technique, we provide examples from the literature, an analysis of some of its advantages and disadvantages, and a discussion of how to use it effectively. We also briefly talk about field study design in general, and data analysis. {\textcopyright}2005 Springer Science + Business Media, Inc.},
author = {Lethbridge, Timothy C and Sim, Susan Elliott and Singer, Janice},
doi = {10.1007/s10664-005-1290-x},
issn = {1382-3256},
journal = {Empirical Software Engineering},
keywords = {Empirical software engineering,Field studies,Work practices},
month = {jul},
number = {3},
pages = {311--341},
title = {{Studying software engineers: Data collection techniques for software field studies}},
volume = {10},
year = {2005}
}
@book{Creswell:2017vn,
author = {Creswell, John W},
edition = {4th},
isbn = {860-1-40-429618-5},
publisher = {SAGE},
title = {{Research design: Qualitative, quantitative, and mixed methods approaches}},
year = {2017}
}
@article{Nykaza:2002td,
abstract = {This paper steps the reader through a needs assessment of programmers that was conducted by instructional designers. The assessment's purpose was to identify what learning support programmers need and want to successfully use a new software development kit (SDK). The paper includes the challenges the researchers encountered, the questions asked and the responses, the types of individuals interviewed, and the conclusions reached from the research. Recommendations also are presented. Those responsible with developing documentation, training, and other learning support systems for programmers may find this assessment helpful. Marketing, product development and customer support people may also find value in learning more about the needs of this unique audience.},
address = {Toronto, ON, Canada},
author = {Nykaza, Janet and Messinger, Rhonda and Boehme, Fran and Norman, Cherie L and Mace, Matthew and Gordon, Manuel},
doi = {10.1145/584955.584976},
journal = {Proceedings of the 20th annual International Conference on Computer Documentation},
keywords = {API documentation,Developer documentation,Needs analysis,Needs assessment,Programmer documentation,SDK documentation},
month = {oct},
pages = {133--141},
publisher = {ACM},
title = {{What programmers really want: Results of a needs assessment for SDK documentation}},
year = {2002}
}
@article{Robinson:2007tp,
abstract = {Over the past decade we have performed a sustained series of qualitative studies of software development practice, focusing on social factors. Using an ethnographically-informed approach, we have addressed four areas of software practice: software quality management systems, the emergence of object technology, professional end user development and agile development. Several issues have arisen from this experience, including the nature of research questions that such studies can address, the advantages and challenges associated with being a member of the community under study, and how to maintain rigour in data collection. In this paper, we will draw on our studies to illustrate our approach and to discuss these and other issues. {\textcopyright}2007 Elsevier B.V. All rights reserved.},
author = {Robinson, Hugh and Segal, Judith and Sharp, Helen},
doi = {10.1016/j.infsof.2007.02.007},
issn = {0950-5849},
journal = {Information and Software Technology},
keywords = {Field studies,Qualitative analysis,Software practice},
number = {6},
pages = {540--551},
title = {{Ethnographically-informed empirical studies of software practice}},
volume = {49},
year = {2007}
}
@incollection{Kitchenham:2007ux,
author = {Kitchenham, Barbara A and Pfleeger, Shari L},
booktitle = {Guide to Advanced Empirical Software Engineering},
chapter = {3},
month = {nov},
pages = {63--92},
publisher = {Springer Science {\&} Business Media},
title = {{Personal opinion surveys}},
year = {2007}
}
@inproceedings{Ortiz:2017wg,
author = {Ortiz, Andres L Martinez},
booktitle = {EIAPortugal},
howpublished = {$\backslash$url{\{}http://bit.ly/2S40er8{\}}},
month = {jul},
title = {{Curating Content with Google Machine Learning Application Programming Interfaces}},
year = {2017}
}
@phdthesis{Nelson:1981ue,
author = {Nelson, Bruce Jay},
school = {Carnegie Mellon University},
title = {{Remote Procedure Call}},
year = {1981}
}
@book{Krathwohl:2001wr,
author = {Bloom, Benjamin Samuel},
edition = {2nd},
isbn = {978-0-58-228010-6},
publisher = {Addison-Wesley Longman},
title = {{Taxonomy of Educational Objectives, Handbook 1: Cognitive Domain}},
year = {1956}
}
@article{Hayete:2005tn,
abstract = {The Gene Ontology (GO) offers a comprehensive and standardized way to describe a protein's biological role. Proteins are annotated with GO terms based on direct or indirect experimental evidence. Term assignments are also inferred from homology and literature mining. Regardless of the type of evidence used, GO assignments are manually curated or electronic. Unfortunately, manual curation cannot keep pace with the data, available from publications and various large experimental datasets. Automated literature-based annotation methods have been developed in order to speed up the annotation. However, they only apply to proteins that have been experimentally investigated or have close homologs with sufficient and consistent annotation. One of the homology-based electronic methods for GO annotation is provided by the InterPro database. The InterPro2GO/PFAM2GO associates individual protein domains with GO terms and thus can be used to annotate the less studied proteins. However, protein classification via a single functional domain demands stringency to avoid large number of false positives. This work broadens the basic approach. We model proteins via their entire functional domain content and train individual decision tree classifiers for each GO term using known protein assignments. We demonstrate that our approach is sensitive, specific and precise, as well as fairly robust to sparse data. We have found that our method is more sensitive when compared to the InterPro2GO performance and suffers only some precision decrease. In comparison to the InterPro2GO we have improved the sensitivity by 22{\%}, 27{\%} and 50{\%} for Molecular Function, Biological Process and Cellular GO terms respectively.},
address = {Hawaii, USA},
author = {Hayete, Boris and Bienkowska, Jadwiga R},
doi = {10.1142/9789812702456_0013},
isbn = {9-81-256046-7},
journal = {Proceedings of the Pacific Symposium on Biocomputing 2005, PSB 2005},
month = {jan},
pages = {127--138},
publisher = {World Scientific Publishing Company},
title = {{Gotrees: Predicting go associations from protein domain composition using decision trees}},
year = {2005}
}
@inproceedings{Lei:2016wi,
abstract = {Prediction without justification has limited applicability. As a remedy, we learn to extract pieces of input text as justifications - rationales - that are tailored to be short and coherent, yet sufficient for making the same prediction. Our approach combines two modular components, generator and encoder, which are trained to operate well together. The generator specifies a distribution over text fragments as candidate rationales and these are passed through the encoder for prediction. Rationales are never given during training. Instead, the model is regularized by desiderata for rationales. We evaluate the approach on multi-aspect sentiment analysis against manually annotated test cases. Our approach outperforms attention-based baseline by a significant margin. We also successfully illustrate the method on the question retrieval task.},
address = {Austin, TX, USA},
archivePrefix = {arXiv},
arxivId = {1606.04155},
author = {Lei, Tao and Barzilay, Regina and Jaakkola, Tommi},
booktitle = {Proceedings of the 9th International Joint Conference on Natural Language Processing and Conference on Empirical Methods in Natural Language Processing},
doi = {10.18653/v1/d16-1011},
eprint = {1606.04155},
isbn = {978-1-94-562625-8},
month = {nov},
pages = {107--117},
publisher = {Association for Computational Linguistics},
title = {{Rationalizing neural predictions}},
year = {2016}
}
@inproceedings{myers2018patterns,
abstract = {Voice User Interfaces (VUIs) are growing in popularity. However, even the most current VUIs regularly cause frustration for their users. Very few studies exist on what people do to overcome VUI problems they encounter, or how VUIs can be designed to aid people when these problems occur. In this paper, we analyze empirical data on how users (n=12) interact with our VUI calendar system, DiscoverCal, over three sessions. In particular, we identify the main obstacle categories and types of tactics our participants employ to overcome them. We analyzed the patterns of how different tactics are used in each obstacle category. We found that while NLP Error obstacles occurred the most, other obstacles are more likely to frustrate or confuse the user. We also found patterns that suggest participants were more likely to employ a "guessing" approach rather than rely on visual AIDS or knowledge recall.},
address = {Montreal, QC, Canada},
author = {Myers, Chelsea and Furqan, Anushay and Nebolsky, Jessica and Caro, Karina and Zhu, Jichen},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3173574.3173580},
isbn = {978-1-45-035620-6},
keywords = {User experience,Voice User Interfaces,Voice control},
month = {apr},
pages = {6},
publisher = {ACM},
title = {{Patterns for how users overcome obstacles in Voice User Interfaces}},
volume = {2018-April},
year = {2018}
}
@incollection{Easterbrook:2007ws,
author = {Easterbrook, Steve and Singer, Janice and Storey, Margaret-Anne and Damian, Daniela},
booktitle = {Guide to Advanced Empirical Software Engineering},
chapter = {11},
month = {nov},
pages = {285--311},
publisher = {Springer Science {\&} Business Media},
title = {{Selecting empirical methods for software engineering research}},
year = {2007}
}
@inproceedings{Feelders:2000ve,
abstract = {A common form of prior knowledge in economic modelling concerns the monotonicity of relations between the dependent and explanatory variables. Monotonicity may also be an important requirement with a view toward explaining and justifying decisions based on such models. We explore the use of monotonicity constraints in classification tree algorithms.We present an application of monotonic classification trees to a problem in house pricing. In this preliminary study we found that the monotonic trees were only slightly worse in classification performance, but were much simpler than their non-monotonic counterparts.},
address = {Lyon, France},
author = {Feelders, A J},
booktitle = {Proceedings of the 4th European Conference on Principles of Data Mining and Knowledge Discovery},
doi = {10.1007/3-540-45372-5_42},
isbn = {978-3-54-041066-9},
issn = {1611-3349},
month = {sep},
pages = {395--400},
publisher = {Springer},
title = {{Prior knowledge in economic applications of data mining}},
volume = {1910},
year = {2000}
}
@misc{InternationalOrganizationforStandardization1999,
author = {{International Organization for Standardization}},
month = {nov},
title = {{ISO/IEC 9126 Information Technology - Software Product Evaluation - Quality Characteristics and Guidelines for Their Use}},
url = {http://bit.ly/2tgMHUE},
year = {1999}
}
@inproceedings{Eykholt:2018vk,
abstract = {Recent studies show that the state-of-the-art deep neural networks (DNNs) are vulnerable to adversarial examples, resulting from small-magnitude perturbations added to the input. Given that that emerging physical systems are using DNNs in safety-critical situations, adversarial examples could mislead these systems and cause dangerous situations. Therefore, understanding adversarial examples in the physical world is an important step towards developing resilient learning algorithms. We propose a general attack algorithm, Robust Physical Perturbations (RP2), to generate robust visual adversarial perturbations under different physical conditions. Using the real-world case of road sign classification, we show that adversarial examples generated using RP2 achieve high targeted misclassification rates against standard-architecture road sign classifiers in the physical world under various environmental conditions, including viewpoints. Due to the current lack of a standardized testing method, we propose a two-stage evaluation methodology for robust physical adversarial examples consisting of lab and field tests. Using this methodology, we evaluate the efficacy of physical adversarial manipulations on real objects. With a perturbation in the form of only black and white stickers, we attack a real stop sign, causing targeted misclassification in 100{\%} of the images obtained in lab settings, and in 84.8{\%} of the captured video frames obtained on a moving vehicle (field test) for the target classifier.},
address = {Honolulu, HI, USA},
author = {Eykholt, Kevin and Evtimov, Ivan and Fernandes, Earlence and Li, Bo and Rahmati, Amir and Xiao, Chaowei and Prakash, Atul and Kohno, Tadayoshi and Song, Dawn},
booktitle = {Proceedings of the 2017 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2018.00175},
isbn = {978-1-53-866420-9},
issn = {1063-6919},
month = {jul},
pages = {1625--1634},
title = {{Robust Physical-World Attacks on Deep Learning Visual Classification}},
year = {2018}
}
@article{Pearl:2018uv,
abstract = {THE DRAMATIC SUCCESS In machine learning has led to an explosion of artificial intelligence (AI) applications and increasing expectations for autonomous systems that exhibit human-level intelligence. These expectations have, however, met with fundamental obstacles that cut across many application areas. One such obstacle is adaptability, or robustness. Machine learning researchers have noted current systems lack the ability to recognize or react to new circumstances they have not been specifically programmed or trained for.},
author = {Pearl, Judea},
doi = {10.1145/3241036},
issn = {1557-7317},
journal = {Communications of the ACM},
number = {3},
pages = {54--60},
title = {{The seven tools of causal inference, with reflections on machine learning}},
volume = {62},
year = {2019}
}
@misc{ISO9126:1999,
author = {{International Organization for Standardization}},
month = {nov},
title = {{ISO/IEC 9126. Information technology -- Software product quality}},
year = {1999}
}
@inproceedings{Tahir:2018ks,
abstract = {This paper investigates how developers discuss code smells and anti-patterns over Stack Overflow to understand better their perceptions and understanding of these two concepts. Understanding developers' perceptions of these issues are important in order to inform and align future research efforts and direct tools vendors in the area of code smells and anti-patterns. In addition, such insights could lead the creation of solutions to code smells and anti-patterns that are better fit to the realities developers face in practice. We applied both quantitative and qualitative techniques to analyse discussions containing terms associated with code smells and anti-patterns. Our findings show that developers widely use Stack Overflow to ask for general assessments of code smells or anti-patterns, instead of asking for particular refactoring solutions. An interesting finding is that developers very often ask their peers 'to smell their code' (i.e., ask whether their own code 'smells' or not), and thus, utilize Stack Overflow as an informal, crowd-based code smell/anti-pattern detector. We conjecture that the crowd-based detection approach considers contextual factors, and thus, tends to be more trusted by developers over automated detection tools. We also found that developers often discuss the downsides of implementing specific design patterns, and 'flag' them as potential anti-patterns to be avoided. Conversely, we found discussions on why some anti-patterns previously considered harmful should not be flagged as anti-patterns. Our results suggest that there is a need for: 1) more context-based evaluations of code smells and anti-patterns, and 2) better guidelines for making trade-offs when applying design patterns or eliminating smells/anti-patterns in industry.},
address = {Christchurch, New Zealand},
author = {Tahir, Amjed and Yamashita, Aiko and Licorish, Sherlock and Dietrich, Jens and Counsell, Steve},
booktitle = {Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering},
doi = {10.1145/3210459.3210466},
isbn = {978-1-45-036403-4},
keywords = {Anti-patterns,Code smells,Empirical study,Mining software repositories,Stack Overflow},
month = {jun},
pages = {68--78},
publisher = {ACM},
title = {{Can you tell me if it smells? A study on how developers discuss code smells and anti-patterns in Stack Overflow}},
volume = {Part F1377},
year = {2018}
}
@inproceedings{amershi2015modeltracker,
abstract = {Model building in machine learning is an iterative process. The performance analysis and debugging step typically involves a disruptive cognitive switch from model building to error analysis, discouraging an informed approach to model building. We present Model Tracker, an interactive visualization that subsumes information contained in numerous traditional summary statistics and graphs while displaying example-level performance and enabling direct error examination and debugging. Usage analysis from machine learning practitioners building real models with Model Tracker over six months shows Model Tracker is used often and throughout model building. A controlled experiment focusing on Model Tracker's debugging capabilities shows participants prefer Model Tracker over traditional tools without a loss in model performance.},
address = {Seoul, Republic of Korea},
author = {Amershi, Saleema and Chickering, Max and Drucker, Steven M and Lee, Bongshin and Simard, Patrice and Suh, Jina},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
doi = {10.1145/2702123.2702509},
isbn = {978-1-45-033145-6},
keywords = {Debugging,Interactive visualization,Machine learning,Performance analysis},
month = {apr},
pages = {337--346},
publisher = {ACM - Association for Computing Machinery},
title = {{Modeltracker: Redesigning performance analysis tools for machine learning}},
volume = {2015-April},
year = {2015}
}
@article{Liu:2018fa,
abstract = {CONTEXT.— Nodal metastasis of a primary tumor influences therapy decisions for a variety of cancers. Histologic identification of tumor cells in lymph nodes can be laborious and error-prone, especially for small tumor foci. OBJECTIVE.— To evaluate the application and clinical implementation of a state-of-the-art deep learning-based artificial intelligence algorithm (LYmph Node Assistant or LYNA) for detection of metastatic breast cancer in sentinel lymph node biopsies. DESIGN.— Whole slide images were obtained from hematoxylin-eosin-stained lymph nodes from 399 patients (publicly available Camelyon16 challenge dataset). LYNA was developed by using 270 slides and evaluated on the remaining 129 slides. We compared the findings to those obtained from an independent laboratory (108 slides from 20 patients/86 blocks) using a different scanner to measure reproducibility. RESULTS.— LYNA achieved a slide-level area under the receiver operating characteristic (AUC) of 99{\%} and a tumor-level sensitivity of 91{\%} at 1 false positive per patient on the Camelyon16 evaluation dataset. We also identified 2 "normal" slides that contained micrometastases. When applied to our second dataset, LYNA achieved an AUC of 99.6{\%}. LYNA was not affected by common histology artifacts such as overfixation, poor staining, and air bubbles. CONCLUSIONS.— Artificial intelligence algorithms can exhaustively evaluate every tissue patch on a slide, achieving higher tumor-level sensitivity than, and comparable slide-level performance to, pathologists. These techniques may improve the pathologist's productivity and reduce the number of false negatives associated with morphologic detection of tumor cells. We provide a framework to aid practicing pathologists in assessing such algorithms for adoption into their workflow (akin to how a pathologist assesses immunohistochemistry results).},
author = {Liu, Yun and Kohlberger, Timo and Norouzi, Mohammad and Dahl, George E and Smith, Jenny L and Mohtashamian, Arash and Olson, Niels and Peng, Lily H and Hipp, Jason D and Stumpe, Martin C},
doi = {10.5858/arpa.2018-0147-OA},
howpublished = {$\backslash$url{\{}http://www.ncbi.nlm.nih.gov/pubmed/30295070{\}}},
issn = {1543-2165},
journal = {Archives of pathology {\&} laboratory medicine},
month = {oct},
pages = {859--868},
pmid = {30295070},
title = {{Artificial Intelligence-Based Breast Cancer Nodal Metastasis Detection.}},
year = {2018}
}
@book{Rokach:2008wc,
abstract = {This is the first comprehensive book dedicated entirely to the field of decision trees in data mining and covers all aspects of this important technique. Decision trees have become one of the most powerful and popular approaches in knowledge discovery and data mining, the science and technology of exploring large and complex bodies of data in order to discover useful patterns. The area is of great importance because it enables modeling and knowledge extraction from the abundance of data available. Both theoreticians and practitioners are continually seeking techniques to make the process more efficient, cost-effective and accurate. Decision trees, originally implemented in decision theory and statistics, are highly effective tools in other areas such as data mining, text mining, information extraction, machine learning, and pattern recognition.This book invites readers to explore the many benefits in data mining that decision trees offer: self-explanatory and easy to follow when compacted; able to handle a variety of input data: nominal, numeric and textual; able to process datasets that may have errors or missing values; high predictive performance for a relatively small computational effort; available in many data mining packages over a variety of platforms; and, useful for various tasks, such as classification, regression, clustering and feature selection.},
author = {Lori, Rokach and Oded, Maimon},
isbn = {978-9-81-277171-1},
pages = {244},
publisher = {World Scientific Publishing Company},
title = {{Data mining with decision trees}},
volume = {69},
year = {2008}
}
@inproceedings{hardt2016equality,
abstract = {We propose a criterion for discrimination against a specified sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our definition. Our framework also improves incentives by shifting the cost of poor classification from disadvantaged groups to the decision maker, who can respond by improving the classification accuracy. We enourage readers to consult the more complete manuscript on the arXiv.},
address = {Barcelona, Spain},
archivePrefix = {arXiv},
arxivId = {1610.02413},
author = {Hardt, Moritz and Price, Eric and Srebro, Nathan},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing},
eprint = {1610.02413},
issn = {1049-5258},
month = {dec},
pages = {3323--3331},
title = {{Equality of opportunity in supervised learning}},
year = {2016}
}
@inproceedings{Narayanan:2002ti,
abstract = {Web services - Web-accessible programs and devices - are a key application area for the Semantic Web. With the proliferation of Web services and the evolution towards the Semantic Web comes the opportunity to automate various Web services tasks. Our objective is to enable markup and automated reasoning technology to describe, simulate, compose, test, and verify compositions of Web services. We take as our starting point the DAML-S DAML+OIL ontology for describing the capabilities of Web services. We define the semantics for a relevant subset of DAML-S in terms of a first-order logical language. With the semantics in hand, we encode our service descriptions in a Petri Net formalism and provide decision procedures for Web service simulation, verification and composition. We also provide an analysis of the complexity of these tasks under different restrictions to the DAML-S composite services we can describe. Finally, we present an implementation of our analysis techniques. This implementation takes as input a DAML-S description of a Web service, automatically generates a Petri Net and performs the desired analysis. Such a tool has broad applicability both as a back end to existing manual Web service composition tools, and as a stand-alone tool for Web service developers.},
address = {Honolulu, HI, USA},
author = {Narayanan, Srini and McIlraith, Sheila A},
booktitle = {Proceedings of the 11th International Conference on World Wide Web},
doi = {10.1145/511446.511457},
isbn = {1-58-113449-5},
keywords = {Automated reasoning,DAML,Distributed systems,Ontologies,Semantic web,Web service composition,Web services},
month = {may},
pages = {77--88},
publisher = {ACM},
title = {{Simulation, verification and automated composition of web services}},
year = {2002}
}
@inproceedings{VanAssche:2007wc,
abstract = {Ensemble methods are popular learning methods that are usually able to increase the predictive accuracy of a classifier. On the other hand, this comes at the cost of interpretability, and insight in the decision process of an ensemble is hard to obtain. This is a major reason why ensemble methods have not been extensively used in the setting of inductive logic programming. In this paper we aim to overcome this issue of comprehensibility by learning a single first order interpretable model that approximates the first order ensemble. The new model is obtained by exploiting the class distributions predicted by the ensemble. These are employed to compute heuristics for deciding which tests are to be used in the new model. As such we obtain a model that is able to give insight in the decision process of the ensemble, while being more accurate than the single model directly learned on the data. {\textcopyright}2008 Springer-Verlag Berlin Heidelberg.},
address = {Corvallis, OR, USA},
author = {{Van Assche}, Anneleen and Blockeel, Hendrik},
booktitle = {Proceedings of the 17th International Conference on Inductive Logic Programming},
doi = {10.1007/978-3-540-78469-2_26},
isbn = {3-54-078468-3},
issn = {0302-9743},
keywords = {Comprehensibility,Ensembles,First order decision trees},
month = {jun},
pages = {269--279},
publisher = {Springer},
title = {{Seeing the forest through the trees learning a comprehensible model from a first order ensemble}},
volume = {4894 LNAI},
year = {2007}
}
@misc{IEEE:1990wp,
abstract = {Describes the IEEE Std 610.12-1990, IEEE standard glossary of software engineering terminology, which identifies terms currently in use in the field of software engineering. Standard definitions for those terms are established.},
author = {IEEE},
doi = {10.1109/IEEESTD.1990.101064},
keywords = {definitions,dictionary,glossary,software engineering,terminology},
number = {1},
pages = {1},
title = {{IEEE Standard Glossary of Software Engineering Terminology}},
volume = {121990},
year = {1990}
}
@inproceedings{Szegedy:2013vw,
abstract = {Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains the semantic information in the high layers of neural networks. Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extent. We can cause the network to misclassify an image by applying a certain hardly perceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.},
address = {Banff, AB, Canada},
archivePrefix = {arXiv},
arxivId = {1312.6199},
author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
booktitle = {Proceedings of the 2nd International Conference on Learning Representations},
eprint = {1312.6199},
month = {apr},
publisher = {ACM},
title = {{Intriguing properties of neural networks}},
year = {2014}
}
@article{Seaman:1999vc,
abstract = {While empirical studies in software engineering are beginning to gain recognition in the research community, this subarea is also entering a new level of maturity by beginning to address the human aspects of software development. This added focus has added a new layer of complexity to an already challenging area of research. Along with new research questions, new research methods are needed to study nontechnical aspects of software engineering. In many other disciplines, qualitative research methods have been developed and are commonly used to handle the complexity of issues involving human behavior. This paper presents several qualitative methods for data collection and analysis and describes them in terms of how they might be incorporated into empirical studies of software engineering, in particular how they might be combined with quantitative methods. To illustrate this use of qualitative methods, examples from real software engineering studies are used throughout. Index Terms - Qualitative methods, data collection, data analysis, experimental design, empirical software engineering, participant observation, interviewing. {\textcopyright}1999 IEEE.},
author = {Seaman, Carolyn B},
doi = {10.1109/32.799955},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
number = {4},
pages = {557--572},
title = {{Qualitative methods in empirical studies of software engineering}},
volume = {25},
year = {1999}
}
@inproceedings{Pautasso2008,
abstract = {Recent technology trends in the Web Services (WS) domain indicate that a solution eliminating the presumed complexity of the WS-* standards may be in sight: advocates of REpresentational State Transfer (REST) have come to believe that their ideas explaining why the World Wide Web works are just as applicable to solve enterprise application integration problems and to simplify the plumbing required to build service-oriented architectures. In this paper we objectify the WS-* vs. REST debate by giving a quantitative technical comparison based on architectural principles and decisions. We show that the two approaches differ in the number of architectural decisions that must be made and in the number of available alternatives. This discrepancy between freedom-from-choice and freedom-of-choice explains the complexity difference perceived. However, we also show that there are significant differences in the consequences of certain decisions in terms of resulting development and maintenance costs. Our comparison helps technical decision makers to assess the two integration styles and technologies more objectively and select the one that best fits their needs: REST is well suited for basic, ad hoc integration scenarios, WS-* is more flexible and addresses advanced quality of service requirements commonly occurring in enterprise computing.},
author = {Pautasso, Cesare and Zimmermann, Olaf and Leymann, Frank},
booktitle = {Proceedings of the 17th International Conference on World Wide Web},
doi = {10.1145/1367497.1367606},
isbn = {978-1-60-558085-2},
keywords = {Architectural decision modeling,HTTP,REST,Resource oriented architecture,SOAP,Service oriented architecture,Technology comparison,WS-* vs. REST,WSDL,Web services},
title = {{RESTful web services vs. "Big" web services: Making the right architectural decision}},
year = {2008}
}
@inproceedings{Bussone:2015wm,
abstract = {Clinical decision support systems (CDSS) are increasingly used by healthcare professionals for evidence-based diagnosis and treatment support. However, research has suggested that users often over-rely on system suggestions - even if the suggestions are wrong. Providing explanations could potentially mitigate misplaced trust in the system and over-reliance. In this paper, we explore how explanations are related to user trust and reliance, as well as what information users would find helpful to better understand the reliability of a system's decision-making. We investigated these questions through an exploratory user study in which healthcare professionals were observed using a CDSS prototype to diagnose hypothetic cases using fictional patients suffering from a balance-related disorder. Our results show that the amount of system confidence had only a slight effect on trust and reliance. More importantly, giving a fuller explanation of the facts used in making a diagnosis had a positive effect on trust but also led to over-reliance issues, whereas less detailed explanations made participants question the system's reliability and led to self-reliance problems. To help them in their assessment of the reliability of the system's decisions, study participants wanted better explanations to help them interpret the system's confidence, to verify that the disorder fit the suggestion, to better understand the reasoning chain of the decision model, and to make differential diagnoses. Our work is a first step toward improved CDSS design that better supports clinicians in making correct diagnoses.},
address = {Dallas, TX, USA},
author = {Bussone, Adrian and Stumpf, Simone and O'Sullivan, Dympna},
booktitle = {Proceedings of the 2015 IEEE International Conference on Healthcare Informatics},
doi = {10.1109/ICHI.2015.26},
isbn = {978-1-46-739548-9},
keywords = {CDSS,Explanations,Reliability,Reliance,Trust,User study},
month = {oct},
pages = {160--169},
publisher = {IEEE},
title = {{The role of explanations on trust and reliance in clinical decision support systems}},
year = {2015}
}
@inproceedings{Reboucas:2016tw,
abstract = {Recently, Apple released Swift, a modern programming language built to be the successor of Objective-C. In less than a year and a half after its first release, Swift became one of the most popular programming languages in the world, considering different popularity measures. A significant part of this success is due to Apple's strict control over its ecosystem, and the clear message that it will replace Objective-C in a near future. According to Apple, "Swift is a powerful and intuitive programming language[...]. Writing Swift code is interactive and fun, the syntax is concise yet expressive." However, little is known about how Swift developers perceive these benefits. In this paper, we conducted two studies aimed at uncovering the questions and strains that arise from this early adoption. First, we perform a thorough analysis on 59,156 questions asked about Swift on StackOverflow. Second, we interviewed 12 Swift developers to cross-validate the initial results. Our study reveals that developers do seem to find the language easy to understand and adopt, although 17.5{\%} of the questions are about basic elements of the language. Still, there are many questions about problems in the toolset (compiler, Xcode, libraries). Some of our interviewees reinforced these problems.},
address = {Suita, Japan},
author = {Reboucas, Marcel and Pinto, Gustavo and Ebert, Felipe and Torres, Weslley and Serebrenik, Alexander and Castor, Fernando},
booktitle = {Proceedings of the 23rd International Conference on Software Analysis, Evolution, and Reengineering},
doi = {10.1109/saner.2016.66},
month = {mar},
pages = {634--638},
publisher = {IEEE},
title = {{An Empirical Study on the Usage of the Swift Programming Language}},
year = {2016}
}
@article{Lipton:2016if,
archivePrefix = {arXiv},
arxivId = {1606.03490},
author = {Lipton, Zachary C},
doi = {10.1145/3233231},
eprint = {1606.03490},
issn = {1557-7317},
journal = {Communications of the ACM},
number = {10},
pages = {35--43},
title = {{The mythos of model interpretability}},
volume = {61},
year = {2018}
}
@techreport{McCarthy:1960:PCS:889202,
abstract = {Interesting work is being done in programming computers to solve problems which require a high degree of intelligence in humans. However, certain elementary verbal reasoning processes so simple that they can be carried out by any non-feeble minded human have yet to be simulated by machine programs.},
address = {Cambridge, MA, USA},
author = {McCarthy, J},
booktitle = {Proceedings of the Symposium on the Mechanization of Thought Processes},
pages = {1--15},
title = {{Programs with common sense}},
year = {1963}
}
@inproceedings{Beyer:2014ec,
abstract = {While many tutorials, code examples, and documentation about Android APIs exist, developers still face various problems with the implementation of Android Apps. Many of these issues are discussed on Q{\&}A-sites, such as Stack Overflow. In this paper we present a manual categorization of 450 Android related posts of Stack Overflow concerning their question and problem types. The idea is to find dependencies between certain problems and question types to get better insights into issues of Android App development. The categorization is developed using card sorting with three experienced Android App developers. An initial approach to automate the classification of Stack Overflow posts using Lucene is also presented. The study highlights that the most common question types are 'How to⋯?' and 'What is the problem⋯?'. The problems that are discussed most often are related to 'User Interface' and 'Core Elements'. In particular, the problem category 'Layout' is often related to 'What is the problem⋯?' and 'Frameworks' issues often come with 'Is it possible⋯?' questions.},
address = {Victoria, BC, Canada},
author = {Beyer, Stefanie and Pinzger, Martin},
booktitle = {Proceedings of the 30th International Conference on Software Maintenance and Evolution},
doi = {10.1109/ICSME.2014.88},
isbn = {978-0-76-955303-0},
month = {sep},
pages = {531--535},
publisher = {IEEE Computer Society},
title = {{A manual categorization of android app development issues on stack overflow}},
year = {2014}
}
@article{rgensen:2016gl,
abstract = {Context The trustworthiness of research results is a growing concern in many empirical disciplines. Aim The goals of this paper are to assess how much the trustworthiness of results reported in software engineering experiments is affected by researcher and publication bias, given typical statistical power and significance levels, and to suggest improved research practices. Method First, we conducted a small-scale survey to document the presence of researcher and publication biases in software engineering experiments. Then, we built a model that estimates the proportion of correct results for different levels of researcher and publication bias. A review of 150 randomly selected software engineering experiments published in the period 2002-2013 was conducted to provide input to the model. Results The survey indicates that researcher and publication bias is quite common. This finding is supported by the observation that the actual proportion of statistically significant results reported in the reviewed papers was about twice as high as the one expected assuming no researcher and publication bias. Our models suggest a high proportion of incorrect results even with quite conservative assumptions. Conclusion Research practices must improve to increase the trustworthiness of software engineering experiments. A key to this improvement is to avoid conducting studies with unsatisfactory low statistical power.},
author = {J{\o}rgensen, Magne and Dyb{\aa}, Tore and Liest{\o}l, Knut and Sj{\o}berg, Dag I K},
doi = {10.1016/j.jss.2015.03.065},
issn = {0164-1212},
journal = {Journal of Systems and Software},
keywords = {Controlled experiments,Empirical software engineering,Statistical hypothesis testing},
pages = {133--145},
title = {{Incorrect results in software engineering experiments: How to improve research practices}},
volume = {116},
year = {2016}
}
@misc{Howard:2018tz,
annote = {Accessed: 28 August 2018},
author = {Howard, Christian},
month = {may},
title = {{Introducing Google AI}},
url = {http://bit.ly/2uI6vAr},
year = {2018}
}
@article{Barua:2012gz,
abstract = {Programming question and answer (Q{\&}A) websites, such as Stack Overflow, leverage the knowledge and expertise of users to provide answers to technical questions. Over time, these websites turn into repositories of software engineering knowledge. Such knowledge repositories can be invaluable for gaining insight into the use of specific technologies and the trends of developer discussions. Previous work has focused on analyzing the user activities or the social interactions in Q{\&}A websites. However, analyzing the actual textual content of these websites can help the software engineering community to better understand the thoughts and needs of developers. In the article, we present a methodology to analyze the textual content of Stack Overflow discussions. We use latent Dirichlet allocation (LDA), a statistical topic modeling technique, to automatically discover the main topics present in developer discussions. We analyze these discovered topics, as well as their relationships and trends over time, to gain insights into the development community. Our analysis allows us to make a number of interesting observations, including: the topics of interest to developers range widely from jobs to version control systems to C{\#} syntax; questions in some topics lead to discussions in other topics; and the topics gaining the most popularity over time are web development (especially jQuery), mobile applications (especially Android), Git, and MySQL. {\textcopyright}2012 Springer Science+Business Media New York.},
author = {Barua, Anton and Thomas, Stephen W and Hassan, Ahmed E},
doi = {10.1007/s10664-012-9231-y},
issn = {1573-7616},
journal = {Empirical Software Engineering},
keywords = {Knowledge repository,Latent Dirichlet allocation,Mining software repositories,Q{\&}A websites,Topic models,Trend analysis},
number = {3},
pages = {619--654},
title = {{What are developers talking about? An analysis of topics and trends in Stack Overflow}},
volume = {19},
year = {2014}
}
@article{Szafron:2004uf,
abstract = {Proteome Analyst (PA) (http://www.cs.ualberta.ca/{\~{}}bioinfo/PA/) is a publicly available, high-throughput, web-based system for predicting various properties of each protein in an entire proteome. Using machine-learned classifiers, PA can predict, for example, the GeneQuiz general function and Gene Ontology (GO) molecular function of a protein. In addition, PA is currently the most accurate and most comprehensive system for predicting subcellular localization, the location within a cell where a protein performs its main function. Two other capabilities of PA are notable. First, PA can create a custom classifier to predict a new property, without requiring any programming, based on labeled training data (i.e. a set of examples, each with the correct classification label) provided by a user. PA has been used to create custom classifiers for potassium-ion channel proteins and other general function ontologies. Second, PA provides a sophisticated explanation feature that shows why one prediction is chosen over another. The PA system produces a Na{\"{i}}ve Bayes classifier, which is amenable to a graphical and interactive approach to explanations for its predictions; transparent predictions increase the user's confidence in, and understanding of, PA. {\textcopyright}Oxford University Press 2004; all rights reserved.},
author = {Szafron, Duane and Lu, Paul and Greiner, Russell and Wishart, David S and Poulin, Brett and Eisner, Roman and Lu, Zhiyong and Anvik, John and Macdonell, Cam and Fyshe, Alona and Meeuwis, David},
doi = {10.1093/nar/gkh485},
issn = {0305-1048},
journal = {Nucleic Acids Research},
number = {WEB SERVER ISS.},
pages = {W365--------------------------------W371},
title = {{Proteome Analyst: Custom predictions with explanations in a web-based tool for high-throughput proteome annotations}},
volume = {32},
year = {2004}
}
@article{Drummond2006,
abstract = {This paper introduces cost curves, a graphical technique for visualizing the performance (error rate or expected cost) of 2-class classifiers over the full range of possible class distributions and misclassification costs. Cost curves are shown to be superior to ROC curves for visualizing classifier performance for most purposes. This is because they visually support several crucial types of performance assessment that cannot be done easily with ROC curves, such as showing confidence intervals on a classifier's performance, and visualizing the statistical significance of the difference in performance of two classifiers. A software tool supporting all the cost curve analysis described in this paper is available from the authors. {\textcopyright}Springer Science + Business Media, LLC 2006.},
author = {Drummond, Chris and Holte, Robert C},
doi = {10.1007/s10994-006-8199-5},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {Classifiers,Machine learning,Performance evaluation,ROC curves},
month = {oct},
number = {1},
pages = {95--130},
title = {{Cost curves: An improved method for visualizing classifier performance}},
volume = {65},
year = {2006}
}
@inproceedings{Petersen:2008td,
abstract = {BACKGROUND: A software engineering systematic map is a defined method to build a classification scheme and structure a software engineering field of interest. The analysis of results focuses on frequencies of publications for categories within the scheme. Thereby, the coverage of the research field can be determined. Different facets of the scheme can also be combined to answer more specific research questions. OBJECTIVE: We describe how to conduct a systematic mapping study in software engineering and provide guidelines. We also compare systematic maps and systematic reviews to clarify how to chose between them. This comparison leads to a set of guidelines for systematic maps. METHOD: We have defined a systematic mapping process and applied it to complete a systematic mapping study. Furthermore, we compare systematic maps with systematic reviews by systematically analyzing existing systematic reviews. RESULTS: We describe a process for software engineering systematic mapping studies and compare it to systematic reviews. Based on this, guidelines for conducting systematic maps are defined. CONCLUSIONS: Systematic maps and reviews are different in terms of goals, breadth, validity issues and implications. Thus, they should be used complementarily and require different methods (e.g., for analysis).},
author = {Petersen, Kai and Feldt, Robert and Mujtaba, Shahid and Mattsson, Michael},
booktitle = {Proceedings of the 12th International Conference on Evaluation and Assessment in Software Engineering, EASE 2008},
doi = {10.14236/ewic/ease2008.8},
keywords = {Evidence based software engineering,Systematic mapping studies,Systematic reviews},
pages = {68--77},
title = {{Systematic mapping studies in software engineering}},
year = {2008}
}
@article{Henning:2009hz,
author = {Henning, Michi},
doi = {10.1145/1506409.1506424},
issn = {0001-0782},
journal = {Communications of the ACM},
number = {5},
pages = {46--56},
title = {{API design matters}},
volume = {52},
year = {2009}
}
@article{Light:1971vz,
abstract = {Notes that various procedures are available for measuring agreement among 2 or more os who classify responses among nominal categories, but that different problem situations require different measures. The general model of a contingency table with fixed margins is used to suggest (a) a measure of level of agreement among several os when compared internally, (b) a conditional measurement of agreement for several os compared internally, (c) a test for the joint agreement of several os when compared with a standard, and (d) a statistic for evaluating the pattern of agreement between 2 os. Illustrations are presented for each situation, and results of a monte carlo study of the behavior of the pattern agreement statistic are discussed. (19 ref.) (PsycINFO Database Record (c) 2006 APA, all rights reserved). {\textcopyright}1971 American Psychological Association.},
author = {Light, Richard J},
doi = {10.1037/h0031643},
issn = {0033-2909},
journal = {Psychological Bulletin},
keywords = {response agreement measurement among 2 or more Os},
number = {5},
pages = {365--377},
title = {{Measures of response agreement for qualitative data: Some generalizations and alternatives}},
volume = {76},
year = {1971}
}
@article{Dhar:2000vo,
abstract = {Prediction in financial domains is notoriously difficult for a number of reasons. First, theories tend to be weak or non-existent, which makes problem formulation open ended by forcing us to consider a large number of independent variables and thereby increasing the dimensionality of the search space. Second, the weak relationships among variables tend to be nonlinear, and may hold only in limited areas of the search space. Third, in financial practice, where analysts conduct extensive manual analysis of historically well performing indicators, a key is to find the hidden interactions among variables that perform well in combination. Unfortunately, these are exactly the patterns that the greedy search biases incorporated by many standard rule learning algorithms will miss. In this paper, we describe and evaluate several variations of a new genetic learning algorithm (GLOWER) on a variety of data sets. The design of GLOWER has been motivated by financial prediction problems, but incorporates successful ideas from tree induction and rule learning. We examine the performance of several GLOWER variants on two UCI data sets as well as on a standard financial prediction problem (S{\&}P500 stock returns), using the results to identify one of the better variants for further comparisons. We introduce a new (to KDD) financial prediction problem (predicting positive and negative earnings surprises), and experiment with GLOWER, contrasting it with tree- and rule-induction approaches. Our results are encouraging, showing that GLOWER has the ability to uncover effective patterns for difficult problems that have weak structure and significant nonlinearities. {\textcopyright}2000 Kluwer Academic Publishers.},
author = {Dhar, Vasant and Chou, Dashin and Provost, Foster},
doi = {10.1023/A:1009848126475},
issn = {1384-5810},
journal = {Data Mining and Knowledge Discovery},
keywords = {Data mining,Financial prediction,Genetic algorithms,Investment decision making,Knowledge discovery,Machine learning,Rule learning,Systematic trading},
number = {4},
pages = {69--80},
title = {{Discovering interesting patterns for investment decision making with GLOWER - A genetic learner overlaid with entropy reduction}},
volume = {4},
year = {2000}
}
@book{Hwang:2017tr,
address = {Cambridge, MA, USA},
author = {Wang, Kai},
isbn = {978-0-26-203641-2},
pages = {624},
publisher = {MIT Press},
title = {{Cloud Computing for Machine Learning and Cognitive Applications: A Machine Learning Approach}},
year = {2017}
}
@inproceedings{Subramanian:2014bg,
abstract = {Application Programming Interfaces (APIs) provide powerful abstraction mechanisms that enable complex functionality to be used by client programs. However, this abstraction does not come for free: understanding how to use an API can be difficult. While API documentation can help, it is often insufficient on its own. Online sites like Stack Overflow and Github Gists have grown to fill the gap between traditional API documentation and more example-based resources. Unfortunately, these two important classes of documentation are independent. In this paper we describe an iterative, deductive method of linking source code examples to API documentation. We also present an implementation of this method, called Baker, that is highly precise (0.97) and supports both Java and JavaScript. Baker can be used to enhance traditional API documentation with up-to-date source code examples; it can also be used to incorporate links to the API documentation into the code snippets that use the API.},
address = {Hyderabad, India},
author = {Subramanian, Siddharth and Inozemtseva, Laura and Holmes, Reid},
booktitle = {Proceedings of the 36th International Conference on Software Engineering},
doi = {10.1145/2568225.2568313},
issn = {0270-5257},
keywords = {Source code examples,documentation,source code search},
month = {may},
number = {CONFCODENUMBER},
pages = {643--652},
publisher = {ACM Press},
title = {{Live API documentation}},
year = {2014}
}
@article{Su:2017uw,
abstract = {Recent research has revealed that the output of deep neural networks (DNNs) can be easily altered by adding relatively small perturbations to the input vector. In this paper, we analyze an attack in an extremely limited scenario where only one pixel can be modified. For that we propose a novel method for generating one-pixel adversarial perturbations based on differential evolution (DE). It requires less adversarial information (a black-box attack) and can fool more types of networks due to the inherent features of DE. The results show that 67.97{\%} of the natural images in Kaggle CIFAR-10 test dataset and 16.04{\%} of the ImageNet (ILSVRC 2012) test images can be perturbed to at least one target class by modifying just one pixel with 74.03{\%} and 22.91{\%} confidence on average. We also show the same vulnerability on the original CIFAR-10 dataset. Thus, the proposed attack explores a different take on adversarial machine learning in an extreme limited scenario, showing that current DNNs are also vulnerable to such low dimension attacks. Besides, we also illustrate an important application of DE (or broadly speaking, evolutionary computation) in the domain of adversarial machine learning: creating tools that can effectively generate low-cost adversarial attacks against neural networks for evaluating robustness.},
archivePrefix = {arXiv},
arxivId = {1710.08864},
author = {Su, Jiawei and Vargas, Danilo Vasconcellos and Sakurai, Kouichi},
doi = {10.1109/TEVC.2019.2890858},
eprint = {1710.08864},
issn = {1941-0026},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Convolutional neural network,differential evolution (DE),image recognition,information security},
number = {5},
pages = {828--841},
title = {{One Pixel Attack for Fooling Deep Neural Networks}},
volume = {23},
year = {2019}
}
@book{Bass:2003wi,
abstract = {This report is another in a series of Software Engineering Institute (SEISM) case studies of organizations that have adopted the software product line approach for developing systems. It details the story of Salion, Inc., an enterprise software company providing Revenue Acquisition Management solutions tailored to the unique needs of automotive suppliers. Salion's solutions enable suppliers to organize and manage their disparate customer-interfacing activities as one coordinated business process, resulting in higher revenues, profit margins, and customer satisfaction. This case study is unique in that Salion did not have substantial experience in its application area, although its key designers and strategists were knowledgeable about related domains. Salion pursued a reactive approach to its product line that let it respond flexibly to spontaneous business opportunities and that significantly lowered the cost of adopting the product line paradigm to its software system development. This case study describes relevant dimensions of Salion's context, how it approached several product line practice areas that were key to its strategy, the benefits gained through its product line, lessons learned, and the major thematic aspects of the Salion story.},
author = {Bass, Len and Clements, Paul and Kazman, Rick},
booktitle = {Software Architecture},
edition = {2nd},
isbn = {0-32-115495-9},
pages = {560},
publisher = {Addison-Wesley},
title = {{Software Architecture in Practice}},
year = {2003}
}
@book{Spector:1992uj,
abstract = {Summated scales have four characteristics: multiple items; quantitative measurement; no right answer; and, each item of scale is a statement. Mutliple item scales are used for reliability and precision. "Reliability assures that a scale can consistently measure something, but it does not assure that it will measure what it is designed to measure. This property (that a scale measures its intended construct) is validity" (6-7). While reliability is evaluated with test-retest, internal consistency or other types of reliability tests, validity if evaluated in reference to theoretical context and hypothesized relationships with the construct and other variables. The theory of summated rating scales is described in chapter 2, where it is noted that one of the most troublesome sources of biases (or non-random error) is social desirability. Another is acquiescence responses, where people tend to agree with all items regardless of content. Chapter 3 addresses the importance of defining the construct to be measured, and chapter 4 desiging a scale. Approach recommended is inductive one in which theoretical ideas guide validation strategy. The deductive approach is more exploratory and leaves much room for misinterpretation. Constructs vary from being specific and narrow to being multi-dimensional and involving sub-scales."Locus of control" reserach is used as an example throughout this monograph to discuss scale construction. Three types of response choices are described: agreement, evaluation, and frequency. Scales can be unipolar or bipolar. Attitudes are often bipolar because there is a positive, neutral, negative response. These scales can be numbered from 1to x or from -x to +x. Five rules for good items are: express only one idea; use both positively and negatively worded items; avoid expressions, jargon, etc.; consider reading level of respondents; and, avoid use of negatives to reverse wording. Chapter 5 discusses conducting the item analysis, in order to determine internal consistency of the scale and eliminate inconsistent items. The item-remainder (or part-whole or item-whole) coefficient measures how well each item relates to other items in the analysis. Items should be scaled in same direction, so some scales may need to be reversed before the analysis. Two methods can be used to decide if items should be retained: m-items chosen or criterion for coefficient (e.g., 0.40). Coefficient alpha also measures consistency, and is a function of number of items and their degree of correlation. Note that internal consistency can result if more than one highly corrrelated measure constructs comprise the scale. In choosing scale items, both item-remainder and alpha coefficient are used. Items may also be deleted based on their correlations with external variables (such as a social desirability measure). When item analysis results in too few items, it may be helpful to estimate number of items needed to achieve acceptable level of internal consistency, using, e.g., Spearman-Brown prophesy formula. Multidimensional scales are discussed starting on pg. 39. Many constructs are broad and may contain multiple aspects. Attitudes toward complex things wuch as gov't often contain many dimensions. Subscales are useful for these constructs. Shared items in scales may cause problems because relationships among the sub-scale constructs may be due to a real relationship or to shared items. Chapter 6 discusses validation. Typical strategy involves testing scale in context of hypothesized interrelations between construct and other variables. This is similar to testing a theory, in that validity cannot be proven. Evidence is simply collected to support or refute validity. As with a theory, a construct is tentatively accepted because it is useful. A few methods of validity evaluation are described: criterion-related validity, discrimnant and convergent validities, and factor analysis. For criterion-related validity, scale is validated in relation to theoretically-based hypotheses. Concurrent validity involve simultaneously collected data on scale and related variables, while predictive validity involves collecting data on scale of interest prior to criterion variables. Known-groups validity assess hypothesized differences between certain groups using t-tests, ANOVA, etc. Convergent validity means different measures of same construct are strongly related, while discriminant validity means measures of different constructs should relate only modestly. An example of Multitrait-Multimethod Matrix is presented. Two types of factor analysis are discussed: confirmatory, where there is a hypothesized structure, and exploratory. Basic idea of factor analysis is to reduce number of items to smaller number of underlying gorups of items, called factors. For multidimensional scales, additional items tend to produce stronger factors that account for more variable. Poor items and response biases can wreak havoc on factor solution. The eigenvalue represents relative proportion of variance accounted for by factor. If items don't correlate, eigenvalues will reflect only variance in original items and will equal 1. If perfectly correlated, single factor is produced with eigenvalue equal to number of items and other eigenvalues with equal 0. If items for several factors, each will have eigenvalue greater than one, meaning it is accounting for more variance than a single item. Once factors identified, orthogonal rotation procedure is applied, in order to produce clusters of items based on mathematical criteria. Loading matrix produces factor loadings that are correlations of item with each factor. Minimum value of {\~{}}0.30-.35 suggests that an item loads significantly onto a factor. One difficulty is the subjective judgement necessary to determine number of factors. Note that factor analysis can be sensitive to total set of items, and adding/deleting single item can have profound effects. Factor analysis is not likely to be useful for scales with few items. With exploratory factor analysis, best fitting factor structure is fit to data. With confirmatory factor analsyis, structure is hypothesized in advance. Covariance structure modeling structures such as LISREL and EQS are described. Lastly, reliability and norms are discussed in chapter 7.},
address = {Newbury Park, CA, USA},
author = {Spector, Paul},
booktitle = {Summated Rating Scale Construction},
doi = {10.4135/9781412986038},
isbn = {978-0-80-394341-4},
publisher = {SAGE},
title = {{Summated Rating Scale Construction}},
year = {1992}
}
@article{Richards:2001vw,
abstract = {This paper describes the analysis of a database of diabetic patients' clinical records and death certificates. The objective of the study was to find rules that describe associations between observations made of patients at their first visit to the hospital and early mortality. Pre-processing was carried out and a knowledge discovery in databases (KDD) package, developed by the Lanner Group and the University of East Anglia, was used for rule induction using simulated annealing. The most significant discovered rules describe an association that was not generally known or accepted by the medical community, however, recent independent studies confirm their validity. {\textcopyright}2001 Elsevier Science B.V.},
author = {Richards, G and Rayward-Smith, V J and S{\"{o}}nksen, P H and Carey, S and Weng, C},
doi = {10.1016/S0933-3657(00)00110-X},
issn = {0933-3657},
journal = {Artificial Intelligence in Medicine},
keywords = {Data mining,Diabetes,Neuropathy,Rule induction},
number = {3},
pages = {215--231},
title = {{Data mining for indicators of early mortality in a database of clinical records}},
volume = {22},
year = {2001}
}
@article{Freitas:2014ic,
abstract = {The vast majority of the literature evaluates the performance of classification models using only the criterion of predictive accuracy. This paper reviews the case for considering also the comprehensibility (interpretability) of classification models, and discusses the interpretability of five types of classification models, namely decision trees, classification rules, decision tables, nearest neighbors and Bayesian network classifiers. We discuss both interpretability issues which are specific to each of those model types and more generic interpretability issues, namely the drawbacks of using model size as the only criterion to evaluate the comprehensibility of a model, and the use of monotonicity constraints to improve the comprehensibility and acceptance of classification models by users.},
author = {Freitas, Alex A},
doi = {10.1145/2594473.2594475},
issn = {1931-0145},
journal = {ACM SIGKDD Explorations Newsletter},
month = {mar},
number = {1},
pages = {1--10},
title = {{Comprehensible classification models}},
volume = {15},
year = {2014}
}
@inproceedings{Rubey:1968fg,
address = {Las Vegas, NV, USA},
author = {Rubey, Raymond J and Hartwick, R Dean},
booktitle = {Proceedings of the 1968 23rd ACM National Conference},
doi = {10.1145/800186.810631},
isbn = {978-1-45-037486-6},
month = {aug},
pages = {671--677},
publisher = {ACM},
title = {{Quantitative measurement of program quality}},
year = {1968}
}
@inproceedings{1572302,
abstract = {Today's information technology society increasingly relies on software at all levels. Nevertheless, software quality generally continues to fall short of expectations, and software systems continue to suffer from symptoms of aging as they are adapted to changing requirements and environments. The only way to overcome or avoid the negative effects of software aging is by placing change and evolution in the center of the software development process. In this article we describe what we believe to be some of the most important research challenges in software evolution. The goal of this document is to provide novel research directions in the software evolution domain. {\textcopyright}2005 IEEE.},
address = {Lisbon, Portugal},
author = {Mens, Tom and Demeyer, Serge and Wermelinger, Michel and Hirschfeld, Robert and Ducasse, St{\'{e}}phane and Jazayeri, Mehdi},
booktitle = {Proceedings of the 8th International Workshop on Principles of Software Evolution},
doi = {10.1109/IWPSE.2005.7},
isbn = {0-76-952349-8},
issn = {1550-4077},
keywords = {Aging,Business,Collaborative software,Computer industry,Conferences,Information technology,Programming,Software quality,Software systems,Software tools,formal specification,formal verification,information technology society,requirements analysis,software aging,software development process,software evolution,software maintenance,software quality,software system},
month = {sep},
pages = {13--22},
publisher = {IEEE},
title = {{Challenges in software evolution}},
volume = {2005},
year = {2005}
}
@inproceedings{Elazmeh:2007tp,
abstract = {The paper presents ongoing issues, challenges, and difficulties we face in applying machine learning methods to retrospectively collected clinical data. The objective of our research is to build a reliable prediction model for early assessment of emergency pediatric asthma exacerbations. This predictive model should be able to distinguish between patients with mild or moderate/severe asthma attacks at a medically acceptable level of performance. Our real-life data set presents us with some difficult challenges which we communicate in this paper. Our approach to overcoming some of these difficulties is to use external expert knowledge to aid with classification by decomposing the classification problem into a two-tier concept, where concepts can be explicitly described in terms of the external knowledge source. Such an approach also has the advantage of significantly reducing the size of the training set required. Copyright {\textcopyright}2007, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
address = {Vancouver, BC, Canada},
author = {Elazmeh, William and Matwin, Stan and O'Sullivan, Dympna and Michalowski, Wojtek and Farion, Ken},
booktitle = {Proceedings of the 22nd Conference on Artificial Intelligence},
isbn = {978-1-57-735332-4},
month = {jul},
pages = {10--15},
publisher = {AAAI},
title = {{Insights from predicting pediatric asthma exacerbations from retrospective clinical data}},
volume = {WS-07-05},
year = {2007}
}
@inproceedings{Goodman:2016wf,
abstract = {We summarize the potential impact that the European Union's new General Data Protection Regulation will have on the routine use of machine learning algorithms. Slated to take effect as law across the EU in 2018, it will restrict automated individual decision-making (that is, algorithms that make decisions based on user-level predictors) which "significantly affect" users. The law will also create a "right to explanation," whereby a user can ask for an explanation of an algorithmic decision that was made about them. We argue that while this law will pose large challenges for industry, it highlights opportunities for machine learning researchers to take the lead in designing algorithms and evaluation frameworks which avoid discrimination.},
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {1606.08813},
author = {{Wachter, Mitterlstadt}, Floridi},
booktitle = {Proceedings of the 2016 ICML Workshop on Human Interpretability in Machine Learning},
eprint = {1606.08813},
howpublished = {$\backslash$url{\{}http://arxiv.org/abs/1606.08813{\}}},
keywords = {machine learning},
month = {jun},
number = {Whi},
pages = {26--30},
title = {{EU regulations on algorithmic decision-making and a "right to explanation"}},
year = {2016}
}
@article{Narayanan:2018ud,
abstract = {Recent years have seen a boom in interest in machine learning systems that can provide a human-understandable rationale for their predictions or decisions. However, exactly what kinds of explanation are truly human-interpretable remains poorly understood. This work advances our understanding of what makes explanations interpretable in the specific context of verification. Suppose we have a machine learning system that predicts X, and we provide rationale for this prediction X. Given an input, an explanation, and an output, is the output consistent with the input and the supposed rationale? Via a series of user-studies, we identify what kinds of increases in complexity have the greatest effect on the time it takes for humans to verify the rationale, and which seem relatively insensitive.},
archivePrefix = {arXiv},
arxivId = {1802.00682},
author = {Narayanan, Menaka and Chen, Emily and He, Jeffrey and Kim, Been and Gershman, Sam and Doshi-Velez, Finale},
eprint = {1802.00682},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {InPress},
mendeley-tags = {InPress},
title = {{How do Humans Understand Explanations from Machine Learning Systems? An Evaluation of the Human-Interpretability of Explanation}},
year = {2018}
}
@inproceedings{Schwabacher:2001wc,
abstract = {Pages: 489 - 496. Year of Publication: . ISBN:1-55860-778-1. Authors, Mark , Pat , Publisher, Morgan Kaufmann Publishers Inc.},
address = {Williamstown, MA, USA},
author = {Schwabacher, Mark and Langley, Pat},
booktitle = {Proceedings of the 18th International Conference on Machine Learning},
isbn = {978-1-55-860778-1},
month = {jun},
pages = {489--496},
publisher = {Morgan Kaufmann},
title = {{Discovering communicable scientific knowledge from spatio-temporal data}},
year = {2001}
}
@article{Hadley:2006vv,
abstract = {This article describes the Web Application Description Language (WADL). An increasing number of Web-based enterprises (Google, Yahoo, Amazon, Flickr - to name but a few) are developing HTTP-based applications that provide access to their internal data using XML. Typically these applications are described using a combination of textual protocol descriptions combined with XML schema-based data format descriptions; WADL is designed to provide a machine processable protocol description format for use with such HTTP-based Web applications, especially those using XML.},
author = {Hadley, Marc J and Marc, Hadley},
howpublished = {$\backslash$url{\{}http://bit.ly/2RXRhQ1{\}}},
journal = {Search},
number = {TR-2006-153},
pages = {1--31},
publisher = {W3C},
title = {{Web Application Description Language}},
volume = {12},
year = {2009}
}
@inproceedings{Wang:2013ue,
address = {Coimbra, Portugal},
author = {Wang, Shaowei and Lo, David and Jiang, Lingxiao},
booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},
doi = {10.1145/2480362.2480557},
month = {mar},
pages = {1019--1024},
publisher = {ACM},
title = {{An empirical study on developer interactions in StackOverflow}},
year = {2013}
}
@inproceedings{Wang:2013ub,
abstract = {Software frameworks provide sets of generic functionalities that can be later customized for a specific task. When developers invoke API methods in a framework, they often encounter obstacles in finding the correct usage of the API, let alone to employ best practices. Previous research addresses this line of questions by mining API usage patterns to induce API usage templates, by conducting and compiling interviews of developers, and by inferring correlations among APIs. In this paper, we analyze API-related posts regarding iOS and Android development from a Q{\&}A website, stackoverflow.com. Assuming that API-related posts are primarily about API usage obstacles, we find several iOS and Android API classes that appear to be particularly likely to challenge developers, even after we factor out API usage hotspots, inferred by modelling API usage of open source iOS and Android applications. For each API with usage obstacles, we further apply a topic mining tool to posts that are tagged with the API, and we discover several repetitive scenarios in which API usage obstacles occur. We consider our work as a stepping stone towards understanding API usage challenges based on forum-based input from a multitude of developers, input that is prohibitively expensive to collect through interviews. Our method helps to motivate future research in API usage, and can allow designers of platforms - such as iOS and Android - to better understand the problems developers have in using their platforms, and to make corresponding improvements. {\textcopyright}2013 IEEE.},
address = {San Francisco, CA, USA},
author = {Wang, Wei and Godfrey, Michael W},
booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
doi = {10.1109/MSR.2013.6624006},
isbn = {978-1-46-732936-1},
issn = {2160-1852},
month = {may},
pages = {61--64},
publisher = {IEEE},
title = {{Detecting API usage obstacles: A study of iOS and android developer questions}},
year = {2013}
}
@article{Parasuraman:1988wh,
abstract = {This paper describes the development of a 22-item instrument (called SERVQUAL) for assessing customer perceptions of service quality in service and retailing organizations. After a discussion of the conceptualization and operationalization of the service quality construct, the procedures used in constructing and refining a multiple-item scale to measure the construct are described. Evidence of the scale's reliability, factor structure, and validity on the basis of analyzing data from four independent samples is presented next. The paper concludes with a discussion of potential applications of the scale.},
author = {Berry, Leonard L and Parasuraman, A and Zeithaml, Valarie A},
doi = {10.1016/S0148-2963(99)00084-3},
isbn = {00224359},
issn = {0022-4359},
journal = {Journal of retailing},
number = {1},
pages = {12--40},
pmid = {6353339},
title = {{SERVQUAL: A multiple-item scale for measuring consumer perceptions of service quality}},
volume = {64},
year = {1988}
}
@article{BenDavid:1995up,
abstract = {Decision trees that are based on information-theory are useful paradigms for learning from examples. However, in some real-world applications, known information-theoretic methods frequently generate nonmonotonic decision trees, in which objects with better attribute values are sometimes classified to lower classes than objects with inferior values. This property is undesirable for problem solving in many application domains, such as credit scoring and insurance premium determination, where monotonicity of subsequent classifications is important. An attribute-selection metric is proposed here that takes both the error as well as monotonicity into account while building decision trees. The metric is empirically shown capable of significantly reducing the degree of non-monotonicity of decision trees without sacrificing their inductive accuracy. {\textcopyright}1995, Kluwer Academic Publishers. All rights reserved.},
author = {Ben-David, Arie},
doi = {10.1023/A:1022655006810},
issn = {1573-0565},
journal = {Machine Learning},
keywords = {accuracy,consistency,information theory,monotonic classification problems,monotonic decision trees},
number = {1},
pages = {29--43},
title = {{Monotonicity Maintenance in Information-Theoretic Machine Learning Algorithms}},
volume = {19},
year = {1995}
}
@inproceedings{Pal:2012te,
abstract = {Community Question Answering (CQA) services thrive as a result of a small number of highly active users, typically called experts, who provide a large number of high quality useful answers. Understanding the temporal dynamics and interactions between experts can present key insights into how community members evolve over time. In this paper, we present a temporal study of experts in CQA and analyze the changes in their behavioral patterns over time. Further, using unsupervised machine learning methods, we show the interesting evolution patterns that can help us distinguish experts from one another. Using supervised classification methods, we show that the models based on evolutionary data of users can be more effective at expert identification than the models that ignore evolution. We run our experiments on two large online CQA to show the generality of our proposed approach. Copyright {\textcopyright}2012, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
address = {Dublin, Ireland},
author = {Pal, Aditya and Chang, Shuo and Konstan, Joseph A},
booktitle = {Proceedings of the 6th International AAAI Conference on Weblogs and Social Media},
isbn = {978-1-57-735556-4},
month = {jun},
pages = {274--281},
publisher = {AAAI},
title = {{Evolution of experts in question answering communities}},
year = {2012}
}
@book{Breiman:1984tu,
abstract = {The methodology used to construct tree structured rules is the focus of this monograph. Unlike many other statistical procedures, which moved from pencil and paper to calculators, this text's use of trees was unthinkable before computers. Both the practical and theoretical sides have been developed in the authors' study of tree methods. Classification and Regression Trees reflects these two sides, covering the use of trees as a data analysis method, and in a more mathematical framework, proving some of their fundamental properties.},
address = {New York, NY, USA},
author = {Breiman, Leo and Friedman, Jerome H and Olshen, Richard A and Stone, Charles J},
booktitle = {Classification and Regression Trees},
doi = {10.1201/9781315139470},
isbn = {978-1-35-146049-1},
issn = {1661-8564},
pages = {1--358},
publisher = {CRC press},
title = {{Classification and regression trees}},
year = {1984}
}
@techreport{BernersLee:2004vf,
author = {Berners-Lee, Tim and Fielding, Roy and Masinter, Larry},
title = {{Uniform resource identifier (URI): Generic syntax}},
year = {2004}
}
@article{Wachter:2017hx,
abstract = {The aim of this contribution is to analyse the real borderlines of the 'right to explanation' in the GDPR and to discretely distinguish between dif ferent levels of information and of consumers' awareness in the 'black box society. In order to combine transparency and comprehensibility we propose the new concept of algorithm 'legibility'. We argue that a systemic interpretation is needed in this field, since it can be beneficial not only for individuals but also for businesses. This may be an opportunity for auditing algorithms and correcting unknown machine biases, thus similarly enhancing the quality of decision-making outputs. Accordingly, we show how a systemic interpretation of Articles 13-15 and 22 GDPR is necessary, considering in particular that: The threshold of minimum human intervention required so that the decision-making is 'solely' automated (Article 22(1)) can also include nominal human intervention; the envisaged 'significant effects' on individuals (Article 22(1)) can encompass as well marketing manipulation, price discrimination, etc; 'meaningful information' that should be pro-vided to data subjects about the logic, signifi-cance and consequences of decision-making (Article 15(1 )(h){\textgreater}should be read as 'legibility' of 'architecture' and 'implementation' of algorith-mic processing; trade secret protection might limit the right of access of data subjects, but there is a general legal favour for data protection rights that should reduce the impact of trade secrets protection. In addition, we recommend a 'legibility test' that data controllers should perform in order to com-ply with the duty to provide meaningful information about the logic involved in an automated decision-making.},
author = {Malgieri, Gianclaudio and Comand{\'{e}}, Giovanni},
doi = {10.1093/idpl/ipx019},
issn = {2044-4001},
journal = {International Data Privacy Law},
month = {jun},
number = {4},
pages = {243--265},
title = {{Why a right to legibility of automated decision-making exists in the general data protection regulation}},
volume = {7},
year = {2017}
}
@inproceedings{Domingos:1998ug,
abstract = {Occam's razor has been the subject of much controversy. This paper argues that this is partly because it has been interpreted in two quite different ways, the first of which (simplicity is a goal in itself) is essentially correct, while the second (simplicity leads to greater accuracy) is not. The paper reviews the large variety of theoretical arguments and empirical evidence for and against the "second razor", and concludes that the balance is strongly against it. In particular, it builds on the case of (Schaffer, 1993) and (Webb, 1996) by considering additional theoretical arguments and recent empirical evidence that the second razor fails in most domains. A version of the first razor more appropriate to KDD is proposed, and we argue that continuing to apply the second razor risks causing significant opportunities to be missed.},
address = {New York, NY, USA},
author = {Domingos, P},
booktitle = {Proceedings of the 4th International Conference on Knowledge Discovery and Data Mining},
doi = {10.1.1.40.3278},
month = {aug},
pages = {37--43},
publisher = {AAAI},
title = {{Occam's Two Razors: The Sharp and the Blunt}},
year = {1998}
}
@inproceedings{Treude:2011fh,
abstract = {Question and Answer (Q{\&}A) websites, such as Stack Overflow, use social media to facilitate knowledge exchange between programmers and fill archives with millions of entries that contribute to the body of knowledge in software development. Understanding the role of Q{\&}A websites in the documentation landscape will enable us to make recommendations on how individuals and companies can leverage this knowledge effectively. In this paper, we analyze data from Stack Overflow to categorize the kinds of questions that are asked, and to explore which questions are answered well and which ones remain unanswered. Our preliminary findings indicate that Q{\&}A websites are particularly effective at code reviews and conceptual questions. We pose research questions and suggest future work to explore the motivations of programmers that contribute to Q{\&}A websites, and to understand the implications of turning Q{\&}A exchanges into technical mini-blogs through the editing of questions and answers. {\textcopyright}2011 ACM.},
address = {Honolulu, HI, USA},
author = {Treude, Christoph and Barzilay, Ohad and Storey, Margaret Anne},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
doi = {10.1145/1985793.1985907},
isbn = {978-1-45-030445-0},
issn = {0270-5257},
keywords = {q{\&}a,questions,social media,stack overflow},
month = {may},
pages = {804--807},
publisher = {ACM},
title = {{How do programmers ask and answer questions on the web? (NIER track)}},
year = {2011}
}
@inproceedings{Dorn:2010wl,
abstract = {This paper reports on a study of professional web designers and developers. We provide a detailed characterization of their knowledge of fundamental programming concepts elicited through card sorting. Additionally, we present qualitative findings regarding their motivation to learn new concepts and the learning strategies they employ. We find a high level of recognition of basic concepts, but we identify a number of concepts that they do not fully understand, consider difficult to learn, and use infrequently. We also note that their learning process is motivated by work projects and often follows a pattern of trial and error. We conclude with implications for end-user programming researchers. {\textcopyright}2010 ACM.},
address = {Atlanta, GA, USA},
author = {Dorn, Brian and Guzdial, Mark},
booktitle = {Proceedings of the 28th ACM Conference on Human Factors in Computing Systems},
doi = {10.1145/1753326.1753430},
isbn = {978-1-60-558929-9},
keywords = {informal learning,web development},
month = {apr},
pages = {703--712},
publisher = {ACM},
title = {{Learning on the job: Characterizing the programming knowledge and learning strategies of web designers}},
volume = {2},
year = {2010}
}
@book{Japkowicz:2011vy,
abstract = {The field of machine learning has matured to the point where many sophisticated learning approaches can be applied to practical applications. Thus it is of critical importance that researchers have the proper tools to evaluate learning approaches and understand the underlying issues. This book examines various aspects of the evaluation process with an emphasis on classification algorithms. The authors describe several techniques for classifier performance assessment, error estimation and resampling, obtaining statistical significance as well as selecting appropriate domains for evaluation. They also present a unified evaluation framework and highlight how different components of evaluation are both significantly interrelated and interdependent. The techniques presented in the book are illustrated using R and WEKA facilitating better practical insight as well as implementation. Aimed at researchers in the theory and applications of machine learning, this book offers a solid basis for conducting performance evaluations of algorithms in practical settings.},
author = {Japkowicz, Nathalie and Shah, Mohak},
booktitle = {Evaluating Learning Algorithms: A Classification Perspective},
doi = {10.1017/CBO9780511921803},
isbn = {978-0-51-192180-3},
pages = {1--406},
publisher = {Cambridge University Press},
title = {{Evaluating learning algorithms: A classification perspective}},
volume = {9780521196000},
year = {2011}
}
@inproceedings{Choi:2015wo,
abstract = {We present a preliminary investigation of Stack Overflow to reveal practitioner's interests about code clones. We then discuss possible future directions of research on code clones.},
address = {Montreal, QC, Canada},
author = {Choi, Eunjong and Yoshida, Norihiro and Kula, Raula Gaikovina and Inoue, Katsuro},
booktitle = {Proceedings of the 9th International Workshop on Software Clones},
doi = {10.1109/IWSC.2015.7069890},
isbn = {978-1-46-736914-5},
month = {mar},
pages = {49--50},
title = {{What do practitioners ask about code clone? a preliminary investigation of stack overflow}},
year = {2015}
}
@inproceedings{Barnett:2015ut,
abstract = {Modern IDEs provide limited support for developers when starting a new data-driven mobile app. App developers are currently required to write copious amounts of boilerplate code, scripts, organise complex directories, and author actual functionality. Although this scenario is ripe for automation, current tools are yet to address it adequately. In this paper we present RAPPT, a tool that generates the scaffolding of a mobile app based on a high level description specified in a Domain Specific Language (DSL). We demonstrate the feasibility of our approach by an example case study and feedback from a professional development team. Demo at: https://www.youtube.com/watch?v=ffquVgBYpLM.},
address = {Florence, Italy},
author = {Barnett, Scott and Vasa, Rajesh and Grundy, John},
booktitle = {Proceedings of the 37th International Conference on Software Engineering},
doi = {10.1109/ICSE.2015.216},
isbn = {978-1-47-991934-5},
issn = {0270-5257},
keywords = {Code Generation,Mobile App Prototyping,Model Driven Development},
month = {may},
pages = {657--660},
publisher = {IEEE},
title = {{Bootstrapping Mobile App Development}},
volume = {2},
year = {2015}
}
@book{Pham:2000ua,
author = {Pham, Hoang},
edition = {1st},
isbn = {978-1-84-628295-9},
publisher = {Springer},
title = {{System Software Reliability}},
year = {2000}
}
@article{daMotaSilveira:2017vp,
abstract = {This paper brings to light an important discussion on how to create better assistive technologies for visually impaired people with the new advances in the computer vision field. Until very recently, assistive technology solutions required large and expensive hardware, as well as complex software. However, this scenario seems to be changing with web services on cloud that turns available computer vision features, offering image and video content analysis. The challenge is on how the results of these analyses will be processed and which will be the action or interaction displayed afterwards, showing the importance of appropriate user interface to visually impaired.},
author = {{da Mota Silveira}, Henrique and Martini, Luiz C{\'{e}}sar},
doi = {10.20897/jisem.201709},
issn = {2468-4376},
journal = {Journal of Information Systems Engineering {\&} Management},
number = {2},
pages = {1--3},
title = {{How the New Approaches on Cloud Computer Vision can Contribute to Growth of Assistive Technologies to Visually Impaired in the Following Years?}},
volume = {2},
year = {2017}
}
@book{Pressman:2005vf,
author = {Pressman, Roger S},
edition = {8th},
isbn = {978-0-07-802212-8},
publisher = {McGraw-Hill},
title = {{Software Engineering: A Practitioner's Approach}},
year = {2005}
}
@book{Casati:2003vi,
author = {Casati, Fabio and Kuno, Harumi and Alonso, G and Machiraju, V},
isbn = {978-3-64-207888-0},
title = {{Web Services-Concepts, Architectures and Applications}},
year = {2004}
}
@book{Tassey:2002vu,
abstract = {N/A},
author = {Tassey, Gregory},
booktitle = {National Institute of Standards and Technology (NIST)},
doi = {10.1080/10438590500197315},
month = {sep},
publisher = {National Institute of Standards and Technology},
title = {{The economic impacts of inadequate infrastructure for software testing}},
year = {2002}
}
@inproceedings{Iyengar:2017fb,
abstract = {A wide variety of services are available over the Web which can dramatically improve the functionality of applications. These services include information retrieval (including data lookups from a variety of sources and Web searches), natural language understanding, visual recognition, and data storage. A key problem is how to provide support for applications which use these services. This paper presents a rich software development kit (SDK) which accesses these services and provides a variety of features applications need to use these services, optimize performance, and compare them. A key aspect of our SDK is its support for natural language understanding services. We also present a personalized knowledge base built on top of our rich SDK that uses publically available data sources as well as private information. The knowledge base supports data analysis and reasoning over data.},
address = {Atlanta, GA, USA},
author = {Iyengar, Arun},
booktitle = {Proceedings of the 37th International Conference on Distributed Computing Systems},
doi = {10.1109/ICDCS.2017.172},
isbn = {978-1-53-861791-5},
keywords = {Cloud client,Cloud service ranking,Cognitive client,Cognitive services,Service ranking,Software development kit},
month = {jun},
pages = {1856--1864},
publisher = {IEEE},
title = {{Supporting Data Analytics Applications Which Utilize Cognitive Services}},
year = {2017}
}
@book{Sommerville:2011uc,
author = {Sommerville, Ian},
edition = {9th},
isbn = {978-0-13-703515-1},
publisher = {Addison-Wesley},
title = {{Software Engineering}},
year = {2011}
}
@inproceedings{Curumsing:2020semotion,
address = {Seoul, Republic of Korea},
author = {Curumsing, Maheshwaree Kissoon and Cummaudo, Alex and Graestch, Ulrike Maria and Barnett, Scott and Vasa, Rajesh},
booktitle = {Proceedings of the 5th International Workshop on Emotion Awareness in Software Engineering},
keywords = {InReview},
mendeley-tags = {InReview},
month = {may},
title = {{Ranking Computer Vision Service Issues using Emotion}},
year = {2020}
}
@book{Weerawarana:2005wx,
abstract = {``Other books claim to present the complete Web services platform architecture, but this is the first one I've seen that really does. The authors have been intimately involved in the creation of the architecture. Who better to write this book?'' - Anne Thomas Manes, Vice President and Research Director, Burton Group ``This is a very important book, providing a lot of technical detail and background that very few (if any) other books will be able to provide. The list of authors includes some of the top experts in the various specifications covered, and they have done an excellent job explaining the background motivation for and pertinent details of each specification. The benefit of their perspectives and collective expertise alone make the book worth reading.'' - Eric Newcomer, CTO, IONA Technologies},
author = {Weerawarana, Sanjiva and Curbera, Francisco and Leymann, Frank and Storey, Tony and Ferguson, Donald F},
booktitle = {Web Services Platform Archecture},
isbn = {0-13-148874-0},
pages = {456},
publisher = {Prentice-Hall},
title = {{Web Services Platform Architecture}},
year = {2005}
}
@book{Wohlin:2012bu,
abstract = {Like other sciences and engineering disciplines, software engineering requires a cycle of model building, experimentation, and learning. Experiments are valuable tools for all software engineers who are involved in evaluating and choosing between different methods, techniques, languages and tools. The purpose of Experimentation in Software Engineering is to introduce students, teachers, researchers, and practitioners to empirical studies in software engineering, using controlled experiments. The introduction to experimentation is provided through a process perspective, and the focus is on the steps that we have to go through to perform an experiment. The book is divided into three parts. The first part provides a background of theories and methods used in experimentation. Part II then devotes one chapter to each of the five experiment steps: scoping, planning, execution, analysis, and result presentation. Part III completes the presentation with two examples. Assignments and statistical material are provided in appendixes. Overall the book provides indispensable information regarding empirical studies in particular for experiments, but also for case studies, systematic literature reviews, and surveys. It is a revision of the authors' book, which was published in 2000. In addition, substantial new material, e.g. concerning systematic literature reviews and case study research, is introduced. The book is self-contained and it is suitable as a course book in undergraduate or graduate studies where the need for empirical studies in software engineering is stressed. Exercises and assignments are included to combine the more theoretical material with practical aspects. Researchers will also benefit from the book, learning more about how to conduct empirical studies, and likewise practitioners may use it as a "cookbook" when evaluating new methods or techniques before implementing them in their organization.},
address = {Berlin, Heidelberg},
author = {Wohlin, Claes and Runeson, Per and H{\"{o}}st, Martin and Ohlsson, Magnus C and Regnell, Bj{\"{o}}rn and Wessl{\'{e}}n, Anders},
doi = {10.1007/978-3-642-29044-2},
isbn = {978-3-64-229044-2},
issn = {0098-5589},
publisher = {Springer},
title = {{Experimentation in Software Engineering}},
year = {2012}
}
@inproceedings{Boehm:1978vv,
abstract = {The study reported in this paper establishes a conceptual framework and some key initial results in the analysis of the characteristics of software quality. Its main results and conclusions are: • Explicit attention to characteristics of software quality can lead to significant savings in software life-cycle costs. • The current software state-of-the-art imposes specific limitations on our ability to automatically and quantitatively evaluate the quality of software. • A definitive hierarchy of well-defined, well-differentiated characteristics of software quality is developed. Its higher-level structure reflects the actual uses to which software quality evaluation would be put; its lower-level characteristics are closely correlated with actual software metric evaluations which can be performed. • A large number of software quality-evaluation metrics have been defined, classified, and evaluated with respect to their potential benefits, quantifiability, and ease of automation. • Particular software life-cycle activities have been identified which have significant leverage on software quality. Most importantly, we believe that the study reported in this paper provides for the first time a clear, well-defined framework for assessing the often slippery issues associated with software quality, via the consistent and mutually supportive sets of definitions, distinctions, guidelines, and experiences cited. This framework is certainly not complete, but it has been brought to a point sufficient to serve as a viable basis for future refinements and extensions.},
address = {San Francisco, California, USA},
author = {Boehm, B W and Brown, J R and Lipow, M},
booktitle = {Proceedings of the 2nd International Conference on Software Engineering},
issn = {0270-5257},
keywords = {Management by objectives,Quality assurance,Quality characteristics,Quality metrics,Software engineering,Software measurement and evaluation,Software quality,Software reliability,Software standards,Testing},
month = {oct},
pages = {592--605},
publisher = {IEEE Computer Society Press},
title = {{Quantitative evaluation of software quality}},
year = {1976}
}
@article{murphy2007approach,
abstract = {Some machine learning applications are intended to learn properties of data sets where the correct answers are not already known to human users. It is challenging to test such ML software, because there is no reliable test oracle. We describe a software testing approach aimed at addressing this problem. We present our findings from testing implementations of two different ML ranking algorithms: Support Vector Machines and Marti Rank. Copyright {\textcopyright}(2007) by Knowledge Systems Institute (KSI).},
address = {Boston, MA, USA},
author = {Murphy, Christian and Kaiser, Gail and Arias, Marta},
isbn = {978-1-62-748661-3},
journal = {Proceedings of the 19th International Conference on Software Engineering and Knowledge Engineering},
month = {jul},
pages = {167--172},
title = {{An approach to software testing of machine learning applications}},
year = {2007}
}
@article{996017,
abstract = {Multiobjective evolutionary algorithms (EAs) that use nondominated sorting and sharing have been criticized mainly for their: 1) O(MN3) computational complexity (where M is the number of objectives and N is the population size); 2) nonelitism approach; and 3) the need for specifying a sharing parameter. In this paper, we suggest a nondominated sorting-based multiobjective EA (MOEA), called nondominated sorting genetic algorithm II (NSGA-II), which alleviates all the above three difficulties. Specifically, a fast nondominated sorting approach with O(MN2) computational complexity is presented. Also, a selection operator is presented that creates a mating pool by combining the parent and offspring populations and selecting the best (with respect to fitness and spread) N solutions. Simulation results on difficult test problems show that the proposed NSGA-II, in most problems, is able to find much better spread of solutions and better convergence near the true Pareto-optimal front compared to Pareto-archived evolution strategy and strength-Pareto EA - two other elitist MOEAs that pay special attention to creating a diverse Pareto-optimal front. Moreover, we modify the definition of dominance in order to solve constrained multiobjective problems efficiently. Simulation results of the constrained NSGA-II on a number of test problems, including a five-objective seven-constraint nonlinear problem, are compared with another constrained multiobjective optimizer and much better performance of NSGA-II is observed.},
author = {Deb, Kalyanmoy and Pratap, Amrit and Agarwal, Sameer and Meyarivan, T},
doi = {10.1109/4235.996017},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Constraint handling,Elitism,Genetic algorithms,Multicriterion decision making,Multiobjective optimization,Pareto-optimal solutions},
month = {apr},
number = {2},
pages = {182--197},
title = {{A fast and elitist multiobjective genetic algorithm: NSGA-II}},
volume = {6},
year = {2002}
}
@inproceedings{Wang:2018vl,
abstract = {Transfer learning is a powerful approach that allows users to quickly build accurate deep-learning (Student) models by "learning" from centralized (Teacher) models pretrained with large datasets, e.g. Google's Inception V3. We hypothesize that the centralization of model training increases their vulnerability to misclas-sification attacks leveraging knowledge of publicly accessible Teacher models. In this paper, we describe our efforts to understand and experimentally validate such attacks in the context of image recognition. We identify techniques that allow attackers to associate Student models with their Teacher counterparts, and launch highly effective misclassification attacks on black-box Student models. We validate this on widely used Teacher models in the wild. Finally, we propose and evaluate multiple approaches for defense, including a neuron-distance technique that successfully defends against these attacks while also obfuscates the link between Teacher and Student models.},
address = {Baltimore, MD, USA},
author = {Wang, Bolun and Yao, Yuanshun and Viswanath, Bimal and Zheng, Haitao and Zhao, Ben Y},
booktitle = {Proceedings of the 27th USENIX Security Symposium},
isbn = {978-1-93-913304-5},
month = {jul},
pages = {1281--1297},
publisher = {USENIX Association},
title = {{With great training comes great vulnerability: Practical attacks against transfer learning}},
year = {2018}
}
@article{Lavrac:1999tf,
abstract = {Widespread use of medical information systems and explosive growth of medical databases require traditional manual data analysis to be coupled with methods for efficient computer-assisted analysis. This paper presents selected data mining techniques that can be applied in medicine, and in particular some machine learning techniques including the mechanisms that make them better suited for the analysis of medical databases (derivation of symbolic rules, use of background knowledge, sensitivity and specificity of induced descriptions). The importance of the interpretability of results of data analysis is discussed and illustrated on selected medical applications.},
author = {Lavra{\v{c}}, Nada},
doi = {10.1016/S0933-3657(98)00062-1},
issn = {0933-3657},
journal = {Artificial Intelligence in Medicine},
keywords = {Data mining,Machine learning,Medical applications},
number = {1},
pages = {3--23},
pmid = {10225344},
title = {{Selected techniques for data mining in medicine}},
volume = {16},
year = {1999}
}
@article{Freitas:2004vv,
abstract = {This paper addresses the problem of how to evaluate the quality of a model built from the data in a multi-objective optimization scenario, where two or more quality criteria must be simultaneously optimized. A typical example is a scenario where one wants to maximize both the accuracy and the simplicity of a classification model or a candidate attribute subset in attribute selection. One reviews three very different approaches to cope with this problem, namely: (a) transforming the original multi-objective problem into a single-objective problem by using a weighted formula; (b) the lexicographical approach, where the objectives are ranked in order of priority; and (c) the Pareto approach, which consists of finding as many non-dominated solutions as possible and returning the set of non-dominated solutions to the user. One also presents a critical review of the case for and against each of these approaches. The general conclusions are that the weighted formula approach -- which is by far the most used in the data mining literature -- is to a large extent an ad-hoc approach for multi-objective optimization, whereas the lexicographic and the Pareto approach are more principled approaches, and therefore deserve more attention from the data mining community.},
author = {Freitas, Alex A},
doi = {10.1145/1046456.1046467},
issn = {1931-0145},
journal = {ACM SIGKDD Explorations Newsletter},
number = {2},
pages = {77},
title = {{A critical review of multi-objective optimization in data mining}},
volume = {6},
year = {2004}
}
@article{DoshiVelez:2017vm,
abstract = {The ubiquity of systems using artificial intelligence or "AI" has brought increasing attention to how those systems should be regulated. The choice of how to regulate AI systems will require care. AI systems have the potential to synthesize large amounts of data, allowing for greater levels of personalization and precision than ever before|applications range from clinical decision support to autonomous driving and predictive policing. That said, common sense reasoning [McCarthy, 1960] remains one of the holy grails of AI, and there exist legitimate concerns about the intentional and unintentional negative consequences of AI systems [Bostrom, 2003, Amodei et al., 2016, Sculley et al., 2014]. There are many ways to hold AI systems accountable. In this work, we focus on one: explanation. Questions about a legal right to explanation from AI systems was recently debated in the EU General Data Protection Regulation [Goodman and Flaxman, 2016, Wachter et al., 2017], and thus thinking carefully about when and how explanation from AI systems might improve accountability is timely. Good choices about when to demand explanation can help prevent negative consequences from AI systems, while poor choices may not only fail to hold AI systems accountable but also hamper the development of much-needed beneficial AI systems. Below, we briefly review current societal, moral, and legal norms around explanation, and then focus on the different contexts under which explanation is currently required under the law. We find that there exists great variation around when explanation is demanded, but there also exists important consistencies: when demanding explanation from humans, what we typically want to know is how and whether certain input factors affected the final decision or outcome. These consistencies allow us to list the technical considerations that must be considered if we desired AI systems that could provide kinds of explanations that are currently required of humans under the law. Contrary to popular wisdom of AI systems as indecipherable black boxes, we find that this level of explanation should often be technically feasible but may sometimes be practically onerous|there are certain aspects of explanation that may be simple for humans to provide but challenging for AI systems, and vice versa. As an interdisciplinary team of legal scholars, computer scientists, and cognitive scientists, we recommend that for the present, AI systems can and should be held to a similar standard of explanation as humans currently are; in the future we may wish to hold an AI to a different standard.},
archivePrefix = {arXiv},
arxivId = {1711.01134},
author = {Doshi-Velez, Finale and Kortz, Mason and Budish, Ryan and Bavitz, Christopher and Gershman, Samuel J and O'Brien, David and Shieber, Stuart and Waldo, Jim and Weinberger, David and Wood, Alexandra},
doi = {10.2139/ssrn.3064761},
eprint = {1711.01134},
journal = {SSRN Electronic Journal},
month = {nov},
title = {{Accountability of AI Under the Law: The Role of Explanation}},
year = {2017}
}
@article{Canfora:2006vk,
author = {Canfora, Gerardo and {Di Penta}, Massimiliano},
doi = {10.1109/MITP.2006.51},
issn = {1520-9202},
journal = {IT Professional},
number = {2},
pages = {10--17},
title = {{Testing services and service-centric systems: Challenges and opportunities}},
volume = {8},
year = {2006}
}
@article{Usman:2017hn,
abstract = {Context: Software Engineering (SE) is an evolving discipline with new subareas being continuously developed and added. To structure and better understand the SE body of knowledge, taxonomies have been proposed in all SE knowledge areas. Objective: The objective of this paper is to characterize the state-of-the-art research on SE taxonomies. Method: A systematic mapping study was conducted, based on 270 primary studies. Results: An increasing number of SE taxonomies have been published since 2000 in a broad range of venues, including the top SE journals and conferences. The majority of taxonomies can be grouped into the following SWEBOK knowledge areas: construction (19.55{\%}), design (19.55{\%}), requirements (15.50{\%}) and maintenance (11.81{\%}). Illustration (45.76{\%}) is the most frequently used approach for taxonomy validation. Hierarchy (53.14{\%}) and faceted analysis (39.48{\%}) are the most frequently used classification structures. Most taxonomies rely on qualitative procedures to classify subject matter instances, but in most cases (86.53{\%}) these procedures are not described in sufficient detail. The majority of the taxonomies (97{\%}) target unique subject matters and many taxonomy-papers are cited frequently. Most SE taxonomies are designed in an ad-hoc way. To address this issue, we have revised an existing method for developing taxonomies in a more systematic way. Conclusion: There is a strong interest in taxonomies in SE, but few taxonomies are extended or revised. Taxonomy design decisions regarding the used classification structures, procedures and descriptive bases are usually not well described and motivated.},
author = {Usman, Muhammad and Britto, Ricardo and B{\"{o}}rstler, J{\"{u}}rgen and Mendes, Emilia},
doi = {10.1016/j.infsof.2017.01.006},
issn = {0950-5849},
journal = {Information and Software Technology},
keywords = {Classification,Software engineering,Systematic mapping study,Taxonomy},
month = {may},
pages = {43--59},
title = {{Taxonomies in software engineering: A Systematic mapping study and a revised taxonomy development method}},
volume = {85},
year = {2017}
}
@article{Fung:2005we,
author = {Fung, Glenn and Sandilya, Sathyakama and Rao, R Bharat},
doi = {10.1007/978-3-540-75390-2_4},
journal = {Studies in Computational Intelligence},
number = {1},
pages = {83--107},
publisher = {Springer},
title = {{Rule extraction from linear support vector machines}},
volume = {80},
year = {2009}
}
@book{Calhoun:1995ww,
author = {Alway, Joan and Calhoun, Craig},
booktitle = {Contemporary Sociology},
doi = {10.2307/2076647},
issn = {0094-3061},
number = {1},
pages = {119--120},
publisher = {American Sociological Association},
title = {{Critical Social Theory: Culture, History, and the Challenge of Difference.}},
volume = {26},
year = {1997}
}
@article{5416726,
abstract = {BACKGROUND-The systematic review is becoming a more commonly employed research instrument in empirical software engineering. Before undue reliance is placed on the outcomes of such reviews it would seem useful to consider the robustness of the approach in this particular research context. OBJECTIVE-The aim of this study is to assess the reliability of systematic reviews as a research instrument. In particular, we wish to investigate the consistency of process and the stability of outcomes. METHOD-We compare the results of two independent reviews undertaken with a common research question. RESULTS-The two reviews find similar answers to the research question, although the means of arriving at those answers vary. CONCLUSIONS-In addressing a well-bounded research question, groups of researchers with similar domain experience can arrive at the same review outcomes, even though they may do so in different ways. This provides evidence that, in this context at least, the systematic review is a robust research method. {\textcopyright}2010 IEEE.},
author = {MacDonell, Stephen and Shepperd, Martin and Kitchenham, Barbara and Mendes, Emilia},
doi = {10.1109/TSE.2010.28},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Empirical software engineering,cost estimation,meta-analysis,systematic review},
month = {sep},
number = {5},
pages = {676--687},
title = {{How reliable are systematic reviews in empirical software engineering?}},
volume = {36},
year = {2010}
}
@article{Jiang:2005ua,
abstract = {Background: Determining the functions of uncharacterized proteins is one of the most pressing problems in the post-genomic era. Large scale protein-protein interaction assays, global mRNA expression analyses and systematic protein localization studies provide experimental information that can be used for this purpose. The data from such experiments contain many false positives and false negatives, but can be processed using computational methods to provide reliable information about protein-protein relationships and protein function. An outstanding and important goal is to predict detailed functional annotation for all uncharacterized proteins that is reliable enough to effectively guide experiments. Results: We present AVID, a computational method that uses a multi-stage learning framework to integrate experimental results with sequence information, generating networks reflecting functional similarities among proteins. We illustrate use of the networks by making predictions of detailed Gene Ontology (GO) annotations in three categories: molecular function, biological process, and cellular component. Applied to the yeast Saccharomyces cerevisiae, AVID provides 37,451 pair-wise functional linkages between 4,191 proteins. These relationships are ∼65-78{\%} accurate, as assessed by cross-validation testing. Assignments of highly detailed functional descriptors to proteins, based on the networks, are estimated to be ∼67{\%} accurate for GO categories describing molecular function and cellular component and ∼52{\%} accurate for terms describing biological process. The predictions cover 1,490 proteins with no previous annotation in GO and also assign more detailed functions to many proteins annotated only with less descriptive terms. Predictions made by AVID are largely distinct from those made by other methods. Out of 37,451 predicted pair-wise relationships, the greatest number shared in common with another method is 3,413. Conclusions: AVID provides three networks reflecting functional associations among proteins. We use these networks to generate new, highly detailed functional predictions for roughly half of the yeast proteome that are reliable enough to drive targeted experimental investigations. The predictions suggest many specific, testable hypotheses. All of the data are available as downloadable files as well as through an interactive website at http://bmc-140.mit.edu/avid. Thus, AVID will be a valuable resource for experimental biologists. {\textcopyright}2005 Jiang and Keating, licensee BioMed Central Ltd.},
author = {Jiang, Taijiao and Keating, Amy E},
doi = {10.1186/1471-2105-6-136},
issn = {1471-2105},
journal = {BMC Bioinformatics},
number = {1},
pages = {136},
title = {{AVID: An integrative framework for discovering functional relationship among proteins}},
volume = {6},
year = {2005}
}
@inproceedings{Ko:2011fb,
abstract = {While many studies have investigated the challenges that developers face in finding and using API documentation, few have considered the role of developers' conceptual knowledge in these tasks. We designed a study in which developers were asked to explore the feasibility of two requirements concerning networking protocols and application platforms that most participants were unfamiliar with, observing the effect that a lack of conceptual knowledge had on their use of documentation. Our results show that without conceptual knowledge, developers struggled to formulate effective queries and to evaluate the relevance or meaning of content they found. Our results suggest that API documentation should not only include detailed examples of API use, but also thorough introductions to the concepts, standards, and ideas manifested in an API's data structures and functionality. {\textcopyright}2011 IEEE.},
address = {Pitts},
author = {Ko, Andrew J and Riche, Yann},
booktitle = {Proceedings of the 2011 IEEE Symposium on Visual Languages and Human Centric Computing},
doi = {10.1109/VLHCC.2011.6070395},
isbn = {978-1-45-771245-6},
keywords = {API usability,documentation,feasibility},
month = {sep},
pages = {173--176},
publisher = {IEEE},
title = {{The role of conceptual knowledge in API usability}},
year = {2011}
}
@inproceedings{Foster:2003ur,
abstract = {In this paper, we discuss a model-based approach to verifying Web service compositions for Web service implementations. The approach supports verification against specification models and assigns semantics to the behavior of implementation model so as to confirm expected results for both the designer and implementer. Specifications of the design are modeled in UML (Unified Modeling Language), in the form of message sequence charts (MSC), and mechanically compiled into the finite state process notation (FSP) to concisely describe and reason about the concurrent programs. Implementations are mechanically translated to FSP to allow a trace equivalence verification process to be performed. By providing early design verification, the implementation, testing, and deployment of Web service compositions can be eased through the understanding of the differences, limitations and undesirable traces allowed by the composition. The approach is supported by a suite of cooperating tools for specification, formal modeling and trace animation of the composition workflow.},
address = {Linz, Austria},
author = {Foster, H and Uchitel, S and Magee, J and Kramer, J},
booktitle = {Proceedings of the 18th International Conference on Automated Software Engineering},
doi = {10.1109/ase.2003.1240303},
month = {sep},
pages = {152--161},
publisher = {IEEE},
title = {{Model-based verification of Web service compositions}},
year = {2004}
}
@inproceedings{4659256,
abstract = {Change is an essential characteristic of software development, as software systems must respond to evolving requirements, platforms, and other environmental pressures. In this paper, we discuss the concept of software evolution from several perspectives. We examine how it relates to and differs from software maintenance. We discuss insights about software evolution arising from Lehman's laws of software evolution and the staged lifecycle model of Bennett and Rajlich. We compare software evolution to other kinds of evolution, from science and social sciences, and we examine the forces that shape change. Finally, we discuss the changing nature of software in general as it relates to evolution, and we propose open challenges and future directions for software evolution research. {\textcopyright}2008 IEEE.},
address = {Beijing, China},
author = {Godfrey, Michael W and German, Daniel M},
booktitle = {Proceedings of the 2008 Frontiers of Software Maintenance},
doi = {10.1109/FOSM.2008.4659256},
isbn = {978-1-42-442655-3},
keywords = {software development management,software maintenan},
month = {oct},
pages = {129--138},
title = {{The past, present, and future of software evolution}},
year = {2008}
}
@article{Cummaudo:2020jss,
author = {Cummaudo, Alex and Vasa, Rajesh and Grundy, John},
journal = {Journal of Systems and Software},
keywords = {InReview},
mendeley-tags = {InReview},
title = {{Assessing the efficacy of API documentation knowledge against practitioners and computer vision services}},
year = {2020}
}
@book{Bramer:2007vg,
address = {London, England, UK},
author = {Bramer, Max},
doi = {10.1007/978-1-4471-7307-6},
isbn = {978-1-44-717306-9},
publisher = {Springer},
series = {Undergraduate Topics in Computer Science},
title = {{Principles of Data Mining}},
volume = {180},
year = {2016}
}
@book{demeyer2008software,
abstract = {Software has become omnipresent and vital in our information-based society, so all software producers should assume responsibility for its reliability. While "reliable" originally assumed implementations that were effective and mainly error-free, additional issues like adaptability and maintainability have gained equal importance recently. For example, the 2004 ACM/IEEE Software Engineering Curriculum Guidelines list software evolution as one of ten key areas of software engineering education.Mens and Demeyer, both international authorities in the field of software evolution, together with the invited contributors, focus on novel trends in software evolution research and its relations with other emerging disciplines such as model-driven software engineering, service-oriented software development, and aspect-oriented software development. They do not restrict themselves to the evolution of source code but also address the evolution of other, equally important software artifacts such as databases and database schemas, design models, software architectures, and process management. The contributing authors provide broad overviews of related work, and they also contribute to a comprehensive glossary, a list of acronyms, and a list of books, journals, websites, standards and conferences that together represent the community's body of knowledge. Combining all these features, this book is the indispensable source for researchers and professionals looking for an introduction and comprehensive overview of the state of the art. In addition, it is an ideal basis for an advanced course on software evolution. {\textcopyright}Springer-Verlag Berlin Heidelberg 2008.},
address = {Berlin, Heidelberg},
author = {Mens, Tom and Demeyer, Serge},
doi = {10.1007/978-3-540-76440-3},
isbn = {978-3-54-076439-7},
publisher = {Springer},
title = {{Software Evolution}},
year = {2008}
}
@article{Huysmans:2011gq,
abstract = {An important objective of data mining is the development of predictive models. Based on a number of observations, a model is constructed that allows the analysts to provide classifications or predictions for new observations. Currently, most research focuses on improving the accuracy or precision of these models and comparatively little research has been undertaken to increase their comprehensibility to the analyst or end-user. This is mainly due to the subjective nature of 'comprehensibility', which depends on many factors outside the model, such as the user's experience and his/her prior knowledge. Despite this influence of the observer, some representation formats are generally considered to be more easily interpretable than others. In this paper, an empirical study is presented which investigates the suitability of a number of alternative representation formats for classification when interpretability is a key requirement. The formats under consideration are decision tables, (binary) decision trees, propositional rules, and oblique rules. An end-user experiment was designed to test the accuracy, response time, and answer confidence for a set of problem-solving tasks involving the former representations. Analysis of the results reveals that decision tables perform significantly better on all three criteria, while post-test voting also reveals a clear preference of users for decision tables in terms of ease of use. {\textcopyright}2010 Elsevier B.V. All rights reserved.},
author = {Huysmans, Johan and Dejaeger, Karel and Mues, Christophe and Vanthienen, Jan and Baesens, Bart},
doi = {10.1016/j.dss.2010.12.003},
issn = {0167-9236},
journal = {Decision Support Systems},
keywords = {Classification,Comprehensibility,Data mining,Decision tables,Knowledge representation},
month = {apr},
number = {1},
pages = {141--154},
title = {{An empirical evaluation of the comprehensibility of decision table, tree and rule based predictive models}},
volume = {51},
year = {2011}
}
@article{Sun:2010ut,
abstract = {Null hypothesis significance testing has dominated quantitative research in education and psychology. However, the statistical significance of a test as indicated by a p-value does not speak to the practical significance of the study. Thus, reporting effect size to supplement p-value is highly recommended by scholars, journal editors, and academic associations. As a measure of practical significance, effect size quantifies the size of mean differences or strength of associations and directly answers the research questions. Furthermore, a comparison of effect sizes across studies facilitates meta-analytic assessment of the effect size and accumulation of knowledge. In the current comprehensive review, we investigated the most recent effect size reporting and interpreting practices in 1,243 articles published in 14 academic journals from 2005 to 2007. Overall, 49{\%} of the articles reported effect size-57{\%} of which interpreted effect size. As an empirical study for the sake of good research methodology in education and psychology, in the present study we provide an illustrative example of reporting and interpreting effect size in a published study. Furthermore, a 7-step guideline for quantitative researchers is also summarized along with some recommended resources on how to understand and interpret effect size. {\textcopyright}2010 American Psychological Association.},
author = {Sun, Shuyan and Pan, Wei and Wang, Lihshing Leigh},
doi = {10.1037/a0019507},
issn = {0022-0663},
journal = {Journal of Educational Psychology},
keywords = {Confidence intervals,Effect size,NHST,Practical significance,Statistical significance},
number = {4},
pages = {989--1004},
title = {{A Comprehensive Review of Effect Size Reporting and Interpreting Practices in Academic Journals in Education and Psychology}},
volume = {102},
year = {2010}
}
@inproceedings{Mitchell:2018in,
abstract = {Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type [15]) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model. To solidify the concept, we provide cards for two supervised models: One trained to detect smiling faces in images, and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related artificial intelligence technology, increasing transparency into how well artificial intelligence technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation.},
address = {Atlanta, GA, USA},
archivePrefix = {arXiv},
arxivId = {1810.03993},
author = {Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
booktitle = {Proceedings of the 2nd Conference on Fairness, Accountability, and Transparency},
doi = {10.1145/3287560.3287596},
eprint = {1810.03993},
isbn = {978-1-45-036125-5},
keywords = {Datasheets,Disaggregated evaluation,Documentation,Ethical considerations,Fairness evaluation,ML model evaluation,Model cards},
month = {jan},
pages = {220--229},
publisher = {ACM},
title = {{Model cards for model reporting}},
year = {2019}
}
@inproceedings{Hou:2013jf,
abstract = {Text categorization, automatically labeling natural language text with pre-defined semantic categories, is an essential task for managing the abundant online data. An example of such data in Software Engineering is the large, ever-growing volume of forum discussions on how to use particular APIs. We have conducted a study to explore the question as to how well machine learning algorithms can be applied to categorize API discussions based on their content. Our goal is two-fold: (1) Can a relatively straightforward algorithm such as Naive Bayes work sufficiently well for this task? (2) If yes, how can we control its performance? We have achieved the best test accuracy mean (TAM) of 94.1{\%} with our largest training data set for the AWT/Swing API, which consists of 833 forum discussions distributed over eight categories/topics. We have also investigated factors that impact classification accuracy, with the most important two being the size of the training set and multi-label documents (the phenomenon that some discussions involve more than one category). {\textcopyright}2013 IEEE.},
address = {Eindhoven, Netherlands},
author = {Hou, Daqing and Mo, Lingfeng},
booktitle = {Proceedings of the 29th International Conference on Software Maintenance},
doi = {10.1109/ICSM.2013.17},
keywords = {APIs,AWT/Swing,MALLET,Naive Bayes,Online Forums,Text Categorization},
month = {sep},
pages = {60--69},
publisher = {IEEE},
title = {{Content categorization of API discussions}},
year = {2013}
}
@article{Zahalka:2011ux,
abstract = {A widely persisting interpretation of Occam's razor is that given two classifiers with the same training error, the simpler classifier is more likely to generalize better. Within a long-lasting debate in the machine learning community over Occam's razor, Domingos (Data Min. Knowl. Discov. 3:409-425, 1999) rejects this interpretation and proposes that model complexity is only a confounding factor usually correlated with the number of models from which the learner selects. It is thus hypothesized that the risk of overfitting (poor generalization) follows only from the number of model tests rather than the complexity of the selected model. We test this hypothesis on 30 UCI data sets using polynomial classification models. The results confirm Domingos' hypothesis on the 0.05 significance level and thus refutes the above interpretation of Occam's razor. Our experiments however also illustrate that decoupling the two factors (model complexity and number of model tests) is problematic. {\textcopyright}The Author(s) 2010.},
author = {Zah{\'{a}}lka, Jan and {\v{Z}}elezn{\'{y}}, Filip},
doi = {10.1007/s10994-010-5227-2},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {Empirical evaluation,Generalization,Model complexity},
number = {3},
pages = {475--481},
title = {{An experimental test of Occam's razor in classification}},
volume = {82},
year = {2011}
}
@article{Robillard:2009uk,
abstract = {Most software projects reuse components exposed through APIs, which provide developers access to implemented functionality. APIs have grown large and diverse, which raises questions regarding their usability. This article reports on a study of the obstacles professional developers at Microsoft faced when learning how to use APIs. The study was grounded in developers' experience, collected through a survey and interviews. The resulting data showed that learning resources for APIs are critically important and shed light on three issues: the need to discover the design and rationale of the API when needed, the challenge of finding credible usage API examples at the right level of complexity, and the challenge of understanding inexplicable API behavior. The article describes each of these challenges in detail and discusses associated implications for API users and designers. {\textcopyright}2009 IEEE.},
author = {Robillard, Martin P},
doi = {10.1109/MS.2009.193},
issn = {0740-7459},
journal = {IEEE Software},
keywords = {API design,API usability,Application interfaces,Code examples,Context,Data mining,Documentation,Empirical study,Software documentation,Usability},
number = {6},
pages = {27--34},
title = {{What makes APIs hard to learn? answers from developers}},
volume = {26},
year = {2009}
}
@article{Uddin:2015hn,
abstract = {Formal documentation can be a crucial resource for learning to how to use an API. However, producing high-quality documentation can be nontrivial. Researchers investigated how 10 common documentation problems manifested themselves in practice. The results are based on two surveys of a total of 323 professional software developers and analysis of 179 API documentation units. The three severest problems were ambiguity, incompleteness, and incorrectness of content. The respondents often mentioned six of the 10 problems as 'blockers" that forced them to use another API.},
author = {Uddin, Gias and Robillard, Martin P},
doi = {10.1109/MS.2014.80},
issn = {0740-7459},
journal = {IEEE Software},
keywords = {API,documentation,software development,software engineering,user study},
month = {jun},
number = {4},
pages = {68--75},
title = {{How API Documentation Fails}},
volume = {32},
year = {2015}
}
@misc{ISO25010:2011,
author = {{International Organization for Standardization}},
title = {{ISO25010:2011 - Systems and software engineering -- Systems and software Quality Requirements and Evaluation (SQuaRE) -- System and software quality models}},
year = {2011}
}
@article{Freitas:2010vk,
abstract = {The literature on protein function prediction is currently dominated by works aimed at maximizing predictive accuracy, ignoring the important issues of validation and interpretation of discovered knowledge, which can lead to new insights and hypotheses that are biologically meaningful and advance the understanding of protein functions by biologists. The overall goal of this paper is to critically evaluate this approach, offering a refreshing new perspective on this issue, focusing not only on predictive accuracy but also on the comprehensibility of the induced protein function prediction models. More specifically, this paper aims to offer two main contributions to the area of protein function prediction. First, it presents the case for discovering comprehensible protein function prediction models from data, discussing in detail the advantages of such models, namely, increasing the confidence of the biologist in the system's predictions, leading to new insights about the data and the formulation of new biological hypotheses, and detecting errors in the data. Second, it presents a critical review of the pros and cons of several different knowledge representations that can be used in order to support the discovery of comprehensible protein function prediction models. {\textcopyright}2006 IEEE.},
author = {Freitas, Alex A and Wieser, Daniela C and Apweiler, Rolf},
doi = {10.1109/TCBB.2008.47},
issn = {1545-5963},
journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
keywords = {Biology,Classifier design and evaluation,Induction,Machine learning,Machine learning.},
number = {1},
pages = {172--182},
title = {{On the importance of comprehensible classification models for protein function prediction}},
volume = {7},
year = {2010}
}
@article{EhteshamiBejnordi:2017kq,
abstract = {IMPORTANCE: Application of deep learning algorithms to whole-slide pathology imagescan potentially improve diagnostic accuracy and efficiency. OBJECTIVE: Assess the performance of automated deep learning algorithms at detecting metastases in hematoxylin and eosin-stained tissue sections of lymph nodes of women with breast cancer and compare it with pathologists' diagnoses in a diagnostic setting. DESIGN, SETTING, AND PARTICIPANTS: Researcher challenge competition (CAMELYON16) to develop automated solutions for detecting lymph node metastases (November 2015-November 2016). A training data set of whole-slide images from 2 centers in the Netherlands with (n = 110) and without (n = 160) nodal metastases verified by immunohistochemical staining were provided to challenge participants to build algorithms. Algorithm performance was evaluated in an independent test set of 129 whole-slide images (49 with and 80 without metastases). The same test set of corresponding glass slides was also evaluated by a panel of 11 pathologists with time constraint (WTC) from the Netherlands to ascertain likelihood of nodal metastases for each slide in a flexible 2-hour session, simulating routine pathology workflow, and by 1 pathologist without time constraint (WOTC). EXPOSURES: Deep learning algorithms submitted as part of a challenge competition or pathologist interpretation. MAIN OUTCOMES AND MEASURES: The presence of specific metastatic foci and the absence vs presence of lymph node metastasis in a slide or image using receiver operating characteristic curve analysis. The 11 pathologists participating in the simulation exercise rated their diagnostic confidence as definitely normal, probably normal, equivocal, probably tumor, or definitely tumor. RESULTS: The area under the receiver operating characteristic curve (AUC) for the algorithms ranged from 0.556 to 0.994. The top-performing algorithm achieved a lesion-level, true-positive fraction comparable with that of the pathologist WOTC (72.4{\%} [95{\%} CI, 64.3{\%}-80.4{\%}]) at a mean of 0.0125 false-positives per normal whole-slide image. For the whole-slide image classification task, the best algorithm (AUC, 0.994 [95{\%} CI, 0.983-0.999]) performed significantly better than the pathologists WTC in a diagnostic simulation (mean AUC, 0.810 [range, 0.738-0.884]; P {\textless}.001). The top 5 algorithms had a mean AUC that was comparable with the pathologist interpreting the slides in the absence of time constraints (mean AUC, 0.960 [range, 0.923-0.994] for the top 5 algorithms vs 0.966 [95{\%} CI, 0.927-0.998] for the pathologist WOTC). CONCLUSIONS AND RELEVANCE: In the setting of a challenge competition, some deep learning algorithms achieved better diagnostic performance than a panel of 11 pathologists participating in a simulation exercise designed to mimic routine pathology workflow; algorithm performance was comparable with an expert pathologist interpreting whole-slide images without time constraints. Whether this approach has clinical utility will require evaluation in a clinical setting.},
author = {Bejnordi, Babak Ehteshami and Veta, Mitko and {Van Diest}, Paul Johannes and {Van Ginneken}, Bram and Karssemeijer, Nico and Litjens, Geert and {Van Der Laak}, Jeroen A W M and Hermsen, Meyke and Manson, Quirine F and Balkenhol, Maschenka and Geessink, Oscar and Stathonikos, Nikolaos and {Van Dijk}, Marcory C R F and Bult, Peter and Beca, Francisco and Beck, Andrew H and Wang, Dayong and Khosla, Aditya and Gargeya, Rishab and Irshad, Humayun and Zhong, Aoxiao and Dou, Qi and Li, Quanzheng and Chen, Hao and Lin, Huang Jing and Heng, Pheng Ann and Ha{\ss}, Christian and Bruni, Elia and Wong, Quincy and Halici, Ugur and {\"{O}}ner, Mustafa {\"{U}}mit and Cetin-Atalay, Rengul and Berseth, Matt and Khvatkov, Vitali and Vylegzhanin, Alexei and Kraus, Oren and Shaban, Muhammad and Rajpoot, Nasir and Awan, Ruqayya and Sirinukunwattana, Korsuk and Qaiser, Talha and Tsang, Yee Wah and Tellez, David and Annuscheit, Jonas and Hufnagl, Peter and Valkonen, Mira and Kartasalo, Kimmo and Latonen, Leena and Ruusuvuori, Pekka and Liimatainen, Kaisa and Albarqouni, Shadi and Mungal, Bharti and George, Ami and Demirci, Stefanie and Navab, Nassir and Watanabe, Seiryo and Seno, Shigeto and Takenaka, Yoichi and Matsuda, Hideo and Phoulady, Hady Ahmady and Kovalev, Vassili and Kalinovsky, Alexander and Liauchuk, Vitali and Bueno, Gloria and Fernandez-Carrobles, M Milagro and Serrano, Ismael and Deniz, Oscar and Racoceanu, Daniel and Ven{\^{a}}ncio, Rui},
doi = {10.1001/jama.2017.14585},
issn = {1538-3598},
journal = {JAMA - Journal of the American Medical Association},
month = {dec},
number = {22},
pages = {2199--2210},
pmid = {29234806},
title = {{Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer}},
volume = {318},
year = {2017}
}
@webpage{Jimerson:2017vh,
address = {San Francisco, CA, USA},
author = {Jimerson, Brian and Gregory, Brian},
howpublished = {$\backslash$url{\{}http://bit.ly/2RUBIIL{\}}},
month = {dec},
title = {{Pivotal Cloud Foundry, Google ML, and Spring}},
year = {2017}
}
@article{Venners:2003vw,
author = {Venners, B},
howpublished = {$\backslash$url{\{}https://www.artima.com/intv/contracts.html{\}}},
journal = {Artima Developer},
title = {{Design by Contract: A Conversation with Bertrand Meyer}},
year = {2003}
}
@article{Bellazzi:2008tv,
abstract = {Background: The widespread availability of new computational methods and tools for data analysis and predictive modeling requires medical informatics researchers and practitioners to systematically select the most appropriate strategy to cope with clinical prediction problems. In particular, the collection of methods known as 'data mining' offers methodological and technical solutions to deal with the analysis of medical data and construction of prediction models. A large variety of these methods requires general and simple guidelines that may help practitioners in the appropriate selection of data mining tools, construction and validation of predictive models, along with the dissemination of predictive models within clinical environments. Purpose: The goal of this review is to discuss the extent and role of the research area of predictive data mining and to propose a framework to cope with the problems of constructing, assessing and exploiting data mining models in clinical medicine. Methods: We review the recent relevant work published in the area of predictive data mining in clinical medicine, highlighting critical issues and summarizing the approaches in a set of learned lessons. Results: The paper provides a comprehensive review of the state of the art of predictive data mining in clinical medicine and gives guidelines to carry out data mining studies in this field. Conclusions: Predictive data mining is becoming an essential instrument for researchers and clinical practitioners in medicine. Understanding the main issues underlying these methods and the application of agreed and standardized procedures is mandatory for their deployment and the dissemination of results. Thanks to the integration of molecular and clinical data taking place within genomic medicine, the area has recently not only gained a fresh impulse but also a new set of complex problems it needs to address. {\textcopyright}2006 Elsevier Ireland Ltd. All rights reserved.},
author = {Bellazzi, Riccardo and Zupan, Blaz},
doi = {10.1016/j.ijmedinf.2006.11.006},
issn = {1386-5056},
journal = {International Journal of Medical Informatics},
keywords = {Clinical medicine,Data analysis,Data mining,Data mining process,Predictive models},
number = {2},
pages = {81--97},
title = {{Predictive data mining in clinical medicine: Current issues and guidelines}},
volume = {77},
year = {2008}
}
@inproceedings{Szegedy:2016ws,
abstract = {Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2{\%} top-1 and 5:6{\%} top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3:5{\%} top-5 error and 17:3{\%} top-1 error on the validation set and 3:6{\%} top-5 error on the official test set.},
address = {Las Vegas, NV, USA},
archivePrefix = {arXiv},
arxivId = {1512.00567},
author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
booktitle = {Proceedings of the 2016 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2016.308},
eprint = {1512.00567},
isbn = {978-1-46-738850-4},
issn = {1063-6919},
month = {jun},
pages = {2818--2826},
publisher = {IEEE},
title = {{Rethinking the Inception Architecture for Computer Vision}},
year = {2016}
}
@article{Taylor:1968tq,
author = {Taylor, R S},
doi = {10.5860/crl_29_03_178},
journal = {College and Research Libraries},
number = {3},
title = {{Question-Negotiation and Information Seeking in Libraries}},
volume = {29},
year = {1968}
}
@book{Juristo:2013vj,
abstract = {Basics of Software Engineering Experimentation is a practical guide to experimentation in a field which has long been underpinned by suppositions, assumptions, speculations and beliefs. It demonstrates to software engineers how Experimental Design and Analysis can be used to validate their beliefs and ideas. The book does not assume its readers have an in-depth knowledge of mathematics, specifying the conceptual essence of the techniques to use in the design and analysis of experiments and keeping the mathematical calculations clear and simple. Basics of Software Engineering Experimentation is practically oriented and is specially written for software engineers, all the examples being based on real and fictitious software engineering experiments.},
address = {Boston, MA, USA},
author = {Juristo, Natalia and Moreno, Ana M},
doi = {10.1007/978-1-4757-3304-4},
month = {mar},
publisher = {Springer Science {\&} Business Media},
title = {{Basics of Software Engineering Experimentation}},
year = {2001}
}
@inproceedings{Hosseini:2018jr,
abstract = {Google has recently introduced the Cloud Vision API for image analysis. According to the demonstration website, the API 'quickly classifies images into thousands of categories, detects individual objects and faces within images, and finds and reads printed words contained within images.' It can be also used to 'detect different types of inappropriate content from adult to violent content.' In this paper, we evaluate the robustness of Google Cloud Vision API to input perturbation. In particular, we show that by adding sufficient noise to the image, the API generates completely different outputs for the noisy image, while a human observer would perceive its original content. We show that the attack is consistently successful, by performing extensive experiments on different image types, including natural images, images containing faces and images with texts. For instance, using images from ImageNet dataset, we found that adding an average of 14.25{\%} impulse noise is enough to deceive the API. Our findings indicate the vulnerability of the API in adversarial environments. For example, an adversary can bypass an image filtering system by adding noise to inappropriate images. We then show that when a noise filter is applied on input images, the API generates mostly the same outputs for restored images as for original images. This observation suggests that cloud vision API can readily benefit from noise filtering, without the need for updating image analysis algorithms.},
address = {Cancun, Mexico},
archivePrefix = {arXiv},
arxivId = {1704.05051},
author = {Hosseini, Hossein and Xiao, Baicen and Poovendran, Radha},
booktitle = {Proceedings of the 16th IEEE International Conference on Machine Learning and Applications},
doi = {10.1109/ICMLA.2017.0-172},
eprint = {1704.05051},
isbn = {978-1-53-861417-4},
keywords = {Adversarial machine learning,Google Cloud Vision API,Image Noise,Machine learning},
month = {dec},
pages = {101--105},
publisher = {IEEE},
title = {{Google's cloud vision API is not robust to noise}},
volume = {2017-Decem},
year = {2017}
}
@incollection{OpenSoftwareFoundation:1991vp,
author = {{Open Software Foundation}},
booktitle = {OSF DCE application development guide: revision 1.0},
month = {dec},
publisher = {Prentice Hall},
title = {{Part 3: DCE Remote Procedure Call (RPC)}},
year = {1991}
}
@inproceedings{Piccioni:2013em,
abstract = {Modern software development extensively involves reusing library components accessed through their Application Programming Interfaces (APIs). Usability is therefore a fundamental goal of API design, but rigorous empirical studies of API usability are still relatively uncommon. In this paper, we present the design of an API usability study which combines interview questions based on the cognitive dimensions framework, with systematic observations of programmer behavior while solving programming tasks based on ''tokens''. We also discuss the implementation of the study to assess the usability of a persistence library API (offering functionalities such as storing objects into relational databases). The study involved 25 programmers (including students, researchers, and professionals), and provided additional evidence to some critical features evidenced by related studies, such as the difficulty of finding good names for API features and of discovering relations between API types. It also discovered new issues relevant to API design, such as the impact of flexibility, and confirmed the crucial importance of accurate documentation for usability. {\textcopyright}2013 IEEE.},
address = {Baltimore, MD, USA},
author = {Piccioni, Marco and Furia, Carlo A and Meyer, Bertrand},
booktitle = {Proceedings of the 13th International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2013.14},
issn = {1949-3770},
keywords = {application programming interfaces},
month = {oct},
pages = {5--14},
publisher = {IEEE},
title = {{An empirical study of API usability}},
year = {2013}
}
@inproceedings{Ridgeway:1998ud,
abstract = {Voting methods such as boosting and bagging provide substantial improvements in classification performance in many problem domains. However, the resulting predictions can prove inscrutable to end-users. This is especially problematic in domains such as medicine, where end-user acceptance often depends on the ability of a classifier to explain its reasoning. Here we propose a variant of the boosted na{\"{i}}ve Bayes classifier that facilitates explanations while retaining predictive performance.},
address = {New York, NY, USA},
author = {Ridgeway, Greg and Madigan, David and Richardson, Thomas and O'Kane, John},
booktitle = {Proceedings of the 4th International Conference on Knowledge Discovery and Data Mining},
pages = {101--104},
publisher = {AAAI},
title = {{Interpretable Boosted Na{\"{i}}ve Bayes Classification}},
year = {1998}
}
@techreport{Kitchenham:2007dd,
address = {Keele, UK},
author = {Kitchenham, Barbara and Charters, S},
booktitle = {EBSE Technical Report},
institution = {Software Engineering Group, Keele University and Department of Computer Science, University of Durham},
title = {{Guidelines for performing Systematic Literature Reviews in Software Engineering}},
year = {2007}
}
@article{Martens:2011uh,
abstract = {This paper proposes a complete framework to assess the overall performance of classification models from a user perspective in terms of accuracy, comprehensibility, and justifiability. A review is provided of accuracy and comprehensibility measures, and a novel metric is introduced that allows one to measure the justifiability of classification models. Furthermore, taxonomy of domain constraints is introduced, and an overview of the existing approaches to impose constraints and include domain knowledge in data mining techniques is presented. Finally, justifiability metric is applied to a credit scoring and customer churn prediction case. {\textcopyright}2011 Elsevier B.V. All rights reserved.},
author = {Martens, David and Vanthienen, Jan and Verbeke, Wouter and Baesens, Bart},
doi = {10.1016/j.dss.2011.01.013},
issn = {0167-9236},
journal = {Decision Support Systems},
keywords = {Classification,Comprehensibility,Data mining,Justifiability,Metrics},
number = {4},
pages = {782--793},
title = {{Performance of classification models from a user perspective}},
volume = {51},
year = {2011}
}
@inproceedings{Nybom:2018ef,
abstract = {Background: Application Programming Interfaces (APIs) are key to software reuse. Software developers can link functionality and behaviour found in other software with their own software by taking an API into use. However, figuring out how an API works is usually demanding, and may require that the developers spend a notable amount of time familiarizing themselves with the API. Good API documentation is of key importance to simplify this task. Objective: To present a comprehensive, unbiased overview of the state-of-the-art on tools and approaches for API documentation generation. Method: A systematic mapping study on published tools and approaches that can be used for generating API documentation, or for assisting in the API documentation process. Results: 36 studies on API documentation generation tools and approaches analyzed and categorized in a variety of ways. Among other things, the paper presents an overview of what kind of tools have been developed, what kind of documentation they generate, and what sources the documentation approaches require. Conclusion: Out of the identified approaches, many contribute to API documentation in the areas of natural language documentation and code examples and templates. Many of the approaches contribute to ease API users' understanding and learning of the API, but also to the maintenance and generation of API documentation. Most of the approaches are automatic, simplifying the API documentation generation notably, under the assumption that relevant sources for the generation are available. Most of the API documentation approaches are evaluated either by exercise of the approach followed by analysis of the results, or by empirical evaluation methods.},
address = {Prague, Czech Republic},
author = {Nybom, Kristian and Ashraf, Adnan and Porres, Ivan},
booktitle = {Proceedings of the 44th Euromicro Conference on Software Engineering and Advanced Applications},
doi = {10.1109/SEAA.2018.00081},
isbn = {978-1-53-867382-9},
keywords = {API,API documentation,Systematic mapping study},
month = {aug},
pages = {462--469},
publisher = {IEEE},
title = {{A systematic mapping study on API documentation generation approaches}},
year = {2018}
}
@inproceedings{Ribeiro:2016gg,
address = {San Francisco, CA, USA},
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {2939672.2939778},
month = {aug},
pages = {1135--1144},
publisher = {ACM Press},
title = {{`Why Should I Trust You?': Explaining the Predictions of Any Classifier}},
year = {2016}
}
@techreport{murphy2008improving,
abstract = {—As machine learning (ML) applications become prevalent in various aspects of everyday life, their dependability takes on increasing importance. It is challenging to test such applications, however, because they are intended to learn properties of data sets where the correct answers are not already known. Our work is not concerned with testing how well an ML algorithm learns, but rather seeks to ensure that an application using the algorithm implements the specification correctly and fulfills the users' expectations. These are critical to ensuring the application's dependability. This paper presents three approaches to testing these types of applications. In the first, we create a set of limited test cases for which it is, in fact, possible to predict what the correct output should be. In the second approach, we use random testing to generate large data sets according to parameterization based on the application's equivalence classes. Our third approach is based on metamorphic testing, in which properties of the application are exploited to define transformation functions on the input, such that the new output can easily be predicted based on the original output. Here we discuss these approaches, and our findings from testing the dependability of three real-world ML applications.},
address = {New York, NY, USA},
author = {Murphy, Christian and Kaiser, Gail},
doi = {10.7916/D8RF62VN},
institution = {Department of Computer Science, Columbia University},
keywords = {Index Terms—Machine Learning,Metamorphic Testing,Non-Testable Programs,Oracle Problem,Quality Assurance,Random Testing,Software Dependability,Software Testing},
number = {Ml},
pages = {1--21},
title = {{Improving the Dependability of Machine Learning Applications}},
year = {2008}
}
@article{Selvaraju:2017bk,
abstract = {We propose a technique for producing ‘visual explanations' for decisions from a large class of Convolutional Neural Network (CNN)-based models, making them more transparent and explainable. Our approach—Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept (say ‘dog' in a classification network or a sequence of words in captioning network) flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Unlike previous approaches, Grad-CAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g.VGG), (2) CNNs used for structured outputs (e.g.captioning), (3) CNNs used in tasks with multi-modal inputs (e.g.visual question answering) or reinforcement learning, all without architectural changes or re-training. We combine Grad-CAM with existing fine-grained visualizations to create a high-resolution class-discriminative visualization, Guided Grad-CAM, and apply it to image classification, image captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classification models, our visualizations (a) lend insights into failure modes of these models (showing that seemingly unreasonable predictions have reasonable explanations), (b) outperform previous methods on the ILSVRC-15 weakly-supervised localization task, (c) are robust to adversarial perturbations, (d) are more faithful to the underlying model, and (e) help achieve model generalization by identifying dataset bias. For image captioning and VQA, our visualizations show that even non-attention based models learn to localize discriminative regions of input image. We devise a way to identify important neurons through Grad-CAM and combine it with neuron names (Bau et al. in Computer vision and pattern recognition, 2017) to provide textual explanations for model decisions. Finally, we design and conduct human studies to measure if Grad-CAM explanations help users establish appropriate trust in predictions from deep networks and show that Grad-CAM helps untrained users successfully discern a ‘stronger' deep network from a ‘weaker' one even when both make identical predictions. Our code is available at https://github.com/ramprs/grad-cam/, along with a demo on CloudCV (Agrawal et al., in: Mobile cloud visual media computing, pp 265–290. Springer, 2015) (http://gradcam.cloudcv.org) and a video at http://youtu.be/COjUB9Izk6E.},
author = {Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
doi = {10.1007/s11263-019-01228-7},
issn = {1573-1405},
journal = {International Journal of Computer Vision},
keywords = {Explanations,Grad-CAM,Interpretability,Transparency,Visual explanations,Visualizations},
pages = {618--626},
publisher = {IEEE},
title = {{Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization}},
year = {2019}
}
@article{zurMuehlen:2005ci,
abstract = {This paper presents a case study of the development of standards in the area of cross-organizational workflows based on web services. We discuss two opposing types of standards: those based on SOAP, with tightly coupled designs similar to remote procedure calls, and those based on REST, with loosely coupled designs similar to the navigating of web links. We illustrate the standardization process, clarify the technical underpinnings of the conflict, and analyze the interests of stakeholders. The decision criteria for each group of stakeholders are discussed. Finally, we present implications for both the workflow and the wider Internet communities. {\textcopyright}2004 Elsevier B.V. All rights reserved.},
author = {{Zur Muehlen}, Michael and Nickerson, Jeffrey V and Swenson, Keith D},
doi = {10.1016/j.dss.2004.04.008},
issn = {0167-9236},
journal = {Decision Support Systems},
keywords = {Choreography,Integration,Interoperability,Process,REST,SOAP,Standards,Web services,Workflow},
month = {jul},
number = {1 SPEC. ISS.},
pages = {9--29},
title = {{Developing web services choreography standards - The case of REST vs. SOAP}},
volume = {40},
year = {2005}
}
@article{Sokolova:2009vu,
abstract = {This paper presents a systematic analysis of twenty four performance measures used in the complete spectrum of Machine Learning classification tasks, i.e., binary, multi-class, multi-labelled, and hierarchical. For each classification task, the study relates a set of changes in a confusion matrix to specific characteristics of data. Then the analysis concentrates on the type of changes to a confusion matrix that do not change a measure, therefore, preserve a classifier's evaluation (measure invariance). The result is the measure invariance taxonomy with respect to all relevant label distribution changes in a classification problem. This formal analysis is supported by examples of applications where invariance properties of measures lead to a more reliable evaluation of classifiers. Text classification supplements the discussion with several case studies. {\textcopyright}2009 Elsevier Ltd. All rights reserved.},
author = {Sokolova, Marina and Lapalme, Guy},
doi = {10.1016/j.ipm.2009.03.002},
issn = {0306-4573},
journal = {Information Processing and Management},
keywords = {Machine Learning,Performance evaluation,Text classification},
number = {4},
pages = {427--437},
title = {{A systematic analysis of performance measures for classification tasks}},
volume = {45},
year = {2009}
}
@article{Garvin:1984vf,
author = {Garvin, David A},
journal = {MIT Sloan Management Review},
number = {1},
title = {{What Does 'Product Quality' Really Mean?}},
volume = {26},
year = {1984}
}
@article{Heckel:2005uk,
author = {Heckel, Reiko and Lohmann, Marc},
doi = {10.1016/j.entcs.2004.02.073},
issn = {1571-0661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {jan},
pages = {145--156},
title = {{Towards Contract-based Testing of Web Services}},
volume = {116},
year = {2005}
}
@inproceedings{Canfora:2005vd,
abstract = {Service Oriented Architectures, and particularly Web Services, are receiving a growing attention from research and industry. With Web Services, software is used and not owned and operation happens on machines that are out of the user control. Therefore, providing users with means to build confidence that a service delivers the desired function with the expected QoS becomes a key issue.},
address = {Manchester, England, UK},
author = {Canfora, Gerardo},
booktitle = {Proceedings of the 9th European Conference on Software Maintenance and Reengineering},
doi = {10.1109/csmr.2005.57},
issn = {1534-5351},
month = {mar},
pages = {301},
publisher = {IEEE},
title = {{User-side testing of Web Services}},
year = {2005}
}
@inproceedings{Cummaudo:2020icse-demo,
address = {Seoul, Republic of Korea},
author = {Cummaudo, Alex and Barnett, Scott and Vasa, Rajesh and Grundy, John},
booktitle = {Proceedings of the 42nd International Conference on Software Engineering 2},
keywords = {InReview},
mendeley-tags = {InReview},
month = {may},
publisher = {IEEE},
title = {{Threshy: Supporting Safe Usage of Intelligent Web Services}},
year = {2020}
}
@article{Boehm:2005vj,
author = {Boehm, Barry and Basili, Victor R},
chapter = {12},
doi = {10.1109/9780470049167.ch12},
isbn = {978-0-47-004916-7},
journal = {Software Management},
pages = {419--421},
title = {{Software defect reduction top 10 list}},
year = {2007}
}
@inproceedings{Otero:2013ul,
abstract = {Most ant colony optimization (ACO) algorithms for inducing classification rules use a ACO-based procedure to create a rule in a one-at-a-time fashion. An improved search strategy has been proposed in the cAnt-MinerPB algorithm, where an ACO-based procedure is used to create a complete list of rules (ordered rules), i.e., the ACO search is guided by the quality of a list of rules instead of an individual rule. In this paper we propose an extension of the cAnt-MinerPB algorithm to discover a set of rules (unordered rules). The main motivations for this work are to improve the interpretation of individual rules by discovering a set of rules and to evaluate the impact on the predictive accuracy of the algorithm. We also propose a new measure to evaluate the interpretability of the discovered rules to mitigate the fact that the commonly used model size measure ignores how the rules are used to make a class prediction. Comparisons with state-of-the-art rule induction algorithms, support vector machines, and the cAnt-MinerPB producing ordered rules are also presented.},
author = {Otero, Fernando E B and Freitas, Alex A},
booktitle = {Evolutionary Computation},
doi = {10.1162/EVCO_a_00155},
issn = {1530-9304},
keywords = {Ant colony optimization,Classification,Comprehensibility,Data mining,Sequential covering,Unordered rules},
number = {3},
pages = {385--409},
pmid = {26066807},
publisher = {ACM},
title = {{Improving the interpretability of classification rules discovered by an ant colony algorithm: Extended results}},
volume = {24},
year = {2016}
}
@book{Sugiyama:2017ud,
address = {Cambridge, MA, USA},
author = {Schwaighofer, Anton and Lawrence, Neil D},
editor = {Qui{\~{n}}onero-Candela, Joaquin and Sugiyama, Masashi},
isbn = {978-0-26-217005-5},
publisher = {The MIT Press},
title = {{Dataset shift in machine learning}},
year = {2008}
}
@inproceedings{Dibia:2017iy,
abstract = {Existing research highlight the myriad of benefits realized when technology is sufficiently democratized and made accessible to non-technical or novice users. However, democratizing complex technologies such as artificial intelligence (AI) remains hard. In this work, we draw on theoretical underpinnings from the democratization of innovation, in exploring the design of maker kits that help introduce novice users to complex technologies. We report on our work designing TJBot: an open source cardboard robot that can be programmed using pre-built AI services. We highlight principles we adopted in this process (approachable design, simplicity, extensibility and accessibility), insights we learned from showing the kit at workshops (66 participants) and how users interacted with the project on GitHub over a 12-month period (Nov 2016 - Nov 2017). We find that the project succeeds in attracting novice users (40{\%} of users who forked the project are new to GitHub) and a variety of demographics are interested in prototyping use cases such as home automation, task delegation, teaching and learning.},
address = {Denver, CO, USA},
archivePrefix = {arXiv},
arxivId = {1805.10723},
author = {Dibia, Victor and Cox, Aaron and Weisz, Justin},
booktitle = {Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
eprint = {1805.10723},
month = {may},
pages = {381--384},
publisher = {ACM},
title = {{Designing for Democratization: Introducing Novices to Artificial Intelligence Via Maker Kits}},
year = {2017}
}
@techreport{LoGiudice:2016wf,
author = {{Lo Giudice}, Diego and Mines, Christopher and LeClair, Amanda and Curran, Rowan and Homan, Amy},
month = {nov},
title = {{How AI Will Change Software Development And Applications}},
year = {2016}
}
@article{Gilmore:1974um,
abstract = {"Quality is the degree to which a specific product conforms to a design or specification"},
author = {Gilmore, Harold L},
journal = {Quality progress},
number = {5},
pages = {16--19},
title = {{Product conformance cost}},
volume = {7},
year = {1974}
}
@inproceedings{Cummaudo:2020esecfse,
address = {Sacramento, CA, USA},
author = {Cummaudo, Alex},
booktitle = {28th Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
keywords = {InReview},
mendeley-tags = {InReview},
title = {{ESEC/FSE Paper}}
}
@article{Marshall:2018uj,
abstract = {This paper presents a cognitive computing model, based on artificial intelligence (AI) technologies, supporting task automation in the accounting industry. Drivers and consequences of task automation, globally and in accounting, are reviewed. A framework supporting cognitive task automation is discussed. The paper recognizes essential differences between cognitive computing and data analytics. Cognitive computing technologies that support task automation are incorporated into a model delivering federated knowledge. The impact of task automation on accounting job roles and the resulting creation of new accounting job roles supporting innovation are presented. The paper develops a hypothetical use case of building a cloud-based intelligent accounting application design, defined as cognitive services, using machine learning based on AI. The paper concludes by recognizing the significance of future research into task automation in accounting and suggests the federated knowledge model as a framework for future research into the process of digital transformation based on cognitive computing.},
author = {Marshall, Thomas Edward and Lambert, Sherwood Lane},
doi = {10.2308/jeta-52095},
issn = {1558-7940},
journal = {Journal of Emerging Technologies in Accounting},
keywords = {Artificial intelligence,Augmented intelligence,Cognitive computing,Task automation,Workforce},
number = {1},
pages = {199--215},
title = {{Cloud-based intelligent accounting applications: Accounting task automation using IBM watson cognitive computing}},
volume = {15},
year = {2018}
}
@article{Moody:2009vo,
abstract = {Visual notations form an integral part of the language of software engineering (SE). Yet historically, SE researchers and notation designers have ignored or undervalued issues of visual representation. In evaluating and comparing notations, details of visual syntax are rarely discussed. In designing notations, the majority of effort is spent on semantics, with graphical conventions largely an afterthought. Typically, no design rationale, scientific or otherwise, is provided for visual representation choices. While SE has developed mature methods for evaluating and designing semantics, it lacks equivalent methods for visual syntax. This paper defines a set of principles for designing cognitively effective visual notations: ones that are optimized for human communication and problem solving. Together these form a design theory, called the Physics of Notations as it focuses on the physical (perceptual) properties of notations rather than their logical (semantic) properties. The principles were synthesized from theory and empirical evidence from a wide range of fields and rest on an explicit theory of how visual notations communicate. They can be used to evaluate, compare, and improve existing visual notations as well as to construct new ones. The paper identifies serious design flaws in some of the leading SE notations, together with practical suggestions for improving them. It also showcases some examples of visual notation design excellence from SE and other fields. {\textcopyright}2009 IEEE.},
author = {Moody, Daniel},
doi = {10.1109/TSE.2009.67},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Analysis,Communication,Concrete syntax,Diagrams,Modeling,Visual syntax,Visualization},
number = {6},
pages = {756--779},
title = {{The physics of notations: Toward a scientific basis for constructing visual notations in software engineering}},
volume = {35},
year = {2009}
}
@book{Rutten:2004a,
author = {Rutten, J and Kwiatkowska, M and Norman, G and Parker, D},
editor = {Panangaden, P and van Breugel, F},
publisher = {American Mathematical Society},
series = {CRM Monograph Series},
title = {{Mathematical techniques for analyzing concurrent and probabilistic systems}},
volume = {23},
year = {2004}
}
@article{Dejaeger:2012up,
abstract = {As a consequence of the heightened competition on the education market, the management of educational institutions often attempts to collect information on what drives student satisfaction by e.g. organizing large scale surveys amongst the student population. Until now, this source of potentially very valuable information remains largely untapped. In this study, we address this issue by investigating the applicability of different data mining techniques to identify the main drivers of student satisfaction in two business education institutions. In the end, the resulting models are to be used by the management to support the strategic decision making process. Hence, the aspect of model comprehensibility is considered to be at least equally important as model performance. It is found that data mining techniques are able to select a surprisingly small number of constructs that require attention in order to manage student satisfaction. {\textcopyright}2011 Elsevier B.V. All rights reserved.},
author = {Dejaeger, Karel and Goethals, Frank and Giangreco, Antonio and Mola, Lapo and Baesens, Bart},
doi = {10.1016/j.ejor.2011.11.022},
issn = {0377-2217},
journal = {European Journal of Operational Research},
keywords = {Comprehensibility,Data mining,Education evaluation,Multi class classification},
number = {2},
pages = {548--562},
title = {{Gaining insight into student satisfaction using comprehensible data mining techniques}},
volume = {218},
year = {2012}
}
@book{Pirsig:1974vs,
author = {Pirsig, Robert M},
doi = {9780060589462},
edition = {1st},
publisher = {HarperTorch},
title = {{Zen and the art of motorcycle maintenance: An inquiry into values}},
year = {1974}
}
@inproceedings{Kaufman:1999vg,
abstract = {In concept learning or data mining tasks, the learner is typically faced with a choice of many possible hypotheses characterizing the data. If one can assume that the training data are noise-free, then the generated hypothesis should be complete and consistent with regard to the data. In real-world problems, however, data are often noisy, and an insistence on full completeness and consistency is no longer valid. The problem then is to determine a hypothesis that represents the “best” trade-off between completeness and consistency. This paper presents an approach to this problem in which a learner seeks rules optimizing a description quality criterion that combines completeness and consistency gain, a measure based on consistency that reflects the rule's benefit. The method has been implemented in the AQ18 learning and data mining system and compared to several other methods. Experiments have indicated the flexibility and power of the proposed method.},
address = {Warsaw, Poland},
author = {Kaufman, Kenneth A and Michalski, Ryszard S},
booktitle = {Proceedings of the 11th European Conference on Principles and Practice of Knowledge Discovery in Databases},
doi = {10.1007/BFb0095128},
isbn = {354065965X},
issn = {1611-3349},
month = {sep},
pages = {411--419},
publisher = {Springer},
title = {{Learning from inconsistent and noisy data: The AQ18 approach}},
volume = {1609},
year = {1999}
}
@article{Shannon:1963ti,
address = {Urbana, IL, USA},
author = {Shannon, Claude E and Weaver, Warren},
doi = {10.1002/j.1538-7305.1948.tb01338.x},
journal = {The Bell System Technical Journal},
number = {3},
pages = {379--423},
publisher = {The University of Illinois Press},
title = {{The mathematical theory of communication}},
volume = {27},
year = {1948}
}
@article{Blake:1998vd,
abstract = {This paper describes the hardware implementations of fuzzy systems, neural networks and fuzzy neural networks (FNNs) using Xilinx Field Programmable Gate Arrays (FPGAs). The validity of these approaches is demonstrated by their application to a non-linear function approximation problem. The various elements of each system are discussed and implemented in hardware. The architectures were also implemented in software using the MATLAB neural network toolbox. The results are analysed in terms of an accuracy performance index and in the dimensions of the hardware required. {\textcopyright}1998 Elsevier Science Inc. All rights reserved.},
author = {Blake, J J and Maguire, L P and McGinnity, T M and Roche, B and McDaid, L J},
doi = {10.1016/S0020-0255(98)10029-4},
issn = {0020-0255},
journal = {Information Sciences},
number = {1-4},
pages = {151--168},
title = {{The implementation of fuzzy systems, neural networks and fuzzy neural networks using FPGAs}},
volume = {112},
year = {1998}
}
@inproceedings{Novielli:2015vda,
abstract = {A recent research trend has emerged to study the role of affect in in the social programmer ecosystem, by applying sentiment analysis to the content available in sites such as GitHub and Stack Overflow. In this paper, we aim at assessing the suitability of a state-of-the-art sentiment analysis tool, already applied in social computing, for detecting affective expressions in Stack Overflow. We also aim at verifying the construct validity of choosing sentiment polarity and strength as an appropriate way to operationalize affective states in empirical studies on Stack Overflow. Finally, we underline the need to overcome the limitations induced by domain-dependent use of lexicon that may produce unreliable results.},
address = {Bergamo, Italy},
author = {Novielli, Nicole and Calefato, Fabio and Lanubile, Filippo},
booktitle = {Proceedings of the 7th International Workshop on Social Software Engineering},
doi = {10.1145/2804381.2804387},
isbn = {978-1-45-033818-9},
keywords = {Online Q and A,Overflow,Sentiment Analysis,Social Programmer,Social Software Engineering,Stack,Technical Forum},
month = {aug},
pages = {33--40},
title = {{The challenges of sentiment detection in the social programmer ecosystem}},
year = {2015}
}
@article{GAROUSI2019101,
abstract = {Context: A Multivocal Literature Review (MLR) is a form of a Systematic Literature Review (SLR) which includes the grey literature (e.g., blog posts, videos and white papers) in addition to the published (formal) literature (e.g., journal and conference papers). MLRs are useful for both researchers and practitioners since they provide summaries both the state-of-the art and –practice in a given area. MLRs are popular in other fields and have recently started to appear in software engineering (SE). As more MLR studies are conducted and reported, it is important to have a set of guidelines to ensure high quality of MLR processes and their results. Objective: There are several guidelines to conduct SLR studies in SE. However, several phases of MLRs differ from those of traditional SLRs, for instance with respect to the search process and source quality assessment. Therefore, SLR guidelines are only partially useful for conducting MLR studies. Our goal in this paper is to present guidelines on how to conduct MLR studies in SE. Method: To develop the MLR guidelines, we benefit from several inputs: (1) existing SLR guidelines in SE, (2), a literature survey of MLR guidelines and experience papers in other fields, and (3) our own experiences in conducting several MLRs in SE. We took the popular SLR guidelines of Kitchenham and Charters as the baseline and extended/adopted them to conduct MLR studies in SE. All derived guidelines are discussed in the context of an already-published MLR in SE as the running example. Results: The resulting guidelines cover all phases of conducting and reporting MLRs in SE from the planning phase, over conducting the review to the final reporting of the review. In particular, we believe that incorporating and adopting a vast set of experience-based recommendations from MLR guidelines and experience papers in other fields have enabled us to propose a set of guidelines with solid foundations. Conclusion: Having been developed on the basis of several types of experience and evidence, the provided MLR guidelines will support researchers to effectively and efficiently conduct new MLRs in any area of SE. The authors recommend the researchers to utilize these guidelines in their MLR studies and then share their lessons learned and experiences.},
archivePrefix = {arXiv},
arxivId = {1707.02553},
author = {Garousi, Vahid and Felderer, Michael and M{\"{a}}ntyl{\"{a}}, Mika V},
doi = {10.1016/j.infsof.2018.09.006},
eprint = {1707.02553},
issn = {0950-5849},
journal = {Information and Software Technology},
keywords = {Evidence-based software engineering,Grey literature,Guidelines,Literature study,Multivocal literature review,Systematic literature review,Systematic mapping study},
pages = {101--121},
title = {{Guidelines for including grey literature and conducting multivocal literature reviews in software engineering}},
volume = {106},
year = {2019}
}
@misc{Bessin:2004vc,
author = {Bessin, J},
booktitle = {IBM developerWorks, June},
howpublished = {$\backslash$url{\{}https://ibm.co/2u0UDK0{\}}},
publisher = {IBM Corporation},
title = {{The Business Value of Quality}},
volume = {15},
year = {2004}
}
@article{Krosnick:1999wt,
author = {Krosnick, Jon A},
doi = {10.1146/annurev.psych.50.1.537},
issn = {0066-4308},
journal = {Annual Review of Psychology},
month = {feb},
number = {1},
pages = {537--567},
title = {{Survey Research}},
volume = {50},
year = {1999}
}
@inproceedings{Michie:1988te,
address = {Glasgow, Scotland, UK},
author = {Michie, D},
booktitle = {Proceedings of the 3rd European Conference on European Working Session on Learning},
isbn = {978-0-27-308800-4},
month = {oct},
pages = {107--122},
publisher = {Pitman Publishing, Inc.},
title = {{Machine learning in the next five years}},
year = {1988}
}
@book{Wong:2006ve,
abstract = {Data mining involves the non-trivial extraction of implicit, previously unknown, and potentially useful information from databases. Genetic Programming (GP) and Inductive Logic Programming (ILP) are two of the approaches for data mining. This book first sets the necessary backgrounds for the reader, including an overview of data mining, evolutionary algorithms and inductive logic programming. It then describes a framework, called GGP (Generic Genetic Programming), that integrates GP and ILP based on a formalism of logic grammars. The formalism is powerful enough to represent context- sensitive information and domain-dependent knowledge. This knowledge can be used to accelerate the learning speed and/or improve the quality of the knowledge induced. A grammar-based genetic programming system called LOGENPRO (The LOGic grammar based GENetic PROgramming system) is detailed and tested on many problems in data mining. It is found that LOGENPRO outperforms some ILP systems. We have also illustrated how to apply LOGENPRO to emulate Automatically Defined Functions (ADFs) to discover problem representation primitives automatically. By employing various knowledge about the problem being solved, LOGENPRO can find a solution much faster than ADFs and the computation required by LOGENPRO is much smaller than that of ADFs. Moreover, LOGENPRO can emulate the effects of Strongly Type Genetic Programming and ADFs simultaneously and effortlessly. Data Mining Using Grammar Based Genetic Programming and Applications is appropriate for researchers, practitioners and clinicians interested in genetic programming, data mining, and the extraction of data from databases.},
author = {Wong, Man Leung and Leung, Kwong Sak},
booktitle = {Data Mining Using Grammar Based Genetic Programming and Applications},
doi = {10.1007/b116131},
publisher = {Springer Science {\&} Business Media},
title = {{Data Mining Using Grammar Based Genetic Programming and Applications}},
volume = {3},
year = {2002}
}
@inproceedings{7180082,
abstract = {API design is known to be a challenging craft, as API designers must balance their elegant ideals against 'real-world' concerns, such as utility, performance, backwards compatibility, and unforeseen emergent uses. However, to date, there is no principled method to collect or analyze API usability information that incorporates input from typical developers. In practice, developers often turn to Q{\&}A websites such as stackoverflow.com (SO) when seeking expert advice on API use, the popularity of such sites has thus led to a very large volume of unstructured information that can be searched with diligence for answers to specific questions. The collected wisdom within such sites could, in principle, be of great help to API designers to better support developer needs, if only it could be collected, analyzed, and distilled for practical use. In this paper, we present a methodology that combines several techniques, including social network analysis and topic mining, to recommend SO posts that are likely to concern API design-related issues. To establish a comparison baseline, we introduce two more recommendation approaches: a reputation-based recommender and a random recommender. We have found that when applied to Q{\&}A discussion of two popular mobile platforms, Android and iOS, our methodology achieves up to 93{\%} accuracy and is more stable with its recommendations when compared to the two baseline techniques.},
address = {Florence, Italy},
author = {Wang, Wei and Malik, Haroon and Godfrey, Michael W},
booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
doi = {10.1109/MSR.2015.28},
isbn = {978-0-7695-5594-2},
issn = {2160-1860},
keywords = {API usability,Application program interfaces,Online Q{\&}A,Recommendation systems,Software ecosystems,Stackoverflow},
month = {may},
pages = {224--234},
publisher = {IEEE},
title = {{Recommending Posts concerning API Issues in Developer Q{\&}A Sites}},
year = {2015}
}
@inproceedings{Lin:2014vma,
abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model. {\textcopyright}2014 Springer International Publishing.},
address = {Zurich, Germany},
archivePrefix = {arXiv},
arxivId = {1405.0312},
author = {Lin, Tsung Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'{a}}r, Piotr and Zitnick, C Lawrence},
booktitle = {Proceedings of the 13th European Conference on Computer Vision},
doi = {10.1007/978-3-319-10602-1_48},
editor = {Fleet, David and Pajdla, Tom{\'{a}}s and Schiele, Bernt and Tuytelaars, Tinne},
eprint = {1405.0312},
issn = {1611-3349},
month = {sep},
number = {PART 5},
pages = {740--755},
publisher = {Springer},
title = {{Microsoft COCO: Common objects in context}},
volume = {8693 LNCS},
year = {2014}
}
@article{Dromey:1995wy,
abstract = {A model for software product quality is defined. It has been formulated by associating a set of quality-carrying properties with each of the structural forms that are used to define the statements and statement components of a programming language. These quality-carrying properties are in turn linked to the high-level quality attributes of the International Standard for Software Product Evaluation ISO-9126. The model supports building quality into software, definition of language-specific coding standards, systematically classifying quality defects, and the development of automated code auditors for detecting defects in software.},
author = {Dromey, R Geoff},
doi = {10.1109/32.345830},
isbn = {978-1-11-815666-7},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
number = {2},
pages = {146--162},
title = {{A model for software product quality}},
volume = {21},
year = {1995}
}
@phdthesis{Fielding:2000vh,
author = {Fielding, Roy Thomas},
doi = {978-0-599-87118-2},
school = {University of California, Irvine},
title = {{Architectural Styles and the Design of Network-based Software Architectures}},
year = {2000}
}
@book{Rosenberry:1992up,
author = {Rosenberry, Ward and Kenney, David and Fisher, Gerry},
isbn = {978-1-56-592005-7},
publisher = {O'Reilly {\&} Associates, Inc.},
title = {{Understanding DCE}},
year = {1992}
}
@article{Chambers:1991uh,
abstract = {Less than 20 percent of elderly and other high-risk persons targeted for annual influenza vaccination are immunized each year. In most busy practice settings, it is difficult for primary care physicians to identify every patient in need of preventive health interventions. The purpose of this study was to assess the effect of microcomputer-generated reminders on influenza vaccination rates in a university-based family practice center. The practice uses an interactive encounter form system from which updated clinical information is routinely entered into a cumulative database. During a 2-month period, 686 patients were identified in the database as eligible to receive influenza vaccine according to accepted criteria. Practice physicians (n = 32) were stratified by level of training and randomized to one of three groups, thereby receiving printed reminders on the encounter forms of all, none, or half of their eligible patients. Patients of physicians who always received reminders were more likely to receive influenza vaccine during the study period than patients of the never-reminded physicians (51 percent versus 30 percent, P less than 0.001). Patients whose physicians received reminders for only half their patients had an intermediate likelihood of receiving a vaccination if a reminder was printed (38 percent) but were less likely than the patients of never-reminded physicians to receive the vaccine if no reminder was printed (20 percent, P less than 0.001). This study suggests that physicians learn to depend on reminders for preventive health activities and that reminders are most effective when they are provided at every patient encounter.},
author = {Chambers, C V and Balaban, D J and Carlson, B L and Grasberger, D M},
doi = {10.3122/jabfm.4.1.19},
issn = {0893-8652},
journal = {The Journal of the American Board of Family Practice / American Board of Family Practice},
number = {1},
pages = {19--26},
title = {{The effect of microcomputer-generated reminders on influenza vaccination rates in a university-based family practice center.}},
volume = {4},
year = {1991}
}
@inproceedings{Shaw:2003aa,
address = {Portland, OR, USA},
author = {Shaw, M},
booktitle = {Proceedings of the 25th International Conference on Software Engineering},
isbn = {978-0-76-951877-0},
month = {may},
pages = {726--736},
publisher = {IEEE},
title = {{Writing good software engineering research papers}},
year = {2003}
}
@article{Robillard:2011uv,
abstract = {Large APIs can be hard to learn, and this can lead to decreased programmer productivity. But what makes APIs hard to learn? We conducted a mixed approach, multi-phased study of the obstacles faced by Microsoft developers learning a wide variety of new APIs. The study involved a combination of surveys and in-person interviews, and collected the opinions and experiences of over 440 professional developers. We found that some of the most severe obstacles faced by developers learning new APIs pertained to the documentation and other learning resources. We report on the obstacles developers face when learning new APIs, with a special focus on obstacles related to API documentation. Our qualitative analysis elicited five important factors to consider when designing API documentation: documentation of intent; code examples; matching APIs with scenarios; penetrability of the API; and format and presentation. We analyzed how these factors can be interpreted to prioritize API documentation development efforts {\textcopyright}2010 Springer Science+Business Media, LLC.},
author = {Robillard, Martin P and Deline, Robert},
doi = {10.1007/s10664-010-9150-8},
issn = {1382-3256},
journal = {Empirical Software Engineering},
keywords = {Application programming interfaces,Documentation,Programming,Software libraries},
number = {6},
pages = {703--732},
title = {{A field study of API learning obstacles}},
volume = {16},
year = {2011}
}
@misc{InternationalOrganizationforStandardization2015,
author = {{International Organization for Standardization}},
title = {{ISO 9000:2015 Quality management systems – Fundamentals and vocabulary}},
url = {http://bit.ly/37O4oKo},
year = {2015}
}
@article{Lima:2009tm,
abstract = {Companies' interest in customer relationship modelling and key issues such as customer lifetime value and churn has substantially increased over the years. However, the complexity of building, interpreting and applying these models creates obstacles for their implementation. The main contribution of this paper is to show how domain knowledge can be incorporated in the data mining process for churn prediction, viz. through the evaluation of coefficient signs in a logistic regression model, and secondly, by analysing a decision table (DT) extracted from a decision tree or rule-based classifier. An algorithm to check DTs for violations of monotonicity constraints is presented, which involves the repeated application of condition reordering and table contraction to detect counter-intuitive patterns. Both approaches are applied to two telecom data sets to empirically demonstrate how domain knowledge can be used to ensure the interpretability of the resulting models.Journal of the Operational Research Society (2009) 60, 1096-1106. doi:10.1057/jors.2008.161; published online 18 February 2009 {\textcopyright}2009 Operational Research Society Ltd.},
author = {Lima, E and Mues, C and Baesens, B},
doi = {10.1057/jors.2008.161},
issn = {0160-5682},
journal = {Journal of the Operational Research Society},
keywords = {Churn,Data mining,Decision tables,Domain knowledge},
number = {8},
pages = {1096--1106},
title = {{Domain knowledge integration in data mining using decision tables: Case studies in churn prediction}},
volume = {60},
year = {2009}
}
@inproceedings{covington2016deep,
abstract = {YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous userfacing impact.},
address = {Boston, MA, USA},
author = {Covington, Paul and Adams, Jay and Sargin, Emre},
booktitle = {Proceedings of the 10th ACM Conference on Recommender Systems},
doi = {10.1145/2959100.2959190},
isbn = {978-1-45-034035-9},
keywords = {Deep learning,Recommender system,Scalability},
month = {sep},
pages = {191--198},
publisher = {ACM},
title = {{Deep neural networks for youtube recommendations}},
year = {2016}
}
@article{DoshiVelez:2017wu,
abstract = {As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.},
archivePrefix = {arXiv},
arxivId = {1702.08608},
author = {Doshi-Velez, Finale and Kim, Been},
eprint = {1702.08608},
journal = {arXiv preprint arXiv:1702.08608},
title = {{Towards A Rigorous Science of Interpretable Machine Learning}},
year = {2017}
}
@article{Sculley2015,
abstract = {Machine learning offers a fantastically powerful toolkit for building useful complex prediction systems quickly. This paper argues it is dangerous to think of these quick wins as coming for free. Using the software engineering framework of technical debt, we find it is common to incur massive ongoing maintenance costs in real-world ML systems. We explore several ML-specific risk factors to account for in system design. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, configuration issues, changes in the external world, and a variety of system-level anti-patterns.},
address = {Montreal, QC, Canada},
author = {Sculley, D and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Crespo, Jean Fran{\c{c}}ois and Dennison, Dan},
isbn = {0262017091, 9780262017091},
issn = {1049-5258},
journal = {Proceedings of the 29th Conference on Neural Information Processing Systems},
month = {dec},
pages = {2503--2511},
title = {{Hidden technical debt in machine learning systems}},
year = {2015}
}
@book{Juran:1988tg,
author = {M., Juran J},
isbn = {978-0-02-916681-9},
publisher = {Free Press},
title = {{Juran on Planning for Quality}},
year = {1988}
}
@article{Frey:2007hs,
abstract = {Clustering data by identifying a subset of representative examples is important for processing sensory signals and detecting patterns in data. Such "exemplars" can be found by randomly choosing an initial subset of data points and then iteratively refining it, but this works well only if that initial choice is close to a good solution. We devised a method called "affinity propagation," which takes as input measures of similarity between pairs of data points. Real-valued messages are exchanged between data points until a high-quality set of exemplars and corresponding clusters gradually emerges. We used affinity propagation to cluster images of faces, detect genes in microarray data, identify representative sentences in this manuscript, and identify cities that are efficiently accessed by airline travel. Affinity propagation found clusters with much lower error than other methods, and it did so in less than one-hundredth the amount of time.},
author = {Frey, Brendan J and Dueck, Delbert},
doi = {10.1126/science.1136800},
issn = {0036-8075},
journal = {Science},
month = {feb},
number = {5814},
pages = {972--976},
title = {{Clustering by passing messages between data points}},
volume = {315},
year = {2007}
}
@article{IBMTripleModularRedendancy,
abstract = {One of the proposed techniques for meeting the severe reliability requirements inherent in certain future computer applications is described. This technique involves the use of triple-modular redundancy, which is essentially the use of the two-out-of-three voting concept at a low level. Effects of imperfect voting circuitry and of various interconnections of logical elements are assessed. A hypothetical triple-modular redundant computer is subjected to a Monte Carlo program on the IBM 704, which simulates component failures. Reliability is thereby determined and compared with reliability obtained by analytical calculations based on simplifying assumptions.},
author = {Lyons, R E and Vanderkulk, W},
doi = {10.1147/rd.62.0200},
issn = {0018-8646},
journal = {IBM Journal of Research and Development},
month = {apr},
number = {2},
pages = {200--209},
title = {{The Use of Triple-Modular Redundancy to Improve Computer Reliability}},
volume = {6},
year = {2010}
}
@article{Cavano:1978gz,
abstract = {Research in software metrics incorporated in a framework established for software quality measurement can potentially provide significant benefits to software quality assurance programs. The research described has been conducted by General Electric Company for the Air Force Systems Command Rome Air Development Center. The problems encountered defining software quality and the approach taken to establish a framework for the measurement of software quality are described in this paper.},
author = {Cavano, Joseph P and McCall, James A},
doi = {10.1145/800283.811113},
journal = {Proceedings of the Software Quality Assurance Workshop on Functional and Performance Issues},
month = {nov},
number = {5},
pages = {133--139},
title = {{A framework for the measurement of software quality}},
volume = {3},
year = {1978}
}
@inproceedings{Nakajima:2002ut,
abstract = {Model-checking is a promising technique for the verification and validation of software systems. Web service, an emerging technology in the Internet, is an autonomous server that may offer an individual service. It sometimes requires to combine more than one to meet our requirements. WSFL(Web Services Flow Language) is proposed as a language to provide means to describe Web service aggregation. We are interested in how much the software modelchecking technique can be used as a basis for raising reliability of Web service, Web service flow descriptions in particular. Our experience shows that faulty flow descriptions can be identified with the proposed method. The method is also very helpful in studying an alternative semantics of the WSFL in regard to the handling of dataflows.},
address = {Montreal, QC, Canada},
author = {Nakajima, Shin},
booktitle = {Proceedings of the First International Symposium on Cyber World},
isbn = {978-0-76-951862-6},
month = {nov},
pages = {378--385},
publisher = {IEEE},
title = {{Model-Checking Verification for Reliable Web Service}},
year = {2002}
}
@misc{Tabor:1997tw,
address = {New York, NY, USA},
author = {Tabor, Mary B W},
booktitle = {New York Times},
howpublished = {$\backslash$url{\{}https://nyti.ms/2UiKrrd{\}}},
month = {feb},
title = {{Student Proves That S.A.T. Can Be: (D) Wrong}},
year = {1997}
}
@techreport{RightScaleInc:2018kJ,
abstract = {In January 2016, RightScale surveyed 1,060 technical professionals across a broad cross-section of organizations about their adoption of cloud computing. The company published its annual State of the Cloud Report on February 9, 2016. We also asked a number of additional questions about their adoption of DevOps and use of DevOps tools, including Docker. In this DevOps Trends report, we offer a deep dive into those responses as well as some additional analysis about DevOps. The 2016 State of the Cloud Survey identified several key findings: DevOps growing especially in the enterprise. • DevOps adoption increased from 66 percent in 2015 to 74 percent in 2016. • DevOps adoption is strongest in the enterprise (81 percent of enterprises adopting DevOps compared to 70 percent in SMBs). • Enterprises are adopting DevOps from the bottom up: projects or teams (29 percent) and business units or divisions (31 percent), company-wide (21 percent). Docker},
author = {{RightScale Inc.}},
pages = {1--19},
title = {{State of the Cloud Report: DevOps Trends}},
year = {2016}
}
@book{Jin:2006uf,
address = {Berlin, Heidelberg},
author = {Jin, Yaochu},
doi = {10.1007/3-540-33019-4},
isbn = {978-3-54-030676-4},
publisher = {Springer},
series = {Studies in Computational Intelligence},
title = {{Multi-Objective Machine Learning}},
year = {2006}
}
@inproceedings{Kim:2014ui,
abstract = {We present the Bayesian Case Model (BCM), a general framework for Bayesian case-based reasoning (CBR) and prototype classification and clustering. BCM brings the intuitive power of CBR to a Bayesian generative framework. The BCM learns prototypes, the "quintessential" observations that best represent clusters in a dataset, by performing joint inference on cluster labels, prototypes and important features. Simultaneously, BCM pursues sparsity by learning subspaces, the sets of features that play important roles in the characterization of the prototypes. The prototype and subspace representation provides quantitative benefits in inter-pretability while preserving classification accuracy. Human subject experiments verify statistically significant improvements to participants' understanding when using explanations produced by BCM, compared to those given by prior art.},
address = {Montreal, QC, Canada},
archivePrefix = {arXiv},
arxivId = {1503.01161},
author = {Kim, Been and Rudin, Cynthia and Shah, Julie},
booktitle = {Proceedings of the 28th Conference on Neural Information Processing Systems},
eprint = {1503.01161},
issn = {1049-5258},
month = {dec},
pages = {1952--1960},
title = {{The Bayesian case model: A generative approach for case-based reasoning and prototype classification}},
year = {2014}
}
@inproceedings{Ross:2017vn,
abstract = {Neural networks are among the most accurate supervised learning methods in use today. However, their opacity makes them difficult to trust in critical applications, especially if conditions in training may differ from those in test. Recent work on explanations for black-box models has produced tools (e.g. LIME) to show the implicit rules behind predictions. These tools can help us identify when models are right for the wrong reasons. However, these methods do not scale to explaining entire datasets and cannot correct the problems they reveal. We introduce a method for efficiently explaining and regularizing differentiable models by examining and selectively penalizing their input gradients. We apply these penalties both based on expert annotation and in an unsupervised fashion that produces multiple classifiers with qualitatively different decision boundaries. On multiple datasets, we show our approach generates faithful explanations and models that generalize much better when conditions differ between training and test.},
address = {Melbourne, Australia},
archivePrefix = {arXiv},
arxivId = {1703.03717},
author = {Ross, Andrew Slavin and Hughes, Michael C and Doshi-Velez, Finale},
booktitle = {Proceedings of the 26th International Joint Conferences on Artificial Intelligence},
doi = {10.24963/ijcai.2017/371},
eprint = {1703.03717},
isbn = {978-0-99-924110-3},
issn = {1045-0823},
month = {aug},
pages = {2662--2670},
title = {{Right for the right reasons: Training differentiable models by constraining their explanations}},
year = {2017}
}
@article{Heckerman:2000uw,
abstract = {We describe a graphical model for probabilistic relationships - an alternative to the Bayesian network - called a dependency network. The graph of a dependency network, unlike a Bayesian network, is potentially cyclic. The probability component of a dependency network, like a Bayesian network, is a set of conditional distributions, one for each node given its parents. We identify several basic properties of this representation and describe a computationally efficient procedure for learning the graph and probability components from data. We describe the application of this representation to probabilistic inference, collaborative filtering (the task of predicting preferences), and the visualization of acausal predictive relationships. {\textcopyright}2000 David Heckerman, David Maxwell Chickering, Christopher Meek, Robert Rounthwaite, {\&} Carl Kadie.},
author = {Heckerman, David and Chickering, David Maxwell and Meek, Christopher and Rounthwaite, Robert and Kadie, Carl},
doi = {10.1162/153244301753344614},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {Bayesian networks,Collaborative filtering,Data visualization,Dependency networks,Exploratory data analysis,Gibbs sampling,Graphical models,Probabilistic inference},
number = {1},
pages = {49--75},
title = {{Dependency networks for inference, collaborative filtering, and data visualization}},
volume = {1},
year = {2001}
}
@book{Miles:1994ty,
abstract = {The latest edition of this best-selling textbook by Miles and Huberman not only is considerably expanded in content, but is now available in paperback. Bringing the art of qualitative analysis up-to-date, this edition adds hundreds of new techniques, ideas and references developed in the past decade. The increase in the use of computers in qualitative analysis is also reflected in this volume. There is an extensive appendix on criteria to choose from among the currently available analysis packages. Through examples from a host of social science and professional disciplines, Qualitative Data Analysis remains the most comprehensive and complete treatment of this topic currently available to scholars and applied researchers.},
author = {Schwandt, Thomas A},
booktitle = {Evaluation and Program Planning},
doi = {10.1016/0149-7189(96)88232-2},
issn = {0149-7189},
number = {1},
pages = {106--107},
publisher = {sage},
title = {{Qualitative data analysis: An expanded sourcebook}},
volume = {19},
year = {1996}
}
@incollection{Singer:2007tu,
author = {Singer, Janice and Sim, Susan E and Lethbridge, Timothy C},
booktitle = {Guide to Advanced Empirical Software Engineering},
chapter = {1},
month = {nov},
pages = {9--34},
publisher = {Springer Science {\&} Business Media},
title = {{Software engineering data collection for field studies}},
year = {2007}
}
@book{Witten:2016ut,
abstract = {Data Mining: Practical Machine Learning Tools and Techniques, Fourth Edition, offers a thorough grounding in machine learning concepts, along with practical advice on applying these tools and techniques in real-world data mining situations. This highly anticipated fourth edition of the most acclaimed work on data mining and machine learning teaches readers everything they need to know to get going, from preparing inputs, interpreting outputs, evaluating results, to the algorithmic methods at the heart of successful data mining approaches. Extensive updates reflect the technical changes and modernizations that have taken place in the field since the last edition, including substantial new chapters on probabilistic methods and on deep learning. Accompanying the book is a new version of the popular WEKA machine learning software from the University of Waikato. Authors Witten, Frank, Hall, and Pal include today's techniques coupled with the methods at the leading edge of contemporary research. Please visit the book companion website at http://www.cs.waikato.ac.nz/ml/weka/book.html It contains Powerpoint slides for Chapters 1-12. This is a very comprehensive teaching resource, with many PPT slides covering each chapter of the book Online Appendix on the Weka workbench; again a very comprehensive learning aid for the open source software that goes with the book Table of contents, highlighting the many new sections in the 4th edition, along with reviews of the 1st edition, errata, etc. Provides a thorough grounding in machine learning concepts, as well as practical advice on applying the tools and techniques to data mining projects Presents concrete tips and techniques for performance improvement that work by transforming the input or output in machine learning methods Includes a downloadable WEKA software toolkit, a comprehensive collection of machine learning algorithms for data mining tasks-in an easy-to-use interactive interface Includes open-access online courses that introduce practical applications of the material in the book.},
author = {Witten, Ian H and Frank, Eibe and Hall, Mark A and Pal, Christopher J},
booktitle = {Data Mining: Practical Machine Learning Tools and Techniques},
doi = {10.1016/c2009-0-19715-5},
isbn = {978-0-12-804291-5},
pages = {1--621},
publisher = {Morgan Kaufmann},
title = {{Data Mining: Practical Machine Learning Tools and Techniques}},
year = {2016}
}
@inproceedings{Aghajani:2019bo,
abstract = {(Good) Software documentation provides developers and users with a description of what a software system does, how it operates, and how it should be used. For example, technical documentation (e.g., an API reference guide) aids developers during evolution/maintenance activities, while a user manual explains how users are to interact with a system. Despite its intrinsic value, the creation and the maintenance of documentation is often neglected, negatively impacting its quality and usefulness, ultimately leading to a generally unfavourable take on documentation. Previous studies investigating documentation issues have been based on surveying developers, which naturally leads to a somewhat biased view of problems affecting documentation. We present a large scale empirical study, where we mined, analyzed, and categorized 878 documentation-related artifacts stemming from four different sources, namely mailing lists, Stack Overflow discussions, issue repositories, and pull requests. The result is a detailed taxonomy of documentation issues from which we infer a series of actionable proposals both for researchers and practitioners.},
address = {Montreal, QC, Canada},
author = {Aghajani, Emad and Nagy, Csaba and Vega-Marquez, Olga Lucero and Linares-Vasquez, Mario and Moreno, Laura and Bavota, Gabriele and Lanza, Michele},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
doi = {10.1109/ICSE.2019.00122},
isbn = {978-1-72-810869-8},
issn = {0270-5257},
keywords = {Documentation,Empirical Study},
month = {may},
pages = {1199--1210},
publisher = {IEEE},
title = {{Software Documentation Issues Unveiled}},
year = {2019}
}
@book{Simon:1996uw,
abstract = {Continuing his exploration of the organization of complexity and the science of design, this new edition of Herbert Simon's classic work on artificial intelligence adds a chapter that sorts out the current themes and tools—chaos, adaptive systems, genetic algorithms—for analyzing complexity and complex systems. There are updates throughout the book as well. These take into account important advances in cognitive psychology and the science of design while confirming and extending the book's basic thesis: that a physical symbol system has the necessary and sufficient means for intelligent action. The chapter "Economic Reality" has also been revised to reflect a change in emphasis in Simon's thinking about the respective roles of organizations and markets in economic systems.},
author = {Michalos, Alex C and Simon, Herbert A},
booktitle = {Technology and Culture},
doi = {10.2307/3102825},
issn = {0040165X},
number = {1},
pages = {118},
publisher = {MIT press},
title = {{The Sciences of the Artificial}},
volume = {11},
year = {1970}
}
@inproceedings{hohman2019gamut,
abstract = {Without good models and the right tools to interpret them, data scientists risk making decisions based on hidden biases, spurious correlations, and false generalizations. This has led to a rallying cry for model interpretability. Yet the concept of interpretability remains nebulous, such that researchers and tool designers lack actionable guidelines for how to incorporate interpretability into models and accompanying tools. Through an iterative design process with expert machine learning researchers and practitioners, we designed a visual analytics system, Gamut, to explore how interactive interfaces could better support model interpretation. Using Gamut as a probe, we investigated why and how professional data scientists interpret models, and how interface affordances can support data scientists in answering questions about model interpretability. Our investigation showed that interpretability is not a monolithic concept: data scientists have different reasons to interpret models and tailor explanations for specific audiences, often balancing competing concerns of simplicity and completeness. Participants also asked to use Gamut in their work, highlighting its potential to help data scientists understand their own data.},
address = {Glasgow, Scotland, UK},
author = {Hohman, Fred and Head, Andrew and Caruana, Rich and DeLine, Robert and Drucker, Steven M},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3290605.3300809},
isbn = {978-1-45-035970-2},
keywords = {Data visualization,Design probe,Interactive interfaces,Machine learning interpretability,Visual analytics},
month = {may},
publisher = {ACM},
title = {{Gamut: A design probe to understand how data scientists understand machine learning models}},
year = {2019}
}
@article{Lau:1999vs,
abstract = {Based on recent reviews regarding its use in information systems (IS) studies, this paper argues that action research is still not well recognized by IS researchers and mainstream IS journals especially in North America. To make the situation worse, existing criteria used to assess the quality of action research studies are found to be inadequate when applied to IS. In order to advance its understanding and use by IS researchers and practitioners, the IS action research framework proposed recently by Lau is refined and presented as a set of guidelines in this paper. The implications of this refined framework on IS research and practice are discussed. {\textcopyright}1999, MCB UP Limited},
author = {Lau, Francis},
doi = {10.1108/09593849910267206},
issn = {0959-3845},
journal = {Information Technology {\&} People},
keywords = {Action research,Assessment,Information systems,Methodology,Quality,Research},
number = {2},
pages = {148--176},
title = {{Toward a framework for action research in information systems studies}},
volume = {12},
year = {1999}
}
@inproceedings{nishi2018test,
abstract = {As machine learning (ML) technology continues to spread by rapid evolution, the system or service using Machine Learning technology, called ML product, makes big impact on our life, society and economy. Meanwhile, Quality Assurance (QA) for ML product is quite more difficult than hardware, non-ML software and service because performance of ML technology is much better than non-ML technology in exchange for the characteristics of ML product, e.g. low explainability. We must keep rapid evolution and reduce quality risk of ML product simultaneously. In this paper, we show a Quality Assurance Framework for Machine Learning product. Scope of QA in this paper is limited to product evaluation. First, a policy of QA for ML Product is proposed. General principles of product evaluation is introduced and applied to ML product evaluation as a part of the policy. They are composed of A-ARAI: Allowability, Achievability, Robustness, Avoidability and Improvability. A strategy of ML Product Evaluation is constructed as another part of the policy. Quality Integrity Level for ML product is also modelled. Second, we propose a test architecture of ML product testing. It consists of test levels and fundamental test types of ML product testing, including snapshot testing, learning testing and confrontation testing. Finally, we defines QA activity levels for ML product.},
address = {V{\"{a}}ster{\aa}s, Sweden},
author = {Nishi, Yasuharu and Masuda, Satoshi and Ogawa, Hideto and Uetsuki, Keiji},
booktitle = {Proceedings of the 11th International Conference on Software Testing, Verification and Validation Workshops},
doi = {10.1109/ICSTW.2018.00060},
isbn = {978-1-53-866352-3},
keywords = {Artificial intelligence,Functional safety,Machine learning,Quality assurance,Test architecture,Test design,Test level,Test type},
month = {apr},
pages = {273--278},
publisher = {IEEE},
title = {{A test architecture for machine learning product}},
year = {2018}
}
@inproceedings{Yi:2004ve,
abstract = {Web services aim to support efficient integration of applications over Web. Most Web services are stateful, such as services for business processes, and they converse with each other via properly ordered interactions, instead of individual unrelated invocations. In order to address efficient integration of conversational Web services, we create a unified specification model for both conversation protocol and composition; we propose methods to integrate a partner service with complex conversation protocol into a composition of Web services; assure the correctness of composition by formal verification. The mapping between our model and BPEL4WS is also discussed.},
address = {San Diego, CA, USA},
author = {Yi, Xiaochuan and Kochut, Krys J},
booktitle = {Proceedings of the 2004 IEEE International Conference on Web Services},
doi = {10.1109/icws.2004.1314810},
isbn = {0-76-952167-3},
month = {jul},
pages = {756--760},
publisher = {IEEE},
title = {{A CP-nets-based design and verification framework for web services composition}},
year = {2004}
}
@book{Shull:2007vh,
abstract = {Empirical studies have become an integral element of software engineering research and practice. This unique text/reference includes chapters from some of the top international empirical software engineering researchers and focuses on the practical knowledge necessary for conducting, reporting and using empirical methods in software engineering. Part 1, 'Research Methods and Techniques', examines the proper use of various strategies for collecting and analysing data, and the uses for which those strategies are most appropriate. Part 2, 'Practical Foundations', provides a discussion of several important global issues that need to be considered from the very beginning of research planning. Finally, 'Knowledge Creation' offers insight on using a set of disparate studies to provide useful decision support. Topics and features: Offers information across a range of techniques, methods, and qualitative and quantitative issues, providing a toolkit for the reader that is applicable across the diversity of software development contexts Presents reference material with concrete software engineering examples Provides guidance on how to design, conduct, analyse, interpret and report empirical studies, taking into account the common difficulties and challenges encountered in the field Arms researchers with the information necessary to avoid fundamental risks Tackles appropriate techniques for addressing disparate studies - ensuring the relevance of empirical software engineering, and showing its practical impact Describes methods that are less often used in the field, providing less conventional but still rigorous and useful ways of collecting data Supplies detailed information on topics (such as surveys) that often contain methodological errors This broad-ranging, practical guide will prove an invaluable and useful reference for practising software engineers and researchers. In addition, it will be suitable for graduate students studying empirical methods in software development. {\textcopyright}Springer-Verlag London Limited 2008.},
author = {Shull, Forrest and Singer, Janice and Sj{\o}berg, Dag I K},
doi = {10.1007/978-1-84800-044-5},
editor = {Shull, Forrest and Singer, Janice and Sj{\o}berg, Dag I K},
isbn = {978-1-84-800043-8},
month = {nov},
publisher = {Springer Science {\&} Business Media},
title = {{Guide to Advanced Empirical Software Engineering}},
year = {2008}
}
@article{Jaspers:2011hy,
abstract = {Objective: To synthesize the literature on clinical decision-support systems' (CDSS) impact on healthcare practitioner performance and patient outcomes. Design: Literature search on Medline, Embase, Inspec, Cinahl, Cochrane/Dare and analysis of high-quality systematic reviews (SRs) on CDSS in hospital settings. Two-stage inclusion procedure: (1) selection of publications on predefined inclusion criteria; (2) independent methodological assessment of preincluded SRs by the 11-item measurement tool, AMSTAR. Inclusion of SRs with AMSTAR score 9 or above. SRs were thereafter rated on level of evidence. Each stage was performed by two independent reviewers. Results: 17 out of 35 preincluded SRs were of high methodological quality and further analyzed. Evidence that CDSS significantly impacted practitioner performance was found in 52 out of 91 unique studies of the 16 SRs examining this effect (57{\%}). Only 25 out of 82 unique studies of the 16 SRs reported evidence that CDSS positively impacted patient outcomes (30{\%}). Conclusions: Few studies have found any benefits on patient outcomes, though many of these have been too small in sample size or too short in time to reveal clinically important effects. There is significant evidence that CDSS can positively impact healthcare providers' performance with drug ordering and preventive care reminder systems as most clear examples. These outcomes may be explained by the fact that these types of CDSS require a minimum of patient data that are largely available before the advice is (to be) generated: at the time clinicians make the decisions.},
author = {Jaspers, Monique W M and Smeulers, Marian and Vermeulen, Hester and Peute, Linda W},
doi = {10.1136/amiajnl-2011-000094},
issn = {1067-5027},
journal = {Journal of the American Medical Informatics Association},
number = {3},
pages = {327--334},
pmid = {21422100},
title = {{Effects of clinical decision-support systems on practitioner performance and patient outcomes: A synthesis of high-quality systematic review findings}},
volume = {18},
year = {2011}
}
@book{Boehm:1981ua,
address = {Englewood Cliffs, NJ, USA},
author = {Boehm, Barry W},
isbn = {0-13-822122-7},
publisher = {Prentice-Hall},
title = {{Software engineering economics}},
year = {1981}
}
@article{Verbeke:2011vo,
abstract = {Customer churn prediction models aim to detect customers with a high propensity to attrite. Predictive accuracy, comprehensibility, and justifiability are three key aspects of a churn prediction model. An accurate model permits to correctly target future churners in a retention marketing campaign, while a comprehensible and intuitive rule-set allows to identify the main drivers for customers to churn, and to develop an effective retention strategy in accordance with domain knowledge. This paper provides an extended overview of the literature on the use of data mining in customer churn prediction modeling. It is shown that only limited attention has been paid to the comprehensibility and the intuitiveness of churn prediction models. Therefore, two novel data mining techniques are applied to churn prediction modeling, and benchmarked to traditional rule induction techniques such as C4.5 and RIPPER. Both AntMiner+ and ALBA are shown to induce accurate as well as comprehensible classification rule-sets. AntMiner+ is a high performing data mining technique based on the principles of Ant Colony Optimization that allows to include domain knowledge by imposing monotonicity constraints on the final rule-set. ALBA on the other hand combines the high predictive accuracy of a non-linear support vector machine model with the comprehensibility of the rule-set format. The results of the benchmarking experiments show that ALBA improves learning of classification techniques, resulting in comprehensible models with increased performance. AntMiner+ results in accurate, comprehensible, but most importantly justifiable models, unlike the other modeling techniques included in this study. {\textcopyright}2010 Elsevier Ltd. All rights reserved.},
author = {Verbeke, Wouter and Martens, David and Mues, Christophe and Baesens, Bart},
doi = {10.1016/j.eswa.2010.08.023},
issn = {0957-4174},
journal = {Expert Systems with Applications},
keywords = {ALBA,Ant Colony Optimization,Churn prediction,Classification,Comprehensible rule induction,Data mining},
number = {3},
pages = {2354--2364},
title = {{Building comprehensible customer churn prediction models with advanced rule induction techniques}},
volume = {38},
year = {2011}
}
@misc{Mapillar97:online,
annote = {Accessed: 25 January 2019},
author = {{GeoSpatial World}},
month = {sep},
title = {{Mapillary and Amazon Rekognition collaborate to build a parking solution for US cities through computer vision}},
url = {http://bit.ly/36AdRmS},
year = {2018}
}
@article{braiek2018testing,
abstract = {Nowadays, we are witnessing a wide adoption of Machine learning (ML) models in many safety-critical systems, thanks to recent breakthroughs in deep learning and reinforcement learning. Many people are now interacting with systems based on ML every day, e.g., voice recognition systems used by virtual personal assistants like Amazon Alexa or Google Home. As the field of ML continues to grow, we are likely to witness transformative advances in a wide range of areas, from finance, energy, to health and transportation. Given this growing importance of ML-based systems in our daily life, it is becoming utterly important to ensure their reliability. Recently, software researchers have started adapting concepts from the software testing domain (e.g., code coverage, mutation testing, or property-based testing) to help ML engineers detect and correct faults in ML programs. This paper reviews current existing testing practices for ML programs. First, we identify and explain challenges that should be addressed when testing ML programs. Next, we report existing solutions found in the literature for testing ML programs. Finally, we identify gaps in the literature related to the testing of ML programs and make recommendations of future research directions for the scientific community. We hope that this comprehensive review of software testing practices will help ML engineers identify the right approach to improve the reliability of their ML-based systems. We also hope that the research community will act on our proposed research directions to advance the state of the art of testing for ML programs.},
archivePrefix = {arXiv},
arxivId = {1812.02257},
author = {Braiek, Houssem Ben and Khomh, Foutse},
eprint = {1812.02257},
howpublished = {$\backslash$url{\{}http://arxiv.org/abs/1812.02257{\}}},
journal = {arXiv preprint arXiv:1812.02257},
month = {dec},
title = {{On Testing Machine Learning Programs}},
year = {2018}
}
@inproceedings{Sinha:2013tt,
abstract = {Success of a Q{\&}A forum depends on volume of content (questions and answers) and quality of content (are the questions asked relevant, answers provided correct etc). Community participation is essential to create and curate content. Since their inception in 2008, stack exchange based forums have been able to engage a large number of users to create a rich repository of good quality questions and answers. In this paper, we wish to investigate the "activeness" of users in the stackexchange network particularly from a perspective of content creation. We also attempt to measure how the forums' incentive mechanism has enabled user's activeness. Further, we investigate how user's have diffused to other parts of the stack exchange network over time, hence bootstrapping new forums. {\textcopyright}2013 IEEE.},
address = {San Francisco, CA, USA},
author = {Sinha, Vibha Singhal and Mani, Senthil and Gupta, Monika},
booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
doi = {10.1109/MSR.2013.6624010},
isbn = {978-1-46-732936-1},
issn = {2160-1852},
month = {may},
pages = {77--80},
publisher = {IEEE},
title = {{Exploring activeness of users in QA forums}},
year = {2013}
}
@article{Cohen:1960tf,
abstract = {A coefficient of interjudge agreement for nominal scales, formula-omitted, is presented. It is directly interpretable as the pro-portion of joint judgments in which there is agreement, after chance agreement is excluded. Its upper limit is +1.00, and its lower limit falls between zero and -1.00, depending on the distribution of judgments by the two judges. The maximum value which x can take for any given problem is given, and the implications of this value to the question of agreement discussed. An interesting characteristic of x is its identity with 0 in the dichotomous case when the judges give the same marginal distributions. Finally, its standard error and techniques for estimation and hypothesis testing are presented. {\textcopyright}1960, Sage Publications. All rights reserved.},
author = {Cohen, Jacob},
doi = {10.1177/001316446002000104},
issn = {1552-3888},
journal = {Educational and Psychological Measurement},
number = {1},
pages = {37--46},
title = {{A Coefficient of Agreement for Nominal Scales}},
volume = {20},
year = {1960}
}
@inproceedings{Ohtake:2019vi,
abstract = {Intelligent APIs, such as Google Cloud Vision or Amazon Rekognition, are becoming evermore pervasive and easily accessible to developers to build applications. Because of the stochastic nature that machine learning entails and disparate datasets used in their training, the output from different APIs varies over time, with low reliability in some cases when compared against each other. Merging multiple unreliable API responses from multiple vendors may increase the reliability of the overall response, and thus the reliability of the intelligent end-product. We introduce a novel methodology – inspired by the proportional representation used in electoral systems – to merge outputs of different intelligent computer vision APIs provided by multiple vendors. Experiments show that our method outperforms both naive merge methods and traditional proportional representation methods by 0.015 F-measure.},
address = {Daejeon, Republic of Korea},
author = {Ohtake, Tomohiro and Cummaudo, Alex and Abdelrazek, Mohamed and Vasa, Rajesh and Grundy, John},
booktitle = {Proceedings of the 19th International Conference on Web Engineering},
doi = {10.1007/978-3-030-19274-7\_28},
isbn = {978-3-03-019273-0},
issn = {1611-3349},
keywords = {Application programming interfaces,Artificial intelligence,Data integration,Supervised learning,Web services},
month = {jun},
pages = {391--406},
publisher = {Springer},
title = {{Merging intelligent API responses using a proportional representation approach}},
year = {2019}
}
@article{Ritzer:1991ge,
abstract = {"The contributors and editor of this work are to be commended for their successful efforts in delineating many of the concerns current within education and in calling for frank debate on these issues by all interested parties. Furthermore, they have stimulated good scholarship by readily admitting to the current state of affairs being one of more questions than answers and more confusion than clarity. They thus remind us that the search for knowledge is one fraught with conflict in a public arena. "The appropriate audience for this volume is assessed to be the reader who derives satisfaction from critical thinking. It would be appropriate for graduate students in education, human services, social sciences, or theology, or any person committed to the endeavor and process of education. "The Paradigm Dialog is one of those rare books that simultaneously stretches the mind while projecting one into self-reflection. For the applied practitioner, whether teacher, counselor, or consultant, the possibility of gaining further insight into the underlying assumptions which constrain one's pedagogy or practice is highly possible upon a critical reading." -The Journal of Applied Rehabilitation Counseling Is scientific positivism, long the reigning paradigm for research in the social sciences, the "best way" to conduct social research? This is the central question examined in The Paradigm Dialog. Recently three key challengers have appeared-postpositivism, critical theory, and constructivism. All three offer researchers new methodological approaches, and all three present fundamental questions that must be addressed. Can research be conducted between paradigms? Are they equally useful in answering questions of applied research? What constitutes good, or ethical, research in each? In this volume, these and other significant questions are examined by a multidisciplinary group of leading figures in qualitative research. Not surprisingly, there is no agreement on the "best" paradigm question, but the dialog offered in this compelling volume deftly explores important issues in selecting the proper paradigm for tackling a variety of research questions. With a group of contributors that reads like a veritable who's who in qualitative research, The Paradigm Dialog is a must for anyone conducting research in the social sciences.},
author = {Ritzer, George and Guba, Egon},
doi = {10.2307/3340973},
issn = {0318-6431},
journal = {Canadian Journal of Sociology},
number = {4},
pages = {446},
title = {{The Paradigm Dialog}},
volume = {16},
year = {1991}
}
@article{Landis:1977kv,
abstract = {This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.},
author = {Landis, J Richard and Koch, Gary G},
doi = {10.2307/2529310},
issn = {0006341X},
journal = {Biometrics},
month = {mar},
number = {1},
pages = {159},
pmid = {843571},
title = {{The Measurement of Observer Agreement for Categorical Data}},
volume = {33},
year = {1977}
}
@inproceedings{Cummaudo:2019icsme,
abstract = {Recent advances in artificial intelligence (AI) and machine learning (ML), such as computer vision, are now available as intelligent services and their accessibility and simplicity is compelling. Multiple vendors now offer this technology as cloud services and developers want to leverage these advances to provide value to end-users. However, there is no firm investigation into the maintenance and evolution risks arising from use of these intelligent services; in particular, their behavioural consistency and transparency of their functionality. We evaluated the responses of three different intelligent services (specifically computer vision) over 11 months using 3 different data sets, verifying responses against the respective documentation and assessing evolution risk. We found that there are: (1) inconsistencies in how these services behave; (2) evolution risk in the responses; and (3) a lack of clear communication that documents these risks and inconsistencies. We propose a set of recommendations to both developers and intelligent service providers to inform risk and assist maintainability.},
address = {Cleveland, OH, USA},
archivePrefix = {arXiv},
arxivId = {1906.07328},
author = {Cummaudo, Alex and Vasa, Rajesh and Grundy, John and Abdelrazek, Mohamed and Cain, Andrew},
booktitle = {Proceedings of the 35th IEEE International Conference on Software Maintenance and Evolution},
doi = {10.1109/ICSME.2019.00051},
eprint = {1906.07328},
isbn = {978-1-72-813094-1},
month = {dec},
pages = {333--342},
publisher = {IEEE},
title = {{Losing Confidence in Quality: Unspoken Evolution of Computer Vision Services}},
year = {2019}
}
@book{Horch:2003uv,
author = {Horch, John W},
isbn = {978-1-58-053604-2},
pages = {286},
publisher = {Artech House},
title = {{Practical Guide To Software Quality Management}},
year = {2003}
}
@article{Huang:2005tc,
abstract = {The area under the ROC (Receiver Operating Characteristics) curve, or simply AUC, has been traditionally used in medical diagnosis since the 1970s. It has recently been proposed as an alternative single-number measure for evaluating the predictive ability of learning algorithms. However, no formal arguments were given as to why AUC should be preferred over accuracy. In this paper, we establish formal criteria for comparing two different measures for learning algorithms and we show theoretically and empirically that AUC is a better measure (defined precisely) than accuracy. We then reevaluate well-established claims in machine learning based on accuracy using AUC and obtain interesting and surprising new results. For example, it has been well-established and accepted that Naive Bayes and decision trees are very similar in predictive accuracy. We show, however, that Naive Bayes is significantly better than decision trees in AUC. The conclusions drawn in this paper may make a significant impact on machine learning and data mining applications. {\textcopyright}2005 IEEE.},
author = {Huang, Jin and Ling, Charles X},
doi = {10.1109/TKDE.2005.50},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {AUC of ROC,Accuracy,Evaluation of learning algorithms,ROC},
number = {3},
pages = {299--310},
title = {{Using AUC and accuracy in evaluating learning algorithms}},
volume = {17},
year = {2005}
}
@inproceedings{Shepperd:2018hr,
abstract = {Context: There is growing interest in establishing software engineering as an evidence-based discipline. To that end, replication is often used to gain confidence in empirical findings, as opposed to reproduction where the goal is showing the correctness, or validity of the published results. Objective: To consider what is required for a replication study to confirm the original experiment and apply this understanding in software engineering. Method: Simulation is used to demonstrate why the prediction interval for confirmation can be surprisingly wide. This analysis is applied to three recent replications. Results: It is shown that because the prediction intervals are wide, almost all replications are confirmatory, so in that sense there is no 'replication crisis', however, the contributions to knowledge are negligible. Conclusion: Replicating empirical software engineering experiments, particularly if they are under-powered or under-reported, is a waste of scientific resources. By contrast, meta-analysis is strongly advocated so that all relevant experiments are combined to estimate the population effect.},
address = {Gothenburg, Sweden},
archivePrefix = {arXiv},
arxivId = {1802.04580},
author = {Shepperd, Martin},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
doi = {10.1145/3183399.3183423},
eprint = {1802.04580},
isbn = {978-1-45-035662-6},
issn = {0270-5257},
keywords = {Software engineering,empirical study,evidence,replication},
month = {may},
pages = {73--76},
publisher = {ACM},
title = {{Replication studies considered harmful}},
year = {2018}
}
@inproceedings{Johansson:2009uo,
abstract = {Some data mining problems require predictive models to be not only accurate but also comprehensible. Comprehensibility enables human inspection and understanding of the model, making it possible to trace why individual predictions are made. Since most high-accuracy techniques produce opaque models, accuracy is, in practice, regularly sacrificed for comprehensibility. One frequently studied technique, often able to reduce this accuracy vs. comprehensibility tradeoff, is rule extraction, i.e., the activity where another, transparent, model is generated from the opaque. In this paper, it is argued that techniques producing transparent models, either directly from the dataset, or from an opaque model, could benefit from using an oracle guide. In the experiments, genetic programming is used to evolve decision trees, and a neural network ensemble is used as the oracle guide. More specifically, the datasets used by the genetic programming when evolving the decision trees, consist of several different combinations of the original training data and "oracle data", i.e., training or test data instances, together with corresponding predictions from the oracle. In total, seven different ways of combining regular training data with oracle data were evaluated, and the results, obtained on 26 UCI datasets, clearly show that the use of an oracle guide improved the performance. As a matter of fact, trees evolved using training data only had the worst test set accuracy of all setups evaluated. Furthermore, statistical tests show that two setups, both using the oracle guide, produced significantly more accurate trees, compared to the setup using training data only. {\textcopyright}2009 IEEE.},
address = {Nashville, TN, USA},
author = {Johansson, Ulf and Niklasson, Lars},
booktitle = {Proceedings of the 2009 IEEE Symposium on Computational Intelligence and Data Mining},
doi = {10.1109/CIDM.2009.4938655},
isbn = {978-1-42-442765-9},
month = {may},
pages = {238--244},
publisher = {IEEE},
title = {{Evolving decision trees using oracle guides}},
year = {2009}
}
@article{Ashby:1957db,
author = {Ashby, W Ross and Pierce, J R},
journal = {Physics Today},
month = {jul},
number = {7},
pages = {34--36},
title = {{An Introduction to Cybernetics}},
volume = {10},
year = {1957}
}
@inproceedings{Lakkaraju:2016ka,
abstract = {One of the most important obstacles to deploying predictive models is the fact that humans do not understand and trust them. Knowing which variables are important in a model's prediction and how they are combined can be very powerful in helping people understand and trust automatic decision making systems. Here we propose interpretable decision sets, a framework for building predictive models that are highly accurate, yet also highly interpretable. Decision sets are sets of independent if-then rules. Because each rule can be applied independently, decision sets are simple, concise, and easily interpretable. We formalize decision set learning through an objective function that simultaneously optimizes accuracy and interpretability of the rules. In particular, our approach learns short, accurate, and non-overlapping rules that cover the whole feature space and pay attention to small but important classes. Moreover, we prove that our objective is a nonmonotone submodular function, which we efficiently optimize to find a near-optimal set of rules. Experiments show that interpretable decision sets are as accurate at classification as state-of-the-art machine learning techniques. They are also three times smaller on average than rule-based models learned by other methods. Finally, results of a user study show that people are able to answer multiple-choice questions about the decision boundaries of interpretable decision sets and write descriptions of classes based on them faster and more accurately than with other rule-based models that were designed for interpretability. Overall, our framework provides a new approach to interpretable machine learning that balances accuracy, interpretability, and computational efficiency.},
address = {San Francisco, CA, USA},
author = {Lakkaraju, Himabindu and Bach, Stephen H and Leskovec, Jure},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/2939672.2939874},
isbn = {978-1-45-034232-2},
month = {aug},
pages = {1675--1684},
publisher = {ACM},
title = {{Interpretable decision sets: A joint framework for description and prediction}},
year = {2016}
}
@inproceedings{Pazzani:1997vp,
address = {Washington, DC, USA},
author = {Pazzani, M},
booktitle = {Proceedings of the First Federal Data Mining Conference and Exposition},
pages = {73--82},
title = {{Comprehensible knowledge discovery: gaining insight from data}},
year = {1997}
}
@article{Doderer:2006vt,
abstract = {In silico prediction of protein subcellular localization based on amino acid sequence can reveal valuable information about the protein's innate roles in the cell. Unfortunately, such prediction is made difficult because of complex protein sorting signals. Some prediction methods are based on searching for similar proteins with known localization, assuming that known homologs exist. However, it may not perform well on proteins with no known homolog. In contrast, machine learning-based approaches attempt to infer a predictive model that describes the protein sorting signals. Alas, in doing so, it does not take advantage of known homologs (if they exist) by doing a simple "table lookup". Here, we capture the best of both worlds by combining both approaches. On a dataset with 12 locations, similarity-based and machine learning independently achieve an accuracy of 83.8{\%} and 72.6{\%}, respectively. Our hybrid approach yields an improved accuracy of 85.9{\%}. We compared our method with three other methods' published results. For two of the methods, we used their published datasets for comparison. For the third we used the 12 location dataset. The Error Correcting Output Code algorithm was used to construct our predictive model. This algorithm gives attention to all the classes regardless of number of instances and led to high accuracy among each of the classes and a high prediction rate overall. We also illustrated how the machine learning classifier we use, built over a meaningful set of features can produce interpretable rules that may provide valuable insights into complex protein sorting mechanisms. {\textcopyright}2006 IOS Press. All rights reserved.},
author = {Doderer, Mark and Yoon, Kihoon and Salinas, John and Kwek, Stephen},
issn = {1386-6338},
journal = {In Silico Biology},
keywords = {Blast,Decision tree,Error correcting output code,Similarity search,Subcellular localization prediction},
number = {5},
pages = {419--433},
title = {{Protein subcellular localization prediction using a hybrid of similarity search and Error-Correcting Output Code techniques that produces interpretable results}},
volume = {6},
year = {2006}
}
@book{Sheskin:2003tx,
abstract = {Called the "bible of applied statistics," the first two editions of the Handbook of Parametric and Nonparametric Statistical Procedures were unsurpassed in accessibility, practicality, and scope. Now author David Sheskin has gone several steps further and added even more tests, more examples, and more background information-more than 200 pages of new material.The Third Edition provides unparalleled, up-to-date coverage of over 130 parametric and nonparametric statistical procedures as well as many practical and theoretical issues relevant to statistical analysis. If you need toDecide what method of analysis to useUse a particular test for the first timeDistinguish acceptable from unacceptable researchInterpret and better understand the results of pubished studiesthe Handbook of Parametric and Nonparametric Statistical Procedures will help you get the job done.},
address = {New York, NY, USA},
author = {Sheskin, David J},
doi = {10.4324/9780203489536},
publisher = {Chapman and Hall/CRC},
title = {{Handbook of Parametric and Nonparametric Statistical Procedures}},
year = {2004}
}
@inproceedings{Watson:2012uy,
abstract = {Computer technology has made amazing advances in the past few decades; however, the software documentation of today still looks strikingly similar to the software documentation used 30 years ago. If this continues into the 21st century, more and more soft-ware developers could be using 20 th-century-style documentation to solve 21 st-century problems with 21 st-century technologies. Is 20 th-century- style documentation up to the challenge? How can that be measured? This paper seeks to answer those questions by developing a heuristic to identify whether the documentation set for an application programming interface (API) contains the key elements of API reference documentation that help software developers learn an API. The resulting heuristic was tested on a collection of software documentation that was chosen to provide a diverse set of examples with which to validate the heuristic. In the course of testing the heuristic, interesting patterns in the API documentation were observed. For example, twenty-five percent of the documentation sets studied did not have any overview information, which, according to studies, is one of the most basic elements an API documentation set needs to help software developers learn to use the API. The heuristic produced by this research can be used to evaluate large sets of API documentation, track trends in API documentation, and facilitate additional research. Copyright {\textcopyright}2012 ACM.},
address = {Seattle, WA, USA},
author = {Watson, Robert},
booktitle = {Proceedings of the 30th ACM International Conference on Design of Communication},
doi = {10.1145/2379057.2379112},
isbn = {978-1-45-031497-8},
keywords = {API,API reference documentation,Application programming interface,Software documentation,Software libraries},
month = {oct},
pages = {295--302},
publisher = {ACM},
title = {{Development and application of a heuristic to assess trends in API documentation}},
year = {2012}
}
@inproceedings{LaForge:2018tm,
address = {London, England, UK},
author = {Laforge, Guillaume},
booktitle = {QCon},
howpublished = {$\backslash$url{\{}http://bit.ly/2S0xC1B{\}}},
month = {jun},
pages = {1--58},
title = {{Machine Intelligence at Google Scale}},
year = {2018}
}
@article{boyd2018just,
abstract = {Objective To compare voice-activated internet searches by smartphone (two digital assistants) with laptop ones for information and advice related to smoking cessation. Design Responses to 80 questions on a range of topics related to smoking cessation (including the FAQ from a NHS website), compared for quality. Setting Smartphone and internet searches as performed in New Zealand. Main outcome measures Ranked responses to the questions. Results Google laptop internet searches came first (or first equal) for best quality smoking cessation advice for 83{\%} (66/80) of the responses. Voiced questions to Google Assistant (“OK Google”) came first/first equal 76{\%} of the time vs Siri (Apple) at 28{\%}. Google and Google Assistant were statistically significantly better than Siri searches (odds ratio 12.4 and 8.5 respectively, p{\textless}0.0001 in each comparison). When asked FAQs from the National Health Service website, or to find information the Centers for Disease Control has made videos on, the best search results used expert sources 59{\%} (31/52) of the time, “some expertise” (eg, Wikipedia) 18{\%} of the time, but also magazines and other low quality sources 19{\%} of the time. Using all three methods failed to find relevant information 8{\%} (6/80) of the time, with Siri having the most failed responses (53{\%} of the time). Conclusion Google internet searches and Google Assistant were found to be significantly superior to the Siri digital assistant for smoking cessation information. While expert content was returned over half the time, there is still substantial room for improvement in how these software systems deliver smoking cessation advice.},
author = {Boyd, Matt and Wilson, Nick},
doi = {10.1371/journal.pone.0194811},
issn = {1932-6203},
journal = {PLoS ONE},
number = {3},
pages = {e0194811},
publisher = {Public Library of Science},
title = {{Just ask Siri? A pilot study comparing smartphone digital assistants and laptop Google searches for smoking cessation advice}},
volume = {13},
year = {2018}
}
@inproceedings{Boz:2002uv,
abstract = {Neural Networks are successful in acquiring hidden knowledge in datasets. Their biggest weakness is that the knowledge they acquire is represented in a form not understandable to humans. Researchers tried to address this problem by extracting rules from trained Neural Networks. Most of the proposed rule extraction methods required specialized type of Neural Networks; some required binary inputs and some were computationally expensive. Craven proposed extracting MofN type Decision Trees from Neural Networks. We believe MofN type Decision Trees are only good for MofN type problems and trees created for regular high dimensional real world problems may be very complex. In this paper, we introduced a new method for extracting regular C4.5 like Decision Trees from trained Neural Networks. We showed that the new method (DecText) is effective in extracting high fidelity trees from trained networks. We also introduced a new discretization technique to make DecText be able to handle continuous features and a new pruning technique for finding simplest tree with the highest fidelity.},
address = {Edmonton, AB, Canada},
author = {Boz, Olcay},
booktitle = {Proceedings of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/775107.775113},
month = {jul},
pages = {456--461},
publisher = {ACM},
title = {{Extracting decision trees from trained neural networks}},
year = {2002}
}
@misc{InternationalOrganizationforStandardization1986,
author = {{International Organization for Standardization}},
title = {{ISO 8402:1986 Information Technology - Software Product Evaluation - Quality Characteristics and Guidelines for Their Use}},
url = {http://bit.ly/37SK4HP},
year = {1986}
}
@article{McHugh:2012up,
abstract = {The kappa statistic is frequently used to test interrater reliability. The importance of rater reliability lies in the fact that it represents the extent to which the data collected in the study are correct representations of the variables measured. Measurement of the extent to which data collectors (raters) assign the same score to the same variable is called interrater reliability. While there have been a variety of methods to measure interrater reliability, traditionally it was measured as percent agreement, calculated as the number of agreement scores divided by the total number of scores. In 1960, Jacob Cohen critiqued use of percent agreement due to its inability to account for chance agreement. He introduced the Cohen's kappa, developed to account for the possibility that raters actually guess on at least some variables due to uncertainty. Like most correlation statistics, the kappa can range from -1 to +1. While the kappa is one of the most commonly used statistics to test interrater reliability, it has limitations. Judgments about what level of kappa should be acceptable for health research are questioned. Cohen's suggested interpretation may be too lenient for health related studies because it implies that a score as low as 0.41 might be acceptable. Kappa and percent agreement are compared, and levels for both kappa and percent agreement that should be demanded in healthcare studies are suggested.},
author = {McHugh, Mary L},
doi = {10.11613/bm.2012.031},
issn = {1330-0962},
journal = {Biochemia Medica},
keywords = {Interrater,Kappa,Rater,Reliability},
number = {3},
pages = {276--282},
pmid = {23092060},
title = {{Interrater reliability: The kappa statistic}},
volume = {22},
year = {2012}
}
@inproceedings{Brandt:2009tm,
abstract = {This paper investigates the role of online resources in problem solving. We look specifically at how programmers-an exemplar form of knowledge workers-opportunistically interleave Web foraging, learning, and writing code. We describe two studies of how programmers use online resources. The first, conductcd in the lab. observed participants' Web u*e while building an online chat room. We found that programmers leverage online resources with a range of intentions: They engage in just-in-time learning of new skills and approaches, clarify and extend their existing knowledge, and remind themselves of details deemed not worth remembering. The results also suggest that queries for different purposes have different styles and durations. Do programmers' queries "in the wild" have the same range of intentions, or is this result an artifact of the particular lab setting? We analyzed a month of queries to an online programming portal, examining the lexical structure, refinements made, and result pages visited. Here we also saw traits that suggest the Web is being used for learning and reminding. These results contribute to a theory of online resource usage in programming, and suggest opportunities for tools to facilitate online knowledge work. Copyright 2009 ACM.},
address = {Boston, MA, USA},
author = {Brandt, Joel and Guo, Philip J and Lewenstein, Joel and Dontcheva, Mira and Klemmer, Scott R},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing System},
doi = {10.1145/1518701.1518944},
isbn = {978-1-60-558247-4},
keywords = {Copy-and-paste,Opportunistic programming,Prototyping},
month = {apr},
pages = {1589--1598},
publisher = {ACM},
title = {{Two studies of opportunistic programming: Interleaving web foraging, learning, and writing code}},
year = {2009}
}
@inproceedings{Beyer:2018fm,
abstract = {Software developers frequently solve development issues with the help of question and answer web forums, such as Stack Overflow (SO). While tags exist to support question searching and browsing, they are more related to technological aspects than to the question purposes. Tagging questions with their purpose can add a new dimension to the investigation of topics discussed in posts on SO. In this paper, we aim to automate such a classification of SO posts into seven question categories. As a first step, we have manually created a curated data set of 500 SO posts, classified into the seven categories. Using this data set, we apply machine learning algorithms (Random Forest and Support Vector Machines) to build a classification model for SO questions. We then experiment with 82 different configurations regarding the preprocessing of the text and representation of the input data. The results of the best performing models show that our models can classify posts into the correct question category with an average precision and recall of 0.88 and 0.87 when using Random Forest and the phrases indicating a question category as input data for the training. The obtained model can be used to aid developers in browsing SO discussions or researchers in building recommenders based on SO.},
address = {Gothenburg, Sweden},
author = {Beyer, Stefanie and MacHo, Christian and Pinzger, Martin and {Di Penta}, Massimiliano},
booktitle = {Proceedings of the 26th International Conference on Program Comprehension},
doi = {10.1145/3196321.3196333},
isbn = {978-1-45-035714-2},
issn = {0270-5257},
month = {may},
pages = {211--221},
publisher = {ACM},
title = {{Automatically classifying posts into question categories on stack overflow}},
year = {2018}
}
@article{WordNetMiller1995,
abstract = {This database links English nouns, verbs, adjectives, and adverbs to sets of synonyms that are in turn linked through semantic relations that determine word definitions. {\textcopyright}1995, ACM. All rights reserved.},
address = {New York, NY, USA},
author = {Miller, George A},
doi = {10.1145/219717.219748},
issn = {1557-7317},
journal = {Communications of the ACM},
month = {nov},
number = {11},
pages = {39--41},
publisher = {ACM},
title = {{WordNet: A Lexical Database for English}},
volume = {38},
year = {1995}
}
@article{Aghajani:2018et,
abstract = {The concept of monolithic stand-Alone software systems developed completely from scratch has become obsolete, as modern systems nowadays leverage the abundant presence of Application Programming Interfaces (APIs) developed by third parties, which leads on the one hand to accelerated development, but on the other hand introduces potentially fragile dependencies on external resources. In this context, the design of any API strongly influences how developers write code utilizing it. A wrong design decision like a poorly chosen method name can lead to a steeper learning curve, due to misunderstandings, misuse and eventually bug-prone code in the client projects using the API. It is not unfrequent to find APIs with poorly expressive or misleading names, possibly lacking appropriate documentation. Such issues can manifest in what have been defined in the literature as Linguistic Antipatterns (LAs), i.e., inconsistencies among the naming, documentation, and implementation of a code entity. While previous studies showed the relevance of LAs for software developers, their impact on (developers of) client projects using APIs affected by LAs has not been investigated. This paper fills this gap by presenting a large-scale study conducted on 1.6k releases of popular Maven libraries, 14k open-source Java projects using these libraries, and 4.4k questions related to the investigated APIs asked on Stack Overflow. In particular, we investigate whether developers of client projects have higher chances of introducing bugs when using APIs affected by LAs and if these trigger more questions on Stack Overflow as compared to non-Affected APIs.},
address = {Madrid, Spain},
author = {Aghajani, Emad and Nagy, Csaba and Bavota, Gabriele and Lanza, Michele},
doi = {10.1109/ICSME.2018.00012},
isbn = {978-1-53-867870-1},
journal = {Proceedings of the 34th International Conference on Software Maintenance and Evolution},
keywords = {Application Programming Interfaces (APIs),Empirical Study,Linguistic Antipatterns},
month = {sep},
pages = {25--35},
publisher = {IEEE},
title = {{A Large-scale empirical study on linguistic antipatterns affecting apis}},
year = {2018}
}
@inproceedings{Cummaudo:2020icse,
address = {Seoul, Republic of Korea},
author = {Cummaudo, Alex and Vasa, Rajesh and Barnett, Scott and Grundy, John and Abdelrazek, Mohamed},
booktitle = {Proceedings of the 42nd International Conference on Software Engineering},
keywords = {InPress},
mendeley-tags = {InPress},
month = {may},
publisher = {IEEE},
title = {{Interpreting Cloud Computer Vision Pain-Points: A Mining Study of Stack Overflow}},
year = {2020}
}
@inproceedings{Allahyari:2011ud,
abstract = {This paper reviews methods for evaluating and analyzing the understandability of classification models in the context of data mining. The motivation for this study is the fact that the majority of previous work on evaluation and optimization of classification models has focused on assessing or increasing the accuracy of the models and thus user-oriented properties such as comprehensibility and understandability have been largely overlooked. We conduct a quantitative survey to examine the concept of understandability from the user's point of view. The survey results are analyzed using the analytic hierarchy process (AHP) to rank models according to their understandability. The results indicate that decision tree models are perceived as more understandable than rule-based models. Using the survey results regarding understandability of a number of models in conjunction with quantitative measurements of the complexity of the models, we are able to establish a negative correlation between the complexity and understandability of the classification models, at least for one of the two studied data sets. ?? 2011 The authors and IOS Press. All rights reserved.},
address = {Trondheim, Norway},
author = {Allahyari, Hiva and Lavesson, Niklas},
booktitle = {Proceedings of the 11th Scandinavian Conference on Artificial Intelligence},
doi = {10.3233/978-1-60750-754-3-11},
isbn = {978-1-60-750753-6},
issn = {0922-6389},
keywords = {Classification,evaluation,understandability},
month = {may},
pages = {11--19},
publisher = {IOS Press},
title = {{User-oriented assessment of classification model understandability}},
volume = {227},
year = {2011}
}
@inproceedings{Sen:1995uk,
address = {Montreal, QC, Canada},
author = {Sen, Sandip and Knight, Leslie},
booktitle = {Proceedings of the International Joint Conference on Artificial Intelligence},
month = {aug},
pages = {725--733},
publisher = {Morgan Kaufmann},
title = {{A genetic prototype learner}},
year = {1995}
}
@article{Krizhevsky:2012wl,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%}, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used nonsaturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
doi = {10.1145/3065386},
issn = {1557-7317},
journal = {Communications of the ACM},
number = {6},
pages = {84--90},
title = {{ImageNet classification with deep convolutional neural networks}},
volume = {60},
year = {2017}
}
@article{Wohlin:2014jq,
abstract = {Several factors make empirical research in software engineering particularly challenging as it requires studying not only technology but its stakeholders' activities while drawing concepts and theories from social science. Researchers, in general, agree that selecting a research design in empirical software engineering research is challenging, because the implications of using individual research methods are not well recorded. The main objective of this article is to make researchers aware and support them in their research design, by providing a foundation of knowledge about empirical software engineering research decisions, in order to ensure that researchers make well-founded and informed decisions about their research designs. This article provides a decision-making structure containing a number of decision points, each one of them representing a specific aspect on empirical software engineering research. The article provides an introduction to each decision point and its constituents, as well as to the relationships between the different parts in the decision-making structure. The intention is the structure should act as a starting point for the research design before going into the details of the research design chosen. The article provides an in-depth discussion of decision points in relation to the research design when conducting empirical research.},
author = {Wohlin, Claes and Aurum, Ayb{\"{u}}ke},
doi = {10.1007/s10664-014-9319-7},
issn = {1573-7616},
journal = {Empirical Software Engineering},
keywords = {Empirical software engineering research,Research design,Research methods,Selecting research method},
month = {may},
number = {6},
pages = {1427--1455},
title = {{Towards a decision-making structure for selecting a research design in empirical software engineering}},
volume = {20},
year = {2015}
}
@proceedings{Bai:2007tl,
abstract = {A key issue with Web Services (WS) is the verification and validation (V{\&}V) of services to build trust between service providers and service users. This paper proposed a test-broker architecture so that all stakeholder within WS can contribute to improve the testing of the services. The test broker supports the submission, indexing, and querying of test artifacts such as test cases, defect reports and evaluations. It can also provide the services for the test generation, test coordination, and distributed testing services. The DCV{\&}V (Decentralized, Collaborative, Verification and Validation) framework is proposed with a set of distributed and collaborated test brokers dedicated to different V{\&}V tasks to enable scalable and flexible test collaborations. The paper explores the concept of design-by-contract and applies the principle to DCV{\&}V. It identifies two categories of testing contracts including TSC (Testing Service Contracts) and TCC (Test Collaboration Contracts). It illustrates the application of TSC with contract-based test generation based on WS OWL-S specification. It elaborates TCC with the analysis of the test artifacts definitions. {\textcopyright}Springer-Verlag Berlin Heidelberg 2007.},
address = {Medford, MA, USA},
author = {Bai, Xiaoying and Wang, Yongbo and Dai, Guilan and Tsai, Wei Tek and Chen, Yinong},
booktitle = {Proceedings of the 10th International Symposium of Component-Based Software Engineering},
doi = {10.1007/978-3-540-73551-9_18},
editor = {Schmidt, Heinz W and Crnkovic, Ivica and Heineman, George T and Stafford, Judith A},
isbn = {978-3-54-073550-2},
issn = {0302-9743},
keywords = {Contract-based,Verification and validation,Web services},
month = {jul},
pages = {258--273},
publisher = {Springer},
title = {{A framework for contract-based collaborative verification and validation of Web services}},
year = {2007}
}
@misc{FileShad33:online,
annote = {Accessed: 25 January 2019},
author = {BusinessWire},
month = {jul},
title = {{FileShadow Delivers Machine Learning to End Users with Google Vision API | Business Wire}},
url = {https://bwnews.pr/2O5qv78},
year = {2018}
}
@article{Stevens:2013vf,
address = {San Francisco, CA, USA},
author = {Stevens, Ryan and Ganz, Jonathan and Filkov, Vladimir and Devanbu, Premkumar and Chen, Hao},
isbn = {978-1-46-732936-1},
journal = {Proceedings of the 10th Working Conference on Mining Software Repositories},
month = {may},
pages = {31--40},
publisher = {IEEE},
title = {{Asking for (and about) permissions used by Android apps}},
year = {2013}
}
@inproceedings{Garg:2011gw,
abstract = {With the growth of Cloud Computing, more and more companies are offering different cloud services. From the customer's point of view, it is always difficult to decide whose services they should use, based on users' requirements. Currently there is no software framework which can automatically index cloud providers based on their needs. In this work, we propose a framework and a mechanism, which measure the quality and prioritize Cloud services. Such framework can make significant impact and will create healthy competition among Cloud providers to satisfy their Service Level Agreement (SLA) and improve their Quality of Services (QoS). {\textcopyright}2011 IEEE.},
address = {Melbourne, Australia},
author = {Garg, Saurabh Kumar and Versteeg, Steve and Buyya, Rajkumar},
booktitle = {Proceedings of the 4th IEEE International Conference on Utility and Cloud Computing},
doi = {10.1109/UCC.2011.36},
isbn = {978-0-76-954592-9},
keywords = {Cloud Computing,Quality of Service,Service Measurement},
month = {dec},
pages = {210--218},
publisher = {IEEE},
title = {{SMICloud: A framework for comparing and ranking cloud services}},
year = {2011}
}
@inproceedings{Abadi:2016vn,
abstract = {TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. TensorFlow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous "parameter server" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with particularly strong support for training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model in contrast to existing systems, and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.},
address = {Savannah, GA, USA},
archivePrefix = {arXiv},
arxivId = {1605.08695},
author = {Abadi, Mart{\'{i}}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
booktitle = {Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation},
eprint = {1605.08695},
isbn = {978-1-93-197133-1},
pages = {265--283},
publisher = {ACM},
title = {{TensorFlow: A system for large-scale machine learning}},
year = {2016}
}
@article{Klein:1999uv,
abstract = {This article discusses the conduct and evaluation of interpretive research in information systems. While the conventions for evaluating information systems case studies conducted according to the natural science model of social science are now widely accepted, this is not the case for interpretive field studies. A set of principles for the conduct and evaluation of interpretive field research in information systems is proposed, along with their philosophical rationale. The usefulness of the principles is illustrated by evaluating three published interpretive field studies drawn from the IS research literature. The intention of the paper is to further reflection and debate on the important subject of grounding interpretive research methodology.},
author = {Klein, Heinz K and Myers, Michael D},
doi = {10.2307/249410},
issn = {0276-7783},
journal = {MIS Quarterly: Management Information Systems},
keywords = {Case study,Critical perspective,Ethnography,Field study,Hermeneutics,IS research methodologies,Interpretivist perspective},
number = {1},
pages = {67--94},
title = {{A set of principles for conducting and evaluating interpretive field studies in information systems}},
volume = {23},
year = {1999}
}
@article{Wettschereck:1997vw,
abstract = {Many lazy learning algorithms are derivatives of the k-nearest neighbor (k-NN) classifier, which uses a distance function to generate predictions from stored instances. Several studies have shown that k-NN's performance is highly sensitive to the definition of its distance function. Many k-NN variants have been proposed to reduce this sensitivity by parameterizing the distance function with feature weights. However, these variants have not been categorized nor empirically compared. This paper reviews a class of weight-setting methods for lazy learning algorithms. We introduce a framework for distinguishing these methods and empirically compare them. We observed four trends from our experiments and conducted further studies to highlight them. Our results suggest that methods which use performance feedback to assign weight settings demonstrated three advantages over other methods: they require less pre-processing, perform better in the presence of interacting features, and generally require less training data to learn good settings. We also found that continuous weighting methods tend to outperform feature selection algorithms for tasks where some features are useful but less important than others.},
author = {Wettschereck, Dietrich and Aha, David W and Mohri, Takao},
doi = {10.1007/978-94-017-2053-3_11},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
keywords = {Comparison,Feature weights,Lazy learning,k-nearest neighbor},
number = {1-5},
pages = {273--314},
title = {{A Review and Empirical Evaluation of Feature Weighting Methods for a Class of Lazy Learning Algorithms}},
volume = {11},
year = {1997}
}
@inproceedings{Kavaler:2013uh,
abstract = {Programming is knowledge intensive. While it is well understood that programmers spend lots of time looking for information, with few exceptions, there is a significant lack of data on what information they seek, and why. Modern platforms, like Android, comprise complex APIs that often perplex programmers. We ask: which elements are confusing, and why? Increasingly, when programmers need answers, they turn to StackOverflow. This provides a novel opportunity. There are a vast number of applications for Android devices, which can be readily analyzed, and many traces of interactions on StackOverflow. These provide a complementary perspective on using and asking, and allow the two phenomena to be studied together. How does the market demand for the USE of an API drive the market for knowledge about it? Here, we analyze data from Android applications and StackOverflow together, to find out what it is that programmers want to know and why. {\textcopyright}2013 Springer International Publishing.},
address = {Kyoto, Japan},
author = {Kavaler, David and Posnett, Daryl and Gibler, Clint and Chen, Hao and Devanbu, Premkumar and Filkov, Vladimir},
booktitle = {Proceedings of the 5th International Conference on Social Infomatics},
doi = {10.1007/978-3-319-03260-3_35},
editor = {Jatowt, Adam and Lim, Ee-Peng and Ding, Ying and Miura, Asako and Tezuka, Taro and Dias, Ga{\"{e}}l and Tanaka, Katsumi and Flanagin, Andrew and Dai, Bing Tian},
isbn = {978-3-31-903259-7},
issn = {0302-9743},
month = {nov},
pages = {405--418},
publisher = {Springer},
title = {{Using and asking: APIs used in the Android market and asked about in StackOverflow}},
year = {2013}
}
@inproceedings{LinaresVasquez:2014vj,
abstract = {The growing number of questions related to mobile development in StackOverow highlights an increasing interest of software developers in mobile programming. For the Android platform, 213,836 questions were tagged with Android-related labels in StackOverow between July 2008 and August 2012. This paper aims at investigating how changes occurring to Android APIs trigger questions and activity in StackOverflow, and whether this is particularly true for certain kinds of changes. Our findings suggest that Android developers usually have more questions when the behavior of APIs is modified. In addition, deleting public methods from APIs is a trigger for questions that are (i) more discussed and of major interest for the community, and (ii) posted by more experienced developers. In general, results of this paper provide important insights about the use of social media to learn about changes in software ecosystems, and establish solid foundations for building new recommenders for notifying developers/managers about important changes and recommending them relevant crowdsourced solutions.},
address = {Hyderabad, India},
author = {Linares-V{\'{a}}squez, Mario and Bavota, Gabriele and {Di Penta}, Massimiliano and Oliveto, Rocco and Poshyvanyk, Denys},
booktitle = {Proceedings of the 22nd International Conference on Program Comprehension},
doi = {10.1145/2597008.2597155},
isbn = {978-1-45-032879-1},
keywords = {API Changes,Android,Social Media,StackOverflow},
month = {jun},
pages = {83--94},
publisher = {ACM},
title = {{How do API changes trigger stack overflow discussions? A study on the android SDK}},
year = {2014}
}
@article{Michie:1994wi,
abstract = {Statistical, machine learning and neural network approaches to classification are all covered in this volume. Contributions have been integrated to provide an objective assessment of the potential for machine learning algorithms in solving significant commercial and industrial problems, widening the foundation for exploitation of these and related algorithms.},
author = {{F. Elder} and Michie, Donald and Spiegelhalter, David J and Taylor, Charles C},
doi = {10.2307/2291432},
isbn = {978-0-13-106360-0},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
number = {433},
pages = {436--438},
title = {{Machine Learning, Neural, and Statistical Classification.}},
volume = {91},
year = {1996}
}
@article{THOMAS2014457,
abstract = {Topic models are generative probabilistic models which have been applied to information retrieval to automatically organize and provide structure to a text corpus. Topic models discover topics in the corpus, which represent real world concepts by frequently co-occurring words. Recently, researchers found topics to be effective tools for structuring various software artifacts, such as source code, requirements documents, and bug reports. This research also hypothesized that using topics to describe the evolution of software repositories could be useful for maintenance and understanding tasks. However, research has yet to determine whether these automatically discovered topic evolutions describe the evolution of source code in a way that is relevant or meaningful to project stakeholders, and thus it is not clear whether topic models are a suitable tool for this task. In this paper, we take a first step towards evaluating topic models in the analysis of software evolution by performing a detailed manual analysis on the source code histories of two well-known and well-documented systems, JHotDraw and jEdit. We define and compute various metrics on the discovered topic evolutions and manually investigate how and why the metrics evolve over time. We find that the large majority (87{\%}-89{\%}) of topic evolutions correspond well with actual code change activities by developers. We are thus encouraged to use topic models as tools for studying the evolution of a software system. {\textcopyright}2012 Elsevier B.V. All rights reserved.},
author = {Thomas, Stephen W and Adams, Bram and Hassan, Ahmed E and Blostein, Dorothea},
doi = {10.1016/j.scico.2012.08.003},
issn = {0167-6423},
journal = {Science of Computer Programming},
keywords = {Latent Dirichlet allocation,Mining software repositories,Software evolution,Topic model},
number = {PART B},
pages = {457--479},
title = {{Studying software evolution using topic models}},
volume = {80},
year = {2014}
}
@book{Grunwald:2007vg,
abstract = {A recent study of ovariectomized monkeys, treated with recombinant human parathyroid hormone (rhPTH)(1-34) at 1 or 5 mg/kg/day for 18 months or for 12 months followed by 6 months withdrawal from treatment, showed significant differences in the geometry and histomorphometry of cortical bone of the midshaft humerus. To determine the extent to which the rapid bone turnover and cortical porosity induced by rhPTH(1-34) in ovariectomized monkeys modified mineral content, mineral crystal maturity and collagen maturity (cross-link distribution) in the cortical periosteal and endosteal regions, cross-sections of the cortical bone of the mid-humerus, were examined using Fourier transform infrared imaging (FTIRI). FTIRI analyses demonstrated that rhPTH(1-34) altered bone mineral and collagen properties in a dose-dependent manner. Mineral crystal maturity and collagen cross-link ratio (pyridinoline/dehydro-dihydroxylysinonorleucine) on both endosteal and periosteal surfaces decreased relative to ovariectomized animals, consistent with new bone formation. These changes were partially sustained after withdrawal of the higher dose of rhPTH(1-34), suggesting a prolonged after-effect on bone properties for at least two bone remodeling cycles. In conclusion, treatment of ovariectomized monkeys with rhPTH(1-34) had significant effects on cortical bone mineral-to-matrix ratio, mineral crystal maturity, and collagen cross-link ratio. These were fully reversible when the 1-microg rhPTH(1-34) treatment was withdrawn, but only partially reversed when the 5-microg rhPTH(1-34) dose was withdrawn.},
author = {Gr{\"{u}}nwald, Peter D},
doi = {10.7551/mitpress/4643.001.0001},
publisher = {MIT press},
title = {{The Minimum Description Length Principle}},
year = {2019}
}
@book{Robbins:2014tr,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-{\$}\backslashbackslashalpha{\{}\backslash{\{}{\}}\backslashbackslash{\{}\backslash{\$}{\}}{\{}$\backslash${\}}{\}}-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA}for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
author = {Robbins, Stephen P},
edition = {14th},
isbn = {978-0-13-452470-2},
publisher = {Pearson},
title = {{Essentials of organizational behavior}},
year = {2017}
}
@inproceedings{Clark:1991vi,
abstract = {The CN2 algorithm induces an ordered list of classification rules from examples using entropy as its search heuristic. In this short paper, we describe two improvements to this algorithm. Firstly, we present the use of the Laplacian error estimate as an alternative evaluation function and secondly, we show how unordered as well as ordered rules can be generated. We experimentally demonstrate significantly improved performances resulting from these changes, thus enhancing the usefulness of CN2 as an inductive tool. Comparisons with Quinlan's C4.5 are also made.},
address = {Porto, Portugal},
author = {Clark, Peter and Boswell, Robin},
booktitle = {Proceedings of the 1991 European Working Session on Learning},
doi = {10.1007/BFb0017011},
isbn = {978-3-54-053816-5},
issn = {1611-3349},
keywords = {CN2,Laplace,Learning,Noise,Rule induction},
month = {mar},
pages = {151--163},
publisher = {Springer},
title = {{Rule induction with CN2: Some recent improvements}},
year = {1991}
}
@inproceedings{Petersen:2019ji,
abstract = {Background - Validity threats should be considered and consistently reported to judge the value of an empirical software engineering research study. The relevance of specific threats for a particular research study depends on the worldview or philosophical worldview of the researchers of the study. Problem/Gap - In software engineering, different categorizations exist, which leads to inconsistent reporting and consideration of threats. Contribution - In this paper, we relate different worldviews to software engineering research methods, identify generic categories for validity threats, and provide a categorization of validity threats with respect to their relevance for different world views. Thereafter, we provide a checklist aiding researchers in identifying relevant threats. Method - Different threat categorizations and threats have been identified in literature, and are reflected on in relation to software engineering research. Results - Software engineering is dominated by the pragmatist worldviews, and therefore use multiple methods in research. Maxwell's categorization of validity threats has been chosen as very suitable for reporting validity threats in software engineering research. Conclusion - We recommend to follow a checklist approach, and reporting first the philosophical worldview of the researcher when doing the research, the research methods and all threats relevant, including open, reduced, and mitigated threats. {\textcopyright}2013 IEEE.},
address = {Ankara, Turkey},
author = {Petersen, Kai and Gencel, Cigdem},
booktitle = {Proceedings of the Joint Conference of the 23rd International Workshop on Software Measurement and the 8th International Conference on Software Process and Product Measurement},
doi = {10.1109/IWSM-Mensura.2013.22},
isbn = {978-0-76-955078-7},
month = {oct},
pages = {81--89},
publisher = {IEEE},
title = {{Worldviews, research methods, and their relationship to validity in empirical software engineering research}},
year = {2013}
}
@misc{Finalyson:2018aa,
address = {Fredericksburg, VA, USA},
author = {Finalyson, Ian},
howpublished = {$\backslash$url{\{}http://bit.ly/319GOF9{\{}$\backslash${\%}{\}}0A{\}}},
publisher = {University of Mary Washington},
title = {{Nondeterministic Finite Automata}},
year = {2018}
}
@inproceedings{Ahasanuzzaman:2018kv,
abstract = {The design and maintenance of APIs are complex tasks due to the constantly changing requirements of its users. Despite the efforts of its designers, APIs may suffer from a number of issues (such as incomplete or erroneous documentation, poor performance, and backward incompatibility). To maintain a healthy client base, API designers must learn these issues to fix them. Question answering sites, such as Stack Overflow (SO), has become a popular place for discussing API issues. These posts about API issues are invaluable to API designers, not only because they can help to learn more about the problem but also because they can facilitate learning the requirements of API users. However, the unstructured nature of posts and the abundance of non-issue posts make the task of detecting SO posts concerning API issues difficult and challenging. In this paper, we first develop a supervised learning approach using a Conditional Random Field (CRF), a statistical modeling method, to identify API issue-related sentences. We use the above information together with different features of posts and experience of users to build a technique, called CAPS, that can classify SO posts concerning API issues. Evaluation of CAPS using carefully curated SO posts on three popular API types reveals that the technique outperforms all three baseline approaches we consider in this study. We also conduct studies to test the generalizability of CAPS results and to understand the effects of different sources of information on it.},
address = {Campobasso, Italy},
author = {Ahasanuzzaman, Md and Asaduzzaman, Muhammad and Roy, Chanchal K and Schneider, Kevin A},
booktitle = {Proceedings of the 25th International Conference on Software Analysis, Evolution and Reengineering},
doi = {10.1109/SANER.2018.8330213},
isbn = {978-1-53-864969-5},
keywords = {API Issue,Stack Overflow,feature extraction,text classification,unstructured data mining},
month = {mar},
pages = {244--254},
publisher = {IEEE},
title = {{Classifying stack overflow posts on API issues}},
volume = {2018-March},
year = {2018}
}
@misc{InternationalOrganizationforStandardization2011,
author = {{International Organization for Standardization}},
title = {{ISO/IEC 25010:2011 Systems and software engineering – Systems and software Quality Requirements and Evaluation (SQuaRE) – System and software quality models}},
url = {http://bit.ly/2S4yzGs},
year = {2011}
}
@inproceedings{Zhang:2008vfa,
abstract = {Text extraction in video documents, as an important research field of content-based information indexing and retrieval, has been developing rapidly since 1990s. This has led to much progress in text extraction, performance evaluation, and related applications. By reviewing the approaches proposed during the past five years, this paper introduces the progress made in this area and discusses promising directions for future research.},
address = {Nara, Japan},
author = {Zhang, Jing and Kasturi, Rangachar},
booktitle = {Proceedings of the 8th International Workshop on Document Analysis Systems},
doi = {10.1109/das.2008.49},
month = {sep},
pages = {5--17},
publisher = {IEEE},
title = {{Extraction of Text Objects in Video Documents: Recent Progress}},
year = {2008}
}
@book{Crosby:1979uy,
abstract = {Nontechnical in approach, this how-to manual for managers with accountability for product performance specifies ways in which quality problems can be prevented at each stage of production},
author = {Crosby, Philip B},
isbn = {978-0-07-014512-2},
publisher = {McGraw-Hill},
title = {{Quality is free: The art of making quality certain}},
year = {1979}
}
@article{Reis:2018cp,
abstract = {The visually impaired must face several well-known difficulties on their daily life. The use of technology in assistive systems can greatly improve their lives by helping with navigation and orientation, for which several approaches and technologies have been proposed. Lately, it has been introduced powerful online image processing services, based on machine learning and deep learning, promising truly cognitive assessment capacities. Google and Microsoft are two of these main players. In this work we built a device to be used by the blind in order to test the usage of the Google and Microsoft services to assist the blind. The online services were tested by researchers in a laboratory environment and by blind users on a large meeting room, familiar to them. This work reports on our findings regarding the online services effectiveness, the user interface and system latency.},
author = {Reis, Ars{\'{e}}nio and Paulino, Dennis and Filipe, Vitor and Barroso, Jo{\~{a}}o},
doi = {10.1007/978-3-319-77712-2_17},
isbn = {978-3-31-977711-5},
issn = {2194-5357},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Assistive systems,Cognitive services,Human-computer interaction,Visually impaired},
number = {12},
pages = {174--184},
title = {{Using online artificial vision services to assist the blind - An assessment of Microsoft Cognitive Services and Google Cloud Vision}},
volume = {746},
year = {2018}
}
@article{Hohman2018VisualAI,
abstract = {Deep learning has recently seen rapid development and received significant attention due to its state-of-the-art performance on previously-thought hard problems. However, because of the internal complexity and nonlinear structure of deep neural networks, the underlying decision making processes for why these models are achieving such performance are challenging and sometimes mystifying to interpret. As deep learning spreads across domains, it is of paramount importance that we equip users of deep learning with tools for understanding when a model works correctly, when it fails, and ultimately how to improve its performance. Standardized toolkits for building neural networks have helped democratize deep learning; visual analytics systems have now been developed to support model explanation, interpretation, debugging, and improvement. We present a survey of the role of visual analytics in deep learning research, which highlights its short yet impactful history and thoroughly summarizes the state-of-the-art using a human-centered interrogative framework, focusing on the Five W's and How (Why, Who, What, How, When, and Where). We conclude by highlighting research directions and open research problems. This survey helps researchers and practitioners in both visual analytics and deep learning to quickly learn key aspects of this young and rapidly growing body of research, whose impact spans a diverse range of domains.},
archivePrefix = {arXiv},
arxivId = {1801.06889},
author = {Hohman, Fred and Kahng, Minsuk and Pienta, Robert and Chau, Duen Horng},
doi = {10.1109/TVCG.2018.2843369},
eprint = {1801.06889},
issn = {1941-0506},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Deep learning,information visualization,neural networks,visual analytics},
number = {8},
pages = {2674--2693},
title = {{Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers}},
volume = {25},
year = {2019}
}
@article{Friedman:1997vs,
abstract = {Recent work in supervised learning has shown that a surprisingly simple Bayesian classifier with strong assumptions of independence among features, called naive Bayes, is competitive with state-of-the-art classifiers such as C4.5. This fact raises the question of whether a classifier with less restrictive assumptions can perform even better. In this paper we evaluate approaches for inducing classifiers from data, based on the theory of learning Bayesian networks. These networks are factored representations of probability distributions that generalize the naive Bayesian classifier and explicitly represent statements about independence. Among these approaches we single out a method we call Tree Augmented Naive Bayes (TAN), which outperforms naive Bayes, yet at the same time maintains the computational simplicity (no search involved) and robustness that characterize naive Bayes. We experimentally tested these approaches, using problems from the University of California at Irvine repository, and compared them to C4.5, naive Bayes, and wrapper methods for feature selection.},
author = {Friedman, Nir and Geiger, Dan and Goldszmidt, Moises},
doi = {10.1002/9780470400531.eorms0099},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {Bayesian networks,Classification},
number = {2-3},
pages = {131--163},
title = {{Bayesian Network Classifiers}},
volume = {29},
year = {1997}
}
@article{Singh:2016wu,
abstract = {Recent work in model-agnostic explanations of black-box machine learning has demonstrated that interpretability of complex models does not have to come at the cost of accuracy or model flexibility. However, it is not clear what kind of explanations, such as linear models, decision trees, and rule lists, are the appropriate family to consider, and different tasks and models may benefit from different kinds of explanations. Instead of picking a single family of representations, in this work we propose to use "programs" as model-agnostic explanations. We show that small programs can be expressive yet intuitive as explanations, and generalize over a number of existing interpretable families. We propose a prototype program induction method based on simulated annealing that approximates the local behavior of black-box classifiers around a specific prediction using random perturbations. Finally, we present preliminary application on small datasets and show that the generated explanations are intuitive and accurate for a number of classifiers.},
archivePrefix = {arXiv},
arxivId = {1611.07579},
author = {Singh, Sameer and Ribeiro, Marco Tulio and Guestrin, Carlos},
eprint = {1611.07579},
howpublished = {$\backslash$url{\{}http://arxiv.org/abs/1611.07579{\}}},
journal = {arXiv preprint arXiv:1611.07579},
month = {nov},
title = {{Programs as Black-Box Explanations}},
year = {2016}
}
@article{Arnold:2005vc,
author = {Arnold, Ken},
doi = {10.1145/1071713.1071731},
issn = {1542-7749},
journal = {ACM Queue},
number = {5},
pages = {54--59},
title = {{Programmers are People, Too}},
volume = {3},
year = {2005}
}
@incollection{Seaman:2007wa,
author = {Seaman, Carolyn B},
booktitle = {Guide to Advanced Empirical Software Engineering},
chapter = {2},
month = {nov},
pages = {35--62},
publisher = {Springer Science {\&} Business Media},
title = {{Qualitative methods}},
year = {2007}
}
@article{SiMergeSearchEngineResults,
abstract = {The proliferation of searchable text databases on local area networks and the Internet causes the problem of finding information that may be distributed among many disjoint text databases (distributed information retrieval). How to merge the results returned by selected databases is an important subproblem of the distributed information retrieval task. Previous research assumed that either resource providers cooperate to provide normalizing statistics or search clients down-load all retrieved documents and compute normalized scores without cooperation from resource providers. This article presents a semisupervised learning solution to the result merging problem. The key contribution is the observation that information used to create resource descriptions for resource selection can also be used to create a centralized sample database to guide the normalization of document scores returned by different databases. At retrieval time, the query is sent to the selected databases, which return database-specific document scores, and to a centralized sample database, which returns database-independent document scores. Documents that have both a database-specific score and a database-independent score serve as training data for learning to normalize the scores of other documents. An extensive set of experiments demonstrates that this method is more effective than the well-known CORI result-merging algorithm under a variety of conditions.},
address = {New York, NY, USA},
author = {Si, Luo and Callan, Jamie},
doi = {10.1145/944012.944017},
issn = {1046-8188},
journal = {ACM Transactions on Information Systems},
keywords = {Distributed information retrieval,Resource ranking,Resource selection,Results merging,Semisupervised learning method,Server selection},
month = {oct},
number = {4},
pages = {457--491},
publisher = {ACM},
title = {{A semisupervised learning method to merge search engine results}},
volume = {21},
year = {2003}
}
@article{Kitchenham:2010wy,
abstract = {Systematic literature reviews (SLRs) are a major tool for supporting evidence-based software engineering. Adapting the procedures involved in such a review to meet the needs of software engineering and its literature remains an ongoing process. As part of this process of refinement, we undertook two case studies which aimed 1) to compare the use of targeted manual searches with broad automated searches and 2) to compare different methods of reaching a consensus on quality. For Case 1, we compared a tertiary study of systematic literature reviews published between January 1, 2004 and June 30, 2007 which used a manual search of selected journals and conferences and a replication of that study based on a broad automated search. We found that broad automated searches find more studies than manual restricted searches, but they may be of poor quality. Researchers undertaking SLRs may be justified in using targeted manual searches if they intend to omit low quality papers, or they are assessing research trends in research methodologies. For Case 2, we analyzed the process used to evaluate the quality of SLRs. We conclude that if quality evaluation of primary studies is a critical component of a specific SLR, assessments should be based on three independent evaluators incorporating at least two rounds of discussion. {\textcopyright}2010 Springer Science+Business Media, LLC.},
author = {Kitchenham, Barbara A and Brereton, Pearl and Turner, Mark and Niazi, Mahmood K and Linkman, Stephen and Pretorius, Rialette and Budgen, David},
doi = {10.1007/s10664-010-9134-8},
issn = {1382-3256},
journal = {Empirical Software Engineering},
keywords = {Automated search,Broad search,Case study,Manual search,Mapping studies,Quality evaluation process,Systematic literature review,Targeted search},
number = {6},
pages = {618--653},
title = {{Refining the systematic literature review process-two participant-observer case studies}},
volume = {15},
year = {2010}
}
@article{Hallgren:2012kt,
abstract = {Many research designs require the assessment of inter-rater reliability (IRR) to demonstrate consistency among observational ratings provided by multiple coders. However, many studies use incorrect statistical procedures, fail to fully report the information necessary to interpret their results, or do not address how IRR affects the power of their subsequent analyses for hypothesis testing. This paper provides an overview of methodological issues related to the assessment of IRR with a focus on study design, selection of appropriate statistics, and the computation, interpretation, and reporting of some commonly-used IRR statistics. Computational examples include SPSS and R syntax for computing Cohen's kappa and intra-class correlations to assess IRR.},
author = {Hallgren, Kevin A},
doi = {10.20982/tqmp.08.1.p023},
issn = {1913-4126},
journal = {Tutorials in Quantitative Methods for Psychology},
month = {feb},
number = {1},
pages = {23--34},
pmid = {22833776},
title = {{Computing Inter-Rater Reliability for Observational Data: An Overview and Tutorial}},
volume = {8},
year = {2012}
}
@article{Wickham:2010hy,
abstract = {A grammar of graphics is a tool that enables us to concisely describe the components of a graphic. Such a grammar allows us to move beyond named graphics (e.g., the "scatterplot") and gain insight into the deep structure that underlies statistical graphics. This article builds on Wilkinson, Anand, and Grossman (2005), describing extensions and refinements developed while building an open source implementation of the grammar of graphics for R, ggplot2. The topics in this article include an introduction to the grammar by working through the process of creating a plot, and discussing the components that we need. The grammar is then presented formally and compared toWilkinson's grammar, highlighting the hierarchy of defaults, and the implications of embedding a graphical grammar into a programming language. The power of the grammar is illustrated with a selection of examples that explore different components and their interactions, in more detail. The article concludes by discussing some perceptual issues, and thinking about how we can build on the grammar to learn how to create graphical "poems." Supplemental materials are available online. Copyright {\textcopyright}2010 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America.},
author = {Wickham, Hadley},
doi = {10.1198/jcgs.2009.07098},
issn = {1061-8600},
journal = {Journal of Computational and Graphical Statistics},
keywords = {Grammar of graphics,Statistical graphics},
month = {jan},
number = {1},
pages = {3--28},
title = {{A Layered grammar of graphics}},
volume = {19},
year = {2010}
}
@inproceedings{Caruana:2015jk,
abstract = {In machine learning often a tradeoff must be made between accuracy and intelligibility. More accurate models such as boosted trees, random forests, and neural nets usually are not intelligible, but more intelligible models such as logistic regression, naive-Bayes, and single decision trees often have significantly worse accuracy. This tradeoff sometimes limits the accuracy of models that can be applied in mission-critical applications such as healthcare where being able to understand, validate, edit, and trust a learned model is important. We present two case studies where high-performance generalized additive models with pairwise interactions (GA2Ms) are applied to real healthcare problems yielding intelligible models with state-of-the-art accuracy. In the pneumonia risk prediction case study, the intelligible model uncovers surprising patterns in the data that previously had prevented complex learned models from being fielded in this domain, but because it is intelligible and modular allows these patterns to be recognized and removed. In the 30-day hospital readmission case study, we show that the same methods scale to large datasets containing hundreds of thousands of patients and thousands of attributes while remaining intelligible and providing accuracy comparable to the best (unintelligible) machine learning methods.},
address = {Sydney, Australia},
author = {Caruana, Rich and Lou, Yin and Gehrke, Johannes and Koch, Paul and Sturm, Marc and Elhadad, No{\'{e}}mie},
booktitle = {Proceedings of the 21st ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/2783258.2788613},
isbn = {978-1-45-033664-2},
keywords = {Additive models,Classification,Healthcare,Intelligibility,Interaction detection,Logistic regression,Risk prediction},
month = {aug},
pages = {1721--1730},
publisher = {ACM},
title = {{Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission}},
volume = {2015-Augus},
year = {2015}
}
@article{Baehrens:2010tj,
abstract = {After building a classifier with modern tools of machine learning we typically have a black box at hand that is able to predict well for unseen data. Thus, we get an answer to the question what is the most likely label of a given unseen data point. However, most methods will provide no answer why the model predicted a particular label for a single instance and what features were most influential for that particular instance. The only method that is currently able to provide such explanations are decision trees. This paper proposes a procedure which (based on a set of assumptions) allows to explain the decisions of any classification method. {\textcopyright}2010 David Baehrens, Timon Schroeter, Stefan Harmeling, Motoaki Kawanabe, Katja Hansen and Klaus-Robert M{\"{u}}ller.},
archivePrefix = {arXiv},
arxivId = {0912.1128},
author = {Baehrens, David and Schroeter, Timon and Harmeling, Stefan and Kawanabe, Motoaki and Hansen, Katja and M{\"{u}}ller, Klaus Robert},
eprint = {0912.1128},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {Ames mutagenicity,Black box model,Explaining,Kernel methods,Nonlinear},
number = {Jun},
pages = {1803--1831},
title = {{How to explain individual classification decisions}},
volume = {11},
year = {2010}
}
@inproceedings{Cummaudo:2019esem,
abstract = {Background: Good API documentation facilitates the development process, improving productivity and quality. While the topic of API documentation quality has been of interest for the last two decades, there have been few studies to map the specific constructs needed to create a good document. In effect, we still need a structured taxonomy that captures such knowledge systematically.Aims: This study reports emerging results of a systematic mapping study. We capture key conclusions from previous studies that assess API documentation quality, and synthesise the results into a single framework.Method: By conducting a systematic review of 21 key works, we have developed a five dimensional taxonomy based on 34 categorised weighted recommendations.Results: All studies utilise field study techniques to arrive at their recommendations, with seven studies employing some form of interview and questionnaire, and four conducting documentation analysis. The taxonomy we synthesise reinforces that usage description details (code snippets, tutorials, and reference documents) are generally highly weighted as helpful in API documentation, in addition to design rationale and presentation.Conclusions: We propose extensions to this study aligned to developer utility for each of the taxonomy's categories.},
address = {Porto de Galinhas, Recife, Brazil},
archivePrefix = {arXiv},
arxivId = {1907.13260},
author = {Cummaudo, Alex and Vasa, Rajesh and Grundy, John},
booktitle = {Proceedings of the 13th International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2019.8870148},
eprint = {1907.13260},
isbn = {978-1-72-812968-6},
issn = {1949-3789},
keywords = {API,DevX,documentation,systematic mapping study,taxonomy},
month = {oct},
pages = {1--6},
publisher = {IEEE},
title = {{What should I document? A preliminary systematic mapping study into API documentation knowledge}},
year = {2019}
}
@inproceedings{Garousi:2017:EGE:3084226.3084238,
abstract = {To systematically collect evidence and to structure a given area in software engineering (SE), Systematic Literature Reviews (SLR) and Systematic Mapping (SM) studies have become common. Data extraction is one of the main phases (activities) when conducting an SM or an SLR, whose objective is to extract required data from the primary studies and to accurately record the information researchers need to answer the questions of the SM/SLR study. Based on experience in a large number of SM/SLR studies, we and many other researchers have found the data extraction in SLRs to be time consuming and error-prone, thus raising the real need for heuristics and guidelines for effective and efficient data extraction in these studies, especially to be learnt by junior and young researchers. As a 'guideline' paper, this paper contributes a synthesized list of challenges usually faced during SLRs' data extraction phase and the corresponding solutions (guidelines). For our synthesis, we consider two data sources: (1) the pool of 16 SLR studies in which the authors have been involved in, as well as (2) a review of challenges and guidelines in the existing literature. Our experience in utilizing the presented guidelines in the near past have helped our junior colleagues to conduct data extractions more effectively and efficiently.},
address = {Karlskrona, Sweden},
author = {Garousi, Vahid and Felderer, Michael},
booktitle = {Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering},
doi = {10.1145/3084226.3084238},
isbn = {978-1-45-034804-1},
keywords = {Data extraction,Empirical software engineering,Research methodology,SLR,SM,Systematic literature reviews,Systematic mapping studies},
month = {jun},
pages = {170--179},
publisher = {ACM},
title = {{Experience-based guidelines for effective and efficient data extraction in systematic reviews in software engineering}},
volume = {Part F1286},
year = {2017}
}
@article{Rosen:2016uk,
abstract = {The popularity of mobile devices has been steadily growing in recent years. These devices heavily depend on software from the underlying operating systems to the applications they run. Prior research showed that mobile software is different than traditional, large software systems. However, to date most of our research has been conducted on traditional software systems. Very little work has focused on the issues that mobile developers face. Therefore, in this paper, we use data from the popular online Q{\&}A site, Stack Overflow, and analyze 13,232,821 posts to examine what mobile developers ask about. We employ Latent Dirichlet allocation-based topic models to help us summarize the mobile-related questions. Our findings show that developers are asking about app distribution, mobile APIs, data management, sensors and context, mobile tools, and user interface development. We also determine what popular mobile-related issues are the most difficult, explore platform specific issues, and investigate the types (e.g., what, how, or why) of questions mobile developers ask. Our findings help highlight the challenges facing mobile developers that require more attention from the software engineering research and development communities in the future and establish a novel approach for analyzing questions asked on Q{\&}A forums.},
author = {Rosen, Christoffer and Shihab, Emad},
doi = {10.1007/s10664-015-9379-3},
issn = {1573-7616},
journal = {Empirical Software Engineering},
keywords = {Mobile issues,Mobile software development,Stack overflow},
number = {3},
pages = {1192--1223},
title = {{What are mobile developers asking about? A large scale study using stack overflow}},
volume = {21},
year = {2016}
}
@book{Judd:1991ug,
author = {Judd, C M and Smith, E R and Kidder, L H},
editor = {Kidder, L H},
isbn = {978-0-03-031149-9},
publisher = {Holt, Rinehart, and Winston},
title = {{Research Methods in Social Relations}},
year = {1991}
}
@article{Kononenko:1993td,
abstract = {Although successful in medical diagnostic problems, inductive learning systems were not widely accepted in medical practice. In this paper two different approaches to machine learning in medical applications are compared: the system for inductive learning of decision trees Assistant, and the naive Bayesian classifier. Both methodologies were tested in four medical diagnostic problems: localization of primary tumor, prognostics of recurrence of breast cancer, diagnosis of thyroid diseases, and rheumatology. The accuracy of automatically acquired diagnostic knowledge from stored data records is compared, and the interpretation of the knowledge and the explanation ability of the classification process of each system is discussed. Surprisingly, the naive Bayesian classifier is superior to Assistant in classification accuracy and explanation ability, while the interpretation of the acquired knowledge seems to be equally valuable. In addition, two extensions to naive Bayesian classifier are briefly described: dealing with continuous attributes, and discovering the dependencies among attributes. {\textcopyright}1993 Taylor {\&} Francis Group, LLC.},
author = {Kononenko, Igor},
doi = {10.1080/08839519308949993},
issn = {1087-6545},
journal = {Applied Artificial Intelligence},
number = {4},
pages = {317--337},
title = {{Inductive and bayesian learning in medical diagnosis}},
volume = {7},
year = {1993}
}
@article{Baruch:1999vf,
abstract = {A study was conducted to explore what could and should be a reasonable response rate in academic studies. One hundred and forty-one papers which included 175 different studies were examined. They were published in the Academy of Management Journal, Human Relations, Journal of Applied Psychology, Organizational Behavior and Human Decision Processes, and Journal of International Business Studies in the years 1975, 1985, and 1995, covering about 200,000 respondents. The average response rate was 55.6 with a standard deviation of 19.7. Variations among the journals such as the year of publication and other variables were discussed. Most notable is the decline through the years (average 48.4, standard deviation of 20.1, in 1995), the lower level found in studies involving top management or organizational representatives (average 36.1, standard deviation of 13.3), and the predominance of North American studies. It is suggested that the average and standard deviation found in this stud)' should be used as a norm for future studies, bearing in mind the specific reference group. It is also recommended that a distinction is made between surveys directed at individual participants and those targeting organizational representatives.},
author = {Baruch, Yehuda},
doi = {10.1177/001872679905200401},
issn = {0018-7267},
journal = {Human Relations},
keywords = {Empirical studies,Questionnaires,Research methods,Response rate,Return rate},
number = {4},
pages = {421--438},
title = {{Response rate in academic studies - A comparative analysis}},
volume = {52},
year = {1999}
}
@article{Baesens:2003we,
abstract = {Credit scoring, decision tables, rule extraction, neural networks Abstract: Accuracy and comprehensibility are two important criteria when developing decision support systems for credit scoring. In this paper, we focus on the second criterion and propose the use of decision tables as an alternative knowledge visualisation formalism which lends itself very well to building intelligent and userfriendly credit scoring systems. Starting from a set of propositional if-then rules extracted by a neural network rule extraction algorithm, we construct decision tables and demonstrate their efficiency and user-friendliness for two real-life credit scoring cases.},
address = {Angers, France},
author = {Baesens, Bart and Mues, Christophe and {De Backer}, Manu and Vanthienen, Jan and Setiono, Rudy},
doi = {10.1007/1-4020-2673-0_15},
isbn = {9-72-988161-8},
journal = {Proceedings of the 5th International Conference on Enterprise Information Systems},
month = {apr},
pages = {19--25},
publisher = {IEEE},
title = {{Building intelligent credit scoring systems using decision tables}},
volume = {2},
year = {2003}
}
@misc{Ballinger:2014aa,
annote = {Accessed: 28 August 2018},
author = {Ballinger, Keith},
month = {dec},
title = {{Simplicity and Utility, or, Why SOAP Lost}},
url = {http://bit.ly/37vLms0},
year = {2014}
}
@inproceedings{Suri:2007wl,
abstract = {In this paper we consider the task of prototype selection whose primary goal is to reduce the storage and computational requirements of the Nearest Neighbor classifier while achieving better classification accuracies. We propose a solution to the prototype selection problem using techniques from cooperative game theory and show its efficacy experimentally. {\textcopyright}Springer-Verlag Berlin Heidelberg 2007.},
address = {Warsaw, Poland},
author = {{Rama Suri}, N and Srinivas, V S and {Narasimha Murty}, M},
booktitle = {Proceedings of the 11th European Conference on Principles and Practice of Knowledge Discovery in Databases},
doi = {10.1007/978-3-540-74976-9_58},
isbn = {978-3-54-074975-2},
issn = {0302-9743},
month = {sep},
pages = {556--564},
publisher = {Springer},
title = {{A cooperative game theoretic approach to prototype selection}},
volume = {4702 LNAI},
year = {2007}
}
