\chapter{Introduction}
\label{ch:introduction}
\graphicspath{{mainmatter/introduction/figures/}}

Abstraction layers are the application developer's productivity powerhouse as developers need not continuously consider underlying mechanics. The ubiquitous \glsx{api} enables separation of concerns and reusable component interaction; for example, complex graphics rendering and image manipulation is all achievable via a half-dozen lines of code with appropriate libraries and frameworks, for example OpenCV's \gls{api}.

\Gls{ml}, too, is being abstracted and offered behind \glspl{api}. The 2010s have shown an explosion of cloud-based services providing \textit{web} \glspl{api} typically marketed under an \gls{ai} banner. The \gls{ml} algorithms, data processing pipelines, and infrastructure bringing these techniques to life are also abstracted behind \glspl{api} calls, driven by the motivation to make it easier for developers to blend \gls{ai} into their software.
There is an explosion of interest from application developers (see \cref{fig:introduction:stackoverflow-trends}) that are investigating and exploring how best to infuse recent advances in AI into their software systems. Combined with an ever-increasing buffet of \gls{ai}-based solutions, technologies and products (see \cref{tab:introduction:ai-products}) for developers to choose from, it is evident that we are at the cusp of a new generation of `\gls{ai}-first' software.

Application developers build procedural and functional applications, where code typically evaluates deterministically to produce outcomes. Such software does not rely on probabilistic behaviour, unlike \gls{ai}-first software where, often, \gls{ml} techniques are employed. However, application developers, accustomed to such traditional software engineering paradigms, may not be aware of potential side-effects of those probabilistic techniques. Software that leverages recent advances in \gls{ai}---more specifically data-driven \gls{ml} techniques---will often have a layer of rules that wrap the \gls{ml} components.
%These rule-driven systems typically consume, utilise, and integrate libraries and frameworks, \glsacpl{ide} and other tooling, and cloud-based services such as \gls{aws} \citep{AWS:Home}.
\Gls{ai}-first software is, however, not \textit{solely} procedural-driven and combines large datasets with rules to produce outcomes. Therefore, they are both \textit{data-driven} and procedural-driven. The consequence is that large datasets---that train \gls{ml} models---combined with the algorithmic techniques behind these models result in probabilistic behaviour. Further, since these models can continually learn from \textit{new} data with time, existing probabilistic behaviour can evolve and thus regression testing techniques need to be adjusted as well for new data. 

\input{mainmatter/introduction/tables/ai-products}

\begin{figure}[t!]
\centering
\includegraphics[width=.95\linewidth]{stackoverflow-trends2}
\caption[Increasing interest in the developer community of computer vision services]{Increasing interest within the developer community for \glsplx{cvs} is shown via Stack Overflow posts. These trends of \gls{cvs} usage were measured as discussion of posts tagged with the relevant product name.\footnote{`Microsoft Cognitive Services' merges posts tagged with this name, that of `Cortana Intelligence', and `Azure Cognitive Services'.} This graph is based on data from \cref{ch:icse2020}.}
\label{fig:introduction:stackoverflow-trends}
\end{figure}


Developing \gls{ai}-infused applications requires both code \textit{and data}, and an application developer can approach developing from three perspectives, further expanded in \cref{sec:introduction:context}:
\begin{enumerate}
  \item The application developer defines an \gls{ml} model from scratch and trains it from a curated dataset. This approach is laborious in time and demands experience and knowledge of \gls{ml} methods, but the tradeoff is that they have full autonomy in the models they create.
%   The application developer uses a pre-trained ML model (e.g. YOLO or XYZ). This approach removes the time taken to collect data, design and train the ML model; the developers, still need to know where to find these models, evaluate them, and then learn the frameworks within which they operate to use them effectively.
  \item The application developer downloads a pre-trained model (e.g., YOLO \citep{8100173} for computer vision, or GPT-2 \citep{Radford2019} for natural language processing) and `plugs' it into an existing \gls{ml} framework, such as Tensorflow \citep{Abadi:2016vn} or PyTorch \citep{NIPS2019_9015}. This approach removes the time taken to collect data, design and train the \gls{ml} model; the developers, still need to know where to find these models, evaluate them, and then learn the frameworks\footnote{Thus introducing a verbose list of \gls{ml} terminology to her developer vocabulary. See a list of 328 terms provided by Google here: \url{https://developers.google.com/machine-learning/glossary/}. Last accessed 7 December 2018.} within which they operate to use them effectively.
  \item The application developer uses a cloud-based service. It is fast to integrate into their applications, and the \glspl{api} offered abstract the technical know-how behind a web call.
\end{enumerate}
While much research has investigated these first two perspectives (see \cref{ch:background}), the third is yet to be deeply explored, despite the fact that vendors are promoting new offerings encapsulated under this third perspective. As shown in \cref{tab:introduction:ai-products}, vendors are rapidly pushing out new \gls{ml}-based offerings in the form of cloud-based \glspl{api} end-points (\gls{ai} platforms), where the \gls{api} abstraction masks away the underlying mechanics of the models. Developers that use these cloud-based services are presented with documentation providing a narrative (i.e., marketing and in the documentation) that implies integration of these services are just like other cloud services. But does this implication, coupled with abstractions that hide the assumptions made by the \gls{ai}-service providers, lead to developer pain-points and miscomprehension?
If so, how can the service providers improve their documentation to alleviate this?
Do these data-driven services share similarities to the runtime behaviour of traditional cloud services?
And if not, how best can the application developer integrate the data-driven service into their a procedural-driven application to produce \gls{ai}-first software?

% A \citeyear{LoGiudice:2016wf} report by market research company Forrester captured such growth into four key areas \citep{LoGiudice:2016wf}


\input{mainmatter/introduction/tables/characteristics-of-cloud}

\begin{figure}
\centering
\includegraphics[width=0.95\linewidth]{rule-vs-data}
\caption[Differences between data- and procedural-driven cloud services]{The application developer's procedural-driven toolchain is distinct from data-driven toolchain. A developer must consume a typical, data-driven cloud service in a different way than an intelligent data-driven cloud service as they are not the same type of system.}
\label{fig:introduction:rule-vs-data}
\end{figure}

\Cref{fig:introduction:rule-vs-data} provides an illustrative overview between the context clashing of procedural-driven applications and data-driven cloud services, and we contrast characteristics of typical cloud systems and data-driven ones in \cref{tab:introduction:characteristics-of-cloud}.

\afterpage{\begin{callout}
In this thesis, we show that (i) developers do not properly understand the probabilistic data-driven machine-learnt behaviour abstracted behind the end-points, (ii) the `intelligent behaviour' is not fully contained and leaks into the applications that make use of these end-points, and finally (iii) we present how these concerns can be addressed via better documentation and software architecture. that the integration and developer comprehension of cloud services differ from the procedural-driven nature of end-applications.
% Something more precise and punchy here - e.g. intelligent component abstractions are not fully contained and they leak - developers need to be aware of these and we offer specific insights into doc, integration etc. // or We offer X, Y, Z to resolve challenges developers face when using .. Cloud based AI services
% We show how `intelligent' component abstractions are not fully contained and leak into client applications, which developers must be aware of. We offer specific insights into the documentation and integration challenges of such components, namely ways to better improve service documentation and strategies to address leakage issues.
\end{callout}}

\section{Research Context}
\label{sec:introduction:context}

There are a range of integration techniques available to developers, as reflected by Google AI's\footnote{
Google AI was recently rebranded from Google Research, further highlighting how the `\gls{ai}-first' philosophy is increasingly becoming embedded in companies' product lines and research and development teams. Spearheaded through work achieved at Google, Microsoft and Facebook, the emphasis on an \gls{ai}-first attitude we see through Google's 2018 rebranding of \textit{Google Research} to \textit{Google AI} \citep{Howard:2018tz} is evident. A further example includes how Facebook leverage \gls{ai} \textit{at scale} within their infrastructure and platforms \citep{Parekh:2017hx}.
} \textit{\glslong{ml} spectrum} \citep{Ortiz:2017wg,LaForge:2018tm,McGowen:2019vt}. This range is grouped into the three tiers aforementioned, encompassing skills, effort, users, and types of outputs of integration techniques. At one extreme, this approach involves the academic research of developing algorithms and self-sourcing data to achieve intelligence---coined as \gls{byoml} \citep{Ortiz:2017wg,McGowen:2019vt,Jimerson:2017vh}. The other extreme involves off-the-shelf, `friendlier' (abstracted) intelligence with easy-to-use \glspl{api} targeted towards applications developers. The middle-ground involves a mix of the two, with varying levels of automation to assist in development, that turns custom datasets into machine intelligence. 
We illustrate the slightly varied characteristics within this spectrum in \cref{tab:introduction:comparison-of-ml-spectrum} and \cref{fig:introduction:cv-spectrum}.

\input{mainmatter/introduction/tables/machine-learning-spectrum}
\begin{figure}[p]
\centering
\includegraphics[width=\linewidth]{cv-spectrum}
\caption[The spectrum of machine learning]{Examples within the \gls{ml} spectrum of computer vision. Colour scales indicates the benefits (green) and drawbacks (red) of each end of the spectrum.}
\label{fig:introduction:cv-spectrum}
\end{figure}

These cloud AI-services are gaining traction within developer circles: we show an increasing trend of \glslong{so} posts mentioning intelligent computer vision services in \cref{fig:introduction:stackoverflow-trends}.\footnote{Query run on 12 October 2018 using StackExchange Data Explorer. Refer to \url{https://data.stackexchange.com/stackoverflow/query/910188} for full query.}
Academia provides varied nomenclature for these services, such as \textit{Cognitive Applications} and \textit{Machine Learning Services} \citep{Hwang:2017tr} or \textit{Machine Learning as a Service} \citep{Ribeiro:2015dz}. 
For the context of this thesis, we will refer to such services under broader term of \textbf{\glspl{iws}},\footnote{This term is an extension inspired by the term `web service', as defined by the World Wide Web Consortium. See \url{https://bit.ly/2CQWJ2Z}, last accessed 19 July 2020.} and diagrammatically express their usage within \cref{fig:introduction:cloud-intelliegnce-service}.

\begin{figure}[h!]
\centering
\includegraphics[width=0.9\linewidth]{cloud-intelliegnce-service}
\caption[Overview of intelligent web services]{Overview of \glsplx{iws}.}
\label{fig:introduction:cloud-intelliegnce-service}
\end{figure}

There are many types of \glspl{iws} available to software developers, offering a range of functions, such as optical character recognition, text-to-speech and speech-to-text transcription, object categorisation, facial analysis and recognition, and natural language processing. The general workflow of using an \gls{iws} is more-or-less the same: a developer accesses an \gls{iws} component via \glsac{rest}/\glsac{soap} \gls{api}(s), which is (typically) available as a cloud-based \gls{paas}.\footnote{We note, however, that a development team may use a similar approach \textit{internally} within a product line or service that may not necessarily reflect a \gls{paas} model.}\footnote{A number of services provide the platform infrastructure to rapidly begin training from custom datasets, such as Google's AutoML (\url{https://cloud.google.com/automl/}, last accessed 7 December 2018). Others provide pre-trained datasets `ready-for-use' in production without the need to train data.} Developers send a given request to analyse a specific piece of data (e.g., an image, body of text, audio file etc.) and receive some intelligence on the data (e.g., object detection, text sentiment, transcription of audio) in addition to an associated \textit{confidence} value that represents the likelihood of that result. This is typically serialised as a \glsac{json}/\glsac{xml} response object. 

%We note the intelligence component masks its `intelligence' through a black-box: in recent years, there is a rise in providing human-level intelligence via crowdsourcing Internet marketplaces such as Amazon Mechanical Turk~\citepweb{MTurk:Home} or ScaleAPI~\citepweb{ScaleAPI:Home}. Thus, an \gls{iws} may be powered by varying degrees of intelligence: human intelligence, machine learning, data mining or intelligence by brute-force.

\begin{callout}
Within this thesis, we scope our investigation to a mature \textup{subset} of \glspl{iws} that provide computer vision intelligence~\citepweb{GoogleCloud:Home,Azure:Home,AWS:Home,Pixlab:Home,IBM:Home,Cloudsight:Home,Clarifai:Home,DeepAI:Home,Imagaa:Home,Talkwaler:Home,Kairos:Home,Cognitec:Home,Affectiva:Home}. For the context of this thesis, we will refer to such services as \textbf{\glspl{cvs}}. 
\end{callout}

\input{mainmatter/introduction/motivation}
\input{mainmatter/introduction/goals}
\input{mainmatter/introduction/structure}

