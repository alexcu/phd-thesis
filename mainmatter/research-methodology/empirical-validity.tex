\section{Empirical Validity}
\label{sec:research-methodology:empirical-validity}
\todo{Discuss empirical validity of both methods}

Threats to Validity...


%For this study, we propose running several experiments involving developers and several \glspl{cvcis}, using action-based mixed method approaches and involving documentary analysis. This study will organically evolve by observing phenomena surrounding computer vision \gls{api} internal quality, chiefly their documentation and responses. We adopt a mixed methods approach, performing both qualitative and quantitative data collection on these two key aspects by using documentary research methods for inspecting the \gls{api} documentation and structured observations to quantitatively analyse the results over time (RQs 3 and 4).
%
% Our first proposal for usability studies will survey a number of developers from various levels of seniority and experience (gathering such demographical data to assess a wider sample size) to provide insight into how these developers perceive the non-deterministic nature of computer vision \glspl{api}, asking them specific questions about their conceptual understanding of computer vision to identify any outstanding gaps in their knowledge and factor this into known literature (RQs 1 and 2).
%
%We will then conduct a structured interview with a `mock' computer vision \gls{api} to remove any developer bias toward any one particular computer vision \gls{api} that already exists and by which the developer may have already used in the past. Here, we will investigate if developers have any patterns of practice and if they conform to software engineering best practices (RQs 1, 2 and 3).
%
%From these insights, we can then develop a series of assistive recommendations that aide in improving the validation and verification of the existing computer vision \gls{api} tooling. This may involve a third party tool that helps developers evaluate which particular \gls{api} is right for their specific computer vision use case.


% Ground based on works in Guide to Empitricial SE...%
% Rexplain RQs in the context
% Discuss all methods from GtAESE and why which ones are good/bad
% 




% Get feedback on the first round of survey
% Bypass ethics on this -- find out how/where
% 

%\section{Data Collection and Ethics}
%
%\section{Approach}
%
%\section{Evaluation Methods}

%\section{Threats to Validity}
%
%\subsection{Internal Threats}
%
%\subsection{External Threats}
%
%\subsection{Construct}